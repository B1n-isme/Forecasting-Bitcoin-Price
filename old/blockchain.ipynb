{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for hash_rate...\n",
      "Fetching data for active_addresses...\n",
      "Fetching data for miner_revenue...\n",
      "                x             y         metric\n",
      "0      1416096000  2.854628e+05      hash_rate\n",
      "1      1416182400  2.992438e+05      hash_rate\n",
      "2      1416268800  2.953063e+05      hash_rate\n",
      "3      1416355200  2.744556e+05      hash_rate\n",
      "4      1416441600  2.744556e+05      hash_rate\n",
      "...           ...           ...            ...\n",
      "11170  1736726400  3.803087e+07  miner_revenue\n",
      "11171  1736812800  4.802407e+07  miner_revenue\n",
      "11172  1736899200  4.336063e+07  miner_revenue\n",
      "11173  1736985600  4.056123e+07  miner_revenue\n",
      "11174  1737072000  4.908850e+07  miner_revenue\n",
      "\n",
      "[11175 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Define API base URL and endpoints\n",
    "BASE_URL = 'https://api.blockchain.info/charts/'\n",
    "ENDPOINTS = {\n",
    "    'hash_rate': 'hash-rate',\n",
    "    'active_addresses': 'n-unique-addresses',\n",
    "    'miner_revenue': 'miners-revenue'\n",
    "}\n",
    "\n",
    "# Function to generate date ranges for 1-year intervals starting from 2014-11-15\n",
    "def generate_intervals(start_date):\n",
    "    today = datetime.date.today()\n",
    "    intervals = []\n",
    "\n",
    "    while start_date <= today:  # Ensure the loop includes all days up to today\n",
    "        end_date = min(start_date + datetime.timedelta(days=364), today)  # One year (adjusted for leap years)\n",
    "        intervals.append((start_date, end_date))\n",
    "        start_date = end_date + datetime.timedelta(days=1)  # Move to the next day after the interval\n",
    "\n",
    "    return intervals\n",
    "\n",
    "# Function to fetch data from the API for a specific timespan\n",
    "def fetch_data(metric, start_date, end_date):\n",
    "    url = f\"{BASE_URL}{metric}\"\n",
    "    params = {\n",
    "        'start': start_date.isoformat(),\n",
    "        'end': end_date.isoformat(),\n",
    "        'format': 'json'\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get('values', [])\n",
    "    else:\n",
    "        print(f\"Failed to fetch data for {metric} from {start_date} to {end_date}.\")\n",
    "        return []\n",
    "\n",
    "# Fetch data for all metrics and intervals\n",
    "def fetch_all_metrics(start_date):\n",
    "    intervals = generate_intervals(start_date)\n",
    "    all_data = {metric: [] for metric in ENDPOINTS.keys()}\n",
    "\n",
    "    for metric, endpoint in ENDPOINTS.items():\n",
    "        print(f\"Fetching data for {metric}...\")\n",
    "        for start_date, end_date in intervals:\n",
    "            data = fetch_data(endpoint, start_date, end_date)\n",
    "            all_data[metric].extend(data)\n",
    "\n",
    "    return all_data\n",
    "\n",
    "# Combine data into a single DataFrame for analysis\n",
    "def combine_data(all_data):\n",
    "    combined_df = pd.DataFrame()\n",
    "    for metric, data in all_data.items():\n",
    "        metric_df = pd.DataFrame(data)\n",
    "        metric_df['metric'] = metric\n",
    "        combined_df = pd.concat([combined_df, metric_df], ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    START_DATE = datetime.date(2014, 11, 16)  # Start date\n",
    "\n",
    "    # Fetch data\n",
    "    all_data = fetch_all_metrics(START_DATE)\n",
    "\n",
    "    # Combine and save data\n",
    "    combined_df = combine_data(all_data)\n",
    "    # combined_df.to_csv(\"../data/raw/blockchain_metrics.csv\", index=False)\n",
    "    # print(\"Data saved to blockchain_metrics.csv\")\n",
    "    print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1416096000</td>\n",
       "      <td>2.854628e+05</td>\n",
       "      <td>hash_rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1416182400</td>\n",
       "      <td>2.992438e+05</td>\n",
       "      <td>hash_rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1416268800</td>\n",
       "      <td>2.953063e+05</td>\n",
       "      <td>hash_rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1416355200</td>\n",
       "      <td>2.744556e+05</td>\n",
       "      <td>hash_rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1416441600</td>\n",
       "      <td>2.744556e+05</td>\n",
       "      <td>hash_rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11170</th>\n",
       "      <td>1736726400</td>\n",
       "      <td>3.803087e+07</td>\n",
       "      <td>miner_revenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11171</th>\n",
       "      <td>1736812800</td>\n",
       "      <td>4.802407e+07</td>\n",
       "      <td>miner_revenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11172</th>\n",
       "      <td>1736899200</td>\n",
       "      <td>4.336063e+07</td>\n",
       "      <td>miner_revenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11173</th>\n",
       "      <td>1736985600</td>\n",
       "      <td>4.056123e+07</td>\n",
       "      <td>miner_revenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11174</th>\n",
       "      <td>1737072000</td>\n",
       "      <td>4.908850e+07</td>\n",
       "      <td>miner_revenue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11175 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                x             y         metric\n",
       "0      1416096000  2.854628e+05      hash_rate\n",
       "1      1416182400  2.992438e+05      hash_rate\n",
       "2      1416268800  2.953063e+05      hash_rate\n",
       "3      1416355200  2.744556e+05      hash_rate\n",
       "4      1416441600  2.744556e+05      hash_rate\n",
       "...           ...           ...            ...\n",
       "11170  1736726400  3.803087e+07  miner_revenue\n",
       "11171  1736812800  4.802407e+07  miner_revenue\n",
       "11172  1736899200  4.336063e+07  miner_revenue\n",
       "11173  1736985600  4.056123e+07  miner_revenue\n",
       "11174  1737072000  4.908850e+07  miner_revenue\n",
       "\n",
       "[11175 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully modified and saved to data/blockchain_metrics_updated.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"../data/raw/blockchain_metrics.csv\")\n",
    "\n",
    "# Convert 'x' from Unix timestamp to datetime in the desired format\n",
    "df['x'] = pd.to_datetime(df['x'], unit='s', utc=True)\n",
    "\n",
    "# Find the earliest date to calculate \"days since the first record\"\n",
    "start_date = df['x'].min()\n",
    "df['days_since_start'] = (df['x'] - start_date).dt.days\n",
    "\n",
    "# Preserve the original datetime in a separate column for clarity\n",
    "df['date'] = df['x']  # Copy of the formatted datetime column\n",
    "\n",
    "# Generate a complete range of 'days_since_start' (0 to max days)\n",
    "all_days = pd.DataFrame({'days_since_start': range(df['days_since_start'].max() + 1)})\n",
    "\n",
    "# Handle duplicates by aggregating (e.g., take the mean for duplicate combinations)\n",
    "df = df.groupby(['days_since_start', 'metric'], as_index=False).agg({'y': 'mean', 'date': 'first'})\n",
    "\n",
    "# Pivot the dataset to spread metrics into separate columns\n",
    "pivot_df = df.pivot(index='days_since_start', columns='metric', values='y').reset_index()\n",
    "\n",
    "# Merge with all_days to ensure no missing days\n",
    "pivot_df = all_days.merge(pivot_df, on='days_since_start', how='left')\n",
    "\n",
    "# Add the original datetime (formatted) back to the pivoted DataFrame\n",
    "pivot_df['date'] = start_date + pd.to_timedelta(pivot_df['days_since_start'], unit='d')\n",
    "\n",
    "# Optional: Rename columns for clarity\n",
    "pivot_df.rename(columns={'days_since_start': 'days', \n",
    "                         'hash_rate': 'Hash Rate', \n",
    "                         'active_addresses': 'Active Addresses', \n",
    "                         'miner_revenue': 'Miner Revenue'}, inplace=True)\n",
    "\n",
    "# Drop the first \"days\" column\n",
    "pivot_df.drop(columns=['days'], inplace=True)\n",
    "\n",
    "# Reorder the columns to make \"date\" the first column\n",
    "columns = ['date'] + [col for col in pivot_df.columns if col != 'date']\n",
    "pivot_df = pivot_df[columns]\n",
    "\n",
    "# Save the modified dataset\n",
    "pivot_df.to_csv(\"../data/processed/blockchain_metrics_updated.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
