{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### look back values for btc_close price\n",
    "look_back_values = [1, 2, 5, 10, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from skopt import BayesSearchCV\n",
    "from skorch import NeuralNetRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "import math\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_residuals_df = pd.read_csv(\"../data/final/train_residuals_df.csv\", parse_dates=[\"Date\"], index_col=\"Date\")\n",
    "test_residuals_df = pd.read_csv(\"../data/final/test_residuals_df.csv\", parse_dates=[\"Date\"], index_col=\"Date\")\n",
    "\n",
    "train_residual = train_residuals_df[\"Residuals\"]\n",
    "test_residual = test_residuals_df[\"Residuals\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/residual_scaler.pkl']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_residual_scaled = scaler.fit_transform(train_residual.values.reshape(-1, 1))\n",
    "test_residual_scaled = scaler.transform(test_residual.values.reshape(-1, 1))\n",
    "\n",
    "# save scaler\n",
    "joblib.dump(scaler, \"../models/residual_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_residual_scaled = train_residual_scaled.astype(np.float32)\n",
    "test_residual_scaled = test_residual_scaled.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, max_len, hidden_dim):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.position_encoding = nn.Parameter(torch.zeros(1, max_len, hidden_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.position_encoding[:, :x.size(1), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Seq2SeqTemporalFusionTransformer(nn.Module):\n",
    "    def __init__(self, look_back, num_heads, hidden_dim, feed_forward_dim, dropout_rate,\n",
    "                 num_layers=1, activation=\"relu\", input_feature_dim=1, n_steps_ahead=1):\n",
    "        super(Seq2SeqTemporalFusionTransformer, self).__init__()\n",
    "        self.look_back = look_back\n",
    "        self.n_steps_ahead = n_steps_ahead\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Input projection\n",
    "        self.input_projection = nn.Linear(input_feature_dim, hidden_dim)\n",
    "\n",
    "        # Positional encoding\n",
    "        self.positional_encoding = PositionalEncoding(max_len=look_back + n_steps_ahead, hidden_dim=hidden_dim)\n",
    "\n",
    "        # Define the activation function dynamically\n",
    "        if activation == \"relu\":\n",
    "            self.activation_fn = nn.ReLU()\n",
    "        elif activation == \"elu\":\n",
    "            self.activation_fn = nn.ELU(alpha=1.0)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation function: {activation}\")\n",
    "\n",
    "        # Encoder layers\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            nn.ModuleDict({\n",
    "                \"multi_head_attention\": nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=num_heads, batch_first=True),\n",
    "                \"layer_norm1\": nn.LayerNorm(hidden_dim),\n",
    "                \"feed_forward\": nn.Sequential(\n",
    "                    nn.Linear(hidden_dim, feed_forward_dim),\n",
    "                    self.activation_fn,\n",
    "                    nn.Dropout(dropout_rate),\n",
    "                    nn.Linear(feed_forward_dim, hidden_dim)\n",
    "                ),\n",
    "                \"layer_norm2\": nn.LayerNorm(hidden_dim)\n",
    "            })\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # Decoder layers\n",
    "        self.decoder_layers = nn.ModuleList([\n",
    "            nn.ModuleDict({\n",
    "                \"self_attention\": nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=num_heads, batch_first=True),\n",
    "                \"cross_attention\": nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=num_heads, batch_first=True),\n",
    "                \"layer_norm1\": nn.LayerNorm(hidden_dim),\n",
    "                \"feed_forward\": nn.Sequential(\n",
    "                    nn.Linear(hidden_dim, feed_forward_dim),\n",
    "                    self.activation_fn,\n",
    "                    nn.Dropout(dropout_rate),\n",
    "                    nn.Linear(feed_forward_dim, hidden_dim)\n",
    "                ),\n",
    "                \"layer_norm2\": nn.LayerNorm(hidden_dim)\n",
    "            })\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(hidden_dim, input_feature_dim)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        # Input projection\n",
    "        src = self.input_projection(src)  # Shape: (batch_size, look_back, hidden_dim)\n",
    "        tgt = self.input_projection(tgt)  # Shape: (batch_size, n_steps_ahead, hidden_dim)\n",
    "\n",
    "        # Add positional encoding\n",
    "        src = src + self.positional_encoding(src)\n",
    "        tgt = tgt + self.positional_encoding(tgt)\n",
    "\n",
    "        # Encoder\n",
    "        for layer in self.encoder_layers:\n",
    "            # Self-attention\n",
    "            attn_output, _ = layer[\"multi_head_attention\"](src, src, src)\n",
    "            src = layer[\"layer_norm1\"](src + attn_output)\n",
    "\n",
    "            # Feed-forward network\n",
    "            ff_output = layer[\"feed_forward\"](src)\n",
    "            src = layer[\"layer_norm2\"](src + ff_output)\n",
    "\n",
    "        # Decoder\n",
    "        for layer in self.decoder_layers:\n",
    "            # Self-attention\n",
    "            self_attn_output, _ = layer[\"self_attention\"](tgt, tgt, tgt)\n",
    "            tgt = layer[\"layer_norm1\"](tgt + self_attn_output)\n",
    "\n",
    "            # Cross-attention (attends to encoder output)\n",
    "            cross_attn_output, _ = layer[\"cross_attention\"](tgt, src, src)\n",
    "            tgt = layer[\"layer_norm1\"](tgt + cross_attn_output)\n",
    "\n",
    "            # Feed-forward network\n",
    "            ff_output = layer[\"feed_forward\"](tgt)\n",
    "            tgt = layer[\"layer_norm2\"](tgt + ff_output)\n",
    "\n",
    "        # Output projection\n",
    "        outputs = self.output_layer(tgt)  # Shape: (batch_size, n_steps_ahead, input_feature_dim)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters Tuning using Bayes Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqTemporalFusionTransformerWrapper(nn.Module):\n",
    "    def __init__(self, look_back, num_heads, head_dim, feed_forward_dim, dropout_rate, num_layers, activation, n_steps_ahead):\n",
    "        super(Seq2SeqTemporalFusionTransformerWrapper, self).__init__()\n",
    "        self.look_back = look_back\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = head_dim\n",
    "        self.feed_forward_dim = feed_forward_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.num_layers = num_layers\n",
    "        self.activation = activation\n",
    "        self.n_steps_ahead = n_steps_ahead\n",
    "        \n",
    "        # Initialize the Seq2Seq TFT model\n",
    "        self.model = Seq2SeqTemporalFusionTransformer(\n",
    "            look_back=look_back,\n",
    "            num_heads=num_heads,\n",
    "            hidden_dim=num_heads * head_dim,\n",
    "            feed_forward_dim=feed_forward_dim,\n",
    "            dropout_rate=dropout_rate,\n",
    "            num_layers=num_layers,\n",
    "            activation=activation,\n",
    "            input_feature_dim=1,  # Assuming univariate time series\n",
    "            n_steps_ahead=n_steps_ahead\n",
    "        )\n",
    "\n",
    "    def forward(self, src, tgt=None):\n",
    "        if src.dim() == 2:\n",
    "            src = src.unsqueeze(-1)  # Add feature dimension if missing\n",
    "        \n",
    "        # If tgt is not provided (during inference), initialize it with zeros\n",
    "        if tgt is None:\n",
    "            tgt = torch.zeros(src.size(0), self.n_steps_ahead, 1).to(src.device)  # Shape: (batch_size, n_steps_ahead, 1)\n",
    "        \n",
    "        # Ensure tgt is 3D: (batch_size, n_steps_ahead, input_feature_dim)\n",
    "        if tgt.dim() == 2:\n",
    "            tgt = tgt.unsqueeze(-1)  # Add feature dimension if missing\n",
    "        \n",
    "        # Forward pass through the model\n",
    "        outputs = self.model(src, tgt)  # Shape: (batch_size, n_steps_ahead, 1)\n",
    "        \n",
    "        # Reshape output to (batch_size, n_steps_ahead)\n",
    "        outputs = outputs.squeeze(-1)  # Remove the last dimension if it's 1\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def state_dict(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Override to save only the state_dict of the underlying model.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'hyperparameters': {\n",
    "                'look_back': self.look_back,\n",
    "                'num_heads': self.num_heads,\n",
    "                'head_dim': self.head_dim,\n",
    "                'feed_forward_dim': self.feed_forward_dim,\n",
    "                'dropout_rate': self.dropout_rate,\n",
    "                'num_layers': self.num_layers,\n",
    "                'activation': self.activation,\n",
    "                'n_steps_ahead': self.n_steps_ahead\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def load_state_dict(self, state_dict, strict=True):\n",
    "        \"\"\"\n",
    "        Override to load the state_dict into the underlying model.\n",
    "        \"\"\"\n",
    "        self.model.load_state_dict(state_dict['model_state_dict'], strict=strict)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict on given input data (e.g., X_test or future data).\n",
    "        \n",
    "        Parameters:\n",
    "        - X (np.ndarray or torch.Tensor): Input data of shape (batch_size, look_back).\n",
    "        \n",
    "        Returns:\n",
    "        - np.ndarray: Predicted values of shape (batch_size, n_steps_ahead).\n",
    "        \"\"\"\n",
    "        if not isinstance(X, torch.Tensor):\n",
    "            X = torch.tensor(X, dtype=torch.float32)\n",
    "\n",
    "        if X.dim() == 2:\n",
    "            X = X.unsqueeze(-1)  # Add feature dimension if missing\n",
    "\n",
    "        # Set the model to evaluation mode\n",
    "        self.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predictions = self.forward(X)  # Forward pass for prediction\n",
    "\n",
    "        return predictions.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search space for BayesSearchCV\n",
    "search_space = {\n",
    "    \"num_heads\": Categorical([2, 4, 8]),  \n",
    "    \"head_dim\": Categorical([8, 16, 32]),  \n",
    "    \"feed_forward_dim\": Categorical([128, 256, 512, 1024]),  \n",
    "    \"dropout_rate\": Real(0.1, 0.4),  \n",
    "    \"lr\": Real(5e-5, 5e-3, prior=\"log-uniform\"), \n",
    "    \"batch_size\": Categorical([16, 32, 64]), \n",
    "    \"num_layers\": Categorical([1, 2, 3, 4]),\n",
    "    \"activation\": Categorical([\"relu\", \"elu\"]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(722, 7, 1) (722, 3) (722, 7, 1) (722, 3)\n"
     ]
    }
   ],
   "source": [
    "def create_multi_step_dataset(data, look_back, n_steps_ahead=1):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - look_back - n_steps_ahead + 1):\n",
    "        X.append(data[i:i + look_back, 0])  # Input sequence\n",
    "        y.append(data[i + look_back:i + look_back + n_steps_ahead, 0])  # Multi-step target\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Prepare training and testing datasets\n",
    "look_back = 7\n",
    "n_steps_ahead = 3\n",
    "\n",
    "# Create train and test datasets\n",
    "X_train, y_train = create_multi_step_dataset(train_residual_scaled, look_back, n_steps_ahead)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test, y_test = create_multi_step_dataset(test_residual_scaled, look_back, n_steps_ahead)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TFTEstimator(BaseEstimator):\n",
    "    def __init__(self, look_back=7, num_heads=4, head_dim=16, feed_forward_dim=128,\n",
    "                 dropout_rate=0.1, lr=0.001, batch_size=32, num_layers=2, activation=\"relu\", n_steps_ahead=3):\n",
    "        self.look_back = look_back\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = head_dim\n",
    "        self.feed_forward_dim = feed_forward_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        self.activation = activation\n",
    "        self.n_steps_ahead = n_steps_ahead\n",
    "\n",
    "        # Store model hyperparameters\n",
    "        self.model_params = {\n",
    "            \"look_back\": look_back,\n",
    "            \"num_heads\": num_heads,\n",
    "            \"head_dim\": head_dim,\n",
    "            \"feed_forward_dim\": feed_forward_dim,\n",
    "            \"dropout_rate\": dropout_rate,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"activation\": activation,\n",
    "            \"n_steps_ahead\": n_steps_ahead\n",
    "        }\n",
    "\n",
    "        # # Store training hyperparameters\n",
    "        # self.training_params = {\n",
    "        #     \"lr\": lr,\n",
    "        #     \"batch_size\": batch_size,\n",
    "        # }\n",
    "        \n",
    "        # Initialize the Seq2Seq TFT model\n",
    "        self.model = Seq2SeqTemporalFusionTransformerWrapper(**self.model_params)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Convert inputs to PyTorch tensors\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32)  # Shape: (batch_size, look_back, 1)\n",
    "        y_tensor = torch.tensor(y, dtype=torch.float32)  # Shape: (batch_size, n_steps_ahead, 1)\n",
    "        \n",
    "        # Define loss function and optimizer\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(10):  # Example: 10 epochs\n",
    "            optimizer.zero_grad()\n",
    "            outputs = self.model(X_tensor, y_tensor)  # Forward pass with src and tgt\n",
    "            loss = criterion(outputs, y_tensor)  # Compute loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update weights\n",
    "            print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float32)  # Shape: (batch_size, look_back, 1)\n",
    "            predictions = self.model(X_tensor)  # Forward pass with src only (tgt is initialized internally)\n",
    "        return predictions.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.model_selection import ExpandingWindowSplitter\n",
    "from sklearn.model_selection import BaseCrossValidator\n",
    "# Define ExpandingWindowSplitter\n",
    "expanding_splitter = ExpandingWindowSplitter(initial_window=365, step_length=30, fh=[1, 7])\n",
    "\n",
    "# Custom Wrapper for ExpandingWindowSplitter\n",
    "class SKTimeToSKLearnCV(BaseCrossValidator):\n",
    "    def __init__(self, sktime_splitter, y):\n",
    "        self.sktime_splitter = sktime_splitter\n",
    "        self.y = y\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        for train_idx, test_idx in self.sktime_splitter.split(self.y):\n",
    "            yield train_idx, test_idx\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return self.sktime_splitter.get_n_splits(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.06588783860206604\n",
      "Epoch 1, Loss: 0.8594958782196045\n",
      "Epoch 1, Loss: 0.16960303485393524\n",
      "Epoch 1, Loss: 0.24192939698696136\n",
      "Epoch 1, Loss: 0.043014105409383774\n",
      "Epoch 1, Loss: 0.9541491270065308\n",
      "Epoch 1, Loss: 0.4221175014972687\n",
      "Epoch 1, Loss: 0.04805696755647659\n",
      "Epoch 1, Loss: 0.3923094570636749\n",
      "Epoch 2, Loss: 0.052915167063474655\n",
      "Epoch 1, Loss: 0.11373130232095718\n",
      "Epoch 1, Loss: 0.11613036692142487\n",
      "Epoch 1, Loss: 0.407204806804657\n",
      "Epoch 2, Loss: 0.7076079845428467\n",
      "Epoch 2, Loss: 0.11117853969335556\n",
      "Epoch 2, Loss: 0.024861186742782593\n",
      "Epoch 3, Loss: 0.05006519332528114\n",
      "Epoch 2, Loss: 0.017203669995069504\n",
      "Epoch 2, Loss: 0.2900976240634918\n",
      "Epoch 2, Loss: 0.16548898816108704\n",
      "Epoch 2, Loss: 0.31902244687080383\n",
      "Epoch 2, Loss: 0.7942622303962708\n",
      "Epoch 2, Loss: 0.09521850943565369\n",
      "Epoch 2, Loss: 0.06548501551151276\n",
      "Epoch 3, Loss: 0.076499804854393\n",
      "Epoch 4, Loss: 0.046863261610269547\n",
      "Epoch 3, Loss: 0.5770037174224854\n",
      "Epoch 3, Loss: 0.022709107026457787\n",
      "Epoch 2, Loss: 0.2950529456138611\n",
      "Epoch 3, Loss: 0.005363140720874071\n",
      "Epoch 3, Loss: 0.2115868777036667\n",
      "Epoch 3, Loss: 0.11435306072235107\n",
      "Epoch 4, Loss: 0.062295958399772644\n",
      "Epoch 5, Loss: 0.04042365401983261\n",
      "Epoch 4, Loss: 0.024405471980571747\n",
      "Epoch 3, Loss: 0.22968682646751404\n",
      "Epoch 4, Loss: 0.4588688910007477\n",
      "Epoch 3, Loss: 0.6469702124595642\n",
      "Epoch 3, Loss: 0.04053632915019989\n",
      "Epoch 3, Loss: 0.08672000467777252\n",
      "Epoch 4, Loss: 0.009042364545166492\n",
      "Epoch 3, Loss: 0.2022469937801361\n",
      "Epoch 6, Loss: 0.03390340134501457\n",
      "Epoch 5, Loss: 0.024276211857795715\n",
      "Epoch 4, Loss: 0.14918850362300873\n",
      "Epoch 4, Loss: 0.0818977877497673\n",
      "Epoch 5, Loss: 0.05774911865592003\n",
      "Epoch 5, Loss: 0.3499436676502228\n",
      "Epoch 4, Loss: 0.1652015596628189\n",
      "Epoch 4, Loss: 0.5152028203010559\n",
      "Epoch 7, Loss: 0.029368264600634575\n",
      "Epoch 5, Loss: 0.01654665917158127\n",
      "Epoch 6, Loss: 0.01935676485300064\n",
      "Epoch 4, Loss: 0.03409005329012871\n",
      "Epoch 5, Loss: 0.10681620240211487\n",
      "Epoch 6, Loss: 0.06259862333536148\n",
      "Epoch 4, Loss: 0.08293703943490982\n",
      "Epoch 8, Loss: 0.02562095783650875\n",
      "Epoch 5, Loss: 0.06644807755947113\n",
      "Epoch 4, Loss: 0.13067865371704102\n",
      "Epoch 6, Loss: 0.2678670883178711\n",
      "Epoch 7, Loss: 0.015831444412469864\n",
      "Epoch 6, Loss: 0.018832549452781677\n",
      "Epoch 5, Loss: 0.11741355806589127\n",
      "Epoch 5, Loss: 0.03804316744208336\n",
      "Epoch 5, Loss: 0.4042259156703949\n",
      "Epoch 6, Loss: 0.0811065062880516\n",
      "Epoch 9, Loss: 0.02359938621520996\n",
      "Epoch 7, Loss: 0.06588822603225708\n",
      "Epoch 5, Loss: 0.07862810045480728\n",
      "Epoch 7, Loss: 0.1931108683347702\n",
      "Epoch 7, Loss: 0.01626366190612316\n",
      "Epoch 8, Loss: 0.012020131573081017\n",
      "Epoch 6, Loss: 0.06709488481283188\n",
      "Epoch 6, Loss: 0.04371754080057144\n",
      "Epoch 10, Loss: 0.021012092009186745\n",
      "Epoch 7, Loss: 0.0694776400923729\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3058683557983185, feed_forward_dim=256, head_dim=16, lr=5.691346244168494e-05, num_heads=8, num_layers=2; total time=   2.1s\n",
      "Epoch 5, Loss: 0.07754190266132355\n",
      "Epoch 8, Loss: 0.06694263219833374\n",
      "Epoch 6, Loss: 0.08686129748821259\n",
      "Epoch 6, Loss: 0.3092018663883209\n",
      "Epoch 9, Loss: 0.010766458697617054\n",
      "Epoch 6, Loss: 0.07248314470052719\n",
      "Epoch 8, Loss: 0.1359797567129135\n",
      "Epoch 8, Loss: 0.011587763205170631\n",
      "Epoch 7, Loss: 0.07276064157485962\n",
      "Epoch 9, Loss: 0.061054527759552\n",
      "Epoch 8, Loss: 0.0680742859840393\n",
      "Epoch 7, Loss: 0.04489125683903694\n",
      "Epoch 7, Loss: 0.07176372408866882\n",
      "Epoch 10, Loss: 0.01176062785089016\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3058683557983185, feed_forward_dim=256, head_dim=16, lr=5.691346244168494e-05, num_heads=8, num_layers=2; total time=   2.2s\n",
      "Epoch 9, Loss: 0.09402316808700562\n",
      "Epoch 6, Loss: 0.04596938192844391\n",
      "Epoch 7, Loss: 0.22702699899673462\n",
      "Epoch 7, Loss: 0.06411612033843994\n",
      "Epoch 10, Loss: 0.05461246147751808\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3058683557983185, feed_forward_dim=256, head_dim=16, lr=5.691346244168494e-05, num_heads=8, num_layers=2; total time=   2.3s\n",
      "Epoch 9, Loss: 0.007034834008663893\n",
      "Epoch 9, Loss: 0.07230580598115921\n",
      "Epoch 8, Loss: 0.08184163272380829\n",
      "Epoch 10, Loss: 0.06666026264429092\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3058683557983185, feed_forward_dim=256, head_dim=16, lr=5.691346244168494e-05, num_heads=8, num_layers=2; total time=   2.4s\n",
      "Epoch 8, Loss: 0.06884266436100006\n",
      "Epoch 10, Loss: 0.00447943015024066\n",
      "Epoch 8, Loss: 0.039976783096790314\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3058683557983185, feed_forward_dim=256, head_dim=16, lr=5.691346244168494e-05, num_heads=8, num_layers=2; total time=   2.4s\n",
      "Epoch 8, Loss: 0.0560777448117733\n",
      "Epoch 10, Loss: 0.08044900000095367\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3058683557983185, feed_forward_dim=256, head_dim=16, lr=5.691346244168494e-05, num_heads=8, num_layers=2; total time=   2.4s\n",
      "Epoch 8, Loss: 0.16701827943325043\n",
      "Epoch 7, Loss: 0.029745960608124733\n",
      "Epoch 9, Loss: 0.08454323559999466\n",
      "Epoch 9, Loss: 0.07384339720010757\n",
      "Epoch 9, Loss: 0.12391727417707443\n",
      "Epoch 9, Loss: 0.05023247376084328\n",
      "Epoch 9, Loss: 0.03288239240646362\n",
      "Epoch 8, Loss: 0.02828603982925415\n",
      "Epoch 10, Loss: 0.08291363716125488\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3058683557983185, feed_forward_dim=256, head_dim=16, lr=5.691346244168494e-05, num_heads=8, num_layers=2; total time=   2.6s\n",
      "Epoch 10, Loss: 0.07957970350980759\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3058683557983185, feed_forward_dim=256, head_dim=16, lr=5.691346244168494e-05, num_heads=8, num_layers=2; total time=   2.6s\n",
      "Epoch 10, Loss: 0.09532055258750916\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3058683557983185, feed_forward_dim=256, head_dim=16, lr=5.691346244168494e-05, num_heads=8, num_layers=2; total time=   2.6s\n",
      "Epoch 10, Loss: 0.025353459641337395\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3058683557983185, feed_forward_dim=256, head_dim=16, lr=5.691346244168494e-05, num_heads=8, num_layers=2; total time=   2.6s\n",
      "Epoch 9, Loss: 0.03621958941221237\n",
      "Epoch 10, Loss: 0.045269206166267395\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3058683557983185, feed_forward_dim=256, head_dim=16, lr=5.691346244168494e-05, num_heads=8, num_layers=2; total time=   2.6s\n",
      "Epoch 10, Loss: 0.04706761986017227\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3058683557983185, feed_forward_dim=256, head_dim=16, lr=5.691346244168494e-05, num_heads=8, num_layers=2; total time=   2.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 2.305405855178833\n",
      "Epoch 1, Loss: 0.2776948809623718\n",
      "Epoch 1, Loss: 0.041243650019168854\n",
      "Epoch 1, Loss: 0.20385654270648956\n",
      "Epoch 2, Loss: 5.714081287384033\n",
      "Epoch 1, Loss: 0.18117479979991913\n",
      "Epoch 1, Loss: 0.6469547152519226\n",
      "Epoch 2, Loss: 10.220544815063477\n",
      "Epoch 1, Loss: 0.0652264729142189\n",
      "Epoch 2, Loss: 7.431136608123779\n",
      "Epoch 2, Loss: 7.495070457458496\n",
      "Epoch 1, Loss: 0.06630036979913712\n",
      "Epoch 1, Loss: 0.577885091304779\n",
      "Epoch 3, Loss: 1.8258912563323975\n",
      "Epoch 2, Loss: 13.164457321166992\n",
      "Epoch 1, Loss: 0.7229236364364624\n",
      "Epoch 2, Loss: 7.843813896179199\n",
      "Epoch 3, Loss: 2.733879327774048\n",
      "Epoch 3, Loss: 0.039536185562610626\n",
      "Epoch 1, Loss: 0.3348940908908844\n",
      "Epoch 3, Loss: 0.26153334975242615\n",
      "Epoch 4, Loss: 0.13750986754894257\n",
      "Epoch 2, Loss: 10.983510971069336\n",
      "Epoch 1, Loss: 0.0727357566356659\n",
      "Epoch 2, Loss: 6.248013496398926\n",
      "Epoch 2, Loss: 7.4184889793396\n",
      "Epoch 4, Loss: 0.061765093356370926\n",
      "Epoch 4, Loss: 0.9031299948692322\n",
      "Epoch 3, Loss: 2.747861623764038\n",
      "Epoch 3, Loss: 1.684760570526123\n",
      "Epoch 5, Loss: 0.2694701850414276\n",
      "Epoch 2, Loss: 11.592777252197266\n",
      "Epoch 4, Loss: 1.4090068340301514\n",
      "Epoch 3, Loss: 1.1246954202651978\n",
      "Epoch 6, Loss: 0.5207703113555908\n",
      "Epoch 5, Loss: 0.2603152096271515\n",
      "Epoch 2, Loss: 10.109728813171387\n",
      "Epoch 5, Loss: 1.0290052890777588\n",
      "Epoch 3, Loss: 2.535466432571411\n",
      "Epoch 2, Loss: 6.794179916381836\n",
      "Epoch 4, Loss: 0.05606215447187424\n",
      "Epoch 3, Loss: 1.224948525428772\n",
      "Epoch 4, Loss: 0.17304912209510803\n",
      "Epoch 7, Loss: 0.3786167502403259\n",
      "Epoch 6, Loss: 0.03530300781130791\n",
      "Epoch 4, Loss: 0.6599750518798828\n",
      "Epoch 5, Loss: 0.8758523464202881\n",
      "Epoch 3, Loss: 3.881648540496826\n",
      "Epoch 3, Loss: 3.4196646213531494\n",
      "Epoch 5, Loss: 0.9560254812240601\n",
      "Epoch 6, Loss: 0.7887258529663086\n",
      "Epoch 5, Loss: 0.9614566564559937\n",
      "Epoch 4, Loss: 0.1636890321969986\n",
      "Epoch 4, Loss: 0.4595879316329956\n",
      "Epoch 8, Loss: 0.15249186754226685\n",
      "Epoch 7, Loss: 0.1487678587436676\n",
      "Epoch 3, Loss: 0.12967060506343842\n",
      "Epoch 5, Loss: 0.950284481048584\n",
      "Epoch 6, Loss: 0.7844454050064087\n",
      "Epoch 6, Loss: 0.16792823374271393\n",
      "Epoch 7, Loss: 0.26739227771759033\n",
      "Epoch 9, Loss: 0.056387677788734436\n",
      "Epoch 4, Loss: 0.25194883346557617\n",
      "Epoch 4, Loss: 0.20531368255615234\n",
      "Epoch 6, Loss: 0.6093873977661133\n",
      "Epoch 5, Loss: 0.014720668084919453\n",
      "Epoch 8, Loss: 0.20843608677387238\n",
      "Epoch 6, Loss: 0.45799869298934937\n",
      "Epoch 7, Loss: 0.30499404668807983\n",
      "Epoch 8, Loss: 0.06255265325307846\n",
      "Epoch 10, Loss: 0.09049030393362045\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.10733125637125324, feed_forward_dim=256, head_dim=16, lr=0.0038741087595425307, num_heads=8, num_layers=3; total time=   0.9s\n",
      "Epoch 5, Loss: 0.3952330946922302\n",
      "Epoch 7, Loss: 0.07280062884092331\n",
      "Epoch 4, Loss: 0.4968019425868988\n",
      "Epoch 7, Loss: 0.1569771021604538\n",
      "Epoch 9, Loss: 0.13192179799079895\n",
      "Epoch 9, Loss: 0.14406950771808624\n",
      "Epoch 8, Loss: 0.06206484138965607\n",
      "Epoch 6, Loss: 0.19794341921806335\n",
      "Epoch 8, Loss: 0.24162651598453522\n",
      "Epoch 7, Loss: 0.11108585447072983\n",
      "Epoch 5, Loss: 0.5202286839485168\n",
      "Epoch 6, Loss: 0.6794986724853516\n",
      "Epoch 10, Loss: 0.22474589943885803\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.10733125637125324, feed_forward_dim=256, head_dim=16, lr=0.0038741087595425307, num_heads=8, num_layers=3; total time=   1.0s\n",
      "Epoch 5, Loss: 0.46682530641555786\n",
      "Epoch 8, Loss: 0.05749628320336342\n",
      "Epoch 9, Loss: 0.09829751402139664\n",
      "Epoch 10, Loss: 0.06953731924295425\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.10733125637125324, feed_forward_dim=256, head_dim=16, lr=0.0038741087595425307, num_heads=8, num_layers=3; total time=   1.1s\n",
      "Epoch 9, Loss: 0.279590368270874\n",
      "Epoch 5, Loss: 0.08274054527282715\n",
      "Epoch 7, Loss: 0.2041345238685608\n",
      "Epoch 8, Loss: 0.05587578937411308\n",
      "Epoch 10, Loss: 0.2004317343235016\n",
      "Epoch 7, Loss: 0.4150916635990143\n",
      "Epoch 6, Loss: 0.9940651059150696\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.10733125637125324, feed_forward_dim=256, head_dim=16, lr=0.0038741087595425307, num_heads=8, num_layers=3; total time=   1.2s\n",
      "Epoch 10, Loss: 0.191056489944458\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.10733125637125324, feed_forward_dim=256, head_dim=16, lr=0.0038741087595425307, num_heads=8, num_layers=3; total time=   1.2s\n",
      "Epoch 9, Loss: 0.16804204881191254\n",
      "Epoch 6, Loss: 0.8517069816589355\n",
      "Epoch 6, Loss: 0.08086711168289185\n",
      "Epoch 9, Loss: 0.15524457395076752\n",
      "Epoch 10, Loss: 0.24162597954273224\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.10733125637125324, feed_forward_dim=256, head_dim=16, lr=0.0038741087595425307, num_heads=8, num_layers=3; total time=   1.2s\n",
      "Epoch 7, Loss: 0.7211106419563293\n",
      "Epoch 8, Loss: 0.09075693786144257\n",
      "Epoch 7, Loss: 0.5794459581375122\n",
      "Epoch 8, Loss: 0.13315506279468536\n",
      "Epoch 7, Loss: 0.1601768136024475\n",
      "Epoch 10, Loss: 0.21599239110946655\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.10733125637125324, feed_forward_dim=256, head_dim=16, lr=0.0038741087595425307, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 8, Loss: 0.31602808833122253\n",
      "Epoch 9, Loss: 0.04788960888981819\n",
      "Epoch 9, Loss: 0.048238471150398254\n",
      "Epoch 8, Loss: 0.23492245376110077\n",
      "Epoch 8, Loss: 0.11697639524936676\n",
      "Epoch 10, Loss: 0.09817054122686386\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.10733125637125324, feed_forward_dim=256, head_dim=16, lr=0.0038741087595425307, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.08628777414560318\n",
      "Epoch 10, Loss: 0.1055319607257843\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.10733125637125324, feed_forward_dim=256, head_dim=16, lr=0.0038741087595425307, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.0685441866517067\n",
      "Epoch 9, Loss: 0.06219647824764252\n",
      "Epoch 10, Loss: 0.06726633012294769\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.10733125637125324, feed_forward_dim=256, head_dim=16, lr=0.0038741087595425307, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.07294787466526031\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.10733125637125324, feed_forward_dim=256, head_dim=16, lr=0.0038741087595425307, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.07033499330282211\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.10733125637125324, feed_forward_dim=256, head_dim=16, lr=0.0038741087595425307, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 3.4856555461883545\n",
      "Epoch 1, Loss: 0.6009282469749451\n",
      "Epoch 1, Loss: 1.3686398267745972\n",
      "Epoch 1, Loss: 0.07826394587755203\n",
      "Epoch 1, Loss: 0.09222783148288727\n",
      "Epoch 2, Loss: 2.8058438301086426\n",
      "Epoch 1, Loss: 0.05919525772333145\n",
      "Epoch 2, Loss: 0.9699244499206543\n",
      "Epoch 2, Loss: 0.35307154059410095\n",
      "Epoch 1, Loss: 0.11765539646148682\n",
      "Epoch 1, Loss: 0.1713351011276245\n",
      "Epoch 2, Loss: 0.038118910044431686\n",
      "Epoch 3, Loss: 2.195286512374878\n",
      "Epoch 1, Loss: 0.7555640935897827\n",
      "Epoch 3, Loss: 0.20193684101104736\n",
      "Epoch 3, Loss: 0.6458151936531067\n",
      "Epoch 2, Loss: 0.014344152994453907\n",
      "Epoch 1, Loss: 0.12185133248567581\n",
      "Epoch 2, Loss: 0.006117647979408503\n",
      "Epoch 1, Loss: 0.23268292844295502\n",
      "Epoch 1, Loss: 0.7569245100021362\n",
      "Epoch 2, Loss: 0.10487886518239975\n",
      "Epoch 3, Loss: 0.052308693528175354\n",
      "Epoch 4, Loss: 1.654650092124939\n",
      "Epoch 4, Loss: 0.13878612220287323\n",
      "Epoch 4, Loss: 0.3939460813999176\n",
      "Epoch 2, Loss: 0.08249194175004959\n",
      "Epoch 2, Loss: 0.4465584456920624\n",
      "Epoch 3, Loss: 0.016300803050398827\n",
      "Epoch 2, Loss: 0.07684291899204254\n",
      "Epoch 2, Loss: 0.07873452454805374\n",
      "Epoch 3, Loss: 0.03130944073200226\n",
      "Epoch 2, Loss: 0.4482116103172302\n",
      "Epoch 5, Loss: 1.193955421447754\n",
      "Epoch 3, Loss: 0.08001826703548431\n",
      "Epoch 4, Loss: 0.043062757700681686\n",
      "Epoch 5, Loss: 0.2208818942308426\n",
      "Epoch 5, Loss: 0.14074748754501343\n",
      "Epoch 3, Loss: 0.0756206065416336\n",
      "Epoch 6, Loss: 0.8208639025688171\n",
      "Epoch 4, Loss: 0.03905976191163063\n",
      "Epoch 4, Loss: 0.0341523215174675\n",
      "Epoch 6, Loss: 0.17218972742557526\n",
      "Epoch 5, Loss: 0.025411859154701233\n",
      "Epoch 3, Loss: 0.0828966498374939\n",
      "Epoch 3, Loss: 0.28297650814056396\n",
      "Epoch 3, Loss: 0.027473371475934982\n",
      "Epoch 6, Loss: 0.1076832264661789\n",
      "Epoch 4, Loss: 0.06304225325584412\n",
      "Epoch 3, Loss: 0.2316465675830841\n",
      "Epoch 4, Loss: 0.0916670635342598\n",
      "Epoch 7, Loss: 0.5211023092269897\n",
      "Epoch 7, Loss: 0.1932653933763504\n",
      "Epoch 5, Loss: 0.01564476266503334\n",
      "Epoch 6, Loss: 0.01736260950565338\n",
      "Epoch 5, Loss: 0.04039347916841507\n",
      "Epoch 7, Loss: 0.049952272325754166\n",
      "Epoch 5, Loss: 0.053469326347112656\n",
      "Epoch 8, Loss: 0.1984482705593109\n",
      "Epoch 4, Loss: 0.22160358726978302\n",
      "Epoch 8, Loss: 0.30211856961250305\n",
      "Epoch 5, Loss: 0.08777128159999847\n",
      "Epoch 6, Loss: 0.006140905898064375\n",
      "Epoch 4, Loss: 0.10576147586107254\n",
      "Epoch 8, Loss: 0.03734952583909035\n",
      "Epoch 6, Loss: 0.025244681164622307\n",
      "Epoch 4, Loss: 0.05353822559118271\n",
      "Epoch 7, Loss: 0.018736397847533226\n",
      "Epoch 4, Loss: 0.07005134224891663\n",
      "Epoch 9, Loss: 0.17664530873298645\n",
      "Epoch 9, Loss: 0.15304778516292572\n",
      "Epoch 6, Loss: 0.04210062325000763\n",
      "Epoch 9, Loss: 0.05704198032617569\n",
      "Epoch 5, Loss: 0.225237637758255\n",
      "Epoch 7, Loss: 0.010451970621943474\n",
      "Epoch 6, Loss: 0.06750959903001785\n",
      "Epoch 10, Loss: 0.14915789663791656\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.3583326236411818, feed_forward_dim=128, head_dim=32, lr=0.00012617262877533087, num_heads=8, num_layers=4; total time=   1.0s\n",
      "Epoch 7, Loss: 0.010837988927960396\n",
      "Epoch 5, Loss: 0.0841965526342392\n",
      "Epoch 5, Loss: 0.058244891464710236\n",
      "Epoch 10, Loss: 0.08915093541145325\n",
      "Epoch 10, Loss: 0.06374120712280273\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.3583326236411818, feed_forward_dim=128, head_dim=32, lr=0.00012617262877533087, num_heads=8, num_layers=4; total time=   1.0s\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.3583326236411818, feed_forward_dim=128, head_dim=32, lr=0.00012617262877533087, num_heads=8, num_layers=4; total time=   1.0s\n",
      "Epoch 5, Loss: 0.04875015839934349\n",
      "Epoch 8, Loss: 0.021286271512508392\n",
      "Epoch 7, Loss: 0.031349293887615204\n",
      "Epoch 7, Loss: 0.04889886826276779\n",
      "Epoch 6, Loss: 0.23895880579948425\n",
      "Epoch 8, Loss: 0.018116306513547897\n",
      "Epoch 8, Loss: 0.0056513226591050625\n",
      "Epoch 9, Loss: 0.016691528260707855\n",
      "Epoch 6, Loss: 0.085239939391613\n",
      "Epoch 9, Loss: 0.01887764036655426\n",
      "Epoch 8, Loss: 0.037194304168224335\n",
      "Epoch 7, Loss: 0.2354433238506317\n",
      "Epoch 8, Loss: 0.025007518008351326\n",
      "Epoch 6, Loss: 0.07022090256214142\n",
      "Epoch 6, Loss: 0.03413094952702522\n",
      "Epoch 9, Loss: 0.0099260825663805\n",
      "Epoch 10, Loss: 0.012457609176635742\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.3583326236411818, feed_forward_dim=128, head_dim=32, lr=0.00012617262877533087, num_heads=8, num_layers=4; total time=   1.2s\n",
      "Epoch 10, Loss: 0.0093750124797225\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.3583326236411818, feed_forward_dim=128, head_dim=32, lr=0.00012617262877533087, num_heads=8, num_layers=4; total time=   1.2s\n",
      "Epoch 7, Loss: 0.06417034566402435\n",
      "Epoch 9, Loss: 0.034893181174993515\n",
      "Epoch 8, Loss: 0.21323952078819275\n",
      "Epoch 7, Loss: 0.11188972741365433\n",
      "Epoch 9, Loss: 0.021271681413054466\n",
      "Epoch 7, Loss: 0.02901061438024044\n",
      "Epoch 10, Loss: 0.017863839864730835\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.3583326236411818, feed_forward_dim=128, head_dim=32, lr=0.00012617262877533087, num_heads=8, num_layers=4; total time=   1.3s\n",
      "Epoch 10, Loss: 0.039420563727617264\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.3583326236411818, feed_forward_dim=128, head_dim=32, lr=0.00012617262877533087, num_heads=8, num_layers=4; total time=   1.3s\n",
      "Epoch 8, Loss: 0.03694410249590874\n",
      "Epoch 9, Loss: 0.17716293036937714\n",
      "Epoch 10, Loss: 0.017204929143190384\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.3583326236411818, feed_forward_dim=128, head_dim=32, lr=0.00012617262877533087, num_heads=8, num_layers=4; total time=   1.4s\n",
      "Epoch 8, Loss: 0.14987944066524506\n",
      "Epoch 8, Loss: 0.02709011733531952\n",
      "Epoch 10, Loss: 0.13194629549980164\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.3583326236411818, feed_forward_dim=128, head_dim=32, lr=0.00012617262877533087, num_heads=8, num_layers=4; total time=   1.4s\n",
      "Epoch 9, Loss: 0.017559239640831947\n",
      "Epoch 9, Loss: 0.1717173159122467\n",
      "Epoch 9, Loss: 0.021805519238114357\n",
      "Epoch 10, Loss: 0.16978807747364044\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.3583326236411818, feed_forward_dim=128, head_dim=32, lr=0.00012617262877533087, num_heads=8, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.012430674396455288\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.3583326236411818, feed_forward_dim=128, head_dim=32, lr=0.00012617262877533087, num_heads=8, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.01429868582636118\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.3583326236411818, feed_forward_dim=128, head_dim=32, lr=0.00012617262877533087, num_heads=8, num_layers=4; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.07014721632003784\n",
      "Epoch 1, Loss: 1.0502359867095947\n",
      "Epoch 1, Loss: 0.059631556272506714\n",
      "Epoch 1, Loss: 0.23512403666973114\n",
      "Epoch 2, Loss: 0.051693517714738846\n",
      "Epoch 1, Loss: 0.6311339735984802\n",
      "Epoch 1, Loss: 0.13223083317279816\n",
      "Epoch 2, Loss: 0.8090846538543701\n",
      "Epoch 2, Loss: 0.03760259598493576\n",
      "Epoch 1, Loss: 0.12932264804840088\n",
      "Epoch 3, Loss: 0.04794592037796974\n",
      "Epoch 1, Loss: 0.016429996117949486\n",
      "Epoch 1, Loss: 0.4343346655368805\n",
      "Epoch 2, Loss: 0.420187383890152\n",
      "Epoch 3, Loss: 0.04059179499745369\n",
      "Epoch 3, Loss: 0.6085469126701355\n",
      "Epoch 2, Loss: 0.15204809606075287\n",
      "Epoch 1, Loss: 0.7257333993911743\n",
      "Epoch 1, Loss: 2.838541030883789\n",
      "Epoch 2, Loss: 0.04945075139403343\n",
      "Epoch 4, Loss: 0.04399546980857849\n",
      "Epoch 1, Loss: 0.17055918276309967\n",
      "Epoch 2, Loss: 0.1077812984585762\n",
      "Epoch 2, Loss: 0.016334213316440582\n",
      "Epoch 2, Loss: 0.2692504823207855\n",
      "Epoch 3, Loss: 0.2643912732601166\n",
      "Epoch 3, Loss: 0.10472472757101059\n",
      "Epoch 4, Loss: 0.035134438425302505\n",
      "Epoch 5, Loss: 0.03545333817601204\n",
      "Epoch 4, Loss: 0.4385116994380951\n",
      "Epoch 3, Loss: 0.01279446855187416\n",
      "Epoch 2, Loss: 2.3380250930786133\n",
      "Epoch 2, Loss: 0.5128377079963684\n",
      "Epoch 3, Loss: 0.10170108824968338\n",
      "Epoch 5, Loss: 0.02578478865325451\n",
      "Epoch 4, Loss: 0.14721153676509857\n",
      "Epoch 5, Loss: 0.29995813965797424\n",
      "Epoch 4, Loss: 0.08514876663684845\n",
      "Epoch 6, Loss: 0.026723183691501617\n",
      "Epoch 3, Loss: 0.15527339279651642\n",
      "Epoch 2, Loss: 0.09045574069023132\n",
      "Epoch 3, Loss: 0.01358488854020834\n",
      "Epoch 4, Loss: 0.014224792830646038\n",
      "Epoch 6, Loss: 0.018633900210261345\n",
      "Epoch 4, Loss: 0.09299705922603607\n",
      "Epoch 7, Loss: 0.0212246123701334\n",
      "Epoch 5, Loss: 0.08582284301519394\n",
      "Epoch 5, Loss: 0.08219089359045029\n",
      "Epoch 6, Loss: 0.19843250513076782\n",
      "Epoch 3, Loss: 0.3377767503261566\n",
      "Epoch 3, Loss: 1.8905502557754517\n",
      "Epoch 5, Loss: 0.031249843537807465\n",
      "Epoch 4, Loss: 0.09506145864725113\n",
      "Epoch 4, Loss: 0.007728688884526491\n",
      "Epoch 3, Loss: 0.052566077560186386\n",
      "Epoch 8, Loss: 0.01800050586462021\n",
      "Epoch 7, Loss: 0.01666431874036789\n",
      "Epoch 7, Loss: 0.12980933487415314\n",
      "Epoch 6, Loss: 0.04781418293714523\n",
      "Epoch 6, Loss: 0.08879094570875168\n",
      "Epoch 5, Loss: 0.08359696716070175\n",
      "Epoch 6, Loss: 0.0445718914270401\n",
      "Epoch 9, Loss: 0.015671484172344208\n",
      "Epoch 4, Loss: 0.20429427921772003\n",
      "Epoch 5, Loss: 0.009369570761919022\n",
      "Epoch 4, Loss: 1.4976160526275635\n",
      "Epoch 5, Loss: 0.08240430057048798\n",
      "Epoch 8, Loss: 0.016117436811327934\n",
      "Epoch 8, Loss: 0.0896146222949028\n",
      "Epoch 4, Loss: 0.04838738590478897\n",
      "Epoch 7, Loss: 0.04405763000249863\n",
      "Epoch 7, Loss: 0.09229566156864166\n",
      "Epoch 10, Loss: 0.013120938092470169\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.14878500990972388, feed_forward_dim=256, head_dim=8, lr=8.447889829767462e-05, num_heads=4, num_layers=3; total time=   1.0s\n",
      "Epoch 6, Loss: 0.07138048112392426\n",
      "Epoch 7, Loss: 0.04526086151599884\n",
      "Epoch 5, Loss: 0.1113186702132225\n",
      "Epoch 9, Loss: 0.013813759200274944\n",
      "Epoch 6, Loss: 0.010618639178574085\n",
      "Epoch 9, Loss: 0.0748993530869484\n",
      "Epoch 6, Loss: 0.09714654833078384\n",
      "Epoch 8, Loss: 0.055725086480379105\n",
      "Epoch 5, Loss: 0.05777614563703537\n",
      "Epoch 8, Loss: 0.09028945118188858\n",
      "Epoch 5, Loss: 1.1525709629058838\n",
      "Epoch 10, Loss: 0.010241992771625519\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.14878500990972388, feed_forward_dim=256, head_dim=8, lr=8.447889829767462e-05, num_heads=4, num_layers=3; total time=   1.2s\n",
      "Epoch 8, Loss: 0.036587897688150406\n",
      "Epoch 7, Loss: 0.06479842960834503\n",
      "Epoch 10, Loss: 0.07761867344379425\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.14878500990972388, feed_forward_dim=256, head_dim=8, lr=8.447889829767462e-05, num_heads=4, num_layers=3; total time=   1.2s\n",
      "Epoch 7, Loss: 0.008567507378757\n",
      "Epoch 6, Loss: 0.054968032985925674\n",
      "Epoch 7, Loss: 0.11586008965969086\n",
      "Epoch 9, Loss: 0.08084926754236221\n",
      "Epoch 9, Loss: 0.07876313477754593\n",
      "Epoch 9, Loss: 0.02295832708477974\n",
      "Epoch 8, Loss: 0.006059055682271719\n",
      "Epoch 6, Loss: 0.8568361401557922\n",
      "Epoch 6, Loss: 0.06681326031684875\n",
      "Epoch 7, Loss: 0.03157690912485123\n",
      "Epoch 8, Loss: 0.05897558480501175\n",
      "Epoch 10, Loss: 0.06699177622795105\n",
      "Epoch 8, Loss: 0.13048192858695984\n",
      "Epoch 10, Loss: 0.10026562958955765\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.14878500990972388, feed_forward_dim=256, head_dim=8, lr=8.447889829767462e-05, num_heads=4, num_layers=3; total time=   1.4s\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.14878500990972388, feed_forward_dim=256, head_dim=8, lr=8.447889829767462e-05, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Epoch 10, Loss: 0.013702010735869408\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.14878500990972388, feed_forward_dim=256, head_dim=8, lr=8.447889829767462e-05, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.007617954630404711\n",
      "Epoch 7, Loss: 0.6160587072372437\n",
      "Epoch 7, Loss: 0.06457839906215668\n",
      "Epoch 9, Loss: 0.052213188260793686\n",
      "Epoch 9, Loss: 0.12971104681491852\n",
      "Epoch 8, Loss: 0.032816462218761444\n",
      "Epoch 10, Loss: 0.008275661617517471\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.14878500990972388, feed_forward_dim=256, head_dim=8, lr=8.447889829767462e-05, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 8, Loss: 0.417950838804245\n",
      "Epoch 10, Loss: 0.046905796974897385\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.14878500990972388, feed_forward_dim=256, head_dim=8, lr=8.447889829767462e-05, num_heads=4, num_layers=3; total time=   1.7s\n",
      "Epoch 10, Loss: 0.11582024395465851\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.14878500990972388, feed_forward_dim=256, head_dim=8, lr=8.447889829767462e-05, num_heads=4, num_layers=3; total time=   1.6s\n",
      "Epoch 8, Loss: 0.05351180583238602\n",
      "Epoch 9, Loss: 0.04875714331865311\n",
      "Epoch 10, Loss: 0.07371482253074646\n",
      "Epoch 9, Loss: 0.2680865526199341\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.14878500990972388, feed_forward_dim=256, head_dim=8, lr=8.447889829767462e-05, num_heads=4, num_layers=3; total time=   1.8s\n",
      "Epoch 9, Loss: 0.04098404571413994\n",
      "Epoch 10, Loss: 0.15515579283237457\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.14878500990972388, feed_forward_dim=256, head_dim=8, lr=8.447889829767462e-05, num_heads=4, num_layers=3; total time=   1.9s\n",
      "Epoch 10, Loss: 0.02919708378612995\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.14878500990972388, feed_forward_dim=256, head_dim=8, lr=8.447889829767462e-05, num_heads=4, num_layers=3; total time=   1.9s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 1.5864505767822266\n",
      "Epoch 1, Loss: 0.08553103357553482\n",
      "Epoch 1, Loss: 1.3591434955596924\n",
      "Epoch 1, Loss: 0.3494407832622528\n",
      "Epoch 2, Loss: 0.3256537616252899\n",
      "Epoch 1, Loss: 0.23352500796318054\n",
      "Epoch 1, Loss: 0.3614892065525055\n",
      "Epoch 2, Loss: 1.160652995109558\n",
      "Epoch 1, Loss: 0.1954171508550644\n",
      "Epoch 2, Loss: 0.17521117627620697\n",
      "Epoch 3, Loss: 0.7200955748558044\n",
      "Epoch 1, Loss: 0.6776788234710693\n",
      "Epoch 1, Loss: 3.1803812980651855\n",
      "Epoch 2, Loss: 1.0188826322555542\n",
      "Epoch 2, Loss: 1.027653455734253\n",
      "Epoch 1, Loss: 2.2425854206085205\n",
      "Epoch 2, Loss: 1.3589805364608765\n",
      "Epoch 1, Loss: 1.2123380899429321\n",
      "Epoch 3, Loss: 0.057408832013607025\n",
      "Epoch 4, Loss: 0.48413994908332825\n",
      "Epoch 2, Loss: 1.4840240478515625\n",
      "Epoch 3, Loss: 0.56298828125\n",
      "Epoch 1, Loss: 0.2922237515449524\n",
      "Epoch 3, Loss: 0.34522518515586853\n",
      "Epoch 3, Loss: 0.328502893447876\n",
      "Epoch 2, Loss: 0.5559886693954468\n",
      "Epoch 4, Loss: 0.32585063576698303\n",
      "Epoch 2, Loss: 0.303309828042984\n",
      "Epoch 2, Loss: 0.17170722782611847\n",
      "Epoch 3, Loss: 0.43316444754600525\n",
      "Epoch 5, Loss: 0.17080377042293549\n",
      "Epoch 4, Loss: 0.3743925988674164\n",
      "Epoch 3, Loss: 0.3288007080554962\n",
      "Epoch 2, Loss: 0.38415905833244324\n",
      "Epoch 4, Loss: 0.040110763162374496\n",
      "Epoch 5, Loss: 0.4720219373703003\n",
      "Epoch 4, Loss: 0.014666976407170296\n",
      "Epoch 4, Loss: 0.030706757679581642\n",
      "Epoch 2, Loss: 1.20114004611969\n",
      "Epoch 6, Loss: 0.05554739013314247\n",
      "Epoch 3, Loss: 0.46679818630218506\n",
      "Epoch 5, Loss: 0.1180792972445488\n",
      "Epoch 3, Loss: 0.25276264548301697\n",
      "Epoch 3, Loss: 0.7354760766029358\n",
      "Epoch 4, Loss: 0.06172775477170944\n",
      "Epoch 6, Loss: 0.25793877243995667\n",
      "Epoch 3, Loss: 0.688388466835022\n",
      "Epoch 6, Loss: 0.05376344546675682\n",
      "Epoch 5, Loss: 0.2697272300720215\n",
      "Epoch 5, Loss: 0.23474010825157166\n",
      "Epoch 5, Loss: 0.19285458326339722\n",
      "Epoch 4, Loss: 0.08972398936748505\n",
      "Epoch 7, Loss: 0.11211317032575607\n",
      "Epoch 3, Loss: 0.32326802611351013\n",
      "Epoch 7, Loss: 0.06104229763150215\n",
      "Epoch 4, Loss: 0.6469162702560425\n",
      "Epoch 4, Loss: 0.7328526377677917\n",
      "Epoch 6, Loss: 0.39293935894966125\n",
      "Epoch 7, Loss: 0.13320651650428772\n",
      "Epoch 8, Loss: 0.18680834770202637\n",
      "Epoch 6, Loss: 0.3051123321056366\n",
      "Epoch 6, Loss: 0.30182793736457825\n",
      "Epoch 4, Loss: 0.3179101049900055\n",
      "Epoch 5, Loss: 0.38463345170021057\n",
      "Epoch 8, Loss: 0.022895032539963722\n",
      "Epoch 5, Loss: 0.018435616046190262\n",
      "Epoch 5, Loss: 0.621557891368866\n",
      "Epoch 9, Loss: 0.18759506940841675\n",
      "Epoch 8, Loss: 0.1980106681585312\n",
      "Epoch 5, Loss: 0.4048718512058258\n",
      "Epoch 7, Loss: 0.17160122096538544\n",
      "Epoch 9, Loss: 0.0904339849948883\n",
      "Epoch 6, Loss: 0.41325923800468445\n",
      "Epoch 7, Loss: 0.26855775713920593\n",
      "Epoch 7, Loss: 0.21416494250297546\n",
      "Epoch 6, Loss: 0.12618198990821838\n",
      "Epoch 4, Loss: 0.03386233001947403\n",
      "Epoch 10, Loss: 0.12313778698444366\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3683944867801793, feed_forward_dim=1024, head_dim=8, lr=0.0009479878012022085, num_heads=4, num_layers=4; total time=   1.0s\n",
      "Epoch 5, Loss: 0.05396079272031784\n",
      "Epoch 9, Loss: 0.17691822350025177\n",
      "Epoch 6, Loss: 0.399203896522522\n",
      "Epoch 8, Loss: 0.04037558659911156\n",
      "Epoch 10, Loss: 0.1555132120847702\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3683944867801793, feed_forward_dim=1024, head_dim=8, lr=0.0009479878012022085, num_heads=4, num_layers=4; total time=   1.1s\n",
      "Epoch 8, Loss: 0.09730932861566544\n",
      "Epoch 8, Loss: 0.08050421625375748\n",
      "Epoch 7, Loss: 0.2173105776309967\n",
      "Epoch 7, Loss: 0.183285653591156\n",
      "Epoch 6, Loss: 0.13968525826931\n",
      "Epoch 10, Loss: 0.11252772063016891\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3683944867801793, feed_forward_dim=1024, head_dim=8, lr=0.0009479878012022085, num_heads=4, num_layers=4; total time=   1.1s\n",
      "Epoch 9, Loss: 0.014637855812907219\n",
      "Epoch 6, Loss: 0.054764315485954285\n",
      "Epoch 9, Loss: 0.023343317210674286\n",
      "Epoch 7, Loss: 0.18960195779800415\n",
      "Epoch 5, Loss: 0.2712203562259674\n",
      "Epoch 8, Loss: 0.05664382502436638\n",
      "Epoch 9, Loss: 0.019425898790359497\n",
      "Epoch 8, Loss: 0.13899970054626465\n",
      "Epoch 10, Loss: 0.06456676870584488\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3683944867801793, feed_forward_dim=1024, head_dim=8, lr=0.0009479878012022085, num_heads=4, num_layers=4; total time=   1.2s\n",
      "Epoch 10, Loss: 0.057425618171691895\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3683944867801793, feed_forward_dim=1024, head_dim=8, lr=0.0009479878012022085, num_heads=4, num_layers=4; total time=   1.2s\n",
      "Epoch 7, Loss: 0.15842421352863312\n",
      "Epoch 7, Loss: 0.05279330909252167\n",
      "Epoch 10, Loss: 0.03821992501616478\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3683944867801793, feed_forward_dim=1024, head_dim=8, lr=0.0009479878012022085, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 9, Loss: 0.02773049660027027\n",
      "Epoch 9, Loss: 0.05813438817858696\n",
      "Epoch 8, Loss: 0.06774279475212097\n",
      "Epoch 6, Loss: 0.34245046973228455\n",
      "Epoch 8, Loss: 0.1950209140777588\n",
      "Epoch 10, Loss: 0.09166373312473297\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3683944867801793, feed_forward_dim=1024, head_dim=8, lr=0.0009479878012022085, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 8, Loss: 0.10158143192529678\n",
      "Epoch 10, Loss: 0.013968251645565033\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3683944867801793, feed_forward_dim=1024, head_dim=8, lr=0.0009479878012022085, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 9, Loss: 0.04294102266430855\n",
      "Epoch 7, Loss: 0.20449276268482208\n",
      "Epoch 9, Loss: 0.14458562433719635\n",
      "Epoch 9, Loss: 0.1830863058567047\n",
      "Epoch 10, Loss: 0.07874644547700882\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3683944867801793, feed_forward_dim=1024, head_dim=8, lr=0.0009479878012022085, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 8, Loss: 0.058160457760095596\n",
      "Epoch 10, Loss: 0.2216578722000122\n",
      "Epoch 10, Loss: 0.06771647930145264\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3683944867801793, feed_forward_dim=1024, head_dim=8, lr=0.0009479878012022085, num_heads=4, num_layers=4; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3683944867801793, feed_forward_dim=1024, head_dim=8, lr=0.0009479878012022085, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Epoch 9, Loss: 0.015489176847040653\n",
      "Epoch 10, Loss: 0.0619201585650444\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3683944867801793, feed_forward_dim=1024, head_dim=8, lr=0.0009479878012022085, num_heads=4, num_layers=4; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 2.449687957763672\n",
      "Epoch 1, Loss: 0.29049402475357056\n",
      "Epoch 1, Loss: 0.5262739062309265\n",
      "Epoch 1, Loss: 0.25496554374694824\n",
      "Epoch 2, Loss: 0.3680747151374817\n",
      "Epoch 1, Loss: 0.6799502372741699\n",
      "Epoch 2, Loss: 0.513325572013855\n",
      "Epoch 1, Loss: 0.1109972819685936\n",
      "Epoch 2, Loss: 0.8030430674552917\n",
      "Epoch 3, Loss: 0.5195794701576233\n",
      "Epoch 1, Loss: 0.6435719132423401\n",
      "Epoch 1, Loss: 2.38476300239563\n",
      "Epoch 2, Loss: 0.5522266626358032\n",
      "Epoch 3, Loss: 0.2347324788570404\n",
      "Epoch 1, Loss: 0.11069546639919281\n",
      "Epoch 2, Loss: 0.12355947494506836\n",
      "Epoch 3, Loss: 0.35060667991638184\n",
      "Epoch 1, Loss: 0.6257745027542114\n",
      "Epoch 2, Loss: 0.3842824101448059\n",
      "Epoch 4, Loss: 0.7668655514717102\n",
      "Epoch 1, Loss: 0.045696619898080826\n",
      "Epoch 3, Loss: 0.16763938963413239\n",
      "Epoch 4, Loss: 0.07864394038915634\n",
      "Epoch 4, Loss: 0.09291953593492508\n",
      "Epoch 2, Loss: 0.6832483410835266\n",
      "Epoch 1, Loss: 0.8358917832374573\n",
      "Epoch 3, Loss: 0.3971360921859741\n",
      "Epoch 2, Loss: 0.2730116546154022\n",
      "Epoch 2, Loss: 0.1545175015926361\n",
      "Epoch 5, Loss: 0.5680007338523865\n",
      "Epoch 2, Loss: 0.36938580870628357\n",
      "Epoch 5, Loss: 0.17369236052036285\n",
      "Epoch 2, Loss: 0.05940850451588631\n",
      "Epoch 4, Loss: 0.07130073755979538\n",
      "Epoch 3, Loss: 0.0350729301571846\n",
      "Epoch 6, Loss: 0.26870450377464294\n",
      "Epoch 5, Loss: 0.19906854629516602\n",
      "Epoch 3, Loss: 0.39964529871940613\n",
      "Epoch 6, Loss: 0.1864510327577591\n",
      "Epoch 3, Loss: 0.1251172125339508\n",
      "Epoch 3, Loss: 0.17897148430347443\n",
      "Epoch 3, Loss: 0.4267377257347107\n",
      "Epoch 5, Loss: 0.19462387263774872\n",
      "Epoch 4, Loss: 0.2398887425661087\n",
      "Epoch 4, Loss: 0.26387444138526917\n",
      "Epoch 6, Loss: 0.25245144963264465\n",
      "Epoch 7, Loss: 0.07436901330947876\n",
      "Epoch 2, Loss: 0.03647482022643089\n",
      "Epoch 7, Loss: 0.0959630161523819\n",
      "Epoch 3, Loss: 0.229669451713562\n",
      "Epoch 4, Loss: 0.24562008678913116\n",
      "Epoch 8, Loss: 0.03137655556201935\n",
      "Epoch 5, Loss: 0.06701335310935974\n",
      "Epoch 6, Loss: 0.17135757207870483\n",
      "Epoch 5, Loss: 0.1512610912322998\n",
      "Epoch 4, Loss: 0.1533966213464737\n",
      "Epoch 7, Loss: 0.15196840465068817\n",
      "Epoch 8, Loss: 0.03297605738043785\n",
      "Epoch 9, Loss: 0.08867625892162323\n",
      "Epoch 4, Loss: 0.059952884912490845\n",
      "Epoch 4, Loss: 0.6016927361488342\n",
      "Epoch 7, Loss: 0.06321647018194199\n",
      "Epoch 5, Loss: 0.06530759483575821\n",
      "Epoch 4, Loss: 0.025886379182338715\n",
      "Epoch 3, Loss: 0.37113702297210693\n",
      "Epoch 6, Loss: 0.017174307256937027\n",
      "Epoch 6, Loss: 0.023548750206828117\n",
      "Epoch 9, Loss: 0.04714937508106232\n",
      "Epoch 8, Loss: 0.044036250561475754\n",
      "Epoch 5, Loss: 0.03692534193396568\n",
      "Epoch 10, Loss: 0.16277220845222473\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.11257485728289256, feed_forward_dim=512, head_dim=16, lr=0.0006256824966203076, num_heads=2, num_layers=1; total time=   0.9s\n",
      "Epoch 6, Loss: 0.03559458255767822\n",
      "Epoch 8, Loss: 0.013584206812083721\n",
      "Epoch 9, Loss: 0.02277739904820919\n",
      "Epoch 10, Loss: 0.08154981583356857\n",
      "Epoch 5, Loss: 0.2386205792427063\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.11257485728289256, feed_forward_dim=512, head_dim=16, lr=0.0006256824966203076, num_heads=2, num_layers=1; total time=   1.0s\n",
      "Epoch 7, Loss: 0.092581607401371\n",
      "Epoch 5, Loss: 0.6223927736282349\n",
      "Epoch 7, Loss: 0.032518744468688965\n",
      "Epoch 4, Loss: 0.32543206214904785\n",
      "Epoch 6, Loss: 0.10364914685487747\n",
      "Epoch 5, Loss: 0.059868305921554565\n",
      "Epoch 7, Loss: 0.10071078687906265\n",
      "Epoch 10, Loss: 0.06662382185459137\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.11257485728289256, feed_forward_dim=512, head_dim=16, lr=0.0006256824966203076, num_heads=2, num_layers=1; total time=   1.0s\n",
      "Epoch 9, Loss: 0.04035874828696251\n",
      "Epoch 8, Loss: 0.10327071696519852\n",
      "Epoch 8, Loss: 0.14270621538162231\n",
      "Epoch 6, Loss: 0.39831259846687317\n",
      "Epoch 6, Loss: 0.20394594967365265\n",
      "Epoch 8, Loss: 0.14277082681655884\n",
      "Epoch 6, Loss: 0.10785737633705139\n",
      "Epoch 7, Loss: 0.15724679827690125\n",
      "Epoch 10, Loss: 0.08161463588476181\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.11257485728289256, feed_forward_dim=512, head_dim=16, lr=0.0006256824966203076, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 9, Loss: 0.098344586789608\n",
      "Epoch 7, Loss: 0.17383411526679993\n",
      "Epoch 5, Loss: 0.1358950138092041\n",
      "Epoch 9, Loss: 0.12137353420257568\n",
      "Epoch 7, Loss: 0.07680531591176987\n",
      "Epoch 9, Loss: 0.12221662700176239\n",
      "Epoch 7, Loss: 0.04657464474439621\n",
      "Epoch 8, Loss: 0.11436331272125244\n",
      "Epoch 10, Loss: 0.0617167092859745\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.11257485728289256, feed_forward_dim=512, head_dim=16, lr=0.0006256824966203076, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 10, Loss: 0.039928682148456573\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.11257485728289256, feed_forward_dim=512, head_dim=16, lr=0.0006256824966203076, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 6, Loss: 0.02354644238948822\n",
      "Epoch 10, Loss: 0.06927891075611115\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.11257485728289256, feed_forward_dim=512, head_dim=16, lr=0.0006256824966203076, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 8, Loss: 0.046185027807950974\n",
      "Epoch 8, Loss: 0.009771119803190231\n",
      "Epoch 8, Loss: 0.005147634539753199\n",
      "Epoch 9, Loss: 0.03877551481127739\n",
      "Epoch 9, Loss: 0.03184068202972412\n",
      "Epoch 9, Loss: 0.027755513787269592\n",
      "Epoch 7, Loss: 0.02836032025516033\n",
      "Epoch 9, Loss: 0.02884608879685402\n",
      "Epoch 10, Loss: 0.008719788864254951\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.11257485728289256, feed_forward_dim=512, head_dim=16, lr=0.0006256824966203076, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 10, Loss: 0.08450029045343399\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.11257485728289256, feed_forward_dim=512, head_dim=16, lr=0.0006256824966203076, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.074092797935009\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.11257485728289256, feed_forward_dim=512, head_dim=16, lr=0.0006256824966203076, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 8, Loss: 0.08595762401819229\n",
      "Epoch 10, Loss: 0.05533178150653839\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.11257485728289256, feed_forward_dim=512, head_dim=16, lr=0.0006256824966203076, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 9, Loss: 0.12577953934669495\n",
      "Epoch 10, Loss: 0.11777949333190918\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.11257485728289256, feed_forward_dim=512, head_dim=16, lr=0.0006256824966203076, num_heads=2, num_layers=1; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.23291052877902985\n",
      "Epoch 1, Loss: 0.11725318431854248\n",
      "Epoch 1, Loss: 0.0645289495587349\n",
      "Epoch 1, Loss: 0.3510792851448059\n",
      "Epoch 1, Loss: 1.868849515914917\n",
      "Epoch 2, Loss: 0.23187653720378876\n",
      "Epoch 1, Loss: 0.7350868582725525\n",
      "Epoch 1, Loss: 1.793580412864685\n",
      "Epoch 2, Loss: 0.4014839231967926\n",
      "Epoch 1, Loss: 0.7667023539543152\n",
      "Epoch 2, Loss: 0.5071276426315308\n",
      "Epoch 3, Loss: 0.18010066449642181\n",
      "Epoch 1, Loss: 0.224844291806221\n",
      "Epoch 2, Loss: 0.2656804621219635\n",
      "Epoch 3, Loss: 0.08537878096103668\n",
      "Epoch 2, Loss: 0.31471675634384155\n",
      "Epoch 2, Loss: 0.10514084994792938\n",
      "Epoch 1, Loss: 0.6000961661338806\n",
      "Epoch 1, Loss: 0.18871046602725983\n",
      "Epoch 3, Loss: 0.04666857421398163\n",
      "Epoch 2, Loss: 0.4031616449356079\n",
      "Epoch 2, Loss: 0.0691802129149437\n",
      "Epoch 4, Loss: 0.08060415089130402\n",
      "Epoch 1, Loss: 0.27172812819480896\n",
      "Epoch 4, Loss: 0.04218103364109993\n",
      "Epoch 3, Loss: 0.07066156715154648\n",
      "Epoch 3, Loss: 0.22118166089057922\n",
      "Epoch 2, Loss: 0.07435819506645203\n",
      "Epoch 4, Loss: 0.16552512347698212\n",
      "Epoch 3, Loss: 0.28338876366615295\n",
      "Epoch 2, Loss: 0.30814850330352783\n",
      "Epoch 5, Loss: 0.17349402606487274\n",
      "Epoch 2, Loss: 0.2594442367553711\n",
      "Epoch 3, Loss: 0.05419081449508667\n",
      "Epoch 3, Loss: 0.25662878155708313\n",
      "Epoch 4, Loss: 0.4154975116252899\n",
      "Epoch 5, Loss: 0.04590075463056564\n",
      "Epoch 4, Loss: 0.08053160458803177\n",
      "Epoch 5, Loss: 0.27172020077705383\n",
      "Epoch 2, Loss: 0.11649590730667114\n",
      "Epoch 6, Loss: 0.11271847784519196\n",
      "Epoch 4, Loss: 0.3351665139198303\n",
      "Epoch 3, Loss: 0.29299646615982056\n",
      "Epoch 5, Loss: 0.5212451219558716\n",
      "Epoch 3, Loss: 0.05931652709841728\n",
      "Epoch 3, Loss: 0.1612650752067566\n",
      "Epoch 6, Loss: 0.09580490738153458\n",
      "Epoch 4, Loss: 0.3428385853767395\n",
      "Epoch 6, Loss: 0.1561516672372818\n",
      "Epoch 4, Loss: 0.2874372601509094\n",
      "Epoch 5, Loss: 0.06880559772253036\n",
      "Epoch 7, Loss: 0.030999459326267242\n",
      "Epoch 3, Loss: 0.19715575873851776\n",
      "Epoch 5, Loss: 0.20774710178375244\n",
      "Epoch 6, Loss: 0.3876599073410034\n",
      "Epoch 4, Loss: 0.2670081555843353\n",
      "Epoch 7, Loss: 0.07404385507106781\n",
      "Epoch 5, Loss: 0.22939644753932953\n",
      "Epoch 7, Loss: 0.03593761846423149\n",
      "Epoch 6, Loss: 0.09635436534881592\n",
      "Epoch 4, Loss: 0.12319730967283249\n",
      "Epoch 8, Loss: 0.021072760224342346\n",
      "Epoch 4, Loss: 0.03524838387966156\n",
      "Epoch 5, Loss: 0.4598666727542877\n",
      "Epoch 8, Loss: 0.02354956977069378\n",
      "Epoch 7, Loss: 0.19126276671886444\n",
      "Epoch 6, Loss: 0.08229335397481918\n",
      "Epoch 4, Loss: 0.08361881971359253\n",
      "Epoch 8, Loss: 0.026025721803307533\n",
      "Epoch 9, Loss: 0.06076854467391968\n",
      "Epoch 6, Loss: 0.0915955975651741\n",
      "Epoch 7, Loss: 0.06945106387138367\n",
      "Epoch 5, Loss: 0.11549179255962372\n",
      "Epoch 5, Loss: 0.08977875858545303\n",
      "Epoch 9, Loss: 0.011392471380531788\n",
      "Epoch 6, Loss: 0.43354788422584534\n",
      "Epoch 5, Loss: 0.09161927551031113\n",
      "Epoch 8, Loss: 0.05299197509884834\n",
      "Epoch 7, Loss: 0.040218379348516464\n",
      "Epoch 9, Loss: 0.08588094264268875\n",
      "Epoch 8, Loss: 0.02100219950079918\n",
      "Epoch 10, Loss: 0.08171161264181137\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16852505988682576, feed_forward_dim=128, head_dim=32, lr=0.0004694309462271324, num_heads=2, num_layers=1; total time=   1.0s\n",
      "Epoch 10, Loss: 0.03691558912396431\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16852505988682576, feed_forward_dim=128, head_dim=32, lr=0.0004694309462271324, num_heads=2, num_layers=1; total time=   1.0s\n",
      "Epoch 5, Loss: 0.01474952045828104\n",
      "Epoch 6, Loss: 0.02216934971511364\n",
      "Epoch 6, Loss: 0.022902151569724083\n",
      "Epoch 8, Loss: 0.07057090103626251\n",
      "Epoch 7, Loss: 0.02870539203286171\n",
      "Epoch 10, Loss: 0.12021803855895996\n",
      "Epoch 6, Loss: 0.11799629032611847\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16852505988682576, feed_forward_dim=128, head_dim=32, lr=0.0004694309462271324, num_heads=2, num_layers=1; total time=   1.1s\n",
      "Epoch 9, Loss: 0.01016040239483118\n",
      "Epoch 9, Loss: 0.006195013877004385\n",
      "Epoch 7, Loss: 0.29895567893981934\n",
      "Epoch 7, Loss: 0.0366026796400547\n",
      "Epoch 10, Loss: 0.033153124153614044\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16852505988682576, feed_forward_dim=128, head_dim=32, lr=0.0004694309462271324, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 8, Loss: 0.047637779265642166\n",
      "Epoch 10, Loss: 0.03141921013593674\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16852505988682576, feed_forward_dim=128, head_dim=32, lr=0.0004694309462271324, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 9, Loss: 0.11643092334270477\n",
      "Epoch 7, Loss: 0.06131511181592941\n",
      "Epoch 7, Loss: 0.026270072907209396\n",
      "Epoch 8, Loss: 0.15658512711524963\n",
      "Epoch 6, Loss: 0.04897802323102951\n",
      "Epoch 8, Loss: 0.0936630442738533\n",
      "Epoch 10, Loss: 0.1256246566772461\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16852505988682576, feed_forward_dim=128, head_dim=32, lr=0.0004694309462271324, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 9, Loss: 0.059334367513656616\n",
      "Epoch 8, Loss: 0.012579825706779957\n",
      "Epoch 9, Loss: 0.09915601462125778\n",
      "Epoch 8, Loss: 0.06002584099769592\n",
      "Epoch 7, Loss: 0.08628267794847488\n",
      "Epoch 9, Loss: 0.11507143080234528\n",
      "Epoch 10, Loss: 0.022940436378121376\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16852505988682576, feed_forward_dim=128, head_dim=32, lr=0.0004694309462271324, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 10, Loss: 0.12695005536079407\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16852505988682576, feed_forward_dim=128, head_dim=32, lr=0.0004694309462271324, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 9, Loss: 0.023930074647068977\n",
      "Epoch 9, Loss: 0.0479486808180809\n",
      "Epoch 8, Loss: 0.06772094964981079\n",
      "Epoch 10, Loss: 0.09103210270404816\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16852505988682576, feed_forward_dim=128, head_dim=32, lr=0.0004694309462271324, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 10, Loss: 0.05768546089529991\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16852505988682576, feed_forward_dim=128, head_dim=32, lr=0.0004694309462271324, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.018403558060526848\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16852505988682576, feed_forward_dim=128, head_dim=32, lr=0.0004694309462271324, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 9, Loss: 0.024203963577747345\n",
      "Epoch 10, Loss: 0.006864992436021566\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16852505988682576, feed_forward_dim=128, head_dim=32, lr=0.0004694309462271324, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 2.354269504547119\n",
      "Epoch 1, Loss: 0.5558109879493713\n",
      "Epoch 1, Loss: 0.29240959882736206\n",
      "Epoch 1, Loss: 0.27936115860939026\n",
      "Epoch 2, Loss: 0.4450947642326355\n",
      "Epoch 1, Loss: 0.18356508016586304\n",
      "Epoch 2, Loss: 2.162235736846924\n",
      "Epoch 1, Loss: 0.20222888886928558\n",
      "Epoch 1, Loss: 1.3348575830459595\n",
      "Epoch 1, Loss: 0.12917865812778473\n",
      "Epoch 3, Loss: 0.9333661794662476\n",
      "Epoch 2, Loss: 1.754124402999878\n",
      "Epoch 2, Loss: 2.5447022914886475\n",
      "Epoch 3, Loss: 0.7489340305328369\n",
      "Epoch 2, Loss: 3.5403573513031006\n",
      "Epoch 1, Loss: 0.18162834644317627\n",
      "Epoch 1, Loss: 0.17674018442630768\n",
      "Epoch 2, Loss: 1.9111977815628052\n",
      "Epoch 2, Loss: 0.4836745262145996\n",
      "Epoch 1, Loss: 0.03798928111791611\n",
      "Epoch 4, Loss: 0.4738157093524933\n",
      "Epoch 2, Loss: 1.4922655820846558\n",
      "Epoch 4, Loss: 0.04754970595240593\n",
      "Epoch 3, Loss: 0.6150174736976624\n",
      "Epoch 1, Loss: 0.7223495841026306\n",
      "Epoch 3, Loss: 0.4465169310569763\n",
      "Epoch 3, Loss: 0.420999675989151\n",
      "Epoch 3, Loss: 0.6870576739311218\n",
      "Epoch 2, Loss: 2.969621181488037\n",
      "Epoch 5, Loss: 0.09586914628744125\n",
      "Epoch 3, Loss: 0.028368545696139336\n",
      "Epoch 5, Loss: 0.27060747146606445\n",
      "Epoch 2, Loss: 1.7358280420303345\n",
      "Epoch 2, Loss: 0.37031710147857666\n",
      "Epoch 4, Loss: 0.040445469319820404\n",
      "Epoch 3, Loss: 0.5627238154411316\n",
      "Epoch 2, Loss: 1.3460066318511963\n",
      "Epoch 4, Loss: 0.04724612832069397\n",
      "Epoch 4, Loss: 0.12254314124584198\n",
      "Epoch 5, Loss: 0.21719975769519806\n",
      "Epoch 6, Loss: 0.07009425014257431\n",
      "Epoch 4, Loss: 0.0828324630856514\n",
      "Epoch 6, Loss: 0.4829166531562805\n",
      "Epoch 3, Loss: 0.5407137870788574\n",
      "Epoch 4, Loss: 0.7132594585418701\n",
      "Epoch 4, Loss: 0.21558907628059387\n",
      "Epoch 3, Loss: 0.46905314922332764\n",
      "Epoch 7, Loss: 0.20446400344371796\n",
      "Epoch 7, Loss: 0.3775564730167389\n",
      "Epoch 5, Loss: 0.5304509401321411\n",
      "Epoch 5, Loss: 0.4168815612792969\n",
      "Epoch 3, Loss: 0.8605066537857056\n",
      "Epoch 5, Loss: 0.672929048538208\n",
      "Epoch 3, Loss: 0.6071531772613525\n",
      "Epoch 6, Loss: 0.39197179675102234\n",
      "Epoch 5, Loss: 0.03568001464009285\n",
      "Epoch 5, Loss: 0.4716673791408539\n",
      "Epoch 8, Loss: 0.16597850620746613\n",
      "Epoch 8, Loss: 0.27243655920028687\n",
      "Epoch 4, Loss: 0.09055129438638687\n",
      "Epoch 6, Loss: 0.4511663019657135\n",
      "Epoch 4, Loss: 0.025163564831018448\n",
      "Epoch 4, Loss: 0.28516411781311035\n",
      "Epoch 6, Loss: 0.7437421679496765\n",
      "Epoch 6, Loss: 0.5483421087265015\n",
      "Epoch 7, Loss: 0.31497350335121155\n",
      "Epoch 9, Loss: 0.23312513530254364\n",
      "Epoch 4, Loss: 0.06013637036085129\n",
      "Epoch 9, Loss: 0.040899522602558136\n",
      "Epoch 6, Loss: 0.057124245911836624\n",
      "Epoch 6, Loss: 0.0886458232998848\n",
      "Epoch 7, Loss: 0.23559260368347168\n",
      "Epoch 5, Loss: 0.5418453216552734\n",
      "Epoch 7, Loss: 0.31359022855758667\n",
      "Epoch 8, Loss: 0.15491196513175964\n",
      "Epoch 7, Loss: 0.419940710067749\n",
      "Epoch 5, Loss: 0.30076268315315247\n",
      "Epoch 10, Loss: 0.13817425072193146\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1184408823530442, feed_forward_dim=1024, head_dim=8, lr=0.0012932614391358494, num_heads=4, num_layers=2; total time=   1.0s\n",
      "Epoch 10, Loss: 0.048967793583869934\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1184408823530442, feed_forward_dim=1024, head_dim=8, lr=0.0012932614391358494, num_heads=4, num_layers=2; total time=   1.0s\n",
      "Epoch 7, Loss: 0.143222838640213\n",
      "Epoch 5, Loss: 0.012243885546922684\n",
      "Epoch 5, Loss: 0.09684513509273529\n",
      "Epoch 7, Loss: 0.03578070178627968\n",
      "Epoch 6, Loss: 0.5747861862182617\n",
      "Epoch 8, Loss: 0.06481050699949265\n",
      "Epoch 8, Loss: 0.10050392150878906\n",
      "Epoch 9, Loss: 0.05055792257189751\n",
      "Epoch 8, Loss: 0.12337219715118408\n",
      "Epoch 6, Loss: 0.4225626587867737\n",
      "Epoch 8, Loss: 0.17564217746257782\n",
      "Epoch 6, Loss: 0.20824116468429565\n",
      "Epoch 9, Loss: 0.030101047828793526\n",
      "Epoch 8, Loss: 0.17294423282146454\n",
      "Epoch 6, Loss: 0.2671002745628357\n",
      "Epoch 7, Loss: 0.3338030278682709\n",
      "Epoch 10, Loss: 0.03838391229510307\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1184408823530442, feed_forward_dim=1024, head_dim=8, lr=0.0012932614391358494, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 9, Loss: 0.13764652609825134\n",
      "Epoch 9, Loss: 0.0293636042624712\n",
      "Epoch 9, Loss: 0.03640728071331978\n",
      "Epoch 7, Loss: 0.2806369960308075\n",
      "Epoch 10, Loss: 0.09024447202682495\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1184408823530442, feed_forward_dim=1024, head_dim=8, lr=0.0012932614391358494, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 9, Loss: 0.240976944565773\n",
      "Epoch 7, Loss: 0.2489447295665741\n",
      "Epoch 10, Loss: 0.0942278727889061\n",
      "Epoch 8, Loss: 0.11226402968168259\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1184408823530442, feed_forward_dim=1024, head_dim=8, lr=0.0012932614391358494, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 10, Loss: 0.07460703700780869\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1184408823530442, feed_forward_dim=1024, head_dim=8, lr=0.0012932614391358494, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 8, Loss: 0.1095540001988411\n",
      "Epoch 10, Loss: 0.1031835675239563\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1184408823530442, feed_forward_dim=1024, head_dim=8, lr=0.0012932614391358494, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 7, Loss: 0.2871011793613434\n",
      "Epoch 10, Loss: 0.192082017660141\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1184408823530442, feed_forward_dim=1024, head_dim=8, lr=0.0012932614391358494, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 8, Loss: 0.119476817548275\n",
      "Epoch 9, Loss: 0.030703239142894745\n",
      "Epoch 9, Loss: 0.03194015100598335\n",
      "Epoch 8, Loss: 0.18361124396324158\n",
      "Epoch 9, Loss: 0.02671569399535656\n",
      "Epoch 10, Loss: 0.06673131883144379\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1184408823530442, feed_forward_dim=1024, head_dim=8, lr=0.0012932614391358494, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 10, Loss: 0.0508773997426033\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1184408823530442, feed_forward_dim=1024, head_dim=8, lr=0.0012932614391358494, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 0.07553217560052872\n",
      "Epoch 10, Loss: 0.041287198662757874\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1184408823530442, feed_forward_dim=1024, head_dim=8, lr=0.0012932614391358494, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.031049612909555435\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1184408823530442, feed_forward_dim=1024, head_dim=8, lr=0.0012932614391358494, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.8937679529190063\n",
      "Epoch 1, Loss: 0.7931320667266846\n",
      "Epoch 1, Loss: 1.0383028984069824\n",
      "Epoch 1, Loss: 1.0164092779159546\n",
      "Epoch 1, Loss: 0.8223833441734314\n",
      "Epoch 1, Loss: 1.2728979587554932\n",
      "Epoch 2, Loss: 0.7246875762939453\n",
      "Epoch 1, Loss: 0.08814245462417603\n",
      "Epoch 1, Loss: 0.9808587431907654\n",
      "Epoch 2, Loss: 0.6455151438713074\n",
      "Epoch 2, Loss: 0.8374916911125183\n",
      "Epoch 1, Loss: 1.043163537979126\n",
      "Epoch 3, Loss: 0.5669949054718018\n",
      "Epoch 2, Loss: 0.6492698788642883\n",
      "Epoch 1, Loss: 0.12447333335876465\n",
      "Epoch 3, Loss: 0.5149160027503967\n",
      "Epoch 2, Loss: 0.8563758134841919\n",
      "Epoch 2, Loss: 1.0941824913024902\n",
      "Epoch 3, Loss: 0.6620063781738281\n",
      "Epoch 4, Loss: 0.4277765452861786\n",
      "Epoch 2, Loss: 0.04246975854039192\n",
      "Epoch 1, Loss: 0.22492538392543793\n",
      "Epoch 2, Loss: 0.8026742339134216\n",
      "Epoch 2, Loss: 0.8981066346168518\n",
      "Epoch 4, Loss: 0.41279661655426025\n",
      "Epoch 1, Loss: 0.09104927629232407\n",
      "Epoch 2, Loss: 0.07329610735177994\n",
      "Epoch 3, Loss: 0.509667158126831\n",
      "Epoch 5, Loss: 0.3116529881954193\n",
      "Epoch 3, Loss: 0.7081627249717712\n",
      "Epoch 4, Loss: 0.5055725574493408\n",
      "Epoch 3, Loss: 0.9178734421730042\n",
      "Epoch 5, Loss: 0.32526499032974243\n",
      "Epoch 3, Loss: 0.02203451469540596\n",
      "Epoch 3, Loss: 0.6441413760185242\n",
      "Epoch 6, Loss: 0.21711736917495728\n",
      "Epoch 4, Loss: 0.38753917813301086\n",
      "Epoch 4, Loss: 0.5790923237800598\n",
      "Epoch 5, Loss: 0.37140825390815735\n",
      "Epoch 3, Loss: 0.7706688642501831\n",
      "Epoch 2, Loss: 0.19751623272895813\n",
      "Epoch 3, Loss: 0.03811654448509216\n",
      "Epoch 2, Loss: 0.06124650686979294\n",
      "Epoch 6, Loss: 0.2494027316570282\n",
      "Epoch 7, Loss: 0.14312557876110077\n",
      "Epoch 4, Loss: 0.7634706497192383\n",
      "Epoch 4, Loss: 0.019427843391895294\n",
      "Epoch 4, Loss: 0.508519172668457\n",
      "Epoch 5, Loss: 0.4609823524951935\n",
      "Epoch 6, Loss: 0.26761943101882935\n",
      "Epoch 5, Loss: 0.28396934270858765\n",
      "Epoch 7, Loss: 0.19999979436397552\n",
      "Epoch 4, Loss: 0.6522618532180786\n",
      "Epoch 3, Loss: 0.18149949610233307\n",
      "Epoch 4, Loss: 0.0200677290558815\n",
      "Epoch 8, Loss: 0.08591297268867493\n",
      "Epoch 3, Loss: 0.04472523182630539\n",
      "Epoch 5, Loss: 0.6196414828300476\n",
      "Epoch 5, Loss: 0.026302015408873558\n",
      "Epoch 6, Loss: 0.3651786148548126\n",
      "Epoch 5, Loss: 0.38889631628990173\n",
      "Epoch 8, Loss: 0.1630999743938446\n",
      "Epoch 7, Loss: 0.19110961258411407\n",
      "Epoch 6, Loss: 0.2029111087322235\n",
      "Epoch 9, Loss: 0.047479305416345596\n",
      "Epoch 4, Loss: 0.17400512099266052\n",
      "Epoch 5, Loss: 0.014446166343986988\n",
      "Epoch 5, Loss: 0.5480309724807739\n",
      "Epoch 6, Loss: 0.49796783924102783\n",
      "Epoch 10, Loss: 0.02296522445976734\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2963877913574814, feed_forward_dim=128, head_dim=8, lr=5.082414830665636e-05, num_heads=2, num_layers=3; total time=   0.9s\n",
      "Epoch 6, Loss: 0.28679537773132324\n",
      "Epoch 6, Loss: 0.03330915793776512\n",
      "Epoch 7, Loss: 0.13830158114433289\n",
      "Epoch 8, Loss: 0.14028306305408478\n",
      "Epoch 7, Loss: 0.2824991047382355\n",
      "Epoch 4, Loss: 0.03870773687958717\n",
      "Epoch 9, Loss: 0.1483352780342102\n",
      "Epoch 6, Loss: 0.4529331922531128\n",
      "Epoch 8, Loss: 0.0970306470990181\n",
      "Epoch 7, Loss: 0.38606444001197815\n",
      "Epoch 9, Loss: 0.1055469736456871\n",
      "Epoch 5, Loss: 0.1625422239303589\n",
      "Epoch 7, Loss: 0.035598915070295334\n",
      "Epoch 7, Loss: 0.20210617780685425\n",
      "Epoch 10, Loss: 0.1354839950799942\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2963877913574814, feed_forward_dim=128, head_dim=8, lr=5.082414830665636e-05, num_heads=2, num_layers=3; total time=   1.0s\n",
      "Epoch 6, Loss: 0.01766497828066349\n",
      "Epoch 8, Loss: 0.2126394659280777\n",
      "Epoch 10, Loss: 0.08899611979722977\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2963877913574814, feed_forward_dim=128, head_dim=8, lr=5.082414830665636e-05, num_heads=2, num_layers=3; total time=   1.1s\n",
      "Epoch 5, Loss: 0.03844863176345825\n",
      "Epoch 7, Loss: 0.3717801868915558\n",
      "Epoch 9, Loss: 0.0703120157122612\n",
      "Epoch 8, Loss: 0.031483981758356094\n",
      "Epoch 8, Loss: 0.29028019309043884\n",
      "Epoch 6, Loss: 0.15270598232746124\n",
      "Epoch 8, Loss: 0.13764919340610504\n",
      "Epoch 9, Loss: 0.16260291635990143\n",
      "Epoch 10, Loss: 0.05612093582749367\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2963877913574814, feed_forward_dim=128, head_dim=8, lr=5.082414830665636e-05, num_heads=2, num_layers=3; total time=   1.2s\n",
      "Epoch 6, Loss: 0.03975491225719452\n",
      "Epoch 8, Loss: 0.3090766370296478\n",
      "Epoch 7, Loss: 0.02364150993525982\n",
      "Epoch 9, Loss: 0.21173407137393951\n",
      "Epoch 9, Loss: 0.02348690666258335\n",
      "Epoch 10, Loss: 0.11944656074047089\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2963877913574814, feed_forward_dim=128, head_dim=8, lr=5.082414830665636e-05, num_heads=2, num_layers=3; total time=   1.3s\n",
      "Epoch 7, Loss: 0.14228010177612305\n",
      "Epoch 9, Loss: 0.08941800892353058\n",
      "Epoch 10, Loss: 0.14835400879383087\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2963877913574814, feed_forward_dim=128, head_dim=8, lr=5.082414830665636e-05, num_heads=2, num_layers=3; total time=   1.3s\n",
      "Epoch 7, Loss: 0.038530703634023666\n",
      "Epoch 8, Loss: 0.02992326207458973\n",
      "Epoch 10, Loss: 0.017791666090488434\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2963877913574814, feed_forward_dim=128, head_dim=8, lr=5.082414830665636e-05, num_heads=2, num_layers=3; total time=   1.3s\n",
      "Epoch 9, Loss: 0.25040411949157715\n",
      "Epoch 10, Loss: 0.05551333352923393\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2963877913574814, feed_forward_dim=128, head_dim=8, lr=5.082414830665636e-05, num_heads=2, num_layers=3; total time=   1.3s\n",
      "Epoch 8, Loss: 0.13256603479385376\n",
      "Epoch 9, Loss: 0.033412136137485504\n",
      "Epoch 8, Loss: 0.03543209657073021\n",
      "Epoch 10, Loss: 0.20829597115516663\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2963877913574814, feed_forward_dim=128, head_dim=8, lr=5.082414830665636e-05, num_heads=2, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.12429311126470566\n",
      "Epoch 10, Loss: 0.031131945550441742\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2963877913574814, feed_forward_dim=128, head_dim=8, lr=5.082414830665636e-05, num_heads=2, num_layers=3; total time=   1.5s\n",
      "Epoch 9, Loss: 0.030414052307605743\n",
      "Epoch 10, Loss: 0.11386597901582718\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2963877913574814, feed_forward_dim=128, head_dim=8, lr=5.082414830665636e-05, num_heads=2, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.02391839027404785\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2963877913574814, feed_forward_dim=128, head_dim=8, lr=5.082414830665636e-05, num_heads=2, num_layers=3; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.1182999536395073\n",
      "Epoch 1, Loss: 0.12291152775287628\n",
      "Epoch 1, Loss: 0.32965895533561707\n",
      "Epoch 1, Loss: 0.5065744519233704\n",
      "Epoch 1, Loss: 0.2996285855770111\n",
      "Epoch 1, Loss: 0.2877194881439209\n",
      "Epoch 1, Loss: 0.32902243733406067\n",
      "Epoch 2, Loss: 1.6288237571716309\n",
      "Epoch 2, Loss: 1.6679538488388062\n",
      "Epoch 1, Loss: 0.1908772587776184\n",
      "Epoch 2, Loss: 1.640581488609314\n",
      "Epoch 2, Loss: 1.0768929719924927\n",
      "Epoch 3, Loss: 0.036608755588531494\n",
      "Epoch 2, Loss: 1.2324860095977783\n",
      "Epoch 2, Loss: 0.8493977785110474\n",
      "Epoch 3, Loss: 0.08740302920341492\n",
      "Epoch 3, Loss: 0.43461522459983826\n",
      "Epoch 2, Loss: 1.2785307168960571\n",
      "Epoch 1, Loss: 0.11760938167572021\n",
      "Epoch 1, Loss: 0.09545137733221054\n",
      "Epoch 1, Loss: 0.5403940081596375\n",
      "Epoch 3, Loss: 0.535535454750061\n",
      "Epoch 2, Loss: 1.9369900226593018\n",
      "Epoch 4, Loss: 0.05516943335533142\n",
      "Epoch 4, Loss: 0.4680529236793518\n",
      "Epoch 3, Loss: 0.29944485425949097\n",
      "Epoch 4, Loss: 0.6238056421279907\n",
      "Epoch 1, Loss: 2.152284860610962\n",
      "Epoch 3, Loss: 0.393892377614975\n",
      "Epoch 3, Loss: 0.29008784890174866\n",
      "Epoch 4, Loss: 0.041505299508571625\n",
      "Epoch 5, Loss: 0.3783477246761322\n",
      "Epoch 2, Loss: 1.399308443069458\n",
      "Epoch 2, Loss: 1.9950560331344604\n",
      "Epoch 5, Loss: 0.6148076057434082\n",
      "Epoch 5, Loss: 0.6446546912193298\n",
      "Epoch 4, Loss: 0.028829986229538918\n",
      "Epoch 4, Loss: 0.07549932599067688\n",
      "Epoch 2, Loss: 0.10723164677619934\n",
      "Epoch 2, Loss: 1.8885916471481323\n",
      "Epoch 3, Loss: 0.42012184858322144\n",
      "Epoch 6, Loss: 0.4292517602443695\n",
      "Epoch 6, Loss: 0.2723855674266815\n",
      "Epoch 4, Loss: 0.0697554424405098\n",
      "Epoch 5, Loss: 0.1278429627418518\n",
      "Epoch 5, Loss: 0.1529516577720642\n",
      "Epoch 6, Loss: 0.2597782611846924\n",
      "Epoch 5, Loss: 0.3113803565502167\n",
      "Epoch 7, Loss: 0.21908381581306458\n",
      "Epoch 3, Loss: 0.4907841384410858\n",
      "Epoch 3, Loss: 0.35066521167755127\n",
      "Epoch 4, Loss: 0.0687173381447792\n",
      "Epoch 3, Loss: 0.717228353023529\n",
      "Epoch 3, Loss: 0.28887131810188293\n",
      "Epoch 5, Loss: 0.3297436833381653\n",
      "Epoch 6, Loss: 0.31277573108673096\n",
      "Epoch 7, Loss: 0.04246563836932182\n",
      "Epoch 8, Loss: 0.04698658734560013\n",
      "Epoch 6, Loss: 0.23535026609897614\n",
      "Epoch 7, Loss: 0.03418927639722824\n",
      "Epoch 5, Loss: 0.4817584753036499\n",
      "Epoch 4, Loss: 0.04758639261126518\n",
      "Epoch 6, Loss: 0.3600315451622009\n",
      "Epoch 9, Loss: 0.030684683471918106\n",
      "Epoch 4, Loss: 0.5595131516456604\n",
      "Epoch 6, Loss: 0.3442405164241791\n",
      "Epoch 8, Loss: 0.02099771983921528\n",
      "Epoch 7, Loss: 0.27734988927841187\n",
      "Epoch 4, Loss: 0.1590137481689453\n",
      "Epoch 4, Loss: 0.12913629412651062\n",
      "Epoch 7, Loss: 0.21082592010498047\n",
      "Epoch 7, Loss: 0.17153707146644592\n",
      "Epoch 10, Loss: 0.10990512371063232\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1685680446237222, feed_forward_dim=1024, head_dim=8, lr=0.0010134299887981368, num_heads=2, num_layers=1; total time=   1.0s\n",
      "Epoch 6, Loss: 0.49285855889320374\n",
      "Epoch 8, Loss: 0.052709974348545074\n",
      "Epoch 7, Loss: 0.18305054306983948\n",
      "Epoch 9, Loss: 0.10297718644142151\n",
      "Epoch 5, Loss: 0.250249981880188\n",
      "Epoch 5, Loss: 0.20434072613716125\n",
      "Epoch 8, Loss: 0.12204186618328094\n",
      "Epoch 9, Loss: 0.1591038852930069\n",
      "Epoch 5, Loss: 0.5631186366081238\n",
      "Epoch 10, Loss: 0.16432218253612518\n",
      "Epoch 7, Loss: 0.24978962540626526\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1685680446237222, feed_forward_dim=1024, head_dim=8, lr=0.0010134299887981368, num_heads=2, num_layers=1; total time=   1.1s\n",
      "Epoch 8, Loss: 0.048390112817287445\n",
      "Epoch 5, Loss: 0.5682289004325867\n",
      "Epoch 8, Loss: 0.06683126091957092\n",
      "Epoch 8, Loss: 0.0776975154876709\n",
      "Epoch 10, Loss: 0.22444288432598114\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1685680446237222, feed_forward_dim=1024, head_dim=8, lr=0.0010134299887981368, num_heads=2, num_layers=1; total time=   1.1s\n",
      "Epoch 6, Loss: 0.027746545150876045\n",
      "Epoch 6, Loss: 0.3682343065738678\n",
      "Epoch 9, Loss: 0.020560378208756447\n",
      "Epoch 9, Loss: 0.027084609493613243\n",
      "Epoch 6, Loss: 0.48801323771476746\n",
      "Epoch 9, Loss: 0.044024039059877396\n",
      "Epoch 9, Loss: 0.016594525426626205\n",
      "Epoch 8, Loss: 0.059766899794340134\n",
      "Epoch 6, Loss: 0.47297433018684387\n",
      "Epoch 10, Loss: 0.026653941720724106\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1685680446237222, feed_forward_dim=1024, head_dim=8, lr=0.0010134299887981368, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 7, Loss: 0.2501019835472107\n",
      "Epoch 7, Loss: 0.06445477157831192\n",
      "Epoch 10, Loss: 0.03094978630542755\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1685680446237222, feed_forward_dim=1024, head_dim=8, lr=0.0010134299887981368, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 10, Loss: 0.08365543931722641\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1685680446237222, feed_forward_dim=1024, head_dim=8, lr=0.0010134299887981368, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 10, Loss: 0.08261716365814209\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1685680446237222, feed_forward_dim=1024, head_dim=8, lr=0.0010134299887981368, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 7, Loss: 0.20890097320079803\n",
      "Epoch 9, Loss: 0.02774246223270893\n",
      "Epoch 7, Loss: 0.19266851246356964\n",
      "Epoch 8, Loss: 0.0880122259259224\n",
      "Epoch 10, Loss: 0.09574238955974579\n",
      "Epoch 8, Loss: 0.17091359198093414\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1685680446237222, feed_forward_dim=1024, head_dim=8, lr=0.0010134299887981368, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 8, Loss: 0.034124746918678284\n",
      "Epoch 8, Loss: 0.03707922622561455\n",
      "Epoch 9, Loss: 0.018138879910111427\n",
      "Epoch 9, Loss: 0.2199842631816864\n",
      "Epoch 9, Loss: 0.04345189034938812\n",
      "Epoch 9, Loss: 0.04058126360177994\n",
      "Epoch 10, Loss: 0.05075988546013832\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1685680446237222, feed_forward_dim=1024, head_dim=8, lr=0.0010134299887981368, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.12068377435207367\n",
      "Epoch 10, Loss: 0.19189763069152832\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1685680446237222, feed_forward_dim=1024, head_dim=8, lr=0.0010134299887981368, num_heads=2, num_layers=1; total time=   1.6s\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1685680446237222, feed_forward_dim=1024, head_dim=8, lr=0.0010134299887981368, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.13743595778942108\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1685680446237222, feed_forward_dim=1024, head_dim=8, lr=0.0010134299887981368, num_heads=2, num_layers=1; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.07663776725530624\n",
      "Epoch 1, Loss: 0.14185193181037903\n",
      "Epoch 1, Loss: 0.264703631401062\n",
      "Epoch 1, Loss: 2.1684982776641846\n",
      "Epoch 2, Loss: 11.270844459533691\n",
      "Epoch 1, Loss: 0.14798860251903534\n",
      "Epoch 2, Loss: 9.332198143005371\n",
      "Epoch 2, Loss: 8.13198184967041\n",
      "Epoch 1, Loss: 0.3398277759552002\n",
      "Epoch 2, Loss: 5.511721134185791\n",
      "Epoch 1, Loss: 0.987376868724823\n",
      "Epoch 1, Loss: 0.38028833270072937\n",
      "Epoch 1, Loss: 0.5812175273895264\n",
      "Epoch 3, Loss: 0.8458589911460876\n",
      "Epoch 3, Loss: 1.6347758769989014\n",
      "Epoch 3, Loss: 2.094653844833374\n",
      "Epoch 1, Loss: 0.13214312493801117\n",
      "Epoch 2, Loss: 6.818212509155273\n",
      "Epoch 2, Loss: 7.713345527648926\n",
      "Epoch 3, Loss: 2.0526976585388184\n",
      "Epoch 1, Loss: 0.40996551513671875\n",
      "Epoch 1, Loss: 0.14595791697502136\n",
      "Epoch 4, Loss: 0.09605386853218079\n",
      "Epoch 4, Loss: 0.8579391837120056\n",
      "Epoch 2, Loss: 9.05941104888916\n",
      "Epoch 2, Loss: 8.68345832824707\n",
      "Epoch 2, Loss: 8.541280746459961\n",
      "Epoch 4, Loss: 0.2022782266139984\n",
      "Epoch 4, Loss: 0.2660374939441681\n",
      "Epoch 2, Loss: 13.005803108215332\n",
      "Epoch 5, Loss: 0.8789260983467102\n",
      "Epoch 3, Loss: 2.159353256225586\n",
      "Epoch 3, Loss: 0.19427721202373505\n",
      "Epoch 5, Loss: 0.9533916115760803\n",
      "Epoch 2, Loss: 7.426712512969971\n",
      "Epoch 5, Loss: 0.7715198993682861\n",
      "Epoch 5, Loss: 0.22302432358264923\n",
      "Epoch 6, Loss: 0.7722596526145935\n",
      "Epoch 2, Loss: 9.8478364944458\n",
      "Epoch 6, Loss: 0.3545597493648529\n",
      "Epoch 3, Loss: 2.2845308780670166\n",
      "Epoch 3, Loss: 2.5005626678466797\n",
      "Epoch 3, Loss: 2.8750641345977783\n",
      "Epoch 4, Loss: 0.06545816361904144\n",
      "Epoch 3, Loss: 2.557873249053955\n",
      "Epoch 4, Loss: 2.0588181018829346\n",
      "Epoch 6, Loss: 0.3801797032356262\n",
      "Epoch 7, Loss: 0.2950785458087921\n",
      "Epoch 7, Loss: 0.062483929097652435\n",
      "Epoch 3, Loss: 2.3394784927368164\n",
      "Epoch 6, Loss: 0.6029772758483887\n",
      "Epoch 8, Loss: 0.062452271580696106\n",
      "Epoch 5, Loss: 0.7307067513465881\n",
      "Epoch 3, Loss: 2.146047592163086\n",
      "Epoch 4, Loss: 0.3529299795627594\n",
      "Epoch 5, Loss: 0.550670862197876\n",
      "Epoch 4, Loss: 0.03829922899603844\n",
      "Epoch 7, Loss: 0.07886993885040283\n",
      "Epoch 4, Loss: 0.030998054891824722\n",
      "Epoch 8, Loss: 0.08383370190858841\n",
      "Epoch 4, Loss: 0.05059122294187546\n",
      "Epoch 9, Loss: 0.17866107821464539\n",
      "Epoch 7, Loss: 0.562390148639679\n",
      "Epoch 8, Loss: 0.10276295244693756\n",
      "Epoch 4, Loss: 0.12809543311595917\n",
      "Epoch 5, Loss: 0.1355152577161789\n",
      "Epoch 5, Loss: 0.8059065937995911\n",
      "Epoch 4, Loss: 0.025351567193865776\n",
      "Epoch 6, Loss: 0.10286726802587509\n",
      "Epoch 6, Loss: 0.6915409564971924\n",
      "Epoch 9, Loss: 0.1903473287820816\n",
      "Epoch 5, Loss: 0.9407942891120911\n",
      "Epoch 10, Loss: 0.3120022416114807\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3041487747922119, feed_forward_dim=128, head_dim=16, lr=0.0035631020465158674, num_heads=2, num_layers=4; total time=   0.9s\n",
      "Epoch 9, Loss: 0.20118555426597595\n",
      "Epoch 8, Loss: 0.31873273849487305\n",
      "Epoch 5, Loss: 0.8731096982955933\n",
      "Epoch 10, Loss: 0.2179187685251236\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3041487747922119, feed_forward_dim=128, head_dim=16, lr=0.0035631020465158674, num_heads=2, num_layers=4; total time=   1.0s\n",
      "Epoch 7, Loss: 0.05443310737609863\n",
      "Epoch 6, Loss: 0.5293564200401306\n",
      "Epoch 7, Loss: 0.3893848955631256\n",
      "Epoch 5, Loss: 0.4269322156906128\n",
      "Epoch 6, Loss: 0.8343794941902161\n",
      "Epoch 5, Loss: 0.6844301819801331\n",
      "Epoch 9, Loss: 0.12134255468845367\n",
      "Epoch 6, Loss: 0.8807833194732666\n",
      "Epoch 8, Loss: 0.15803954005241394\n",
      "Epoch 10, Loss: 0.19334867596626282\n",
      "Epoch 6, Loss: 0.8500683903694153\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3041487747922119, feed_forward_dim=128, head_dim=16, lr=0.0035631020465158674, num_heads=2, num_layers=4; total time=   1.1s\n",
      "Epoch 7, Loss: 0.5800808072090149\n",
      "Epoch 8, Loss: 0.1271161288022995\n",
      "Epoch 10, Loss: 0.05331316962838173\n",
      "Epoch 7, Loss: 0.39327168464660645\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3041487747922119, feed_forward_dim=128, head_dim=16, lr=0.0035631020465158674, num_heads=2, num_layers=4; total time=   1.1s\n",
      "Epoch 6, Loss: 0.6923085451126099\n",
      "Epoch 6, Loss: 0.7126421332359314\n",
      "Epoch 9, Loss: 0.20425090193748474\n",
      "Epoch 9, Loss: 0.04733136296272278\n",
      "Epoch 7, Loss: 0.3904845118522644\n",
      "Epoch 8, Loss: 0.363930881023407\n",
      "Epoch 8, Loss: 0.09870721399784088\n",
      "Epoch 7, Loss: 0.3673231601715088\n",
      "Epoch 10, Loss: 0.0981563925743103\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3041487747922119, feed_forward_dim=128, head_dim=16, lr=0.0035631020465158674, num_heads=2, num_layers=4; total time=   1.2s\n",
      "Epoch 7, Loss: 0.30635982751846313\n",
      "Epoch 7, Loss: 0.4806234836578369\n",
      "Epoch 10, Loss: 0.16974075138568878\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3041487747922119, feed_forward_dim=128, head_dim=16, lr=0.0035631020465158674, num_heads=2, num_layers=4; total time=   1.3s\n",
      "Epoch 8, Loss: 0.08981002867221832\n",
      "Epoch 9, Loss: 0.13602431118488312\n",
      "Epoch 9, Loss: 0.06964718550443649\n",
      "Epoch 8, Loss: 0.06569147109985352\n",
      "Epoch 8, Loss: 0.18932579457759857\n",
      "Epoch 8, Loss: 0.07481161504983902\n",
      "Epoch 10, Loss: 0.04867054894566536\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3041487747922119, feed_forward_dim=128, head_dim=16, lr=0.0035631020465158674, num_heads=2, num_layers=4; total time=   1.4s\n",
      "Epoch 9, Loss: 0.07678364217281342\n",
      "Epoch 10, Loss: 0.1817714273929596\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3041487747922119, feed_forward_dim=128, head_dim=16, lr=0.0035631020465158674, num_heads=2, num_layers=4; total time=   1.4s\n",
      "Epoch 9, Loss: 0.06682859361171722\n",
      "Epoch 9, Loss: 0.09138452261686325\n",
      "Epoch 9, Loss: 0.060512494295835495\n",
      "Epoch 10, Loss: 0.19806428253650665\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3041487747922119, feed_forward_dim=128, head_dim=16, lr=0.0035631020465158674, num_heads=2, num_layers=4; total time=   1.4s\n",
      "Epoch 10, Loss: 0.17226377129554749\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3041487747922119, feed_forward_dim=128, head_dim=16, lr=0.0035631020465158674, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.1992800384759903\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3041487747922119, feed_forward_dim=128, head_dim=16, lr=0.0035631020465158674, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.08438751101493835\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3041487747922119, feed_forward_dim=128, head_dim=16, lr=0.0035631020465158674, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 1.0124874114990234\n",
      "Epoch 1, Loss: 0.612945556640625\n",
      "Epoch 1, Loss: 0.05181504786014557\n",
      "Epoch 1, Loss: 0.2548292279243469\n",
      "Epoch 1, Loss: 0.13607710599899292\n",
      "Epoch 2, Loss: 0.26747944951057434\n",
      "Epoch 1, Loss: 0.19188977777957916\n",
      "Epoch 2, Loss: 0.7749375700950623\n",
      "Epoch 1, Loss: 0.059031013399362564\n",
      "Epoch 1, Loss: 2.8810317516326904\n",
      "Epoch 2, Loss: 1.9661253690719604\n",
      "Epoch 2, Loss: 1.1060655117034912\n",
      "Epoch 3, Loss: 0.5756977796554565\n",
      "Epoch 1, Loss: 1.686877965927124\n",
      "Epoch 2, Loss: 0.14165723323822021\n",
      "Epoch 1, Loss: 0.1589936763048172\n",
      "Epoch 1, Loss: 0.04452258720993996\n",
      "Epoch 2, Loss: 1.6399013996124268\n",
      "Epoch 3, Loss: 0.4747393727302551\n",
      "Epoch 3, Loss: 0.23808586597442627\n",
      "Epoch 1, Loss: 0.08719570189714432\n",
      "Epoch 2, Loss: 0.0693589597940445\n",
      "Epoch 2, Loss: 2.2189748287200928\n",
      "Epoch 4, Loss: 0.30881068110466003\n",
      "Epoch 3, Loss: 0.2303939163684845\n",
      "Epoch 3, Loss: 0.26342761516571045\n",
      "Epoch 2, Loss: 0.3352952003479004\n",
      "Epoch 4, Loss: 0.06735028326511383\n",
      "Epoch 5, Loss: 0.07303769886493683\n",
      "Epoch 2, Loss: 1.7098926305770874\n",
      "Epoch 3, Loss: 0.11524547636508942\n",
      "Epoch 2, Loss: 0.9250303506851196\n",
      "Epoch 4, Loss: 0.22594097256660461\n",
      "Epoch 3, Loss: 0.21001245081424713\n",
      "Epoch 3, Loss: 0.7428050637245178\n",
      "Epoch 4, Loss: 0.06989127397537231\n",
      "Epoch 4, Loss: 0.05216224491596222\n",
      "Epoch 2, Loss: 1.1733287572860718\n",
      "Epoch 6, Loss: 0.04704969748854637\n",
      "Epoch 5, Loss: 0.09113220870494843\n",
      "Epoch 5, Loss: 0.6612192392349243\n",
      "Epoch 4, Loss: 0.5394564270973206\n",
      "Epoch 3, Loss: 0.8700090646743774\n",
      "Epoch 7, Loss: 0.13868455588817596\n",
      "Epoch 3, Loss: 0.2016943097114563\n",
      "Epoch 5, Loss: 0.03561432659626007\n",
      "Epoch 4, Loss: 0.4666702449321747\n",
      "Epoch 3, Loss: 0.2121274173259735\n",
      "Epoch 5, Loss: 0.2924812138080597\n",
      "Epoch 6, Loss: 0.23556441068649292\n",
      "Epoch 4, Loss: 0.8773909211158752\n",
      "Epoch 3, Loss: 0.019767310470342636\n",
      "Epoch 6, Loss: 0.5327951908111572\n",
      "Epoch 5, Loss: 0.6111277341842651\n",
      "Epoch 8, Loss: 0.1886405199766159\n",
      "Epoch 4, Loss: 0.5079547762870789\n",
      "Epoch 6, Loss: 0.11770447343587875\n",
      "Epoch 5, Loss: 0.7866799235343933\n",
      "Epoch 7, Loss: 0.22427771985530853\n",
      "Epoch 6, Loss: 0.31331127882003784\n",
      "Epoch 4, Loss: 0.1655939817428589\n",
      "Epoch 5, Loss: 0.4956853687763214\n",
      "Epoch 9, Loss: 0.16040369868278503\n",
      "Epoch 4, Loss: 0.04389546066522598\n",
      "Epoch 7, Loss: 0.21918612718582153\n",
      "Epoch 6, Loss: 0.22325697541236877\n",
      "Epoch 7, Loss: 0.07263710349798203\n",
      "Epoch 4, Loss: 0.4515988528728485\n",
      "Epoch 5, Loss: 0.12204410880804062\n",
      "Epoch 8, Loss: 0.11854953318834305\n",
      "Epoch 7, Loss: 0.15766216814517975\n",
      "Epoch 10, Loss: 0.08943542838096619\n",
      "Epoch 5, Loss: 0.5430617332458496\n",
      "Epoch 8, Loss: 0.03932426869869232\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1468303730795647, feed_forward_dim=1024, head_dim=32, lr=0.0009059398968524022, num_heads=4, num_layers=1; total time=   1.1s\n",
      "Epoch 6, Loss: 0.41580891609191895\n",
      "Epoch 6, Loss: 0.15854483842849731\n",
      "Epoch 8, Loss: 0.011948768049478531\n",
      "Epoch 7, Loss: 0.02890019118785858\n",
      "Epoch 9, Loss: 0.03129484876990318\n",
      "Epoch 6, Loss: 0.030813341960310936\n",
      "Epoch 5, Loss: 0.2632576823234558\n",
      "Epoch 9, Loss: 0.047234512865543365\n",
      "Epoch 8, Loss: 0.03089374676346779\n",
      "Epoch 5, Loss: 0.499472439289093\n",
      "Epoch 7, Loss: 0.09376676380634308\n",
      "Epoch 9, Loss: 0.028486616909503937\n",
      "Epoch 8, Loss: 0.07858972996473312\n",
      "Epoch 6, Loss: 0.43987637758255005\n",
      "Epoch 7, Loss: 0.032869603484869\n",
      "Epoch 10, Loss: 0.13992838561534882\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1468303730795647, feed_forward_dim=1024, head_dim=32, lr=0.0009059398968524022, num_heads=4, num_layers=1; total time=   1.3s\n",
      "Epoch 10, Loss: 0.019730767235159874\n",
      "Epoch 7, Loss: 0.13316740095615387\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1468303730795647, feed_forward_dim=1024, head_dim=32, lr=0.0009059398968524022, num_heads=4, num_layers=1; total time=   1.3s\n",
      "Epoch 6, Loss: 0.26061853766441345\n",
      "Epoch 9, Loss: 0.023553816601634026\n",
      "Epoch 10, Loss: 0.0625002309679985\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1468303730795647, feed_forward_dim=1024, head_dim=32, lr=0.0009059398968524022, num_heads=4, num_layers=1; total time=   1.3s\n",
      "Epoch 8, Loss: 0.018454667180776596\n",
      "Epoch 9, Loss: 0.1864183098077774\n",
      "Epoch 6, Loss: 0.21469470858573914\n",
      "Epoch 8, Loss: 0.2281472235918045\n",
      "Epoch 10, Loss: 0.0897669792175293\n",
      "Epoch 8, Loss: 0.07603102177381516\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1468303730795647, feed_forward_dim=1024, head_dim=32, lr=0.0009059398968524022, num_heads=4, num_layers=1; total time=   1.4s\n",
      "Epoch 7, Loss: 0.18305404484272003\n",
      "Epoch 9, Loss: 0.0895552709698677\n",
      "Epoch 7, Loss: 0.11142173409461975\n",
      "Epoch 10, Loss: 0.22558113932609558\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1468303730795647, feed_forward_dim=1024, head_dim=32, lr=0.0009059398968524022, num_heads=4, num_layers=1; total time=   1.5s\n",
      "Epoch 7, Loss: 0.030147675424814224\n",
      "Epoch 9, Loss: 0.2315443456172943\n",
      "Epoch 9, Loss: 0.17400707304477692\n",
      "Epoch 10, Loss: 0.17306868731975555\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1468303730795647, feed_forward_dim=1024, head_dim=32, lr=0.0009059398968524022, num_heads=4, num_layers=1; total time=   1.5s\n",
      "Epoch 8, Loss: 0.02869078889489174\n",
      "Epoch 8, Loss: 0.016688689589500427\n",
      "Epoch 10, Loss: 0.16041675209999084\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1468303730795647, feed_forward_dim=1024, head_dim=32, lr=0.0009059398968524022, num_heads=4, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.23203925788402557\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1468303730795647, feed_forward_dim=1024, head_dim=32, lr=0.0009059398968524022, num_heads=4, num_layers=1; total time=   1.5s\n",
      "Epoch 8, Loss: 0.029230039566755295\n",
      "Epoch 9, Loss: 0.026731478050351143\n",
      "Epoch 9, Loss: 0.03704414889216423\n",
      "Epoch 9, Loss: 0.11306958645582199\n",
      "Epoch 10, Loss: 0.10069025307893753\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1468303730795647, feed_forward_dim=1024, head_dim=32, lr=0.0009059398968524022, num_heads=4, num_layers=1; total time=   1.6s\n",
      "Epoch 10, Loss: 0.10298711061477661\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1468303730795647, feed_forward_dim=1024, head_dim=32, lr=0.0009059398968524022, num_heads=4, num_layers=1; total time=   1.6s\n",
      "Epoch 10, Loss: 0.16637273132801056\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1468303730795647, feed_forward_dim=1024, head_dim=32, lr=0.0009059398968524022, num_heads=4, num_layers=1; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.04742513224482536\n",
      "Epoch 1, Loss: 0.030332086607813835\n",
      "Epoch 1, Loss: 0.2631281018257141\n",
      "Epoch 1, Loss: 1.2735282182693481\n",
      "Epoch 2, Loss: 11.819755554199219\n",
      "Epoch 1, Loss: 1.0265225172042847\n",
      "Epoch 1, Loss: 0.08135576546192169\n",
      "Epoch 1, Loss: 1.0812324285507202\n",
      "Epoch 2, Loss: 15.554677963256836\n",
      "Epoch 1, Loss: 0.5095446705818176\n",
      "Epoch 3, Loss: 2.0500433444976807\n",
      "Epoch 2, Loss: 9.562204360961914\n",
      "Epoch 2, Loss: 8.276761054992676\n",
      "Epoch 1, Loss: 0.29153597354888916\n",
      "Epoch 2, Loss: 9.251579284667969\n",
      "Epoch 3, Loss: 2.6263418197631836\n",
      "Epoch 2, Loss: 7.4927473068237305\n",
      "Epoch 4, Loss: 0.6472043991088867\n",
      "Epoch 1, Loss: 2.0920186042785645\n",
      "Epoch 3, Loss: 2.484358072280884\n",
      "Epoch 1, Loss: 0.7152013778686523\n",
      "Epoch 3, Loss: 2.1159002780914307\n",
      "Epoch 2, Loss: 14.176299095153809\n",
      "Epoch 1, Loss: 0.11768078804016113\n",
      "Epoch 2, Loss: 8.342061996459961\n",
      "Epoch 3, Loss: 1.6965296268463135\n",
      "Epoch 2, Loss: 13.65810775756836\n",
      "Epoch 4, Loss: 0.08631514012813568\n",
      "Epoch 3, Loss: 0.4811795949935913\n",
      "Epoch 4, Loss: 0.618617832660675\n",
      "Epoch 5, Loss: 0.7132056951522827\n",
      "Epoch 4, Loss: 0.06405457109212875\n",
      "Epoch 2, Loss: 9.057058334350586\n",
      "Epoch 2, Loss: 10.959197998046875\n",
      "Epoch 3, Loss: 3.835628032684326\n",
      "Epoch 3, Loss: 1.7470849752426147\n",
      "Epoch 4, Loss: 0.3291197121143341\n",
      "Epoch 5, Loss: 0.7187846899032593\n",
      "Epoch 5, Loss: 0.7202091813087463\n",
      "Epoch 6, Loss: 0.17287394404411316\n",
      "Epoch 2, Loss: 6.999094009399414\n",
      "Epoch 4, Loss: 1.3783714771270752\n",
      "Epoch 3, Loss: 1.8595364093780518\n",
      "Epoch 5, Loss: 0.7459732294082642\n",
      "Epoch 6, Loss: 0.17741310596466064\n",
      "Epoch 6, Loss: 0.6793474555015564\n",
      "Epoch 7, Loss: 0.08864691108465195\n",
      "Epoch 3, Loss: 2.6043529510498047\n",
      "Epoch 5, Loss: 0.8332126140594482\n",
      "Epoch 4, Loss: 0.05141337588429451\n",
      "Epoch 4, Loss: 0.08955474942922592\n",
      "Epoch 5, Loss: 0.7322672009468079\n",
      "Epoch 3, Loss: 2.4005448818206787\n",
      "Epoch 6, Loss: 0.6500028371810913\n",
      "Epoch 4, Loss: 0.5285822153091431\n",
      "Epoch 7, Loss: 0.0641910508275032\n",
      "Epoch 3, Loss: 0.6627543568611145\n",
      "Epoch 8, Loss: 0.21730279922485352\n",
      "Epoch 7, Loss: 0.2970872223377228\n",
      "Epoch 4, Loss: 0.07895678281784058\n",
      "Epoch 6, Loss: 0.1780172884464264\n",
      "Epoch 5, Loss: 1.1745452880859375\n",
      "Epoch 7, Loss: 0.24745512008666992\n",
      "Epoch 6, Loss: 0.3704216182231903\n",
      "Epoch 9, Loss: 0.1986055076122284\n",
      "Epoch 5, Loss: 0.7492645978927612\n",
      "Epoch 8, Loss: 0.16312354803085327\n",
      "Epoch 4, Loss: 0.20331721007823944\n",
      "Epoch 5, Loss: 0.9518454074859619\n",
      "Epoch 8, Loss: 0.08915714919567108\n",
      "Epoch 10, Loss: 0.10662298649549484\n",
      "Epoch 9, Loss: 0.16063819825649261\n",
      "Epoch 8, Loss: 0.06530306488275528\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3682278891593429, feed_forward_dim=128, head_dim=8, lr=0.004999999999999999, num_heads=4, num_layers=2; total time=   1.1s\n",
      "Epoch 5, Loss: 0.8500584363937378\n",
      "Epoch 4, Loss: 0.15980854630470276\n",
      "Epoch 7, Loss: 0.049359358847141266\n",
      "Epoch 6, Loss: 0.4592697322368622\n",
      "Epoch 7, Loss: 0.07966352999210358\n",
      "Epoch 6, Loss: 0.8207921981811523\n",
      "Epoch 9, Loss: 0.06368564069271088\n",
      "Epoch 9, Loss: 0.09299557656049728\n",
      "Epoch 5, Loss: 1.0523453950881958\n",
      "Epoch 10, Loss: 0.09322847425937653\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3682278891593429, feed_forward_dim=128, head_dim=8, lr=0.004999999999999999, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 8, Loss: 0.09836771339178085\n",
      "Epoch 6, Loss: 0.7327486872673035\n",
      "Epoch 8, Loss: 0.07819213718175888\n",
      "Epoch 7, Loss: 0.12469706684350967\n",
      "Epoch 6, Loss: 0.33681973814964294\n",
      "Epoch 5, Loss: 0.057414907962083817\n",
      "Epoch 7, Loss: 0.2159275859594345\n",
      "Epoch 10, Loss: 0.1194978579878807\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3682278891593429, feed_forward_dim=128, head_dim=8, lr=0.004999999999999999, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 10, Loss: 0.16199328005313873\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3682278891593429, feed_forward_dim=128, head_dim=8, lr=0.004999999999999999, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 9, Loss: 0.1450929492712021\n",
      "Epoch 9, Loss: 0.15360938012599945\n",
      "Epoch 6, Loss: 0.5696491003036499\n",
      "Epoch 8, Loss: 0.051176831126213074\n",
      "Epoch 7, Loss: 0.2420358955860138\n",
      "Epoch 7, Loss: 0.05830610170960426\n",
      "Epoch 6, Loss: 0.13754966855049133\n",
      "Epoch 8, Loss: 0.05148221179842949\n",
      "Epoch 10, Loss: 0.14233602583408356\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3682278891593429, feed_forward_dim=128, head_dim=8, lr=0.004999999999999999, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 10, Loss: 0.1729363054037094\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3682278891593429, feed_forward_dim=128, head_dim=8, lr=0.004999999999999999, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 9, Loss: 0.11367993801832199\n",
      "Epoch 7, Loss: 0.12016522884368896\n",
      "Epoch 8, Loss: 0.18384668231010437\n",
      "Epoch 7, Loss: 0.09500203281641006\n",
      "Epoch 8, Loss: 0.059512943029403687\n",
      "Epoch 9, Loss: 0.16104382276535034\n",
      "Epoch 10, Loss: 0.15311728417873383\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3682278891593429, feed_forward_dim=128, head_dim=8, lr=0.004999999999999999, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 0.26102155447006226\n",
      "Epoch 10, Loss: 0.22353748977184296\n",
      "Epoch 8, Loss: 0.09037501364946365\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3682278891593429, feed_forward_dim=128, head_dim=8, lr=0.004999999999999999, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 9, Loss: 0.12783005833625793\n",
      "Epoch 10, Loss: 0.18406523764133453\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3682278891593429, feed_forward_dim=128, head_dim=8, lr=0.004999999999999999, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 8, Loss: 0.057359423488378525\n",
      "Epoch 10, Loss: 0.2107747197151184\n",
      "Epoch 9, Loss: 0.20202487707138062\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3682278891593429, feed_forward_dim=128, head_dim=8, lr=0.004999999999999999, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 9, Loss: 0.08529140800237656\n",
      "Epoch 10, Loss: 0.20182962715625763\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3682278891593429, feed_forward_dim=128, head_dim=8, lr=0.004999999999999999, num_heads=4, num_layers=2; total time=   1.7s\n",
      "Epoch 10, Loss: 0.11526304483413696\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3682278891593429, feed_forward_dim=128, head_dim=8, lr=0.004999999999999999, num_heads=4, num_layers=2; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.23357412219047546\n",
      "Epoch 1, Loss: 0.33010953664779663\n",
      "Epoch 1, Loss: 0.5334783792495728\n",
      "Epoch 1, Loss: 0.23448680341243744\n",
      "Epoch 2, Loss: 0.11616024374961853\n",
      "Epoch 2, Loss: 0.09570486098527908\n",
      "Epoch 1, Loss: 0.7487069964408875\n",
      "Epoch 1, Loss: 0.5817002654075623\n",
      "Epoch 1, Loss: 1.0475378036499023\n",
      "Epoch 3, Loss: 0.14642055332660675\n",
      "Epoch 1, Loss: 0.9131749868392944\n",
      "Epoch 2, Loss: 0.11213084310293198\n",
      "Epoch 3, Loss: 0.12418663501739502\n",
      "Epoch 2, Loss: 0.19237057864665985\n",
      "Epoch 1, Loss: 0.1929255872964859\n",
      "Epoch 1, Loss: 0.862331211566925\n",
      "Epoch 2, Loss: 0.2305763065814972\n",
      "Epoch 4, Loss: 0.10463400930166245\n",
      "Epoch 2, Loss: 0.1863587349653244\n",
      "Epoch 1, Loss: 1.153512954711914\n",
      "Epoch 1, Loss: 1.6872479915618896\n",
      "Epoch 4, Loss: 0.1574019193649292\n",
      "Epoch 2, Loss: 0.4080854654312134\n",
      "Epoch 3, Loss: 0.08214306831359863\n",
      "Epoch 2, Loss: 0.274260014295578\n",
      "Epoch 3, Loss: 0.17080475389957428\n",
      "Epoch 5, Loss: 0.05233488604426384\n",
      "Epoch 2, Loss: 0.07007355988025665\n",
      "Epoch 3, Loss: 0.048799823969602585\n",
      "Epoch 5, Loss: 0.12247846275568008\n",
      "Epoch 2, Loss: 0.3308941125869751\n",
      "Epoch 4, Loss: 0.19489619135856628\n",
      "Epoch 3, Loss: 0.08175582438707352\n",
      "Epoch 6, Loss: 0.04086447134613991\n",
      "Epoch 3, Loss: 0.1267000287771225\n",
      "Epoch 4, Loss: 0.11940304189920425\n",
      "Epoch 2, Loss: 0.7557740807533264\n",
      "Epoch 6, Loss: 0.06401165574789047\n",
      "Epoch 3, Loss: 0.03326551243662834\n",
      "Epoch 2, Loss: 0.5345883369445801\n",
      "Epoch 3, Loss: 0.12872640788555145\n",
      "Epoch 4, Loss: 0.09663286060094833\n",
      "Epoch 7, Loss: 0.0504712350666523\n",
      "Epoch 5, Loss: 0.21452085673809052\n",
      "Epoch 3, Loss: 0.11893755197525024\n",
      "Epoch 4, Loss: 0.02290055714547634\n",
      "Epoch 4, Loss: 0.211354598402977\n",
      "Epoch 7, Loss: 0.026604201644659042\n",
      "Epoch 5, Loss: 0.09535275399684906\n",
      "Epoch 3, Loss: 0.21381548047065735\n",
      "Epoch 4, Loss: 0.09953592717647552\n",
      "Epoch 8, Loss: 0.05500231310725212\n",
      "Epoch 4, Loss: 0.09372808039188385\n",
      "Epoch 5, Loss: 0.1958361268043518\n",
      "Epoch 8, Loss: 0.027480319142341614\n",
      "Epoch 6, Loss: 0.14819028973579407\n",
      "Epoch 9, Loss: 0.04068901017308235\n",
      "Epoch 3, Loss: 0.21624808013439178\n",
      "Epoch 5, Loss: 0.11568395048379898\n",
      "Epoch 4, Loss: 0.14202675223350525\n",
      "Epoch 5, Loss: 0.24803560972213745\n",
      "Epoch 6, Loss: 0.08927391469478607\n",
      "Epoch 4, Loss: 0.046084605157375336\n",
      "Epoch 5, Loss: 0.22977788746356964\n",
      "Epoch 10, Loss: 0.02374936267733574\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.00024129698764457756, num_heads=8, num_layers=1; total time=   1.1s\n",
      "Epoch 6, Loss: 0.22648365795612335\n",
      "Epoch 9, Loss: 0.048445671796798706\n",
      "Epoch 7, Loss: 0.07235411554574966\n",
      "Epoch 6, Loss: 0.2190038412809372\n",
      "Epoch 5, Loss: 0.040611911565065384\n",
      "Epoch 6, Loss: 0.19966019690036774\n",
      "Epoch 7, Loss: 0.0748499184846878\n",
      "Epoch 4, Loss: 0.14012303948402405\n",
      "Epoch 5, Loss: 0.23329764604568481\n",
      "Epoch 10, Loss: 0.05874049291014671\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.00024129698764457756, num_heads=8, num_layers=1; total time=   1.2s\n",
      "Epoch 7, Loss: 0.19934119284152985\n",
      "Epoch 8, Loss: 0.03296643868088722\n",
      "Epoch 5, Loss: 0.13094192743301392\n",
      "Epoch 6, Loss: 0.26510247588157654\n",
      "Epoch 7, Loss: 0.25678595900535583\n",
      "Epoch 8, Loss: 0.05361960828304291\n",
      "Epoch 7, Loss: 0.12592357397079468\n",
      "Epoch 6, Loss: 0.026562562212347984\n",
      "Epoch 6, Loss: 0.26740896701812744\n",
      "Epoch 9, Loss: 0.0366644412279129\n",
      "Epoch 5, Loss: 0.19530247151851654\n",
      "Epoch 8, Loss: 0.13571982085704803\n",
      "Epoch 8, Loss: 0.06632959842681885\n",
      "Epoch 9, Loss: 0.039190273731946945\n",
      "Epoch 7, Loss: 0.21717968583106995\n",
      "Epoch 8, Loss: 0.23321761190891266\n",
      "Epoch 6, Loss: 0.28468742966651917\n",
      "Epoch 7, Loss: 0.04451814293861389\n",
      "Epoch 10, Loss: 0.061661891639232635\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.00024129698764457756, num_heads=8, num_layers=1; total time=   1.6s\n",
      "Epoch 7, Loss: 0.23908491432666779\n",
      "Epoch 10, Loss: 0.035853587090969086\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.00024129698764457756, num_heads=8, num_layers=1; total time=   1.6s\n",
      "Epoch 9, Loss: 0.0726812481880188\n",
      "Epoch 9, Loss: 0.04594040289521217\n",
      "Epoch 8, Loss: 0.1330411583185196\n",
      "Epoch 9, Loss: 0.17493000626564026\n",
      "Epoch 6, Loss: 0.2689904570579529\n",
      "Epoch 7, Loss: 0.3720793128013611\n",
      "Epoch 10, Loss: 0.0575631745159626\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.00024129698764457756, num_heads=8, num_layers=1; total time=   1.6s\n",
      "Epoch 10, Loss: 0.031681835651397705\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.00024129698764457756, num_heads=8, num_layers=1; total time=   1.7s\n",
      "Epoch 8, Loss: 0.05298735573887825\n",
      "Epoch 8, Loss: 0.17454767227172852\n",
      "Epoch 10, Loss: 0.10575807839632034\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.00024129698764457756, num_heads=8, num_layers=1; total time=   1.6s\n",
      "Epoch 9, Loss: 0.06044149026274681\n",
      "Epoch 7, Loss: 0.2954772710800171\n",
      "Epoch 8, Loss: 0.3698124587535858\n",
      "Epoch 9, Loss: 0.037515539675951004\n",
      "Epoch 9, Loss: 0.10836826264858246\n",
      "Epoch 10, Loss: 0.020597750321030617\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.00024129698764457756, num_heads=8, num_layers=1; total time=   1.7s\n",
      "Epoch 9, Loss: 0.29918789863586426\n",
      "Epoch 10, Loss: 0.01754414103925228\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.00024129698764457756, num_heads=8, num_layers=1; total time=   1.8s\n",
      "Epoch 10, Loss: 0.059550344944000244\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.00024129698764457756, num_heads=8, num_layers=1; total time=   1.8s\n",
      "Epoch 8, Loss: 0.2672704756259918\n",
      "Epoch 10, Loss: 0.2086818367242813\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.00024129698764457756, num_heads=8, num_layers=1; total time=   1.8s\n",
      "Epoch 9, Loss: 0.20825697481632233\n",
      "Epoch 10, Loss: 0.1392919272184372\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.00024129698764457756, num_heads=8, num_layers=1; total time=   1.9s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.07777442038059235\n",
      "Epoch 1, Loss: 0.4797220528125763\n",
      "Epoch 1, Loss: 1.5079277753829956\n",
      "Epoch 1, Loss: 0.08256305754184723\n",
      "Epoch 1, Loss: 0.21954689919948578\n",
      "Epoch 2, Loss: 0.13873478770256042\n",
      "Epoch 2, Loss: 0.1006656065583229\n",
      "Epoch 1, Loss: 0.04465566202998161\n",
      "Epoch 1, Loss: 1.6101980209350586\n",
      "Epoch 2, Loss: 0.0747397243976593\n",
      "Epoch 2, Loss: 0.06675971299409866\n",
      "Epoch 2, Loss: 0.5761154890060425\n",
      "Epoch 3, Loss: 0.073166124522686\n",
      "Epoch 3, Loss: 0.05340132117271423\n",
      "Epoch 2, Loss: 0.086021289229393\n",
      "Epoch 4, Loss: 0.026043960824608803\n",
      "Epoch 2, Loss: 0.7722986340522766\n",
      "Epoch 3, Loss: 0.06112420931458473\n",
      "Epoch 3, Loss: 0.09412841498851776\n",
      "Epoch 4, Loss: 0.15092845261096954\n",
      "Epoch 3, Loss: 0.1257948875427246\n",
      "Epoch 1, Loss: 0.07399996370077133\n",
      "Epoch 5, Loss: 0.0416969433426857\n",
      "Epoch 1, Loss: 0.36382296681404114\n",
      "Epoch 3, Loss: 0.2685531675815582\n",
      "Epoch 4, Loss: 0.02607494778931141\n",
      "Epoch 3, Loss: 0.01916578970849514\n",
      "Epoch 1, Loss: 0.2879343330860138\n",
      "Epoch 4, Loss: 0.10894343256950378\n",
      "Epoch 5, Loss: 0.19283601641654968\n",
      "Epoch 1, Loss: 1.1909648180007935\n",
      "Epoch 2, Loss: 0.05906452611088753\n",
      "Epoch 1, Loss: 0.5176777839660645\n",
      "Epoch 4, Loss: 0.02210521325469017\n",
      "Epoch 6, Loss: 0.03576736897230148\n",
      "Epoch 4, Loss: 0.04772088676691055\n",
      "Epoch 5, Loss: 0.02700917422771454\n",
      "Epoch 2, Loss: 0.08697520941495895\n",
      "Epoch 5, Loss: 0.051020052284002304\n",
      "Epoch 4, Loss: 0.05832145735621452\n",
      "Epoch 5, Loss: 0.18002046644687653\n",
      "Epoch 6, Loss: 0.16163097321987152\n",
      "Epoch 2, Loss: 0.18496091663837433\n",
      "Epoch 3, Loss: 0.014528852887451649\n",
      "Epoch 7, Loss: 0.017360907047986984\n",
      "Epoch 2, Loss: 0.1034613624215126\n",
      "Epoch 6, Loss: 0.033997371792793274\n",
      "Epoch 7, Loss: 0.1016329750418663\n",
      "Epoch 2, Loss: 0.5558227300643921\n",
      "Epoch 6, Loss: 0.02044723555445671\n",
      "Epoch 5, Loss: 0.041622593998909\n",
      "Epoch 8, Loss: 0.011732732877135277\n",
      "Epoch 6, Loss: 0.32630646228790283\n",
      "Epoch 5, Loss: 0.039678916335105896\n",
      "Epoch 3, Loss: 0.075812928378582\n",
      "Epoch 4, Loss: 0.025276659056544304\n",
      "Epoch 7, Loss: 0.02138420008122921\n",
      "Epoch 6, Loss: 0.1415872573852539\n",
      "Epoch 3, Loss: 0.11085112392902374\n",
      "Epoch 7, Loss: 0.03009175695478916\n",
      "Epoch 8, Loss: 0.0517716147005558\n",
      "Epoch 3, Loss: 0.07440375536680222\n",
      "Epoch 9, Loss: 0.021379997953772545\n",
      "Epoch 3, Loss: 0.25459909439086914\n",
      "Epoch 8, Loss: 0.009090851992368698\n",
      "Epoch 5, Loss: 0.010967573150992393\n",
      "Epoch 7, Loss: 0.36938998103141785\n",
      "Epoch 10, Loss: 0.025402963161468506\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.14098669886661597, feed_forward_dim=512, head_dim=16, lr=0.00022379099130096026, num_heads=2, num_layers=3; total time=   1.0s\n",
      "Epoch 4, Loss: 0.1487133502960205\n",
      "Epoch 8, Loss: 0.04936710372567177\n",
      "Epoch 6, Loss: 0.010661655105650425\n",
      "Epoch 9, Loss: 0.029301205649971962\n",
      "Epoch 4, Loss: 0.11268903315067291\n",
      "Epoch 4, Loss: 0.14231501519680023\n",
      "Epoch 7, Loss: 0.24480560421943665\n",
      "Epoch 9, Loss: 0.009553647600114346\n",
      "Epoch 6, Loss: 0.008161047473549843\n",
      "Epoch 8, Loss: 0.3122147023677826\n",
      "Epoch 4, Loss: 0.21424196660518646\n",
      "Epoch 8, Loss: 0.3017951548099518\n",
      "Epoch 10, Loss: 0.017558589577674866\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.14098669886661597, feed_forward_dim=512, head_dim=16, lr=0.00022379099130096026, num_heads=2, num_layers=3; total time=   1.0s\n",
      "Epoch 10, Loss: 0.03492116928100586\n",
      "Epoch 5, Loss: 0.15665461122989655\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.14098669886661597, feed_forward_dim=512, head_dim=16, lr=0.00022379099130096026, num_heads=2, num_layers=3; total time=   1.1s\n",
      "Epoch 9, Loss: 0.04756094887852669\n",
      "Epoch 5, Loss: 0.12132319808006287\n",
      "Epoch 5, Loss: 0.16748470067977905\n",
      "Epoch 7, Loss: 0.017507292330265045\n",
      "Epoch 7, Loss: 0.019208144396543503\n",
      "Epoch 9, Loss: 0.2137557715177536\n",
      "Epoch 9, Loss: 0.29853302240371704\n",
      "Epoch 10, Loss: 0.02952011674642563\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.14098669886661597, feed_forward_dim=512, head_dim=16, lr=0.00022379099130096026, num_heads=2, num_layers=3; total time=   1.2s\n",
      "Epoch 6, Loss: 0.07644839584827423\n",
      "Epoch 8, Loss: 0.029974311590194702\n",
      "Epoch 5, Loss: 0.28296929597854614\n",
      "Epoch 10, Loss: 0.11265718936920166\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.14098669886661597, feed_forward_dim=512, head_dim=16, lr=0.00022379099130096026, num_heads=2, num_layers=3; total time=   1.2s\n",
      "Epoch 6, Loss: 0.10720159113407135\n",
      "Epoch 6, Loss: 0.1719457060098648\n",
      "Epoch 8, Loss: 0.01801922731101513\n",
      "Epoch 10, Loss: 0.2477758228778839\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.14098669886661597, feed_forward_dim=512, head_dim=16, lr=0.00022379099130096026, num_heads=2, num_layers=3; total time=   1.2s\n",
      "Epoch 9, Loss: 0.02228790521621704\n",
      "Epoch 7, Loss: 0.04130236431956291\n",
      "Epoch 7, Loss: 0.05185180902481079\n",
      "Epoch 9, Loss: 0.013050120323896408\n",
      "Epoch 7, Loss: 0.12883740663528442\n",
      "Epoch 10, Loss: 0.009082029573619366\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.14098669886661597, feed_forward_dim=512, head_dim=16, lr=0.00022379099130096026, num_heads=2, num_layers=3; total time=   1.3s\n",
      "Epoch 6, Loss: 0.3268031179904938\n",
      "Epoch 8, Loss: 0.03128929063677788\n",
      "Epoch 10, Loss: 0.01464628241956234\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.14098669886661597, feed_forward_dim=512, head_dim=16, lr=0.00022379099130096026, num_heads=2, num_layers=3; total time=   1.2s\n",
      "Epoch 8, Loss: 0.02496277168393135\n",
      "Epoch 8, Loss: 0.07519982755184174\n",
      "Epoch 9, Loss: 0.03839954733848572\n",
      "Epoch 7, Loss: 0.3033716678619385\n",
      "Epoch 9, Loss: 0.030029889196157455\n",
      "Epoch 9, Loss: 0.03436118736863136\n",
      "Epoch 10, Loss: 0.04641034081578255\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.14098669886661597, feed_forward_dim=512, head_dim=16, lr=0.00022379099130096026, num_heads=2, num_layers=3; total time=   1.4s\n",
      "Epoch 8, Loss: 0.24206037819385529\n",
      "Epoch 10, Loss: 0.04881307855248451\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.14098669886661597, feed_forward_dim=512, head_dim=16, lr=0.00022379099130096026, num_heads=2, num_layers=3; total time=   1.4s\n",
      "Epoch 10, Loss: 0.017119836062192917\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.14098669886661597, feed_forward_dim=512, head_dim=16, lr=0.00022379099130096026, num_heads=2, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.1642400622367859\n",
      "Epoch 10, Loss: 0.09551771730184555\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.14098669886661597, feed_forward_dim=512, head_dim=16, lr=0.00022379099130096026, num_heads=2, num_layers=3; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 1.110095500946045\n",
      "Epoch 1, Loss: 0.6829305291175842\n",
      "Epoch 2, Loss: 0.11316970735788345\n",
      "Epoch 1, Loss: 0.06368099898099899\n",
      "Epoch 1, Loss: 0.45955222845077515\n",
      "Epoch 1, Loss: 2.124680280685425\n",
      "Epoch 1, Loss: 1.1539413928985596\n",
      "Epoch 2, Loss: 0.020710518583655357\n",
      "Epoch 3, Loss: 0.40516069531440735\n",
      "Epoch 1, Loss: 0.35432565212249756\n",
      "Epoch 1, Loss: 2.203674077987671\n",
      "Epoch 2, Loss: 0.08912227302789688\n",
      "Epoch 2, Loss: 0.5005488395690918\n",
      "Epoch 2, Loss: 0.2634603679180145\n",
      "Epoch 4, Loss: 0.4825252294540405\n",
      "Epoch 2, Loss: 0.09975768625736237\n",
      "Epoch 1, Loss: 0.2089354246854782\n",
      "Epoch 1, Loss: 0.07507722079753876\n",
      "Epoch 1, Loss: 0.1273086965084076\n",
      "Epoch 3, Loss: 0.3230770230293274\n",
      "Epoch 2, Loss: 0.08186846226453781\n",
      "Epoch 3, Loss: 0.2795086205005646\n",
      "Epoch 2, Loss: 0.7353119254112244\n",
      "Epoch 5, Loss: 0.2761381268501282\n",
      "Epoch 3, Loss: 0.05435335636138916\n",
      "Epoch 1, Loss: 1.524068832397461\n",
      "Epoch 3, Loss: 0.11338427662849426\n",
      "Epoch 3, Loss: 0.044403962790966034\n",
      "Epoch 4, Loss: 0.32659927010536194\n",
      "Epoch 2, Loss: 0.28668755292892456\n",
      "Epoch 3, Loss: 0.20668625831604004\n",
      "Epoch 6, Loss: 0.08719514310359955\n",
      "Epoch 2, Loss: 0.1485215723514557\n",
      "Epoch 4, Loss: 0.029031651094555855\n",
      "Epoch 5, Loss: 0.1392674595117569\n",
      "Epoch 4, Loss: 0.20735684037208557\n",
      "Epoch 2, Loss: 0.24892598390579224\n",
      "Epoch 3, Loss: 0.09474338591098785\n",
      "Epoch 2, Loss: 0.18518978357315063\n",
      "Epoch 7, Loss: 0.030971011146903038\n",
      "Epoch 6, Loss: 0.020193656906485558\n",
      "Epoch 4, Loss: 0.25481680035591125\n",
      "Epoch 3, Loss: 0.06847938895225525\n",
      "Epoch 4, Loss: 0.3754916787147522\n",
      "Epoch 4, Loss: 0.15687042474746704\n",
      "Epoch 5, Loss: 0.06968401372432709\n",
      "Epoch 5, Loss: 0.11034581810235977\n",
      "Epoch 3, Loss: 0.15399512648582458\n",
      "Epoch 7, Loss: 0.03637704998254776\n",
      "Epoch 8, Loss: 0.07613283395767212\n",
      "Epoch 3, Loss: 0.04085226729512215\n",
      "Epoch 4, Loss: 0.10769719630479813\n",
      "Epoch 3, Loss: 0.22890926897525787\n",
      "Epoch 5, Loss: 0.47957679629325867\n",
      "Epoch 6, Loss: 0.09069381654262543\n",
      "Epoch 5, Loss: 0.058828528970479965\n",
      "Epoch 5, Loss: 0.3880460262298584\n",
      "Epoch 6, Loss: 0.035300470888614655\n",
      "Epoch 9, Loss: 0.13774700462818146\n",
      "Epoch 8, Loss: 0.11021813750267029\n",
      "Epoch 5, Loss: 0.3385663628578186\n",
      "Epoch 4, Loss: 0.032553430646657944\n",
      "Epoch 6, Loss: 0.5021889805793762Epoch 4, Loss: 0.03344716504216194\n",
      "\n",
      "Epoch 4, Loss: 0.1470337212085724\n",
      "Epoch 7, Loss: 0.027043426409363747\n",
      "Epoch 4, Loss: 0.5602065324783325\n",
      "Epoch 10, Loss: 0.1586982160806656\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.0004220556527210704, num_heads=4, num_layers=1; total time=   0.9s\n",
      "Epoch 6, Loss: 0.02445509098470211\n",
      "Epoch 7, Loss: 0.07973577082157135\n",
      "Epoch 9, Loss: 0.14207634329795837\n",
      "Epoch 6, Loss: 0.24581855535507202\n",
      "Epoch 8, Loss: 0.007685594726353884\n",
      "Epoch 5, Loss: 0.12200140953063965\n",
      "Epoch 6, Loss: 0.461205393075943\n",
      "Epoch 7, Loss: 0.3885142207145691\n",
      "Epoch 5, Loss: 0.028414826840162277\n",
      "Epoch 7, Loss: 0.04985072836279869\n",
      "Epoch 10, Loss: 0.115267314016819\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.0004220556527210704, num_heads=4, num_layers=1; total time=   1.0s\n",
      "Epoch 8, Loss: 0.11217651516199112\n",
      "Epoch 5, Loss: 0.497611939907074\n",
      "Epoch 9, Loss: 0.037898387759923935\n",
      "Epoch 5, Loss: 0.10083595663309097\n",
      "Epoch 7, Loss: 0.4262644052505493\n",
      "Epoch 7, Loss: 0.09680120646953583\n",
      "Epoch 6, Loss: 0.09647685289382935\n",
      "Epoch 9, Loss: 0.08953624963760376\n",
      "Epoch 8, Loss: 0.2262260764837265\n",
      "Epoch 6, Loss: 0.07345285266637802\n",
      "Epoch 10, Loss: 0.059736303985118866\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.0004220556527210704, num_heads=4, num_layers=1; total time=   1.1s\n",
      "Epoch 8, Loss: 0.07712772488594055\n",
      "Epoch 8, Loss: 0.31176647543907166\n",
      "Epoch 6, Loss: 0.25532230734825134\n",
      "Epoch 8, Loss: 0.018503203988075256\n",
      "Epoch 9, Loss: 0.09842789173126221\n",
      "Epoch 10, Loss: 0.043859850615262985\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.0004220556527210704, num_heads=4, num_layers=1; total time=   1.2s\n",
      "Epoch 7, Loss: 0.025163505226373672\n",
      "Epoch 6, Loss: 0.017786821350455284\n",
      "Epoch 9, Loss: 0.18506063520908356\n",
      "Epoch 9, Loss: 0.06724093109369278\n",
      "Epoch 10, Loss: 0.029142847284674644\n",
      "Epoch 9, Loss: 0.01976543292403221\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.0004220556527210704, num_heads=4, num_layers=1; total time=   1.2s\n",
      "Epoch 7, Loss: 0.06492924690246582\n",
      "Epoch 7, Loss: 0.07009394466876984\n",
      "Epoch 8, Loss: 0.011114000342786312\n",
      "Epoch 7, Loss: 0.0336654931306839\n",
      "Epoch 10, Loss: 0.06797543913125992\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.0004220556527210704, num_heads=4, num_layers=1; total time=   1.3s\n",
      "Epoch 10, Loss: 0.0380166657269001\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.0004220556527210704, num_heads=4, num_layers=1; total time=   1.3s\n",
      "Epoch 8, Loss: 0.02475956454873085\n",
      "Epoch 10, Loss: 0.08398640900850296\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.0004220556527210704, num_heads=4, num_layers=1; total time=   1.3s\n",
      "Epoch 9, Loss: 0.045697662979364395\n",
      "Epoch 8, Loss: 0.0168682299554348\n",
      "Epoch 8, Loss: 0.07542307674884796\n",
      "Epoch 9, Loss: 0.00479236850515008\n",
      "Epoch 10, Loss: 0.06499113887548447\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.0004220556527210704, num_heads=4, num_layers=1; total time=   1.3s\n",
      "Epoch 9, Loss: 0.0587092824280262\n",
      "Epoch 9, Loss: 0.0670439824461937\n",
      "Epoch 10, Loss: 0.02159140259027481\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.0004220556527210704, num_heads=4, num_layers=1; total time=   1.4s\n",
      "Epoch 10, Loss: 0.019866041839122772\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.0004220556527210704, num_heads=4, num_layers=1; total time=   1.4s\n",
      "Epoch 10, Loss: 0.1394781768321991\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.0004220556527210704, num_heads=4, num_layers=1; total time=   1.4s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.32198917865753174\n",
      "Epoch 1, Loss: 0.1447400599718094\n",
      "Epoch 1, Loss: 0.05586325377225876\n",
      "Epoch 1, Loss: 0.08122338354587555\n",
      "Epoch 1, Loss: 0.5600439310073853\n",
      "Epoch 2, Loss: 9.759262084960938\n",
      "Epoch 1, Loss: 0.2733036279678345\n",
      "Epoch 2, Loss: 11.323144912719727\n",
      "Epoch 1, Loss: 0.035266827791929245\n",
      "Epoch 2, Loss: 9.803071022033691\n",
      "Epoch 3, Loss: 2.180251359939575\n",
      "Epoch 1, Loss: 0.37099337577819824\n",
      "Epoch 2, Loss: 10.517293930053711\n",
      "Epoch 3, Loss: 1.181381106376648\n",
      "Epoch 2, Loss: 6.186240196228027\n",
      "Epoch 1, Loss: 0.354477196931839\n",
      "Epoch 2, Loss: 7.975397109985352\n",
      "Epoch 2, Loss: 14.856283187866211\n",
      "Epoch 4, Loss: 0.06027853488922119\n",
      "Epoch 3, Loss: 0.04691874235868454\n",
      "Epoch 2, Loss: 10.291723251342773\n",
      "Epoch 1, Loss: 0.13402342796325684\n",
      "Epoch 1, Loss: 0.10820720344781876\n",
      "Epoch 3, Loss: 0.08438456058502197\n",
      "Epoch 1, Loss: 1.5253660678863525\n",
      "Epoch 5, Loss: 0.9114475846290588\n",
      "Epoch 3, Loss: 2.717588186264038\n",
      "Epoch 4, Loss: 1.3203788995742798\n",
      "Epoch 3, Loss: 1.728636622428894\n",
      "Epoch 2, Loss: 10.974238395690918\n",
      "Epoch 6, Loss: 0.8410335183143616\n",
      "Epoch 3, Loss: 2.9762227535247803\n",
      "Epoch 2, Loss: 3.878114700317383\n",
      "Epoch 2, Loss: 10.87829303741455\n",
      "Epoch 4, Loss: 1.0326921939849854\n",
      "Epoch 4, Loss: 0.07445606589317322\n",
      "Epoch 5, Loss: 0.9869146943092346\n",
      "Epoch 3, Loss: 2.6420373916625977\n",
      "Epoch 4, Loss: 0.38320401310920715\n",
      "Epoch 7, Loss: 0.37606608867645264\n",
      "Epoch 2, Loss: 7.877951622009277\n",
      "Epoch 3, Loss: 2.275402545928955\n",
      "Epoch 5, Loss: 0.236786350607872\n",
      "Epoch 4, Loss: 0.10945522785186768\n",
      "Epoch 5, Loss: 0.6947005987167358\n",
      "Epoch 4, Loss: 0.1654251664876938\n",
      "Epoch 8, Loss: 0.09568798542022705\n",
      "Epoch 3, Loss: 0.7597430944442749\n",
      "Epoch 4, Loss: 0.058234699070453644\n",
      "Epoch 3, Loss: 2.695808172225952\n",
      "Epoch 5, Loss: 0.05155441164970398\n",
      "Epoch 6, Loss: 0.2885778248310089\n",
      "Epoch 5, Loss: 0.731587827205658\n",
      "Epoch 6, Loss: 0.06334272772073746\n",
      "Epoch 3, Loss: 2.553070306777954\n",
      "Epoch 4, Loss: 0.04975968599319458\n",
      "Epoch 9, Loss: 0.0796821340918541\n",
      "Epoch 6, Loss: 0.8514949083328247\n",
      "Epoch 4, Loss: 1.388110876083374\n",
      "Epoch 6, Loss: 0.10083606839179993\n",
      "Epoch 7, Loss: 0.05739014595746994\n",
      "Epoch 4, Loss: 0.6411001682281494\n",
      "Epoch 5, Loss: 1.0864149332046509\n",
      "Epoch 10, Loss: 0.17519553005695343\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=1024, head_dim=8, lr=0.004198207963631229, num_heads=8, num_layers=2; total time=   0.8s\n",
      "Epoch 5, Loss: 0.8156893849372864\n",
      "Epoch 7, Loss: 0.21406587958335876\n",
      "Epoch 6, Loss: 0.47003236413002014\n",
      "Epoch 5, Loss: 0.6966307163238525\n",
      "Epoch 8, Loss: 0.09666268527507782\n",
      "Epoch 7, Loss: 0.1317741721868515\n",
      "Epoch 5, Loss: 1.2271569967269897\n",
      "Epoch 7, Loss: 0.440727174282074\n",
      "Epoch 4, Loss: 0.12815643846988678\n",
      "Epoch 8, Loss: 0.19152085483074188\n",
      "Epoch 5, Loss: 0.027352331206202507\n",
      "Epoch 7, Loss: 0.13326822221279144\n",
      "Epoch 9, Loss: 0.17238134145736694\n",
      "Epoch 6, Loss: 0.6965361833572388\n",
      "Epoch 6, Loss: 0.8971076011657715\n",
      "Epoch 6, Loss: 0.6876383423805237\n",
      "Epoch 8, Loss: 0.07266853749752045\n",
      "Epoch 9, Loss: 0.09227883070707321\n",
      "Epoch 8, Loss: 0.12972944974899292\n",
      "Epoch 10, Loss: 0.18449509143829346\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=1024, head_dim=8, lr=0.004198207963631229, num_heads=8, num_layers=2; total time=   1.1s\n",
      "Epoch 8, Loss: 0.05357949435710907\n",
      "Epoch 6, Loss: 0.4363495409488678\n",
      "Epoch 7, Loss: 0.29500365257263184\n",
      "Epoch 5, Loss: 0.5216501355171204\n",
      "Epoch 9, Loss: 0.06626646965742111\n",
      "Epoch 7, Loss: 0.4521622359752655\n",
      "Epoch 10, Loss: 0.05983218923211098\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=1024, head_dim=8, lr=0.004198207963631229, num_heads=8, num_layers=2; total time=   1.1s\n",
      "Epoch 7, Loss: 0.15967737138271332\n",
      "Epoch 6, Loss: 0.32071012258529663\n",
      "Epoch 9, Loss: 0.05289185419678688\n",
      "Epoch 9, Loss: 0.11392790824174881\n",
      "Epoch 7, Loss: 0.07550623267889023\n",
      "Epoch 10, Loss: 0.10331794619560242\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=1024, head_dim=8, lr=0.004198207963631229, num_heads=8, num_layers=2; total time=   1.2s\n",
      "Epoch 8, Loss: 0.06273147463798523\n",
      "Epoch 8, Loss: 0.06827858090400696\n",
      "Epoch 10, Loss: 0.11438528448343277\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=1024, head_dim=8, lr=0.004198207963631229, num_heads=8, num_layers=2; total time=   1.2s\n",
      "Epoch 6, Loss: 0.7350658774375916\n",
      "Epoch 8, Loss: 0.1252477616071701\n",
      "Epoch 10, Loss: 0.15179985761642456\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=1024, head_dim=8, lr=0.004198207963631229, num_heads=8, num_layers=2; total time=   1.2s\n",
      "Epoch 8, Loss: 0.10778138786554337\n",
      "Epoch 7, Loss: 0.3803175091743469\n",
      "Epoch 9, Loss: 0.11944685876369476\n",
      "Epoch 9, Loss: 0.22881415486335754\n",
      "Epoch 7, Loss: 0.41670629382133484\n",
      "Epoch 9, Loss: 0.0536765493452549\n",
      "Epoch 9, Loss: 0.23727695643901825\n",
      "Epoch 10, Loss: 0.2763780951499939\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=1024, head_dim=8, lr=0.004198207963631229, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 10, Loss: 0.23015809059143066\n",
      "Epoch 8, Loss: 0.1962401568889618\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=1024, head_dim=8, lr=0.004198207963631229, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 10, Loss: 0.13106758892536163\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=1024, head_dim=8, lr=0.004198207963631229, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 8, Loss: 0.14929883182048798\n",
      "Epoch 10, Loss: 0.26724696159362793\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=1024, head_dim=8, lr=0.004198207963631229, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 9, Loss: 0.05815032497048378\n",
      "Epoch 9, Loss: 0.06208386272192001\n",
      "Epoch 10, Loss: 0.08864188939332962\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=1024, head_dim=8, lr=0.004198207963631229, num_heads=8, num_layers=2; total time=   1.4s\n",
      "Epoch 10, Loss: 0.09867903590202332\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=1024, head_dim=8, lr=0.004198207963631229, num_heads=8, num_layers=2; total time=   1.4s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 2.3201870918273926\n",
      "Epoch 1, Loss: 0.15544618666172028\n",
      "Epoch 2, Loss: 0.7073636651039124\n",
      "Epoch 1, Loss: 0.15567466616630554\n",
      "Epoch 1, Loss: 0.062371090054512024\n",
      "Epoch 1, Loss: 0.11435063183307648\n",
      "Epoch 2, Loss: 0.19145803153514862\n",
      "Epoch 1, Loss: 2.1230103969573975\n",
      "Epoch 3, Loss: 0.04910524934530258\n",
      "Epoch 1, Loss: 0.2573474943637848\n",
      "Epoch 2, Loss: 0.4019366204738617\n",
      "Epoch 1, Loss: 2.2119524478912354\n",
      "Epoch 2, Loss: 0.22735010087490082\n",
      "Epoch 2, Loss: 0.3237189054489136\n",
      "Epoch 1, Loss: 1.1875940561294556\n",
      "Epoch 3, Loss: 0.05111584812402725\n",
      "Epoch 1, Loss: 2.6791982650756836\n",
      "Epoch 4, Loss: 0.1287391483783722\n",
      "Epoch 2, Loss: 0.5501776337623596\n",
      "Epoch 3, Loss: 0.10818592458963394\n",
      "Epoch 3, Loss: 0.06025702506303787\n",
      "Epoch 1, Loss: 0.4455541670322418\n",
      "Epoch 3, Loss: 0.0422825962305069\n",
      "Epoch 2, Loss: 0.6131429672241211\n",
      "Epoch 4, Loss: 0.08647985011339188\n",
      "Epoch 1, Loss: 1.8678977489471436\n",
      "Epoch 5, Loss: 0.3988683819770813\n",
      "Epoch 2, Loss: 0.3037014901638031\n",
      "Epoch 2, Loss: 0.8536302447319031\n",
      "Epoch 3, Loss: 0.0865698829293251\n",
      "Epoch 2, Loss: 0.10147520899772644\n",
      "Epoch 4, Loss: 0.1137920543551445\n",
      "Epoch 4, Loss: 0.11221449822187424\n",
      "Epoch 5, Loss: 0.06317463517189026\n",
      "Epoch 6, Loss: 0.5152705311775208\n",
      "Epoch 4, Loss: 0.03606606647372246\n",
      "Epoch 2, Loss: 0.09884213656187057\n",
      "Epoch 2, Loss: 0.368018239736557\n",
      "Epoch 3, Loss: 0.2413087785243988\n",
      "Epoch 3, Loss: 0.05807548761367798\n",
      "Epoch 3, Loss: 0.07312354445457458\n",
      "Epoch 4, Loss: 0.310910701751709\n",
      "Epoch 5, Loss: 0.15233947336673737\n",
      "Epoch 6, Loss: 0.013931353576481342\n",
      "Epoch 5, Loss: 0.07891357690095901\n",
      "Epoch 5, Loss: 0.19840753078460693\n",
      "Epoch 7, Loss: 0.46074581146240234\n",
      "Epoch 3, Loss: 0.19118866324424744\n",
      "Epoch 4, Loss: 0.4195519685745239\n",
      "Epoch 3, Loss: 0.3038747012615204\n",
      "Epoch 6, Loss: 0.08240921795368195\n",
      "Epoch 4, Loss: 0.22467342019081116\n",
      "Epoch 5, Loss: 0.5307735204696655\n",
      "Epoch 6, Loss: 0.07015244662761688\n",
      "Epoch 7, Loss: 0.019837012514472008\n",
      "Epoch 4, Loss: 0.07540661841630936\n",
      "Epoch 6, Loss: 0.10282981395721436\n",
      "Epoch 3, Loss: 0.25787314772605896\n",
      "Epoch 8, Loss: 0.32422778010368347\n",
      "Epoch 8, Loss: 0.043210674077272415\n",
      "Epoch 4, Loss: 0.11101585626602173\n",
      "Epoch 7, Loss: 0.03677838295698166\n",
      "Epoch 7, Loss: 0.015487435273826122\n",
      "Epoch 7, Loss: 0.01579498127102852\n",
      "Epoch 5, Loss: 0.424617201089859\n",
      "Epoch 6, Loss: 0.5359492897987366\n",
      "Epoch 5, Loss: 0.49160706996917725\n",
      "Epoch 9, Loss: 0.18055878579616547\n",
      "Epoch 4, Loss: 0.5540952086448669\n",
      "Epoch 4, Loss: 0.16480597853660583\n",
      "Epoch 5, Loss: 0.3626748323440552\n",
      "Epoch 9, Loss: 0.029907722026109695\n",
      "Epoch 8, Loss: 0.03948674350976944\n",
      "Epoch 8, Loss: 0.012583347968757153\n",
      "Epoch 7, Loss: 0.40768757462501526\n",
      "Epoch 8, Loss: 0.019817553460597992\n",
      "Epoch 10, Loss: 0.07426905632019043\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.21322263675795053, feed_forward_dim=256, head_dim=8, lr=0.0004308478554790086, num_heads=2, num_layers=1; total time=   1.1s\n",
      "Epoch 6, Loss: 0.3011997640132904\n",
      "Epoch 5, Loss: 0.04090481251478195\n",
      "Epoch 9, Loss: 0.030089281499385834\n",
      "Epoch 9, Loss: 0.0682675838470459\n",
      "Epoch 8, Loss: 0.24399793148040771\n",
      "Epoch 9, Loss: 0.07286068797111511\n",
      "Epoch 6, Loss: 0.5374943614006042\n",
      "Epoch 6, Loss: 0.5529783964157104\n",
      "Epoch 10, Loss: 0.008858298882842064\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.21322263675795053, feed_forward_dim=256, head_dim=8, lr=0.0004308478554790086, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 5, Loss: 0.028161657974123955\n",
      "Epoch 6, Loss: 0.05162344127893448\n",
      "Epoch 10, Loss: 0.046178191900253296\n",
      "Epoch 10, Loss: 0.08657235652208328\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.21322263675795053, feed_forward_dim=256, head_dim=8, lr=0.0004308478554790086, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 5, Loss: 0.596051037311554\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.21322263675795053, feed_forward_dim=256, head_dim=8, lr=0.0004308478554790086, num_heads=2, num_layers=1; total time=   1.1s\n",
      "Epoch 7, Loss: 0.16795949637889862\n",
      "Epoch 9, Loss: 0.1110057458281517\n",
      "Epoch 10, Loss: 0.06323087215423584\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.21322263675795053, feed_forward_dim=256, head_dim=8, lr=0.0004308478554790086, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 7, Loss: 0.4451146721839905\n",
      "Epoch 7, Loss: 0.5371334552764893\n",
      "Epoch 6, Loss: 0.04019942879676819\n",
      "Epoch 7, Loss: 0.0840773805975914\n",
      "Epoch 10, Loss: 0.04162728041410446\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.21322263675795053, feed_forward_dim=256, head_dim=8, lr=0.0004308478554790086, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 8, Loss: 0.08634573221206665\n",
      "Epoch 6, Loss: 0.43933865427970886\n",
      "Epoch 8, Loss: 0.27439871430397034\n",
      "Epoch 8, Loss: 0.42114055156707764\n",
      "Epoch 8, Loss: 0.0787881389260292\n",
      "Epoch 7, Loss: 0.10939602553844452\n",
      "Epoch 9, Loss: 0.0680491179227829\n",
      "Epoch 7, Loss: 0.2409614771604538\n",
      "Epoch 9, Loss: 0.13056446611881256\n",
      "Epoch 9, Loss: 0.26616209745407104\n",
      "Epoch 9, Loss: 0.04653918370604515\n",
      "Epoch 10, Loss: 0.08886308968067169\n",
      "Epoch 8, Loss: 0.12209632992744446\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.21322263675795053, feed_forward_dim=256, head_dim=8, lr=0.0004308478554790086, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 8, Loss: 0.10123410820960999\n",
      "Epoch 10, Loss: 0.04719531536102295\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.21322263675795053, feed_forward_dim=256, head_dim=8, lr=0.0004308478554790086, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 10, Loss: 0.02196647785604\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.21322263675795053, feed_forward_dim=256, head_dim=8, lr=0.0004308478554790086, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.13302184641361237\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.21322263675795053, feed_forward_dim=256, head_dim=8, lr=0.0004308478554790086, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 9, Loss: 0.07457864284515381\n",
      "Epoch 9, Loss: 0.056002985686063766\n",
      "Epoch 10, Loss: 0.024734925478696823\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.21322263675795053, feed_forward_dim=256, head_dim=8, lr=0.0004308478554790086, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.08372735977172852\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.21322263675795053, feed_forward_dim=256, head_dim=8, lr=0.0004308478554790086, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.6152024269104004\n",
      "Epoch 1, Loss: 0.07125449180603027\n",
      "Epoch 1, Loss: 1.9950331449508667\n",
      "Epoch 2, Loss: 0.18965494632720947\n",
      "Epoch 2, Loss: 0.44092053174972534\n",
      "Epoch 1, Loss: 0.35645413398742676\n",
      "Epoch 3, Loss: 0.33656883239746094\n",
      "Epoch 2, Loss: 0.4724563956260681\n",
      "Epoch 1, Loss: 1.12022864818573\n",
      "Epoch 1, Loss: 2.18996262550354\n",
      "Epoch 3, Loss: 0.07370539009571075\n",
      "Epoch 1, Loss: 0.15132534503936768\n",
      "Epoch 4, Loss: 0.2677360773086548\n",
      "Epoch 1, Loss: 0.5476434826850891\n",
      "Epoch 1, Loss: 0.4578317701816559\n",
      "Epoch 2, Loss: 0.24488891661167145\n",
      "Epoch 2, Loss: 0.20685012638568878\n",
      "Epoch 3, Loss: 0.18834203481674194\n",
      "Epoch 4, Loss: 0.08010602742433548\n",
      "Epoch 5, Loss: 0.12212485074996948\n",
      "Epoch 1, Loss: 0.4328934848308563\n",
      "Epoch 1, Loss: 0.29943981766700745\n",
      "Epoch 2, Loss: 0.5883928537368774\n",
      "Epoch 2, Loss: 0.1550268679857254\n",
      "Epoch 2, Loss: 0.12354947626590729\n",
      "Epoch 4, Loss: 0.4544467031955719\n",
      "Epoch 2, Loss: 0.0664726048707962\n",
      "Epoch 6, Loss: 0.04838034138083458\n",
      "Epoch 3, Loss: 0.26001042127609253\n",
      "Epoch 1, Loss: 1.3098236322402954\n",
      "Epoch 5, Loss: 0.1944020390510559\n",
      "Epoch 3, Loss: 0.1175580695271492\n",
      "Epoch 3, Loss: 0.0497504360973835\n",
      "Epoch 2, Loss: 0.05402055010199547\n",
      "Epoch 7, Loss: 0.07443494349718094\n",
      "Epoch 3, Loss: 0.2819051742553711\n",
      "Epoch 6, Loss: 0.1408614069223404\n",
      "Epoch 2, Loss: 0.0750432014465332\n",
      "Epoch 3, Loss: 0.12551170587539673\n",
      "Epoch 4, Loss: 0.336709588766098\n",
      "Epoch 4, Loss: 0.10574383288621902\n",
      "Epoch 3, Loss: 0.22681985795497894\n",
      "Epoch 5, Loss: 0.5925865769386292\n",
      "Epoch 8, Loss: 0.11865352839231491\n",
      "Epoch 4, Loss: 0.15652750432491302\n",
      "Epoch 2, Loss: 0.07697749137878418\n",
      "Epoch 7, Loss: 0.0411340668797493\n",
      "Epoch 5, Loss: 0.04643046483397484\n",
      "Epoch 9, Loss: 0.11603666841983795\n",
      "Epoch 4, Loss: 0.1539624035358429\n",
      "Epoch 4, Loss: 0.019391585141420364\n",
      "Epoch 4, Loss: 0.2761348783969879\n",
      "Epoch 6, Loss: 0.5133573412895203\n",
      "Epoch 8, Loss: 0.012991294264793396\n",
      "Epoch 5, Loss: 0.3854790925979614\n",
      "Epoch 3, Loss: 0.16853667795658112\n",
      "Epoch 3, Loss: 0.232369065284729\n",
      "Epoch 5, Loss: 0.38048839569091797\n",
      "Epoch 10, Loss: 0.07197191566228867\n",
      "Epoch 6, Loss: 0.09206512570381165\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.2928865258722495, feed_forward_dim=256, head_dim=8, lr=0.00043314087722384065, num_heads=2, num_layers=1; total time=   0.8s\n",
      "Epoch 3, Loss: 0.27535513043403625\n",
      "Epoch 9, Loss: 0.05350443348288536\n",
      "Epoch 5, Loss: 0.029947523027658463\n",
      "Epoch 5, Loss: 0.17078351974487305\n",
      "Epoch 7, Loss: 0.33117663860321045\n",
      "Epoch 5, Loss: 0.030037498101592064\n",
      "Epoch 4, Loss: 0.12947525084018707\n",
      "Epoch 6, Loss: 0.4715687334537506\n",
      "Epoch 7, Loss: 0.10665096342563629\n",
      "Epoch 4, Loss: 0.21035970747470856\n",
      "Epoch 6, Loss: 0.28306832909584045\n",
      "Epoch 10, Loss: 0.08958390355110168\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.2928865258722495, feed_forward_dim=256, head_dim=8, lr=0.00043314087722384065, num_heads=2, num_layers=1; total time=   0.9s\n",
      "Epoch 4, Loss: 0.5146010518074036\n",
      "Epoch 6, Loss: 0.07366548478603363\n",
      "Epoch 6, Loss: 0.062378302216529846\n",
      "Epoch 6, Loss: 0.04133281484246254\n",
      "Epoch 8, Loss: 0.16567184031009674\n",
      "Epoch 8, Loss: 0.06258098781108856\n",
      "Epoch 7, Loss: 0.4350522458553314\n",
      "Epoch 7, Loss: 0.14925609529018402\n",
      "Epoch 5, Loss: 0.08425774425268173\n",
      "Epoch 7, Loss: 0.05629538744688034\n",
      "Epoch 7, Loss: 0.029677849262952805\n",
      "Epoch 5, Loss: 0.411314994096756\n",
      "Epoch 9, Loss: 0.016887208446860313\n",
      "Epoch 9, Loss: 0.0706615075469017\n",
      "Epoch 5, Loss: 0.050130054354667664\n",
      "Epoch 8, Loss: 0.31579285860061646\n",
      "Epoch 8, Loss: 0.060117825865745544\n",
      "Epoch 7, Loss: 0.10340987890958786\n",
      "Epoch 8, Loss: 0.01661059260368347\n",
      "Epoch 10, Loss: 0.055794838815927505\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.2928865258722495, feed_forward_dim=256, head_dim=8, lr=0.00043314087722384065, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 10, Loss: 0.010886454954743385\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.2928865258722495, feed_forward_dim=256, head_dim=8, lr=0.00043314087722384065, num_heads=2, num_layers=1; total time=   1.1s\n",
      "Epoch 9, Loss: 0.1906697005033493\n",
      "Epoch 8, Loss: 0.06366347521543503\n",
      "Epoch 6, Loss: 0.015971630811691284\n",
      "Epoch 6, Loss: 0.19347915053367615\n",
      "Epoch 9, Loss: 0.038178395479917526\n",
      "Epoch 6, Loss: 0.019614381715655327\n",
      "Epoch 9, Loss: 0.005639701150357723\n",
      "Epoch 8, Loss: 0.10815726965665817\n",
      "Epoch 10, Loss: 0.08940134942531586\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.2928865258722495, feed_forward_dim=256, head_dim=8, lr=0.00043314087722384065, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 9, Loss: 0.10249536484479904\n",
      "Epoch 10, Loss: 0.06259021162986755\n",
      "Epoch 7, Loss: 0.03734653443098068\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.2928865258722495, feed_forward_dim=256, head_dim=8, lr=0.00043314087722384065, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 10, Loss: 0.024849656969308853\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.2928865258722495, feed_forward_dim=256, head_dim=8, lr=0.00043314087722384065, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 7, Loss: 0.03772345930337906\n",
      "Epoch 9, Loss: 0.06197768449783325\n",
      "Epoch 7, Loss: 0.04437904432415962\n",
      "Epoch 10, Loss: 0.10582958161830902\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.2928865258722495, feed_forward_dim=256, head_dim=8, lr=0.00043314087722384065, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 8, Loss: 0.0836503803730011\n",
      "Epoch 8, Loss: 0.05975134298205376\n",
      "Epoch 10, Loss: 0.01865261234343052\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.2928865258722495, feed_forward_dim=256, head_dim=8, lr=0.00043314087722384065, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 8, Loss: 0.018066028133034706\n",
      "Epoch 9, Loss: 0.09294434636831284\n",
      "Epoch 9, Loss: 0.05239185318350792\n",
      "Epoch 9, Loss: 0.07445176690816879\n",
      "Epoch 10, Loss: 0.061837755143642426\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.2928865258722495, feed_forward_dim=256, head_dim=8, lr=0.00043314087722384065, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 10, Loss: 0.027964452281594276\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.2928865258722495, feed_forward_dim=256, head_dim=8, lr=0.00043314087722384065, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.14085841178894043\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.2928865258722495, feed_forward_dim=256, head_dim=8, lr=0.00043314087722384065, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.13523799180984497\n",
      "Epoch 1, Loss: 0.5921800136566162\n",
      "Epoch 2, Loss: 0.4498172700405121\n",
      "Epoch 1, Loss: 0.6615611910820007\n",
      "Epoch 2, Loss: 0.11098109930753708\n",
      "Epoch 3, Loss: 0.10508384555578232\n",
      "Epoch 1, Loss: 0.17675749957561493\n",
      "Epoch 1, Loss: 0.7609326243400574\n",
      "Epoch 1, Loss: 0.49658024311065674\n",
      "Epoch 4, Loss: 0.0674220472574234\n",
      "Epoch 2, Loss: 0.05770730972290039\n",
      "Epoch 3, Loss: 0.2799188196659088\n",
      "Epoch 1, Loss: 0.5672500729560852\n",
      "Epoch 1, Loss: 0.08258599787950516\n",
      "Epoch 2, Loss: 0.4520193338394165\n",
      "Epoch 1, Loss: 0.08460000902414322\n",
      "Epoch 2, Loss: 0.0688062459230423\n",
      "Epoch 5, Loss: 0.17397162318229675\n",
      "Epoch 2, Loss: 0.349224328994751\n",
      "Epoch 3, Loss: 0.279692679643631\n",
      "Epoch 1, Loss: 0.11661992222070694\n",
      "Epoch 2, Loss: 0.4529950022697449\n",
      "Epoch 1, Loss: 0.03020307794213295\n",
      "Epoch 4, Loss: 0.2591242790222168\n",
      "Epoch 6, Loss: 0.14285755157470703\n",
      "Epoch 3, Loss: 0.09908544272184372\n",
      "Epoch 1, Loss: 2.702432155609131\n",
      "Epoch 3, Loss: 0.35326525568962097\n",
      "Epoch 4, Loss: 0.312161386013031\n",
      "Epoch 2, Loss: 0.07499265670776367\n",
      "Epoch 3, Loss: 0.29917091131210327\n",
      "Epoch 2, Loss: 0.26351600885391235\n",
      "Epoch 7, Loss: 0.04914635047316551\n",
      "Epoch 2, Loss: 0.2830544114112854\n",
      "Epoch 5, Loss: 0.12320886552333832\n",
      "Epoch 4, Loss: 0.10396422445774078\n",
      "Epoch 3, Loss: 0.06935891509056091\n",
      "Epoch 2, Loss: 0.5221536159515381\n",
      "Epoch 5, Loss: 0.1743774712085724\n",
      "Epoch 8, Loss: 0.015295612625777721\n",
      "Epoch 4, Loss: 0.1450178474187851\n",
      "Epoch 2, Loss: 0.45446255803108215\n",
      "Epoch 4, Loss: 0.3589564859867096\n",
      "Epoch 5, Loss: 0.183419868350029\n",
      "Epoch 3, Loss: 0.26868292689323425\n",
      "Epoch 6, Loss: 0.036960192024707794\n",
      "Epoch 9, Loss: 0.05203073471784592\n",
      "Epoch 4, Loss: 0.0937349945306778\n",
      "Epoch 3, Loss: 0.027788925915956497\n",
      "Epoch 3, Loss: 0.10008487850427628\n",
      "Epoch 6, Loss: 0.05930458381772041\n",
      "Epoch 10, Loss: 0.08839531987905502\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.18043976847689736, feed_forward_dim=256, head_dim=8, lr=0.0005187989200097595, num_heads=4, num_layers=4; total time=   0.8s\n",
      "Epoch 5, Loss: 0.06426537036895752\n",
      "Epoch 4, Loss: 0.25571686029434204\n",
      "Epoch 6, Loss: 0.1138073056936264\n",
      "Epoch 3, Loss: 0.09030947089195251\n",
      "Epoch 3, Loss: 0.04119659960269928\n",
      "Epoch 5, Loss: 0.21694982051849365\n",
      "Epoch 4, Loss: 0.17782558500766754\n",
      "Epoch 7, Loss: 0.03902854025363922\n",
      "Epoch 5, Loss: 0.20566269755363464\n",
      "Epoch 7, Loss: 0.037037525326013565\n",
      "Epoch 4, Loss: 0.020746026188135147\n",
      "Epoch 7, Loss: 0.0285581573843956\n",
      "Epoch 8, Loss: 0.08190039545297623\n",
      "Epoch 5, Loss: 0.1262209266424179\n",
      "Epoch 8, Loss: 0.0762040764093399\n",
      "Epoch 6, Loss: 0.1123979464173317\n",
      "Epoch 4, Loss: 0.5142775774002075\n",
      "Epoch 5, Loss: 0.12003367394208908\n",
      "Epoch 6, Loss: 0.13673560321331024\n",
      "Epoch 8, Loss: 0.024654310196638107\n",
      "Epoch 4, Loss: 0.15630219876766205\n",
      "Epoch 6, Loss: 0.08008743822574615\n",
      "Epoch 9, Loss: 0.10081315040588379\n",
      "Epoch 5, Loss: 0.09652364253997803\n",
      "Epoch 9, Loss: 0.11801613122224808\n",
      "Epoch 6, Loss: 0.04207480326294899\n",
      "Epoch 6, Loss: 0.021827302873134613\n",
      "Epoch 9, Loss: 0.06906050443649292\n",
      "Epoch 7, Loss: 0.03278022259473801\n",
      "Epoch 7, Loss: 0.1352369636297226\n",
      "Epoch 10, Loss: 0.07693149149417877\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.18043976847689736, feed_forward_dim=256, head_dim=8, lr=0.0005187989200097595, num_heads=4, num_layers=4; total time=   1.1s\n",
      "Epoch 5, Loss: 0.7105538249015808\n",
      "Epoch 7, Loss: 0.04450814053416252\n",
      "Epoch 5, Loss: 0.2671719491481781\n",
      "Epoch 7, Loss: 0.03614092245697975\n",
      "Epoch 10, Loss: 0.0845264121890068\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.18043976847689736, feed_forward_dim=256, head_dim=8, lr=0.0005187989200097595, num_heads=4, num_layers=4; total time=   1.0s\n",
      "Epoch 6, Loss: 0.10284990817308426\n",
      "Epoch 7, Loss: 0.031669244170188904\n",
      "Epoch 10, Loss: 0.12497507035732269\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.18043976847689736, feed_forward_dim=256, head_dim=8, lr=0.0005187989200097595, num_heads=4, num_layers=4; total time=   1.1s\n",
      "Epoch 8, Loss: 0.015844782814383507\n",
      "Epoch 8, Loss: 0.08491388708353043\n",
      "Epoch 8, Loss: 0.09036047756671906\n",
      "Epoch 6, Loss: 0.1448851078748703\n",
      "Epoch 6, Loss: 0.6176588535308838\n",
      "Epoch 7, Loss: 0.04211515560746193\n",
      "Epoch 8, Loss: 0.07645802944898605\n",
      "Epoch 9, Loss: 0.059758260846138\n",
      "Epoch 8, Loss: 0.08300293982028961\n",
      "Epoch 9, Loss: 0.03292172774672508\n",
      "Epoch 9, Loss: 0.10358497500419617\n",
      "Epoch 9, Loss: 0.12909749150276184\n",
      "Epoch 7, Loss: 0.39856353402137756\n",
      "Epoch 10, Loss: 0.09218037128448486\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.18043976847689736, feed_forward_dim=256, head_dim=8, lr=0.0005187989200097595, num_heads=4, num_layers=4; total time=   1.2s\n",
      "Epoch 8, Loss: 0.009856179356575012\n",
      "Epoch 9, Loss: 0.07795178145170212\n",
      "Epoch 7, Loss: 0.026761898770928383\n",
      "Epoch 10, Loss: 0.017192209139466286\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.18043976847689736, feed_forward_dim=256, head_dim=8, lr=0.0005187989200097595, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 10, Loss: 0.08294931054115295\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.18043976847689736, feed_forward_dim=256, head_dim=8, lr=0.0005187989200097595, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 10, Loss: 0.1374543160200119\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.18043976847689736, feed_forward_dim=256, head_dim=8, lr=0.0005187989200097595, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 9, Loss: 0.029486186802387238\n",
      "Epoch 8, Loss: 0.19226782023906708\n",
      "Epoch 8, Loss: 0.02207547426223755\n",
      "Epoch 10, Loss: 0.0336233451962471\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.18043976847689736, feed_forward_dim=256, head_dim=8, lr=0.0005187989200097595, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 10, Loss: 0.057775743305683136\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.18043976847689736, feed_forward_dim=256, head_dim=8, lr=0.0005187989200097595, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 9, Loss: 0.06636717170476913\n",
      "Epoch 9, Loss: 0.08176980912685394\n",
      "Epoch 10, Loss: 0.03523588180541992\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.18043976847689736, feed_forward_dim=256, head_dim=8, lr=0.0005187989200097595, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 10, Loss: 0.11666356027126312\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.18043976847689736, feed_forward_dim=256, head_dim=8, lr=0.0005187989200097595, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.08953148871660233\n",
      "Epoch 1, Loss: 0.027776919305324554\n",
      "Epoch 1, Loss: 0.10909664630889893\n",
      "Epoch 1, Loss: 0.04327148199081421\n",
      "Epoch 1, Loss: 0.6839290261268616\n",
      "Epoch 1, Loss: 0.05932410806417465\n",
      "Epoch 2, Loss: 0.14886456727981567\n",
      "Epoch 2, Loss: 0.23368391394615173\n",
      "Epoch 2, Loss: 0.31502464413642883\n",
      "Epoch 1, Loss: 0.3888278305530548\n",
      "Epoch 1, Loss: 0.10297487676143646\n",
      "Epoch 1, Loss: 0.20194225013256073\n",
      "Epoch 2, Loss: 0.311689168214798\n",
      "Epoch 1, Loss: 0.20173056423664093\n",
      "Epoch 3, Loss: 0.04237568750977516\n",
      "Epoch 3, Loss: 0.0682675912976265\n",
      "Epoch 2, Loss: 0.08957076817750931\n",
      "Epoch 3, Loss: 0.03443308547139168\n",
      "Epoch 2, Loss: 0.13807101547718048\n",
      "Epoch 2, Loss: 0.37898263335227966\n",
      "Epoch 1, Loss: 0.25042057037353516\n",
      "Epoch 2, Loss: 0.04444846510887146\n",
      "Epoch 4, Loss: 0.0070359967648983\n",
      "Epoch 1, Loss: 0.05106423795223236\n",
      "Epoch 2, Loss: 0.13961470127105713\n",
      "Epoch 3, Loss: 0.0529126338660717\n",
      "Epoch 4, Loss: 0.14297020435333252\n",
      "Epoch 3, Loss: 0.05273320525884628\n",
      "Epoch 2, Loss: 0.3437848687171936\n",
      "Epoch 4, Loss: 0.0839083343744278\n",
      "Epoch 3, Loss: 0.24864259362220764\n",
      "Epoch 3, Loss: 0.17635397613048553\n",
      "Epoch 5, Loss: 0.04924899712204933\n",
      "Epoch 5, Loss: 0.10373058915138245\n",
      "Epoch 5, Loss: 0.15820516645908356\n",
      "Epoch 2, Loss: 0.1442098766565323\n",
      "Epoch 3, Loss: 0.03946094214916229\n",
      "Epoch 4, Loss: 0.10053916275501251\n",
      "Epoch 3, Loss: 0.13926585018634796\n",
      "Epoch 4, Loss: 0.05044134333729744\n",
      "Epoch 2, Loss: 0.15297695994377136\n",
      "Epoch 3, Loss: 0.14351733028888702\n",
      "Epoch 6, Loss: 0.0676552951335907\n",
      "Epoch 6, Loss: 0.02557780221104622\n",
      "Epoch 6, Loss: 0.08677946031093597\n",
      "Epoch 4, Loss: 0.09450569748878479\n",
      "Epoch 4, Loss: 0.30974864959716797\n",
      "Epoch 5, Loss: 0.14346526563167572\n",
      "Epoch 3, Loss: 0.17991741001605988\n",
      "Epoch 4, Loss: 0.05155831575393677\n",
      "Epoch 7, Loss: 0.014689179137349129\n",
      "Epoch 7, Loss: 0.03361332044005394\n",
      "Epoch 7, Loss: 0.031637001782655716\n",
      "Epoch 5, Loss: 0.013943744823336601\n",
      "Epoch 4, Loss: 0.049171946942806244\n",
      "Epoch 4, Loss: 0.006754705682396889\n",
      "Epoch 3, Loss: 0.020257126539945602\n",
      "Epoch 5, Loss: 0.251952588558197\n",
      "Epoch 6, Loss: 0.09975492209196091\n",
      "Epoch 8, Loss: 0.006405760068446398\n",
      "Epoch 8, Loss: 0.06878268718719482\n",
      "Epoch 8, Loss: 0.01721734181046486\n",
      "Epoch 5, Loss: 0.12023697048425674\n",
      "Epoch 5, Loss: 0.10671833902597427\n",
      "Epoch 6, Loss: 0.02777085267007351\n",
      "Epoch 7, Loss: 0.022927360609173775\n",
      "Epoch 5, Loss: 0.025676006451249123\n",
      "Epoch 9, Loss: 0.0599156878888607\n",
      "Epoch 5, Loss: 0.04071379825472832\n",
      "Epoch 9, Loss: 0.015561639331281185\n",
      "Epoch 6, Loss: 0.13073839247226715\n",
      "Epoch 4, Loss: 0.08653758466243744\n",
      "Epoch 9, Loss: 0.057994626462459564\n",
      "Epoch 4, Loss: 0.10501009225845337\n",
      "Epoch 7, Loss: 0.05983579158782959\n",
      "Epoch 6, Loss: 0.13482187688350677\n",
      "Epoch 6, Loss: 0.11688043922185898\n",
      "Epoch 8, Loss: 0.012694270350039005\n",
      "Epoch 10, Loss: 0.02260376140475273\n",
      "Epoch 10, Loss: 0.07197077572345734\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17532182637974747, feed_forward_dim=512, head_dim=8, lr=0.0003771557857870993, num_heads=8, num_layers=1; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17532182637974747, feed_forward_dim=512, head_dim=8, lr=0.0003771557857870993, num_heads=8, num_layers=1; total time=   1.0s\n",
      "Epoch 7, Loss: 0.04845326766371727\n",
      "Epoch 10, Loss: 0.03451487049460411\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17532182637974747, feed_forward_dim=512, head_dim=8, lr=0.0003771557857870993, num_heads=8, num_layers=1; total time=   1.0s\n",
      "Epoch 6, Loss: 0.07337721437215805\n",
      "Epoch 8, Loss: 0.03370657190680504\n",
      "Epoch 6, Loss: 0.019192835316061974\n",
      "Epoch 9, Loss: 0.05056323856115341\n",
      "Epoch 5, Loss: 0.040999118238687515\n",
      "Epoch 5, Loss: 0.07273979485034943\n",
      "Epoch 7, Loss: 0.04571884125471115\n",
      "Epoch 8, Loss: 0.03645791858434677\n",
      "Epoch 7, Loss: 0.08679273724555969\n",
      "Epoch 7, Loss: 0.06327393651008606\n",
      "Epoch 10, Loss: 0.07189136743545532\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17532182637974747, feed_forward_dim=512, head_dim=8, lr=0.0003771557857870993, num_heads=8, num_layers=1; total time=   1.1s\n",
      "Epoch 7, Loss: 0.016955280676484108\n",
      "Epoch 9, Loss: 0.0057558780536055565\n",
      "Epoch 9, Loss: 0.07315628230571747\n",
      "Epoch 6, Loss: 0.015220487490296364\n",
      "Epoch 8, Loss: 0.03047994151711464\n",
      "Epoch 6, Loss: 0.06213607266545296\n",
      "Epoch 8, Loss: 0.010773641988635063\n",
      "Epoch 8, Loss: 0.028282033279538155\n",
      "Epoch 10, Loss: 0.01975562423467636\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17532182637974747, feed_forward_dim=512, head_dim=8, lr=0.0003771557857870993, num_heads=8, num_layers=1; total time=   1.2s\n",
      "Epoch 8, Loss: 0.026165708899497986\n",
      "Epoch 9, Loss: 0.025950053706765175\n",
      "Epoch 7, Loss: 0.07604335993528366\n",
      "Epoch 10, Loss: 0.10914727300405502\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17532182637974747, feed_forward_dim=512, head_dim=8, lr=0.0003771557857870993, num_heads=8, num_layers=1; total time=   1.3s\n",
      "Epoch 7, Loss: 0.02387387491762638\n",
      "Epoch 9, Loss: 0.014527463354170322\n",
      "Epoch 9, Loss: 0.03419778496026993\n",
      "Epoch 9, Loss: 0.017213163897395134\n",
      "Epoch 10, Loss: 0.05402860790491104\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17532182637974747, feed_forward_dim=512, head_dim=8, lr=0.0003771557857870993, num_heads=8, num_layers=1; total time=   1.3s\n",
      "Epoch 8, Loss: 0.05144399404525757\n",
      "Epoch 10, Loss: 0.03116709366440773\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17532182637974747, feed_forward_dim=512, head_dim=8, lr=0.0003771557857870993, num_heads=8, num_layers=1; total time=   1.3s\n",
      "Epoch 8, Loss: 0.05440859869122505\n",
      "Epoch 10, Loss: 0.060917291790246964\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17532182637974747, feed_forward_dim=512, head_dim=8, lr=0.0003771557857870993, num_heads=8, num_layers=1; total time=   1.3s\n",
      "Epoch 10, Loss: 0.011150934733450413\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17532182637974747, feed_forward_dim=512, head_dim=8, lr=0.0003771557857870993, num_heads=8, num_layers=1; total time=   1.4s\n",
      "Epoch 9, Loss: 0.01912873238325119\n",
      "Epoch 9, Loss: 0.047353919595479965\n",
      "Epoch 10, Loss: 0.013425455428659916\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17532182637974747, feed_forward_dim=512, head_dim=8, lr=0.0003771557857870993, num_heads=8, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.018756337463855743\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17532182637974747, feed_forward_dim=512, head_dim=8, lr=0.0003771557857870993, num_heads=8, num_layers=1; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.09224706143140793\n",
      "Epoch 1, Loss: 0.3251131474971771\n",
      "Epoch 1, Loss: 0.14168845117092133\n",
      "Epoch 2, Loss: 0.20597736537456512\n",
      "Epoch 2, Loss: 0.019303856417536736\n",
      "Epoch 1, Loss: 0.10435379296541214\n",
      "Epoch 3, Loss: 0.06992357224225998\n",
      "Epoch 2, Loss: 0.12308637797832489\n",
      "Epoch 1, Loss: 0.24125409126281738\n",
      "Epoch 1, Loss: 0.10051263123750687\n",
      "Epoch 1, Loss: 0.09926799684762955\n",
      "Epoch 1, Loss: 0.08480484783649445\n",
      "Epoch 3, Loss: 0.1470259726047516\n",
      "Epoch 1, Loss: 0.4363160729408264\n",
      "Epoch 2, Loss: 0.2728513181209564\n",
      "Epoch 3, Loss: 0.1015414148569107\n",
      "Epoch 4, Loss: 0.02884889766573906\n",
      "Epoch 4, Loss: 0.16921576857566833\n",
      "Epoch 2, Loss: 0.15264791250228882\n",
      "Epoch 2, Loss: 0.24445965886116028\n",
      "Epoch 1, Loss: 0.37690284848213196\n",
      "Epoch 3, Loss: 0.06222175434231758\n",
      "Epoch 2, Loss: 0.24333691596984863\n",
      "Epoch 1, Loss: 0.051115985959768295\n",
      "Epoch 5, Loss: 0.08145328611135483\n",
      "Epoch 1, Loss: 0.35549062490463257\n",
      "Epoch 4, Loss: 0.03518388420343399\n",
      "Epoch 2, Loss: 0.024254612624645233\n",
      "Epoch 2, Loss: 0.16084295511245728\n",
      "Epoch 5, Loss: 0.08523130416870117\n",
      "Epoch 4, Loss: 0.11240918189287186\n",
      "Epoch 3, Loss: 0.1659242957830429\n",
      "Epoch 3, Loss: 0.05632944777607918\n",
      "Epoch 6, Loss: 0.07302656769752502\n",
      "Epoch 3, Loss: 0.07345201075077057\n",
      "Epoch 6, Loss: 0.018462885171175003\n",
      "Epoch 2, Loss: 0.057292141020298004\n",
      "Epoch 5, Loss: 0.0323026143014431\n",
      "Epoch 3, Loss: 0.0873430073261261\n",
      "Epoch 2, Loss: 0.22744935750961304\n",
      "Epoch 3, Loss: 0.05353734269738197\n",
      "Epoch 4, Loss: 0.09633342921733856\n",
      "Epoch 4, Loss: 0.022220110520720482\n",
      "Epoch 7, Loss: 0.020844994112849236\n",
      "Epoch 5, Loss: 0.1411251276731491\n",
      "Epoch 2, Loss: 0.03876028209924698\n",
      "Epoch 4, Loss: 0.08248383551836014\n",
      "Epoch 3, Loss: 0.1776810884475708\n",
      "Epoch 6, Loss: 0.0504157580435276\n",
      "Epoch 7, Loss: 0.02688860334455967\n",
      "Epoch 4, Loss: 0.192612886428833\n",
      "Epoch 8, Loss: 0.05896396562457085\n",
      "Epoch 3, Loss: 0.04446437954902649\n",
      "Epoch 4, Loss: 0.05759024992585182\n",
      "Epoch 5, Loss: 0.05908926576375961\n",
      "Epoch 5, Loss: 0.09786547720432281Epoch 8, Loss: 0.010531540960073471\n",
      "\n",
      "Epoch 7, Loss: 0.03564221411943436\n",
      "Epoch 5, Loss: 0.11999639868736267\n",
      "Epoch 3, Loss: 0.15436327457427979\n",
      "Epoch 6, Loss: 0.0714268758893013\n",
      "Epoch 4, Loss: 0.20093737542629242\n",
      "Epoch 9, Loss: 0.07878100872039795\n",
      "Epoch 9, Loss: 0.032733991742134094\n",
      "Epoch 5, Loss: 0.07738527655601501\n",
      "Epoch 8, Loss: 0.01104794256389141\n",
      "Epoch 4, Loss: 0.05555475130677223\n",
      "Epoch 5, Loss: 0.1576841026544571\n",
      "Epoch 6, Loss: 0.09736846387386322\n",
      "Epoch 6, Loss: 0.060804739594459534\n",
      "Epoch 10, Loss: 0.06369071453809738\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21062938627843278, feed_forward_dim=256, head_dim=8, lr=0.0003205938533620864, num_heads=4, num_layers=3; total time=   0.9s\n",
      "Epoch 7, Loss: 0.02175140380859375\n",
      "Epoch 10, Loss: 0.04673302173614502\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21062938627843278, feed_forward_dim=256, head_dim=8, lr=0.0003205938533620864, num_heads=4, num_layers=3; total time=   1.0s\n",
      "Epoch 6, Loss: 0.04627733677625656\n",
      "Epoch 4, Loss: 0.17888976633548737\n",
      "Epoch 9, Loss: 0.008708683773875237\n",
      "Epoch 5, Loss: 0.11529893428087234\n",
      "Epoch 5, Loss: 0.11414836347103119\n",
      "Epoch 7, Loss: 0.06638732552528381\n",
      "Epoch 6, Loss: 0.06669094413518906\n",
      "Epoch 8, Loss: 0.036937031894922256\n",
      "Epoch 6, Loss: 0.07007810473442078\n",
      "Epoch 7, Loss: 0.024936841800808907\n",
      "Epoch 10, Loss: 0.022928791120648384\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21062938627843278, feed_forward_dim=256, head_dim=8, lr=0.0003205938533620864, num_heads=4, num_layers=3; total time=   1.0s\n",
      "Epoch 7, Loss: 0.017666643485426903\n",
      "Epoch 5, Loss: 0.09055206179618835\n",
      "Epoch 6, Loss: 0.04206635430455208\n",
      "Epoch 9, Loss: 0.06540500372648239\n",
      "Epoch 8, Loss: 0.007461098954081535\n",
      "Epoch 6, Loss: 0.06998441368341446\n",
      "Epoch 7, Loss: 0.013595948927104473\n",
      "Epoch 8, Loss: 0.037077948451042175\n",
      "Epoch 7, Loss: 0.017628388479351997\n",
      "Epoch 10, Loss: 0.057545505464076996\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21062938627843278, feed_forward_dim=256, head_dim=8, lr=0.0003205938533620864, num_heads=4, num_layers=3; total time=   1.1s\n",
      "Epoch 8, Loss: 0.021465754136443138\n",
      "Epoch 9, Loss: 0.0227190051227808\n",
      "Epoch 7, Loss: 0.03522598370909691\n",
      "Epoch 9, Loss: 0.030776506289839745\n",
      "Epoch 7, Loss: 0.017720019444823265\n",
      "Epoch 8, Loss: 0.010632956400513649\n",
      "Epoch 6, Loss: 0.02464713528752327\n",
      "Epoch 8, Loss: 0.025612028315663338\n",
      "Epoch 9, Loss: 0.03606399893760681\n",
      "Epoch 10, Loss: 0.03737720847129822\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21062938627843278, feed_forward_dim=256, head_dim=8, lr=0.0003205938533620864, num_heads=4, num_layers=3; total time=   1.2s\n",
      "Epoch 10, Loss: 0.03582295775413513\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21062938627843278, feed_forward_dim=256, head_dim=8, lr=0.0003205938533620864, num_heads=4, num_layers=3; total time=   1.3s\n",
      "Epoch 9, Loss: 0.04232208803296089\n",
      "Epoch 8, Loss: 0.019084712490439415\n",
      "Epoch 8, Loss: 0.06842951476573944\n",
      "Epoch 10, Loss: 0.032150495797395706\n",
      "Epoch 9, Loss: 0.05225305259227753\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21062938627843278, feed_forward_dim=256, head_dim=8, lr=0.0003205938533620864, num_heads=4, num_layers=3; total time=   1.3s\n",
      "Epoch 7, Loss: 0.023691944777965546\n",
      "Epoch 10, Loss: 0.0713546946644783\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21062938627843278, feed_forward_dim=256, head_dim=8, lr=0.0003205938533620864, num_heads=4, num_layers=3; total time=   1.3s\n",
      "Epoch 9, Loss: 0.04871850460767746\n",
      "Epoch 10, Loss: 0.04885943606495857\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21062938627843278, feed_forward_dim=256, head_dim=8, lr=0.0003205938533620864, num_heads=4, num_layers=3; total time=   1.3s\n",
      "Epoch 9, Loss: 0.08809120953083038\n",
      "Epoch 8, Loss: 0.05542682483792305\n",
      "Epoch 10, Loss: 0.055254336446523666\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21062938627843278, feed_forward_dim=256, head_dim=8, lr=0.0003205938533620864, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Epoch 10, Loss: 0.07526680827140808\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21062938627843278, feed_forward_dim=256, head_dim=8, lr=0.0003205938533620864, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.07399127632379532\n",
      "Epoch 10, Loss: 0.06246579438447952\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21062938627843278, feed_forward_dim=256, head_dim=8, lr=0.0003205938533620864, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.051268111914396286\n",
      "Epoch 1, Loss: 0.13648654520511627\n",
      "Epoch 1, Loss: 0.053225062787532806\n",
      "Epoch 1, Loss: 0.3161451518535614\n",
      "Epoch 1, Loss: 0.2772520184516907\n",
      "Epoch 2, Loss: 0.1432626098394394\n",
      "Epoch 1, Loss: 1.002897024154663\n",
      "Epoch 1, Loss: 0.10946010053157806\n",
      "Epoch 2, Loss: 0.08025519549846649\n",
      "Epoch 2, Loss: 0.1429353505373001\n",
      "Epoch 2, Loss: 0.12100666761398315\n",
      "Epoch 2, Loss: 0.0776483565568924\n",
      "Epoch 3, Loss: 0.022936547175049782\n",
      "Epoch 2, Loss: 0.06093855947256088\n",
      "Epoch 3, Loss: 0.038895197212696075\n",
      "Epoch 3, Loss: 0.1021168977022171\n",
      "Epoch 2, Loss: 0.26032084226608276\n",
      "Epoch 1, Loss: 1.756356954574585\n",
      "Epoch 1, Loss: 0.39351576566696167\n",
      "Epoch 1, Loss: 0.6782765984535217\n",
      "Epoch 4, Loss: 0.10624689608812332\n",
      "Epoch 3, Loss: 0.19214344024658203\n",
      "Epoch 3, Loss: 0.16022340953350067\n",
      "Epoch 1, Loss: 0.40001171827316284\n",
      "Epoch 4, Loss: 0.023139722645282745Epoch 2, Loss: 0.6742430329322815\n",
      "\n",
      "Epoch 3, Loss: 0.08852580189704895\n",
      "Epoch 3, Loss: 0.05847213417291641\n",
      "Epoch 5, Loss: 0.06554879248142242\n",
      "Epoch 4, Loss: 0.04509657248854637\n",
      "Epoch 1, Loss: 0.5422220230102539\n",
      "Epoch 2, Loss: 0.07927262037992477\n",
      "Epoch 2, Loss: 0.06472323089838028\n",
      "Epoch 4, Loss: 0.13385216891765594\n",
      "Epoch 4, Loss: 0.13006599247455597\n",
      "Epoch 2, Loss: 0.06302957981824875\n",
      "Epoch 3, Loss: 0.1213369369506836\n",
      "Epoch 6, Loss: 0.013924793340265751\n",
      "Epoch 4, Loss: 0.022430943325161934\n",
      "Epoch 3, Loss: 0.19780412316322327\n",
      "Epoch 5, Loss: 0.06459881365299225\n",
      "Epoch 5, Loss: 0.02101152017712593\n",
      "Epoch 4, Loss: 0.18868952989578247\n",
      "Epoch 3, Loss: 0.12629367411136627\n",
      "Epoch 5, Loss: 0.06105639785528183\n",
      "Epoch 7, Loss: 0.0332220084965229\n",
      "Epoch 2, Loss: 0.06763678044080734\n",
      "Epoch 6, Loss: 0.044304024428129196\n",
      "Epoch 6, Loss: 0.04264041408896446\n",
      "Epoch 5, Loss: 0.04790252447128296\n",
      "Epoch 5, Loss: 0.3041347563266754\n",
      "Epoch 5, Loss: 0.010155350901186466\n",
      "Epoch 8, Loss: 0.06032858416438103\n",
      "Epoch 3, Loss: 0.12995022535324097\n",
      "Epoch 4, Loss: 0.013137363828718662\n",
      "Epoch 4, Loss: 0.27955445647239685\n",
      "Epoch 6, Loss: 0.02223271131515503\n",
      "Epoch 4, Loss: 0.20663201808929443\n",
      "Epoch 7, Loss: 0.0468415692448616\n",
      "Epoch 3, Loss: 0.16393452882766724\n",
      "Epoch 7, Loss: 0.010250537656247616\n",
      "Epoch 9, Loss: 0.04113123565912247\n",
      "Epoch 6, Loss: 0.029189739376306534\n",
      "Epoch 6, Loss: 0.04281562194228172\n",
      "Epoch 6, Loss: 0.301709920167923\n",
      "Epoch 5, Loss: 0.1541845202445984\n",
      "Epoch 8, Loss: 0.026793820783495903\n",
      "Epoch 10, Loss: 0.013466437347233295\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.21220699524369946, feed_forward_dim=256, head_dim=8, lr=0.00031280138387898516, num_heads=4, num_layers=2; total time=   0.9s\n",
      "Epoch 5, Loss: 0.25220057368278503\n",
      "Epoch 8, Loss: 0.011592199094593525\n",
      "Epoch 4, Loss: 0.24916045367717743\n",
      "Epoch 7, Loss: 0.03893178701400757\n",
      "Epoch 7, Loss: 0.04680909216403961\n",
      "Epoch 7, Loss: 0.05816556513309479\n",
      "Epoch 4, Loss: 0.19140206277370453\n",
      "Epoch 7, Loss: 0.2185865342617035\n",
      "Epoch 9, Loss: 0.011520704254508018\n",
      "Epoch 5, Loss: 0.10948880761861801\n",
      "Epoch 9, Loss: 0.031882453709840775\n",
      "Epoch 8, Loss: 0.0638314038515091\n",
      "Epoch 6, Loss: 0.3013675808906555\n",
      "Epoch 8, Loss: 0.06657381355762482\n",
      "Epoch 6, Loss: 0.13244158029556274\n",
      "Epoch 10, Loss: 0.017804773524403572\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.21220699524369946, feed_forward_dim=256, head_dim=8, lr=0.00031280138387898516, num_heads=4, num_layers=2; total time=   1.1s\n",
      "Epoch 8, Loss: 0.12208190560340881\n",
      "Epoch 6, Loss: 0.03968224674463272\n",
      "Epoch 8, Loss: 0.02226557582616806\n",
      "Epoch 10, Loss: 0.03530416265130043\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.21220699524369946, feed_forward_dim=256, head_dim=8, lr=0.00031280138387898516, num_heads=4, num_layers=2; total time=   1.1s\n",
      "Epoch 5, Loss: 0.18426179885864258\n",
      "Epoch 9, Loss: 0.04358925297856331\n",
      "Epoch 9, Loss: 0.058844976127147675\n",
      "Epoch 7, Loss: 0.040917135775089264\n",
      "Epoch 5, Loss: 0.1376795917749405\n",
      "Epoch 7, Loss: 0.3559001684188843\n",
      "Epoch 9, Loss: 0.054559700191020966\n",
      "Epoch 6, Loss: 0.08074924349784851\n",
      "Epoch 10, Loss: 0.032638031989336014\n",
      "Epoch 9, Loss: 0.005714705213904381\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.21220699524369946, feed_forward_dim=256, head_dim=8, lr=0.00031280138387898516, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 10, Loss: 0.014728554524481297\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.21220699524369946, feed_forward_dim=256, head_dim=8, lr=0.00031280138387898516, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 8, Loss: 0.016472939401865005\n",
      "Epoch 7, Loss: 0.03980867192149162\n",
      "Epoch 8, Loss: 0.31898820400238037\n",
      "Epoch 6, Loss: 0.057544540613889694\n",
      "Epoch 10, Loss: 0.02754811942577362\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.21220699524369946, feed_forward_dim=256, head_dim=8, lr=0.00031280138387898516, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 10, Loss: 0.01225858461111784\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.21220699524369946, feed_forward_dim=256, head_dim=8, lr=0.00031280138387898516, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 7, Loss: 0.019046198576688766\n",
      "Epoch 9, Loss: 0.04700605198740959\n",
      "Epoch 9, Loss: 0.23662592470645905\n",
      "Epoch 7, Loss: 0.015519692562520504\n",
      "Epoch 8, Loss: 0.07917754352092743\n",
      "Epoch 8, Loss: 0.02506481111049652\n",
      "Epoch 10, Loss: 0.1466595083475113\n",
      "Epoch 10, Loss: 0.08582166582345963\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.21220699524369946, feed_forward_dim=256, head_dim=8, lr=0.00031280138387898516, num_heads=4, num_layers=2; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.21220699524369946, feed_forward_dim=256, head_dim=8, lr=0.00031280138387898516, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 9, Loss: 0.0940832868218422\n",
      "Epoch 8, Loss: 0.024991562590003014\n",
      "Epoch 9, Loss: 0.061562977731227875\n",
      "Epoch 10, Loss: 0.07191761583089828\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.21220699524369946, feed_forward_dim=256, head_dim=8, lr=0.00031280138387898516, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 9, Loss: 0.055743589997291565\n",
      "Epoch 10, Loss: 0.08725113421678543\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.21220699524369946, feed_forward_dim=256, head_dim=8, lr=0.00031280138387898516, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 10, Loss: 0.06919505447149277\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.21220699524369946, feed_forward_dim=256, head_dim=8, lr=0.00031280138387898516, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.13022521138191223\n",
      "Epoch 1, Loss: 0.010931876488029957\n",
      "Epoch 1, Loss: 0.194549098610878\n",
      "Epoch 1, Loss: 0.25234460830688477\n",
      "Epoch 1, Loss: 0.6032096147537231\n",
      "Epoch 2, Loss: 0.11086326837539673\n",
      "Epoch 2, Loss: 0.01616295427083969\n",
      "Epoch 1, Loss: 0.18494951725006104\n",
      "Epoch 1, Loss: 2.4594388008117676\n",
      "Epoch 2, Loss: 0.07366031408309937\n",
      "Epoch 1, Loss: 0.5203895568847656\n",
      "Epoch 3, Loss: 0.09908020496368408\n",
      "Epoch 2, Loss: 0.1881466656923294\n",
      "Epoch 2, Loss: 0.35790613293647766\n",
      "Epoch 1, Loss: 0.09454672038555145\n",
      "Epoch 2, Loss: 0.048857592046260834\n",
      "Epoch 3, Loss: 0.008567003533244133\n",
      "Epoch 3, Loss: 0.030658885836601257\n",
      "Epoch 1, Loss: 0.708604633808136\n",
      "Epoch 2, Loss: 1.8202816247940063\n",
      "Epoch 1, Loss: 0.007672053296118975\n",
      "Epoch 2, Loss: 0.3055918216705322\n",
      "Epoch 1, Loss: 0.8632156252861023\n",
      "Epoch 3, Loss: 0.18299883604049683\n",
      "Epoch 4, Loss: 0.08313240855932236\n",
      "Epoch 3, Loss: 0.012349190190434456\n",
      "Epoch 3, Loss: 0.15768025815486908\n",
      "Epoch 4, Loss: 0.003923201933503151\n",
      "Epoch 4, Loss: 0.0424276627600193\n",
      "Epoch 3, Loss: 1.269010305404663\n",
      "Epoch 2, Loss: 0.04525016248226166\n",
      "Epoch 2, Loss: 0.4490448534488678\n",
      "Epoch 5, Loss: 0.008324905298650265\n",
      "Epoch 5, Loss: 0.06907609850168228\n",
      "Epoch 2, Loss: 0.030261801555752754\n",
      "Epoch 4, Loss: 0.07471718639135361\n",
      "Epoch 2, Loss: 0.620503306388855\n",
      "Epoch 4, Loss: 0.14173074066638947\n",
      "Epoch 3, Loss: 0.16343002021312714\n",
      "Epoch 4, Loss: 0.03546825423836708\n",
      "Epoch 5, Loss: 0.06770950555801392\n",
      "Epoch 4, Loss: 0.8240880966186523\n",
      "Epoch 6, Loss: 0.008627129718661308\n",
      "Epoch 6, Loss: 0.058939363807439804\n",
      "Epoch 3, Loss: 0.25272661447525024\n",
      "Epoch 3, Loss: 0.039646316319704056\n",
      "Epoch 5, Loss: 0.0626264363527298\n",
      "Epoch 3, Loss: 0.43381235003471375\n",
      "Epoch 7, Loss: 0.004750189837068319\n",
      "Epoch 4, Loss: 0.09207889437675476\n",
      "Epoch 5, Loss: 0.03184130787849426\n",
      "Epoch 6, Loss: 0.07388047128915787\n",
      "Epoch 5, Loss: 0.12751588225364685\n",
      "Epoch 7, Loss: 0.05075797066092491\n",
      "Epoch 3, Loss: 0.008103952743113041\n",
      "Epoch 5, Loss: 0.48855382204055786\n",
      "Epoch 8, Loss: 0.00370721984654665\n",
      "Epoch 4, Loss: 0.048076774924993515\n",
      "Epoch 7, Loss: 0.060251571238040924\n",
      "Epoch 4, Loss: 0.13026373088359833\n",
      "Epoch 6, Loss: 0.035213615745306015\n",
      "Epoch 8, Loss: 0.04254590719938278\n",
      "Epoch 6, Loss: 0.06629560887813568\n",
      "Epoch 6, Loss: 0.11054760217666626\n",
      "Epoch 4, Loss: 0.295296311378479\n",
      "Epoch 6, Loss: 0.25257471203804016\n",
      "Epoch 5, Loss: 0.08017370849847794\n",
      "Epoch 9, Loss: 0.005703840870410204\n",
      "Epoch 4, Loss: 0.012759109027683735\n",
      "Epoch 8, Loss: 0.04214351251721382\n",
      "Epoch 9, Loss: 0.03364070877432823\n",
      "Epoch 5, Loss: 0.06387165933847427\n",
      "Epoch 7, Loss: 0.06602410227060318\n",
      "Epoch 7, Loss: 0.05136683210730553\n",
      "Epoch 7, Loss: 0.08840151131153107\n",
      "Epoch 7, Loss: 0.10774074494838715\n",
      "Epoch 5, Loss: 0.046830933541059494\n",
      "Epoch 5, Loss: 0.20375867187976837\n",
      "Epoch 10, Loss: 0.028286824002861977\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.232326815900689, feed_forward_dim=256, head_dim=32, lr=0.0001098692716274952, num_heads=2, num_layers=1; total time=   1.0s\n",
      "Epoch 10, Loss: 0.006772492080926895\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.232326815900689, feed_forward_dim=256, head_dim=32, lr=0.0001098692716274952, num_heads=2, num_layers=1; total time=   1.0s\n",
      "Epoch 6, Loss: 0.1031050905585289\n",
      "Epoch 9, Loss: 0.024583835154771805\n",
      "Epoch 8, Loss: 0.029507523402571678\n",
      "Epoch 8, Loss: 0.09824442863464355\n",
      "Epoch 6, Loss: 0.04933585971593857\n",
      "Epoch 8, Loss: 0.07085267454385757\n",
      "Epoch 5, Loss: 0.01994926482439041\n",
      "Epoch 8, Loss: 0.04719403386116028\n",
      "Epoch 10, Loss: 0.015722207725048065\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.232326815900689, feed_forward_dim=256, head_dim=32, lr=0.0001098692716274952, num_heads=2, num_layers=1; total time=   1.1s\n",
      "Epoch 6, Loss: 0.15480542182922363\n",
      "Epoch 9, Loss: 0.01374626625329256\n",
      "Epoch 9, Loss: 0.057598914951086044\n",
      "Epoch 6, Loss: 0.035698942840099335\n",
      "Epoch 9, Loss: 0.12076125293970108\n",
      "Epoch 7, Loss: 0.13514310121536255\n",
      "Epoch 7, Loss: 0.0661453902721405\n",
      "Epoch 9, Loss: 0.049932874739170074\n",
      "Epoch 10, Loss: 0.04929381608963013\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.232326815900689, feed_forward_dim=256, head_dim=32, lr=0.0001098692716274952, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 10, Loss: 0.00861190166324377\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.232326815900689, feed_forward_dim=256, head_dim=32, lr=0.0001098692716274952, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 10, Loss: 0.12318819761276245\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.232326815900689, feed_forward_dim=256, head_dim=32, lr=0.0001098692716274952, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 7, Loss: 0.024268917739391327\n",
      "Epoch 6, Loss: 0.014133481308817863\n",
      "Epoch 7, Loss: 0.13552193343639374\n",
      "Epoch 8, Loss: 0.15225256979465485\n",
      "Epoch 10, Loss: 0.09371565282344818\n",
      "Epoch 8, Loss: 0.09845112264156342\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.232326815900689, feed_forward_dim=256, head_dim=32, lr=0.0001098692716274952, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 8, Loss: 0.016130506992340088\n",
      "Epoch 7, Loss: 0.00771063519641757\n",
      "Epoch 9, Loss: 0.15530699491500854\n",
      "Epoch 8, Loss: 0.13891859352588654\n",
      "Epoch 9, Loss: 0.1285867989063263\n",
      "Epoch 9, Loss: 0.014655773527920246\n",
      "Epoch 10, Loss: 0.13813580572605133\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.232326815900689, feed_forward_dim=256, head_dim=32, lr=0.0001098692716274952, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 8, Loss: 0.006788818631321192\n",
      "Epoch 10, Loss: 0.14273293316364288\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.232326815900689, feed_forward_dim=256, head_dim=32, lr=0.0001098692716274952, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 9, Loss: 0.15127484500408173\n",
      "Epoch 10, Loss: 0.016851434484124184\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.232326815900689, feed_forward_dim=256, head_dim=32, lr=0.0001098692716274952, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 9, Loss: 0.01052458118647337\n",
      "Epoch 10, Loss: 0.16371871531009674\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.232326815900689, feed_forward_dim=256, head_dim=32, lr=0.0001098692716274952, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 10, Loss: 0.013335337862372398\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.232326815900689, feed_forward_dim=256, head_dim=32, lr=0.0001098692716274952, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 1.3623920679092407\n",
      "Epoch 1, Loss: 0.5300347805023193\n",
      "Epoch 1, Loss: 0.28690919280052185\n",
      "Epoch 1, Loss: 0.02385806106030941\n",
      "Epoch 2, Loss: 0.25561195611953735\n",
      "Epoch 1, Loss: 0.30124419927597046\n",
      "Epoch 1, Loss: 1.3492683172225952\n",
      "Epoch 2, Loss: 0.06326930969953537\n",
      "Epoch 2, Loss: 0.43987366557121277\n",
      "Epoch 2, Loss: 0.24192187190055847\n",
      "Epoch 3, Loss: 0.06568612158298492\n",
      "Epoch 2, Loss: 0.11776383221149445\n",
      "Epoch 1, Loss: 0.24151253700256348\n",
      "Epoch 1, Loss: 0.34285154938697815\n",
      "Epoch 2, Loss: 0.16906216740608215\n",
      "Epoch 3, Loss: 0.29360491037368774\n",
      "Epoch 3, Loss: 0.021742356941103935\n",
      "Epoch 4, Loss: 0.3130989968776703\n",
      "Epoch 1, Loss: 0.18556968867778778\n",
      "Epoch 3, Loss: 0.20542846620082855\n",
      "Epoch 1, Loss: 1.6671228408813477\n",
      "Epoch 1, Loss: 0.47516655921936035\n",
      "Epoch 3, Loss: 0.21195568144321442\n",
      "Epoch 5, Loss: 0.4370362460613251\n",
      "Epoch 3, Loss: 0.11477862298488617\n",
      "Epoch 4, Loss: 0.2590075135231018\n",
      "Epoch 2, Loss: 0.14185915887355804\n",
      "Epoch 1, Loss: 0.1381954699754715\n",
      "Epoch 2, Loss: 0.06007556989789009\n",
      "Epoch 2, Loss: 0.04455190896987915\n",
      "Epoch 4, Loss: 0.09426438808441162\n",
      "Epoch 4, Loss: 0.17647241055965424\n",
      "Epoch 4, Loss: 0.09806667268276215\n",
      "Epoch 2, Loss: 0.4022945165634155\n",
      "Epoch 2, Loss: 0.2614161968231201\n",
      "Epoch 5, Loss: 0.10332159698009491\n",
      "Epoch 4, Loss: 0.41919052600860596\n",
      "Epoch 6, Loss: 0.3659820854663849\n",
      "Epoch 3, Loss: 0.21371260285377502\n",
      "Epoch 3, Loss: 0.2592203915119171\n",
      "Epoch 5, Loss: 0.083672896027565\n",
      "Epoch 3, Loss: 0.17423854768276215\n",
      "Epoch 6, Loss: 0.029978765174746513\n",
      "Epoch 5, Loss: 0.02420595847070217\n",
      "Epoch 7, Loss: 0.21762694418430328\n",
      "Epoch 5, Loss: 0.4469461739063263\n",
      "Epoch 5, Loss: 0.22697745263576508\n",
      "Epoch 2, Loss: 0.1585175096988678\n",
      "Epoch 3, Loss: 0.04893921688199043\n",
      "Epoch 6, Loss: 0.10210984200239182\n",
      "Epoch 3, Loss: 0.13788659870624542\n",
      "Epoch 4, Loss: 0.15768951177597046\n",
      "Epoch 7, Loss: 0.06325887143611908\n",
      "Epoch 6, Loss: 0.09330350905656815\n",
      "Epoch 8, Loss: 0.09361187368631363\n",
      "Epoch 4, Loss: 0.2207663655281067\n",
      "Epoch 6, Loss: 0.05613815411925316\n",
      "Epoch 4, Loss: 0.08783235400915146\n",
      "Epoch 6, Loss: 0.29349830746650696\n",
      "Epoch 3, Loss: 0.11195213347673416\n",
      "Epoch 4, Loss: 0.03403739258646965\n",
      "Epoch 5, Loss: 0.07236789911985397\n",
      "Epoch 8, Loss: 0.11643656343221664\n",
      "Epoch 9, Loss: 0.03182825818657875\n",
      "Epoch 7, Loss: 0.009635419584810734\n",
      "Epoch 4, Loss: 0.26190322637557983\n",
      "Epoch 7, Loss: 0.0781349167227745\n",
      "Epoch 7, Loss: 0.12436031550168991\n",
      "Epoch 7, Loss: 0.09050800651311874\n",
      "Epoch 5, Loss: 0.0801292136311531\n",
      "Epoch 5, Loss: 0.012135820463299751\n",
      "Epoch 9, Loss: 0.12394754588603973\n",
      "Epoch 4, Loss: 0.008638826198875904\n",
      "Epoch 10, Loss: 0.0339653380215168\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16569150005592104, feed_forward_dim=256, head_dim=8, lr=0.0004252527819962865, num_heads=2, num_layers=1; total time=   1.0s\n",
      "Epoch 8, Loss: 0.0356244333088398\n",
      "Epoch 8, Loss: 0.030291974544525146\n",
      "Epoch 6, Loss: 0.0465969443321228\n",
      "Epoch 5, Loss: 0.4566274583339691\n",
      "Epoch 5, Loss: 0.08366043120622635\n",
      "Epoch 10, Loss: 0.08389153331518173\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16569150005592104, feed_forward_dim=256, head_dim=8, lr=0.0004252527819962865, num_heads=2, num_layers=1; total time=   1.0s\n",
      "Epoch 8, Loss: 0.035818811506032944\n",
      "Epoch 8, Loss: 0.06849867850542068\n",
      "Epoch 6, Loss: 0.02533756196498871\n",
      "Epoch 9, Loss: 0.08873536437749863\n",
      "Epoch 5, Loss: 0.03672788664698601\n",
      "Epoch 9, Loss: 0.025936882942914963\n",
      "Epoch 6, Loss: 0.027873985469341278\n",
      "Epoch 7, Loss: 0.07124395668506622\n",
      "Epoch 9, Loss: 0.023233462125062943\n",
      "Epoch 6, Loss: 0.45741286873817444\n",
      "Epoch 10, Loss: 0.09901348501443863\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16569150005592104, feed_forward_dim=256, head_dim=8, lr=0.0004252527819962865, num_heads=2, num_layers=1; total time=   1.1s\n",
      "Epoch 10, Loss: 0.03982406109571457\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16569150005592104, feed_forward_dim=256, head_dim=8, lr=0.0004252527819962865, num_heads=2, num_layers=1; total time=   1.1s\n",
      "Epoch 9, Loss: 0.024168401956558228\n",
      "Epoch 7, Loss: 0.05743785202503204\n",
      "Epoch 6, Loss: 0.10166153311729431\n",
      "Epoch 7, Loss: 0.07195910066366196\n",
      "Epoch 10, Loss: 0.07386896014213562\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16569150005592104, feed_forward_dim=256, head_dim=8, lr=0.0004252527819962865, num_heads=2, num_layers=1; total time=   1.1s\n",
      "Epoch 8, Loss: 0.0862753689289093\n",
      "Epoch 6, Loss: 0.07982703298330307\n",
      "Epoch 7, Loss: 0.3327680826187134\n",
      "Epoch 10, Loss: 0.008223033510148525\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16569150005592104, feed_forward_dim=256, head_dim=8, lr=0.0004252527819962865, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 8, Loss: 0.06647326797246933\n",
      "Epoch 7, Loss: 0.048801910132169724\n",
      "Epoch 8, Loss: 0.09915551543235779\n",
      "Epoch 9, Loss: 0.06396692991256714\n",
      "Epoch 7, Loss: 0.054753415286540985\n",
      "Epoch 8, Loss: 0.18353486061096191\n",
      "Epoch 9, Loss: 0.03129378333687782\n",
      "Epoch 8, Loss: 0.009964264929294586\n",
      "Epoch 9, Loss: 0.10046667605638504\n",
      "Epoch 10, Loss: 0.032679736614227295\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16569150005592104, feed_forward_dim=256, head_dim=8, lr=0.0004252527819962865, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 8, Loss: 0.013286854140460491\n",
      "Epoch 10, Loss: 0.006948196329176426\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16569150005592104, feed_forward_dim=256, head_dim=8, lr=0.0004252527819962865, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 9, Loss: 0.07035618275403976\n",
      "Epoch 9, Loss: 0.026800986379384995\n",
      "Epoch 10, Loss: 0.06651383638381958\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16569150005592104, feed_forward_dim=256, head_dim=8, lr=0.0004252527819962865, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 9, Loss: 0.006189141422510147\n",
      "Epoch 10, Loss: 0.02511698007583618\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16569150005592104, feed_forward_dim=256, head_dim=8, lr=0.0004252527819962865, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 10, Loss: 0.05475233495235443\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16569150005592104, feed_forward_dim=256, head_dim=8, lr=0.0004252527819962865, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 10, Loss: 0.027889421209692955\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16569150005592104, feed_forward_dim=256, head_dim=8, lr=0.0004252527819962865, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.09169421344995499\n",
      "Epoch 1, Loss: 0.15457561612129211\n",
      "Epoch 1, Loss: 0.04082830250263214\n",
      "Epoch 1, Loss: 2.8102223873138428\n",
      "Epoch 1, Loss: 1.4641553163528442\n",
      "Epoch 1, Loss: 1.0532821416854858\n",
      "Epoch 2, Loss: 0.18031282722949982\n",
      "Epoch 2, Loss: 0.2737579047679901\n",
      "Epoch 1, Loss: 0.4781424403190613\n",
      "Epoch 2, Loss: 0.2818373441696167\n",
      "Epoch 1, Loss: 0.20042940974235535\n",
      "Epoch 2, Loss: 1.0144281387329102\n",
      "Epoch 2, Loss: 0.21833913028240204\n",
      "Epoch 3, Loss: 0.08090852946043015\n",
      "Epoch 3, Loss: 0.07375352829694748\n",
      "Epoch 3, Loss: 0.029396643862128258\n",
      "Epoch 2, Loss: 0.2651669681072235\n",
      "Epoch 2, Loss: 0.09180029481649399\n",
      "Epoch 2, Loss: 0.03477443382143974\n",
      "Epoch 3, Loss: 0.2705839276313782\n",
      "Epoch 1, Loss: 1.2594995498657227\n",
      "Epoch 3, Loss: 0.06610167026519775\n",
      "Epoch 4, Loss: 0.0717906728386879\n",
      "Epoch 1, Loss: 0.30096346139907837\n",
      "Epoch 1, Loss: 0.23407912254333496\n",
      "Epoch 4, Loss: 0.005751469172537327\n",
      "Epoch 4, Loss: 0.09775842726230621\n",
      "Epoch 4, Loss: 0.2569628357887268\n",
      "Epoch 3, Loss: 0.08271913230419159\n",
      "Epoch 3, Loss: 0.18528789281845093\n",
      "Epoch 5, Loss: 0.10721851140260696\n",
      "Epoch 1, Loss: 0.12066428363323212\n",
      "Epoch 3, Loss: 0.1448572874069214\n",
      "Epoch 5, Loss: 0.058466363698244095\n",
      "Epoch 4, Loss: 0.3882881700992584\n",
      "Epoch 5, Loss: 0.14841625094413757\n",
      "Epoch 2, Loss: 0.08267322182655334\n",
      "Epoch 2, Loss: 0.2664109766483307\n",
      "Epoch 5, Loss: 0.48326000571250916\n",
      "Epoch 2, Loss: 0.09698683023452759\n",
      "Epoch 6, Loss: 0.05197248235344887\n",
      "Epoch 6, Loss: 0.0765397846698761\n",
      "Epoch 4, Loss: 0.23466286063194275\n",
      "Epoch 4, Loss: 0.21026179194450378\n",
      "Epoch 6, Loss: 0.07212391495704651\n",
      "Epoch 4, Loss: 0.051026713103055954\n",
      "Epoch 5, Loss: 0.48880237340927124\n",
      "Epoch 3, Loss: 0.18200017511844635\n",
      "Epoch 7, Loss: 0.00880501139909029\n",
      "Epoch 2, Loss: 0.11895163357257843\n",
      "Epoch 6, Loss: 0.6226730942726135\n",
      "Epoch 3, Loss: 0.1354273110628128\n",
      "Epoch 7, Loss: 0.035690680146217346\n",
      "Epoch 7, Loss: 0.013417333364486694\n",
      "Epoch 3, Loss: 0.14766834676265717\n",
      "Epoch 5, Loss: 0.1314913034439087\n",
      "Epoch 5, Loss: 0.31518593430519104\n",
      "Epoch 6, Loss: 0.36357682943344116\n",
      "Epoch 5, Loss: 0.012016608379781246\n",
      "Epoch 8, Loss: 0.027353448793292046\n",
      "Epoch 8, Loss: 0.0052058217115700245\n",
      "Epoch 7, Loss: 0.61457759141922\n",
      "Epoch 4, Loss: 0.15793000161647797\n",
      "Epoch 8, Loss: 0.027452008798718452\n",
      "Epoch 4, Loss: 0.3693397343158722\n",
      "Epoch 3, Loss: 0.08508334308862686\n",
      "Epoch 6, Loss: 0.03611285611987114\n",
      "Epoch 7, Loss: 0.1828613430261612\n",
      "Epoch 9, Loss: 0.053486309945583344\n",
      "Epoch 9, Loss: 0.01756436936557293\n",
      "Epoch 6, Loss: 0.29999059438705444\n",
      "Epoch 4, Loss: 0.08284791558980942\n",
      "Epoch 9, Loss: 0.06650590151548386\n",
      "Epoch 6, Loss: 0.0490112230181694\n",
      "Epoch 8, Loss: 0.5036278367042542\n",
      "Epoch 5, Loss: 0.07617524266242981\n",
      "Epoch 10, Loss: 0.03932833671569824\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.29411235155561666, feed_forward_dim=256, head_dim=8, lr=0.0003716706563968191, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 10, Loss: 0.042110953480005264\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.29411235155561666, feed_forward_dim=256, head_dim=8, lr=0.0003716706563968191, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 5, Loss: 0.42364901304244995\n",
      "Epoch 8, Loss: 0.05350027605891228\n",
      "Epoch 7, Loss: 0.019200708717107773\n",
      "Epoch 10, Loss: 0.07071833312511444\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.29411235155561666, feed_forward_dim=256, head_dim=8, lr=0.0003716706563968191, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 7, Loss: 0.22055336833000183\n",
      "Epoch 4, Loss: 0.008502214215695858\n",
      "Epoch 9, Loss: 0.3599907159805298\n",
      "Epoch 7, Loss: 0.06763768196105957\n",
      "Epoch 5, Loss: 0.025349825620651245\n",
      "Epoch 6, Loss: 0.03796740993857384\n",
      "Epoch 9, Loss: 0.01760660856962204\n",
      "Epoch 6, Loss: 0.30468252301216125\n",
      "Epoch 8, Loss: 0.13043749332427979\n",
      "Epoch 8, Loss: 0.059025514870882034\n",
      "Epoch 5, Loss: 0.03068532422184944\n",
      "Epoch 10, Loss: 0.2239319086074829\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.29411235155561666, feed_forward_dim=256, head_dim=8, lr=0.0003716706563968191, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 6, Loss: 0.02891855686903\n",
      "Epoch 8, Loss: 0.04006964713335037\n",
      "Epoch 7, Loss: 0.15191711485385895\n",
      "Epoch 10, Loss: 0.056677184998989105\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.29411235155561666, feed_forward_dim=256, head_dim=8, lr=0.0003716706563968191, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 7, Loss: 0.05559336394071579\n",
      "Epoch 9, Loss: 0.0665457546710968\n",
      "Epoch 9, Loss: 0.09625007212162018\n",
      "Epoch 7, Loss: 0.052535656839609146\n",
      "Epoch 9, Loss: 0.010721099562942982\n",
      "Epoch 8, Loss: 0.0525842122733593\n",
      "Epoch 6, Loss: 0.060845669358968735\n",
      "Epoch 10, Loss: 0.04031221196055412\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.29411235155561666, feed_forward_dim=256, head_dim=8, lr=0.0003716706563968191, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.09328917413949966\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.29411235155561666, feed_forward_dim=256, head_dim=8, lr=0.0003716706563968191, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.009279564023017883\n",
      "Epoch 8, Loss: 0.04645039141178131\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.29411235155561666, feed_forward_dim=256, head_dim=8, lr=0.0003716706563968191, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 9, Loss: 0.03478538990020752\n",
      "Epoch 8, Loss: 0.08117056638002396\n",
      "Epoch 7, Loss: 0.04185187444090843\n",
      "Epoch 9, Loss: 0.021017255261540413\n",
      "Epoch 9, Loss: 0.076625756919384\n",
      "Epoch 10, Loss: 0.06841728836297989\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.29411235155561666, feed_forward_dim=256, head_dim=8, lr=0.0003716706563968191, num_heads=2, num_layers=1; total time=   1.6s\n",
      "Epoch 8, Loss: 0.011121541261672974\n",
      "Epoch 10, Loss: 0.04902993515133858\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.29411235155561666, feed_forward_dim=256, head_dim=8, lr=0.0003716706563968191, num_heads=2, num_layers=1; total time=   1.6s\n",
      "Epoch 10, Loss: 0.005711128003895283\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.29411235155561666, feed_forward_dim=256, head_dim=8, lr=0.0003716706563968191, num_heads=2, num_layers=1; total time=   1.6s\n",
      "Epoch 9, Loss: 0.006344934925436974\n",
      "Epoch 10, Loss: 0.022956112399697304\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.29411235155561666, feed_forward_dim=256, head_dim=8, lr=0.0003716706563968191, num_heads=2, num_layers=1; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.17073628306388855\n",
      "Epoch 1, Loss: 0.1088859811425209Epoch 1, Loss: 0.9743808507919312\n",
      "\n",
      "Epoch 1, Loss: 0.15307803452014923\n",
      "Epoch 1, Loss: 0.22602367401123047\n",
      "Epoch 2, Loss: 0.4804067015647888\n",
      "Epoch 1, Loss: 0.29580309987068176\n",
      "Epoch 2, Loss: 0.5578933358192444\n",
      "Epoch 2, Loss: 0.11924443393945694\n",
      "Epoch 1, Loss: 0.3267855942249298\n",
      "Epoch 2, Loss: 0.34794682264328003\n",
      "Epoch 2, Loss: 0.46277567744255066\n",
      "Epoch 3, Loss: 0.15739013254642487\n",
      "Epoch 1, Loss: 0.0845135748386383\n",
      "Epoch 1, Loss: 0.09495578706264496\n",
      "Epoch 3, Loss: 0.10461469739675522\n",
      "Epoch 3, Loss: 0.46739137172698975\n",
      "Epoch 2, Loss: 0.49082204699516296\n",
      "Epoch 1, Loss: 0.14894795417785645\n",
      "Epoch 1, Loss: 0.2168048769235611\n",
      "Epoch 4, Loss: 0.023842422291636467\n",
      "Epoch 2, Loss: 0.34051939845085144\n",
      "Epoch 3, Loss: 0.16717666387557983\n",
      "Epoch 1, Loss: 0.2194087952375412\n",
      "Epoch 3, Loss: 0.13519716262817383\n",
      "Epoch 4, Loss: 0.15648455917835236\n",
      "Epoch 2, Loss: 0.6659403443336487\n",
      "Epoch 5, Loss: 0.14772318303585052\n",
      "Epoch 4, Loss: 0.41732239723205566\n",
      "Epoch 2, Loss: 0.5330953001976013\n",
      "Epoch 3, Loss: 0.2215992659330368\n",
      "Epoch 3, Loss: 0.198936328291893\n",
      "Epoch 4, Loss: 0.05062524974346161\n",
      "Epoch 2, Loss: 0.26978743076324463\n",
      "Epoch 5, Loss: 0.26938334107398987\n",
      "Epoch 6, Loss: 0.17081524431705475\n",
      "Epoch 3, Loss: 0.07888547331094742\n",
      "Epoch 4, Loss: 0.013563569635152817\n",
      "Epoch 2, Loss: 0.6923225522041321\n",
      "Epoch 5, Loss: 0.182982936501503\n",
      "Epoch 2, Loss: 0.3167491555213928\n",
      "Epoch 3, Loss: 0.0648123174905777\n",
      "Epoch 6, Loss: 0.16487230360507965\n",
      "Epoch 7, Loss: 0.07832979410886765\n",
      "Epoch 4, Loss: 0.051899950951337814\n",
      "Epoch 5, Loss: 0.13080845773220062\n",
      "Epoch 6, Loss: 0.04566904157400131\n",
      "Epoch 5, Loss: 0.1064201146364212\n",
      "Epoch 3, Loss: 0.1717406064271927\n",
      "Epoch 4, Loss: 0.03919404000043869\n",
      "Epoch 3, Loss: 0.08829814940690994\n",
      "Epoch 8, Loss: 0.013952557928860188\n",
      "Epoch 4, Loss: 0.15973086655139923\n",
      "Epoch 4, Loss: 0.1523129791021347\n",
      "Epoch 3, Loss: 0.17408384382724762\n",
      "Epoch 7, Loss: 0.06298912316560745\n",
      "Epoch 7, Loss: 0.05857774615287781\n",
      "Epoch 5, Loss: 0.11963237076997757\n",
      "Epoch 6, Loss: 0.16063179075717926\n",
      "Epoch 9, Loss: 0.02358575165271759\n",
      "Epoch 6, Loss: 0.1256711333990097\n",
      "Epoch 5, Loss: 0.06318587809801102\n",
      "Epoch 5, Loss: 0.3054235875606537\n",
      "Epoch 4, Loss: 0.1439722627401352\n",
      "Epoch 4, Loss: 0.014778233133256435\n",
      "Epoch 5, Loss: 0.2459535300731659\n",
      "Epoch 4, Loss: 0.05233302339911461\n",
      "Epoch 7, Loss: 0.07668386399745941\n",
      "Epoch 8, Loss: 0.04562678560614586\n",
      "Epoch 10, Loss: 0.06511970609426498\n",
      "Epoch 8, Loss: 0.14361093938350677\n",
      "Epoch 7, Loss: 0.06593941152095795\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.30418475337332457, feed_forward_dim=128, head_dim=8, lr=0.0005931649492088002, num_heads=2, num_layers=1; total time=   1.1s\n",
      "Epoch 6, Loss: 0.15520904958248138\n",
      "Epoch 6, Loss: 0.11985358595848083\n",
      "Epoch 9, Loss: 0.09088820219039917\n",
      "Epoch 6, Loss: 0.18280185759067535\n",
      "Epoch 6, Loss: 0.13614310324192047\n",
      "Epoch 8, Loss: 0.011859742924571037\n",
      "Epoch 9, Loss: 0.17830345034599304\n",
      "Epoch 5, Loss: 0.2854745090007782\n",
      "Epoch 8, Loss: 0.018052026629447937\n",
      "Epoch 5, Loss: 0.05056801065802574\n",
      "Epoch 5, Loss: 0.09240061044692993\n",
      "Epoch 7, Loss: 0.09025731682777405\n",
      "Epoch 10, Loss: 0.12069269269704819\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.30418475337332457, feed_forward_dim=128, head_dim=8, lr=0.0005931649492088002, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 10, Loss: 0.1464359164237976\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.30418475337332457, feed_forward_dim=128, head_dim=8, lr=0.0005931649492088002, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 9, Loss: 0.01615624688565731\n",
      "Epoch 7, Loss: 0.09665685147047043\n",
      "Epoch 7, Loss: 0.04615175351500511\n",
      "Epoch 7, Loss: 0.0319608598947525\n",
      "Epoch 9, Loss: 0.02466592751443386\n",
      "Epoch 8, Loss: 0.022847888991236687\n",
      "Epoch 6, Loss: 0.12559442222118378\n",
      "Epoch 6, Loss: 0.17028199136257172\n",
      "Epoch 8, Loss: 0.04046226665377617\n",
      "Epoch 6, Loss: 0.10962828993797302\n",
      "Epoch 10, Loss: 0.05496479198336601\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.30418475337332457, feed_forward_dim=128, head_dim=8, lr=0.0005931649492088002, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 8, Loss: 0.029454611241817474\n",
      "Epoch 10, Loss: 0.05221203714609146\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.30418475337332457, feed_forward_dim=128, head_dim=8, lr=0.0005931649492088002, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 8, Loss: 0.02154945395886898\n",
      "Epoch 9, Loss: 0.013453262858092785\n",
      "Epoch 7, Loss: 0.0830913856625557\n",
      "Epoch 7, Loss: 0.03423597663640976\n",
      "Epoch 9, Loss: 0.010632049292325974\n",
      "Epoch 7, Loss: 0.08628880977630615\n",
      "Epoch 9, Loss: 0.08251450955867767\n",
      "Epoch 10, Loss: 0.04786142706871033\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.30418475337332457, feed_forward_dim=128, head_dim=8, lr=0.0005931649492088002, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 9, Loss: 0.07639089226722717\n",
      "Epoch 8, Loss: 0.03275981917977333\n",
      "Epoch 10, Loss: 0.025609105825424194\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.30418475337332457, feed_forward_dim=128, head_dim=8, lr=0.0005931649492088002, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 8, Loss: 0.01520211435854435\n",
      "Epoch 10, Loss: 0.1077718436717987\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.30418475337332457, feed_forward_dim=128, head_dim=8, lr=0.0005931649492088002, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 8, Loss: 0.028649216517806053\n",
      "Epoch 10, Loss: 0.12112468481063843\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.30418475337332457, feed_forward_dim=128, head_dim=8, lr=0.0005931649492088002, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 9, Loss: 0.024341361597180367\n",
      "Epoch 9, Loss: 0.07729263603687286\n",
      "Epoch 9, Loss: 0.00477942219004035\n",
      "Epoch 10, Loss: 0.11784417182207108\n",
      "Epoch 10, Loss: 0.04902919754385948\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.30418475337332457, feed_forward_dim=128, head_dim=8, lr=0.0005931649492088002, num_heads=2, num_layers=1; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.30418475337332457, feed_forward_dim=128, head_dim=8, lr=0.0005931649492088002, num_heads=2, num_layers=1; total time=   1.6s\n",
      "Epoch 10, Loss: 0.022522829473018646\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.30418475337332457, feed_forward_dim=128, head_dim=8, lr=0.0005931649492088002, num_heads=2, num_layers=1; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 2.772169828414917\n",
      "Epoch 1, Loss: 0.7117695212364197\n",
      "Epoch 1, Loss: 1.4955487251281738\n",
      "Epoch 1, Loss: 0.7059506177902222\n",
      "Epoch 2, Loss: 3.6944997310638428\n",
      "Epoch 2, Loss: 7.047871112823486\n",
      "Epoch 2, Loss: 5.096816062927246\n",
      "Epoch 2, Loss: 12.17934799194336\n",
      "Epoch 3, Loss: 1.2905442714691162\n",
      "Epoch 3, Loss: 2.1546857357025146\n",
      "Epoch 3, Loss: 1.3779910802841187\n",
      "Epoch 4, Loss: 0.1657048761844635\n",
      "Epoch 3, Loss: 3.9700067043304443\n",
      "Epoch 4, Loss: 0.06951087713241577\n",
      "Epoch 1, Loss: 0.16598355770111084\n",
      "Epoch 1, Loss: 0.11654996126890182\n",
      "Epoch 4, Loss: 0.04961642250418663\n",
      "Epoch 5, Loss: 0.12451716512441635\n",
      "Epoch 1, Loss: 0.4434851408004761\n",
      "Epoch 1, Loss: 1.5336189270019531\n",
      "Epoch 4, Loss: 0.23805677890777588\n",
      "Epoch 5, Loss: 0.6822887063026428\n",
      "Epoch 2, Loss: 15.431302070617676\n",
      "Epoch 1, Loss: 0.40758785605430603\n",
      "Epoch 2, Loss: 12.196791648864746\n",
      "Epoch 1, Loss: 1.0965839624404907\n",
      "Epoch 6, Loss: 0.34703749418258667\n",
      "Epoch 5, Loss: 0.629310667514801\n",
      "Epoch 1, Loss: 0.9374455809593201\n",
      "Epoch 2, Loss: 10.723691940307617\n",
      "Epoch 6, Loss: 0.7810816168785095\n",
      "Epoch 3, Loss: 3.707695722579956\n",
      "Epoch 5, Loss: 0.47355353832244873\n",
      "Epoch 1, Loss: 0.0768568366765976\n",
      "Epoch 2, Loss: 5.851861000061035\n",
      "Epoch 7, Loss: 0.3405870497226715\n",
      "Epoch 6, Loss: 0.6345122456550598\n",
      "Epoch 2, Loss: 10.50411319732666\n",
      "Epoch 3, Loss: 2.641247034072876\n",
      "Epoch 7, Loss: 0.4147935211658478\n",
      "Epoch 4, Loss: 0.013496826402842999\n",
      "Epoch 8, Loss: 0.19371555745601654\n",
      "Epoch 2, Loss: 7.2958855628967285\n",
      "Epoch 2, Loss: 6.934456825256348\n",
      "Epoch 7, Loss: 0.2966006398200989\n",
      "Epoch 6, Loss: 1.0123590230941772\n",
      "Epoch 2, Loss: 10.781481742858887\n",
      "Epoch 3, Loss: 1.9384641647338867\n",
      "Epoch 8, Loss: 0.13984204828739166\n",
      "Epoch 3, Loss: 3.169229030609131\n",
      "Epoch 4, Loss: 0.053162701427936554\n",
      "Epoch 3, Loss: 2.4089651107788086\n",
      "Epoch 9, Loss: 0.07893598824739456\n",
      "Epoch 5, Loss: 1.1745647192001343\n",
      "Epoch 7, Loss: 0.7870135307312012\n",
      "Epoch 3, Loss: 2.3032190799713135\n",
      "Epoch 8, Loss: 0.08861738443374634\n",
      "Epoch 10, Loss: 0.06957711279392242\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.33289723794363935, feed_forward_dim=128, head_dim=32, lr=0.0034864989223424613, num_heads=8, num_layers=1; total time=   0.9s\n",
      "Epoch 9, Loss: 0.058002956211566925\n",
      "Epoch 3, Loss: 2.8438422679901123\n",
      "Epoch 5, Loss: 0.8472436666488647\n",
      "Epoch 4, Loss: 0.17652630805969238\n",
      "Epoch 6, Loss: 1.080858588218689\n",
      "Epoch 3, Loss: 2.2419610023498535\n",
      "Epoch 4, Loss: 0.07810111343860626\n",
      "Epoch 8, Loss: 0.33712878823280334\n",
      "Epoch 4, Loss: 0.11462786048650742\n",
      "Epoch 9, Loss: 0.05937016010284424\n",
      "Epoch 4, Loss: 0.16495582461357117\n",
      "Epoch 10, Loss: 0.10581745952367783\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.33289723794363935, feed_forward_dim=128, head_dim=32, lr=0.0034864989223424613, num_heads=8, num_layers=1; total time=   1.0s\n",
      "Epoch 6, Loss: 0.8894108533859253\n",
      "Epoch 7, Loss: 0.4629112184047699\n",
      "Epoch 5, Loss: 1.0092533826828003\n",
      "Epoch 9, Loss: 0.07746991515159607\n",
      "Epoch 5, Loss: 0.4170582592487335\n",
      "Epoch 10, Loss: 0.10899023711681366\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.33289723794363935, feed_forward_dim=128, head_dim=32, lr=0.0034864989223424613, num_heads=8, num_layers=1; total time=   1.0s\n",
      "Epoch 4, Loss: 0.12697695195674896\n",
      "Epoch 4, Loss: 0.05486304312944412\n",
      "Epoch 5, Loss: 0.32760584354400635\n",
      "Epoch 7, Loss: 0.410713255405426\n",
      "Epoch 10, Loss: 0.0962434783577919\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.33289723794363935, feed_forward_dim=128, head_dim=32, lr=0.0034864989223424613, num_heads=8, num_layers=1; total time=   1.1s\n",
      "Epoch 8, Loss: 0.09430492669343948\n",
      "Epoch 6, Loss: 0.865453839302063\n",
      "Epoch 5, Loss: 0.34584149718284607\n",
      "Epoch 5, Loss: 0.47267717123031616\n",
      "Epoch 6, Loss: 0.8897619843482971\n",
      "Epoch 6, Loss: 0.7287859916687012\n",
      "Epoch 8, Loss: 0.0879722610116005\n",
      "Epoch 9, Loss: 0.0686739906668663\n",
      "Epoch 6, Loss: 0.6529892086982727\n",
      "Epoch 7, Loss: 0.3322891592979431\n",
      "Epoch 5, Loss: 0.8377038836479187\n",
      "Epoch 10, Loss: 0.1912579983472824\n",
      "Epoch 6, Loss: 0.8062310218811035\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.33289723794363935, feed_forward_dim=128, head_dim=32, lr=0.0034864989223424613, num_heads=8, num_layers=1; total time=   1.1s\n",
      "Epoch 7, Loss: 0.6061028838157654\n",
      "Epoch 9, Loss: 0.09405821561813354\n",
      "Epoch 7, Loss: 0.7701888084411621\n",
      "Epoch 7, Loss: 0.5023760795593262\n",
      "Epoch 6, Loss: 0.9592437148094177\n",
      "Epoch 8, Loss: 0.06427481770515442\n",
      "Epoch 10, Loss: 0.2276971936225891\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.33289723794363935, feed_forward_dim=128, head_dim=32, lr=0.0034864989223424613, num_heads=8, num_layers=1; total time=   1.2s\n",
      "Epoch 8, Loss: 0.4398716390132904\n",
      "Epoch 8, Loss: 0.2874599099159241\n",
      "Epoch 7, Loss: 0.5631040334701538\n",
      "Epoch 8, Loss: 0.24241602420806885\n",
      "Epoch 9, Loss: 0.17174267768859863\n",
      "Epoch 7, Loss: 0.546927809715271\n",
      "Epoch 9, Loss: 0.08328032493591309\n",
      "Epoch 8, Loss: 0.2413686066865921\n",
      "Epoch 9, Loss: 0.10676848888397217\n",
      "Epoch 9, Loss: 0.07937207818031311\n",
      "Epoch 10, Loss: 0.05628795176744461\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.33289723794363935, feed_forward_dim=128, head_dim=32, lr=0.0034864989223424613, num_heads=8, num_layers=1; total time=   1.4s\n",
      "Epoch 8, Loss: 0.20236839354038239\n",
      "Epoch 10, Loss: 0.2360270619392395\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.33289723794363935, feed_forward_dim=128, head_dim=32, lr=0.0034864989223424613, num_heads=8, num_layers=1; total time=   1.4s\n",
      "Epoch 9, Loss: 0.07510627806186676\n",
      "Epoch 10, Loss: 0.054528508335351944\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.33289723794363935, feed_forward_dim=128, head_dim=32, lr=0.0034864989223424613, num_heads=8, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.07188118994235992\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.33289723794363935, feed_forward_dim=128, head_dim=32, lr=0.0034864989223424613, num_heads=8, num_layers=1; total time=   1.4s\n",
      "Epoch 9, Loss: 0.06101269647479057\n",
      "Epoch 10, Loss: 0.0772598534822464\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.33289723794363935, feed_forward_dim=128, head_dim=32, lr=0.0034864989223424613, num_heads=8, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.08045174181461334\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.33289723794363935, feed_forward_dim=128, head_dim=32, lr=0.0034864989223424613, num_heads=8, num_layers=1; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.17526158690452576\n",
      "Epoch 1, Loss: 0.1884295642375946\n",
      "Epoch 1, Loss: 0.08891147375106812\n",
      "Epoch 1, Loss: 0.21281005442142487\n",
      "Epoch 1, Loss: 0.389413058757782\n",
      "Epoch 1, Loss: 0.6492360830307007\n",
      "Epoch 1, Loss: 0.35285791754722595\n",
      "Epoch 2, Loss: 8.913175582885742\n",
      "Epoch 1, Loss: 0.7456441521644592\n",
      "Epoch 1, Loss: 0.7716522216796875\n",
      "Epoch 2, Loss: 7.13688850402832\n",
      "Epoch 2, Loss: 9.23346996307373\n",
      "Epoch 1, Loss: 0.2544412612915039\n",
      "Epoch 2, Loss: 7.98905086517334\n",
      "Epoch 3, Loss: 1.8589080572128296\n",
      "Epoch 1, Loss: 0.5288559198379517\n",
      "Epoch 2, Loss: 5.568594455718994\n",
      "Epoch 2, Loss: 9.763839721679688\n",
      "Epoch 2, Loss: 6.158843994140625\n",
      "Epoch 1, Loss: 0.5411372780799866\n",
      "Epoch 2, Loss: 5.943636894226074\n",
      "Epoch 3, Loss: 2.8888063430786133\n",
      "Epoch 3, Loss: 1.2482035160064697\n",
      "Epoch 4, Loss: 0.05104045197367668\n",
      "Epoch 3, Loss: 2.131539821624756\n",
      "Epoch 3, Loss: 2.657377243041992\n",
      "Epoch 2, Loss: 5.998349189758301\n",
      "Epoch 2, Loss: 6.1154303550720215\n",
      "Epoch 3, Loss: 1.7666029930114746\n",
      "Epoch 2, Loss: 7.701641082763672\n",
      "Epoch 3, Loss: 2.183992862701416\n",
      "Epoch 4, Loss: 0.18973511457443237\n",
      "Epoch 4, Loss: 0.11520887911319733\n",
      "Epoch 4, Loss: 0.046569839119911194\n",
      "Epoch 5, Loss: 0.8931897282600403\n",
      "Epoch 3, Loss: 1.8969651460647583\n",
      "Epoch 4, Loss: 0.0738958865404129\n",
      "Epoch 2, Loss: 6.836033344268799\n",
      "Epoch 4, Loss: 0.28013288974761963\n",
      "Epoch 6, Loss: 0.8176766633987427\n",
      "Epoch 5, Loss: 0.725124716758728\n",
      "Epoch 5, Loss: 0.5851963758468628\n",
      "Epoch 3, Loss: 1.671380877494812\n",
      "Epoch 3, Loss: 1.7168465852737427\n",
      "Epoch 3, Loss: 1.553647756576538\n",
      "Epoch 4, Loss: 0.08935754746198654\n",
      "Epoch 5, Loss: 0.3424432873725891\n",
      "Epoch 5, Loss: 0.5845310688018799\n",
      "Epoch 6, Loss: 0.6063510775566101\n",
      "Epoch 4, Loss: 0.13846929371356964\n",
      "Epoch 7, Loss: 0.336796373128891\n",
      "Epoch 5, Loss: 0.09877559542655945\n",
      "Epoch 6, Loss: 0.8465185165405273\n",
      "Epoch 8, Loss: 0.06437704712152481\n",
      "Epoch 6, Loss: 0.9435057044029236\n",
      "Epoch 3, Loss: 2.209007740020752\n",
      "Epoch 4, Loss: 0.1171577125787735\n",
      "Epoch 7, Loss: 0.26907289028167725\n",
      "Epoch 6, Loss: 0.785618245601654\n",
      "Epoch 4, Loss: 0.07963988929986954\n",
      "Epoch 5, Loss: 0.30064156651496887\n",
      "Epoch 4, Loss: 0.07121521979570389\n",
      "Epoch 6, Loss: 0.4140239357948303\n",
      "Epoch 5, Loss: 0.3925720155239105\n",
      "Epoch 7, Loss: 0.5775411128997803\n",
      "Epoch 7, Loss: 0.6693657636642456\n",
      "Epoch 9, Loss: 0.09107616543769836\n",
      "Epoch 8, Loss: 0.07362863421440125\n",
      "Epoch 6, Loss: 0.6445910334587097\n",
      "Epoch 7, Loss: 0.6779617667198181\n",
      "Epoch 5, Loss: 0.8835544586181641\n",
      "Epoch 4, Loss: 0.11066305637359619\n",
      "Epoch 5, Loss: 0.33431190252304077\n",
      "Epoch 5, Loss: 0.4827650189399719\n",
      "Epoch 10, Loss: 0.22058597207069397\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.17359271243635896, feed_forward_dim=512, head_dim=16, lr=0.0027745017733705013, num_heads=4, num_layers=2; total time=   1.0s\n",
      "Epoch 7, Loss: 0.53083735704422\n",
      "Epoch 9, Loss: 0.07749560475349426\n",
      "Epoch 8, Loss: 0.2657613456249237\n",
      "Epoch 8, Loss: 0.23903708159923553\n",
      "Epoch 6, Loss: 0.692801833152771\n",
      "Epoch 8, Loss: 0.3602388799190521\n",
      "Epoch 7, Loss: 0.5378624200820923\n",
      "Epoch 8, Loss: 0.4128722846508026\n",
      "Epoch 6, Loss: 0.6945621371269226\n",
      "Epoch 5, Loss: 0.4488280713558197\n",
      "Epoch 10, Loss: 0.1721898317337036\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.17359271243635896, feed_forward_dim=512, head_dim=16, lr=0.0027745017733705013, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 6, Loss: 0.7618970274925232\n",
      "Epoch 6, Loss: 0.6088750958442688\n",
      "Epoch 9, Loss: 0.06209232658147812\n",
      "Epoch 9, Loss: 0.12141284346580505\n",
      "Epoch 9, Loss: 0.06178250536322594\n",
      "Epoch 7, Loss: 0.4934034049510956\n",
      "Epoch 9, Loss: 0.2216251641511917\n",
      "Epoch 10, Loss: 0.09730974584817886\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.17359271243635896, feed_forward_dim=512, head_dim=16, lr=0.0027745017733705013, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 8, Loss: 0.26745960116386414\n",
      "Epoch 10, Loss: 0.06849276274442673\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.17359271243635896, feed_forward_dim=512, head_dim=16, lr=0.0027745017733705013, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 7, Loss: 0.5466172695159912\n",
      "Epoch 7, Loss: 0.4561832547187805\n",
      "Epoch 7, Loss: 0.27134081721305847\n",
      "Epoch 10, Loss: 0.05549271032214165\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.17359271243635896, feed_forward_dim=512, head_dim=16, lr=0.0027745017733705013, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 6, Loss: 0.7495731711387634\n",
      "Epoch 8, Loss: 0.1992420256137848\n",
      "Epoch 10, Loss: 0.08710475265979767\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.17359271243635896, feed_forward_dim=512, head_dim=16, lr=0.0027745017733705013, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 9, Loss: 0.08398567885160446\n",
      "Epoch 8, Loss: 0.19955486059188843\n",
      "Epoch 7, Loss: 0.5025600790977478\n",
      "Epoch 8, Loss: 0.23431247472763062\n",
      "Epoch 8, Loss: 0.06610117107629776\n",
      "Epoch 10, Loss: 0.055989425629377365\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.17359271243635896, feed_forward_dim=512, head_dim=16, lr=0.0027745017733705013, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 9, Loss: 0.049887269735336304\n",
      "Epoch 9, Loss: 0.06311687082052231\n",
      "Epoch 9, Loss: 0.06520286202430725\n",
      "Epoch 9, Loss: 0.08943923562765121\n",
      "Epoch 8, Loss: 0.20059557259082794\n",
      "Epoch 10, Loss: 0.07386164367198944\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.17359271243635896, feed_forward_dim=512, head_dim=16, lr=0.0027745017733705013, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.06841971725225449\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.17359271243635896, feed_forward_dim=512, head_dim=16, lr=0.0027745017733705013, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.07773306965827942\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.17359271243635896, feed_forward_dim=512, head_dim=16, lr=0.0027745017733705013, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.18674732744693756\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.17359271243635896, feed_forward_dim=512, head_dim=16, lr=0.0027745017733705013, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 0.06044149771332741\n",
      "Epoch 10, Loss: 0.08102359622716904\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.17359271243635896, feed_forward_dim=512, head_dim=16, lr=0.0027745017733705013, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.03871573880314827\n",
      "Epoch 1, Loss: 0.0961063802242279\n",
      "Epoch 1, Loss: 0.1390478014945984\n",
      "Epoch 1, Loss: 0.24537751078605652\n",
      "Epoch 1, Loss: 0.6752231121063232\n",
      "Epoch 1, Loss: 1.575268268585205\n",
      "Epoch 2, Loss: 1.033773422241211\n",
      "Epoch 2, Loss: 1.8625744581222534\n",
      "Epoch 1, Loss: 1.2580819129943848\n",
      "Epoch 2, Loss: 1.0637781620025635\n",
      "Epoch 1, Loss: 0.6438412070274353\n",
      "Epoch 2, Loss: 1.4335683584213257\n",
      "Epoch 2, Loss: 0.6021709442138672\n",
      "Epoch 1, Loss: 1.1284162998199463\n",
      "Epoch 3, Loss: 0.17193464934825897\n",
      "Epoch 1, Loss: 1.5248217582702637\n",
      "Epoch 3, Loss: 0.06706832349300385\n",
      "Epoch 1, Loss: 0.012414531782269478\n",
      "Epoch 3, Loss: 0.1513679474592209\n",
      "Epoch 2, Loss: 0.11757370829582214\n",
      "Epoch 4, Loss: 0.3088366687297821\n",
      "Epoch 3, Loss: 0.42961153388023376\n",
      "Epoch 2, Loss: 0.13960427045822144\n",
      "Epoch 1, Loss: 0.08763004839420319\n",
      "Epoch 2, Loss: 0.41202327609062195\n",
      "Epoch 3, Loss: 0.2912248969078064\n",
      "Epoch 2, Loss: 0.378930926322937\n",
      "Epoch 4, Loss: 0.28021785616874695\n",
      "Epoch 5, Loss: 0.6916499733924866\n",
      "Epoch 4, Loss: 0.19482111930847168\n",
      "Epoch 2, Loss: 1.7670505046844482\n",
      "Epoch 3, Loss: 0.6491532325744629\n",
      "Epoch 3, Loss: 0.5765179991722107\n",
      "Epoch 4, Loss: 0.07729612290859222\n",
      "Epoch 4, Loss: 0.11019574105739594\n",
      "Epoch 2, Loss: 0.07231120765209198\n",
      "Epoch 3, Loss: 0.45210984349250793\n",
      "Epoch 5, Loss: 0.43912383913993835\n",
      "Epoch 3, Loss: 0.6462616324424744\n",
      "Epoch 6, Loss: 0.4656728208065033\n",
      "Epoch 4, Loss: 0.5501195192337036\n",
      "Epoch 5, Loss: 0.4243718981742859\n",
      "Epoch 5, Loss: 0.06304293870925903\n",
      "Epoch 4, Loss: 0.48042088747024536\n",
      "Epoch 2, Loss: 1.7815098762512207\n",
      "Epoch 5, Loss: 0.3777807056903839\n",
      "Epoch 3, Loss: 0.17591530084609985\n",
      "Epoch 4, Loss: 0.1447383165359497\n",
      "Epoch 3, Loss: 0.585171103477478\n",
      "Epoch 6, Loss: 0.2374473661184311\n",
      "Epoch 7, Loss: 0.14936992526054382\n",
      "Epoch 6, Loss: 0.29756319522857666\n",
      "Epoch 6, Loss: 0.1563679426908493\n",
      "Epoch 4, Loss: 0.25522083044052124\n",
      "Epoch 5, Loss: 0.22954225540161133\n",
      "Epoch 7, Loss: 0.05332570895552635\n",
      "Epoch 5, Loss: 0.21574248373508453\n",
      "Epoch 6, Loss: 0.4081909656524658\n",
      "Epoch 5, Loss: 0.03851722553372383\n",
      "Epoch 8, Loss: 0.010492510162293911\n",
      "Epoch 4, Loss: 0.27758803963661194\n",
      "Epoch 3, Loss: 0.22124764323234558\n",
      "Epoch 7, Loss: 0.1001831665635109\n",
      "Epoch 4, Loss: 0.418540358543396\n",
      "Epoch 7, Loss: 0.17655478417873383\n",
      "Epoch 5, Loss: 0.03129776194691658\n",
      "Epoch 8, Loss: 0.021714719012379646\n",
      "Epoch 9, Loss: 0.04720514267683029\n",
      "Epoch 6, Loss: 0.04760279878973961\n",
      "Epoch 6, Loss: 0.059908900409936905\n",
      "Epoch 7, Loss: 0.22153514623641968\n",
      "Epoch 6, Loss: 0.11350277811288834\n",
      "Epoch 8, Loss: 0.027503248304128647\n",
      "Epoch 8, Loss: 0.10736582428216934\n",
      "Epoch 4, Loss: 0.15246990323066711\n",
      "Epoch 10, Loss: 0.14865049719810486\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0008666104674873782, num_heads=2, num_layers=1; total time=   1.0s\n",
      "Epoch 5, Loss: 0.12693336606025696\n",
      "Epoch 5, Loss: 0.6649385094642639\n",
      "Epoch 9, Loss: 0.08840055763721466\n",
      "Epoch 8, Loss: 0.0646311417222023\n",
      "Epoch 7, Loss: 0.05668778344988823\n",
      "Epoch 6, Loss: 0.08177631348371506\n",
      "Epoch 7, Loss: 0.06763536483049393\n",
      "Epoch 9, Loss: 0.07677744328975677\n",
      "Epoch 10, Loss: 0.15118974447250366\n",
      "Epoch 9, Loss: 0.03275397792458534\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0008666104674873782, num_heads=2, num_layers=1; total time=   1.1s\n",
      "Epoch 7, Loss: 0.1790897399187088\n",
      "Epoch 6, Loss: 0.026496559381484985\n",
      "Epoch 9, Loss: 0.029757387936115265\n",
      "Epoch 5, Loss: 0.5387066602706909\n",
      "Epoch 8, Loss: 0.1509801745414734\n",
      "Epoch 6, Loss: 0.4606921076774597\n",
      "Epoch 8, Loss: 0.1525643765926361\n",
      "Epoch 10, Loss: 0.14307376742362976\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0008666104674873782, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 7, Loss: 0.19023600220680237\n",
      "Epoch 10, Loss: 0.01363839115947485\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0008666104674873782, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 7, Loss: 0.08209112286567688\n",
      "Epoch 8, Loss: 0.15541677176952362\n",
      "Epoch 9, Loss: 0.20733515918254852\n",
      "Epoch 6, Loss: 0.5015274882316589\n",
      "Epoch 10, Loss: 0.08690494298934937\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0008666104674873782, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 9, Loss: 0.20225483179092407\n",
      "Epoch 7, Loss: 0.14948096871376038\n",
      "Epoch 8, Loss: 0.20546850562095642\n",
      "Epoch 9, Loss: 0.08754513412714005\n",
      "Epoch 10, Loss: 0.19123364984989166\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0008666104674873782, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 10, Loss: 0.18143396079540253\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0008666104674873782, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 7, Loss: 0.25680840015411377\n",
      "Epoch 8, Loss: 0.15869075059890747\n",
      "Epoch 9, Loss: 0.1389225870370865\n",
      "Epoch 8, Loss: 0.011410865001380444\n",
      "Epoch 10, Loss: 0.03444710001349449\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0008666104674873782, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 9, Loss: 0.17791202664375305\n",
      "Epoch 8, Loss: 0.06602802872657776\n",
      "Epoch 10, Loss: 0.060371752828359604\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0008666104674873782, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 9, Loss: 0.05521441623568535\n",
      "Epoch 10, Loss: 0.1415623426437378\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0008666104674873782, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 9, Loss: 0.021003492176532745\n",
      "Epoch 10, Loss: 0.15676642954349518\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0008666104674873782, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.0848175659775734\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0008666104674873782, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.1281581073999405\n",
      "Epoch 1, Loss: 0.33174824714660645\n",
      "Epoch 1, Loss: 0.13826945424079895\n",
      "Epoch 2, Loss: 0.2093210518360138\n",
      "Epoch 1, Loss: 0.23668141663074493\n",
      "Epoch 1, Loss: 0.6787517666816711\n",
      "Epoch 1, Loss: 0.26292091608047485\n",
      "Epoch 3, Loss: 0.07742471992969513\n",
      "Epoch 2, Loss: 0.09565930813550949\n",
      "Epoch 1, Loss: 0.9137784242630005\n",
      "Epoch 2, Loss: 0.09537734091281891\n",
      "Epoch 2, Loss: 0.1665245145559311\n",
      "Epoch 1, Loss: 0.269288569688797\n",
      "Epoch 2, Loss: 0.15759694576263428\n",
      "Epoch 2, Loss: 0.11015225201845169\n",
      "Epoch 1, Loss: 0.2666144371032715\n",
      "Epoch 3, Loss: 0.20739968121051788\n",
      "Epoch 1, Loss: 0.9514116048812866\n",
      "Epoch 4, Loss: 0.058908332139253616\n",
      "Epoch 1, Loss: 0.778863251209259\n",
      "Epoch 1, Loss: 0.127629816532135\n",
      "Epoch 3, Loss: 0.11530104279518127\n",
      "Epoch 2, Loss: 0.22714926302433014\n",
      "Epoch 3, Loss: 0.09758275747299194\n",
      "Epoch 3, Loss: 0.05652809143066406\n",
      "Epoch 3, Loss: 0.1698809266090393\n",
      "Epoch 5, Loss: 0.08603381365537643\n",
      "Epoch 4, Loss: 0.1634359061717987\n",
      "Epoch 2, Loss: 0.05517955496907234\n",
      "Epoch 2, Loss: 0.041023917496204376\n",
      "Epoch 2, Loss: 0.038228362798690796\n",
      "Epoch 4, Loss: 0.08086390048265457\n",
      "Epoch 3, Loss: 0.032413698732852936\n",
      "Epoch 4, Loss: 0.03891603276133537\n",
      "Epoch 2, Loss: 0.19969826936721802\n",
      "Epoch 5, Loss: 0.07133380323648453\n",
      "Epoch 4, Loss: 0.13179215788841248\n",
      "Epoch 6, Loss: 0.05611612647771835\n",
      "Epoch 5, Loss: 0.05095101520419121\n",
      "Epoch 5, Loss: 0.022170614451169968\n",
      "Epoch 2, Loss: 0.21444883942604065\n",
      "Epoch 4, Loss: 0.17176547646522522\n",
      "Epoch 3, Loss: 0.16701145470142365\n",
      "Epoch 3, Loss: 0.10121088474988937\n",
      "Epoch 6, Loss: 0.03672850504517555\n",
      "Epoch 4, Loss: 0.13860255479812622\n",
      "Epoch 7, Loss: 0.017625339329242706\n",
      "Epoch 6, Loss: 0.04111975058913231\n",
      "Epoch 3, Loss: 0.08128812909126282\n",
      "Epoch 3, Loss: 0.13770058751106262\n",
      "Epoch 5, Loss: 0.06564871966838837\n",
      "Epoch 6, Loss: 0.04302792251110077\n",
      "Epoch 3, Loss: 0.07615680247545242\n",
      "Epoch 5, Loss: 0.24084942042827606\n",
      "Epoch 4, Loss: 0.14087432622909546\n",
      "Epoch 4, Loss: 0.04429730772972107\n",
      "Epoch 7, Loss: 0.059640172868967056\n",
      "Epoch 5, Loss: 0.2633875012397766\n",
      "Epoch 7, Loss: 0.03811175376176834\n",
      "Epoch 8, Loss: 0.020376194268465042\n",
      "Epoch 7, Loss: 0.025095373392105103\n",
      "Epoch 4, Loss: 0.25004658102989197\n",
      "Epoch 4, Loss: 0.13573870062828064\n",
      "Epoch 6, Loss: 0.206228107213974\n",
      "Epoch 8, Loss: 0.0820130780339241\n",
      "Epoch 9, Loss: 0.04151041433215141\n",
      "Epoch 6, Loss: 0.04159421846270561\n",
      "Epoch 8, Loss: 0.016163287684321404\n",
      "Epoch 6, Loss: 0.2821991443634033\n",
      "Epoch 5, Loss: 0.051767412573099136\n",
      "Epoch 8, Loss: 0.01910926029086113\n",
      "Epoch 4, Loss: 0.18266649544239044\n",
      "Epoch 5, Loss: 0.015306779183447361\n",
      "Epoch 10, Loss: 0.041310589760541916\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.29385840304274674, feed_forward_dim=512, head_dim=32, lr=0.00029112373713587286, num_heads=2, num_layers=4; total time=   1.1s\n",
      "Epoch 5, Loss: 0.061967696994543076\n",
      "Epoch 7, Loss: 0.1323367804288864\n",
      "Epoch 9, Loss: 0.06871426850557327\n",
      "Epoch 5, Loss: 0.3325308859348297\n",
      "Epoch 7, Loss: 0.21433909237384796\n",
      "Epoch 9, Loss: 0.006096735130995512\n",
      "Epoch 6, Loss: 0.02038210816681385\n",
      "Epoch 10, Loss: 0.03904874995350838\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.29385840304274674, feed_forward_dim=512, head_dim=32, lr=0.00029112373713587286, num_heads=2, num_layers=4; total time=   1.1s\n",
      "Epoch 9, Loss: 0.019256578758358955\n",
      "Epoch 5, Loss: 0.26478588581085205\n",
      "Epoch 7, Loss: 0.05593554675579071\n",
      "Epoch 8, Loss: 0.06191125139594078\n",
      "Epoch 6, Loss: 0.012061548419296741\n",
      "Epoch 10, Loss: 0.016693543642759323\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.29385840304274674, feed_forward_dim=512, head_dim=32, lr=0.00029112373713587286, num_heads=2, num_layers=4; total time=   1.2s\n",
      "Epoch 8, Loss: 0.12667632102966309\n",
      "Epoch 6, Loss: 0.03749547898769379\n",
      "Epoch 6, Loss: 0.2837637662887573\n",
      "Epoch 8, Loss: 0.06087666377425194\n",
      "Epoch 9, Loss: 0.02777176722884178\n",
      "Epoch 6, Loss: 0.2476595938205719\n",
      "Epoch 7, Loss: 0.0199460219591856\n",
      "Epoch 10, Loss: 0.01367404218763113\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.29385840304274674, feed_forward_dim=512, head_dim=32, lr=0.00029112373713587286, num_heads=2, num_layers=4; total time=   1.2s\n",
      "Epoch 9, Loss: 0.053731244057416916\n",
      "Epoch 9, Loss: 0.04167097434401512\n",
      "Epoch 7, Loss: 0.05023614689707756\n",
      "Epoch 10, Loss: 0.02893570065498352\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.29385840304274674, feed_forward_dim=512, head_dim=32, lr=0.00029112373713587286, num_heads=2, num_layers=4; total time=   1.3s\n",
      "Epoch 7, Loss: 0.04997841268777847\n",
      "Epoch 7, Loss: 0.17502906918525696\n",
      "Epoch 7, Loss: 0.17348438501358032\n",
      "Epoch 8, Loss: 0.051172271370887756\n",
      "Epoch 10, Loss: 0.01932978816330433\n",
      "Epoch 10, Loss: 0.0185578390955925\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.29385840304274674, feed_forward_dim=512, head_dim=32, lr=0.00029112373713587286, num_heads=2, num_layers=4; total time=   1.3s\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.29385840304274674, feed_forward_dim=512, head_dim=32, lr=0.00029112373713587286, num_heads=2, num_layers=4; total time=   1.3s\n",
      "Epoch 8, Loss: 0.07708099484443665\n",
      "Epoch 8, Loss: 0.031073033809661865\n",
      "Epoch 8, Loss: 0.07619322836399078\n",
      "Epoch 9, Loss: 0.05935285985469818\n",
      "Epoch 8, Loss: 0.09304705262184143\n",
      "Epoch 9, Loss: 0.06808561086654663\n",
      "Epoch 9, Loss: 0.010585376061499119\n",
      "Epoch 9, Loss: 0.02511160634458065\n",
      "Epoch 10, Loss: 0.0408908948302269\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.29385840304274674, feed_forward_dim=512, head_dim=32, lr=0.00029112373713587286, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Epoch 9, Loss: 0.04585669934749603\n",
      "Epoch 10, Loss: 0.035028982907533646\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.29385840304274674, feed_forward_dim=512, head_dim=32, lr=0.00029112373713587286, num_heads=2, num_layers=4; total time=   1.4s\n",
      "Epoch 10, Loss: 0.010972126387059689\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.29385840304274674, feed_forward_dim=512, head_dim=32, lr=0.00029112373713587286, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.028692465275526047\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.29385840304274674, feed_forward_dim=512, head_dim=32, lr=0.00029112373713587286, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.03348985314369202\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.29385840304274674, feed_forward_dim=512, head_dim=32, lr=0.00029112373713587286, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.7427292466163635\n",
      "Epoch 1, Loss: 0.805494487285614\n",
      "Epoch 1, Loss: 1.1119364500045776\n",
      "Epoch 1, Loss: 0.07703948020935059\n",
      "Epoch 1, Loss: 0.24235427379608154\n",
      "Epoch 1, Loss: 0.08646704256534576\n",
      "Epoch 1, Loss: 2.5890114307403564\n",
      "Epoch 2, Loss: 0.1558070033788681\n",
      "Epoch 1, Loss: 0.21403160691261292\n",
      "Epoch 2, Loss: 0.08868702501058578\n",
      "Epoch 2, Loss: 0.24323081970214844\n",
      "Epoch 2, Loss: 0.19281494617462158\n",
      "Epoch 1, Loss: 0.2243649661540985\n",
      "Epoch 2, Loss: 0.23904280364513397\n",
      "Epoch 2, Loss: 0.09614410996437073\n",
      "Epoch 3, Loss: 0.16058610379695892\n",
      "Epoch 1, Loss: 0.07449223101139069\n",
      "Epoch 3, Loss: 0.15971194207668304\n",
      "Epoch 2, Loss: 0.1222555935382843\n",
      "Epoch 3, Loss: 0.09581373631954193\n",
      "Epoch 3, Loss: 0.06609868258237839\n",
      "Epoch 1, Loss: 0.9821216464042664\n",
      "Epoch 2, Loss: 1.0360755920410156\n",
      "Epoch 1, Loss: 0.49337130784988403\n",
      "Epoch 4, Loss: 0.30340376496315\n",
      "Epoch 2, Loss: 0.028506429865956306\n",
      "Epoch 3, Loss: 0.17167453467845917\n",
      "Epoch 3, Loss: 0.044520001858472824\n",
      "Epoch 4, Loss: 0.30495357513427734\n",
      "Epoch 4, Loss: 0.02458864077925682\n",
      "Epoch 3, Loss: 0.22555573284626007\n",
      "Epoch 3, Loss: 0.1546821892261505\n",
      "Epoch 2, Loss: 0.29571226239204407\n",
      "Epoch 4, Loss: 0.25963789224624634\n",
      "Epoch 5, Loss: 0.26698851585388184\n",
      "Epoch 2, Loss: 0.1759379506111145\n",
      "Epoch 3, Loss: 0.14291971921920776\n",
      "Epoch 5, Loss: 0.29048916697502136\n",
      "Epoch 4, Loss: 0.05680537596344948\n",
      "Epoch 4, Loss: 0.08436509221792221\n",
      "Epoch 5, Loss: 0.07982101291418076\n",
      "Epoch 2, Loss: 0.057357076555490494\n",
      "Epoch 5, Loss: 0.3530576825141907\n",
      "Epoch 6, Loss: 0.14113479852676392\n",
      "Epoch 4, Loss: 0.05548291280865669\n",
      "Epoch 6, Loss: 0.1824023574590683\n",
      "Epoch 6, Loss: 0.07126576453447342\n",
      "Epoch 3, Loss: 0.04404187202453613\n",
      "Epoch 5, Loss: 0.028842179104685783\n",
      "Epoch 7, Loss: 0.048973117023706436\n",
      "Epoch 4, Loss: 0.10763499140739441\n",
      "Epoch 4, Loss: 0.06180189922451973\n",
      "Epoch 3, Loss: 0.027581986039876938\n",
      "Epoch 5, Loss: 0.11103363335132599\n",
      "Epoch 7, Loss: 0.07959864288568497Epoch 6, Loss: 0.31459903717041016\n",
      "\n",
      "Epoch 3, Loss: 0.1956510692834854\n",
      "Epoch 7, Loss: 0.02664240263402462\n",
      "Epoch 5, Loss: 0.23765945434570312\n",
      "Epoch 8, Loss: 0.02263803966343403\n",
      "Epoch 6, Loss: 0.05890943855047226\n",
      "Epoch 4, Loss: 0.09046274423599243\n",
      "Epoch 5, Loss: 0.02910100668668747\n",
      "Epoch 8, Loss: 0.03595034033060074\n",
      "Epoch 6, Loss: 0.06296706199645996\n",
      "Epoch 5, Loss: 0.03168429061770439\n",
      "Epoch 4, Loss: 0.21904923021793365\n",
      "Epoch 7, Loss: 0.20372459292411804\n",
      "Epoch 8, Loss: 0.009143950417637825\n",
      "Epoch 4, Loss: 0.246829092502594\n",
      "Epoch 9, Loss: 0.050958845764398575\n",
      "Epoch 6, Loss: 0.43027570843696594\n",
      "Epoch 7, Loss: 0.08397357910871506\n",
      "Epoch 9, Loss: 0.04671783000230789\n",
      "Epoch 6, Loss: 0.06439602375030518\n",
      "Epoch 7, Loss: 0.014402559027075768\n",
      "Epoch 9, Loss: 0.028717944398522377\n",
      "Epoch 5, Loss: 0.1449449062347412\n",
      "Epoch 10, Loss: 0.09101424366235733\n",
      "Epoch 8, Loss: 0.0976366400718689\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1492770811876184, feed_forward_dim=1024, head_dim=16, lr=0.0003613314717569919, num_heads=2, num_layers=4; total time=   1.1s\n",
      "Epoch 6, Loss: 0.012620359659194946\n",
      "Epoch 10, Loss: 0.08441547304391861\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1492770811876184, feed_forward_dim=1024, head_dim=16, lr=0.0003613314717569919, num_heads=2, num_layers=4; total time=   1.1s\n",
      "Epoch 8, Loss: 0.06052718684077263\n",
      "Epoch 7, Loss: 0.48950421810150146\n",
      "Epoch 8, Loss: 0.023746967315673828\n",
      "Epoch 9, Loss: 0.03943468630313873\n",
      "Epoch 5, Loss: 0.31738144159317017\n",
      "Epoch 6, Loss: 0.07308617979288101\n",
      "Epoch 7, Loss: 0.0709027424454689\n",
      "Epoch 9, Loss: 0.024198587983846664\n",
      "Epoch 7, Loss: 0.04483291506767273\n",
      "Epoch 5, Loss: 0.15052074193954468\n",
      "Epoch 10, Loss: 0.04406201094388962\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1492770811876184, feed_forward_dim=1024, head_dim=16, lr=0.0003613314717569919, num_heads=2, num_layers=4; total time=   1.2s\n",
      "Epoch 8, Loss: 0.44587841629981995\n",
      "Epoch 10, Loss: 0.030317701399326324\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1492770811876184, feed_forward_dim=1024, head_dim=16, lr=0.0003613314717569919, num_heads=2, num_layers=4; total time=   1.2s\n",
      "Epoch 9, Loss: 0.05181575194001198\n",
      "Epoch 8, Loss: 0.036020904779434204\n",
      "Epoch 7, Loss: 0.012305309064686298\n",
      "Epoch 10, Loss: 0.014762134291231632\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1492770811876184, feed_forward_dim=1024, head_dim=16, lr=0.0003613314717569919, num_heads=2, num_layers=4; total time=   1.3s\n",
      "Epoch 6, Loss: 0.26033827662467957\n",
      "Epoch 8, Loss: 0.06658276915550232\n",
      "Epoch 9, Loss: 0.3355995714664459\n",
      "Epoch 10, Loss: 0.05224306136369705\n",
      "Epoch 6, Loss: 0.04762709513306618\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1492770811876184, feed_forward_dim=1024, head_dim=16, lr=0.0003613314717569919, num_heads=2, num_layers=4; total time=   1.3s\n",
      "Epoch 9, Loss: 0.01002681627869606\n",
      "Epoch 9, Loss: 0.050954364240169525\n",
      "Epoch 7, Loss: 0.14614924788475037\n",
      "Epoch 10, Loss: 0.21755321323871613\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1492770811876184, feed_forward_dim=1024, head_dim=16, lr=0.0003613314717569919, num_heads=2, num_layers=4; total time=   1.3s\n",
      "Epoch 8, Loss: 0.02500566653907299\n",
      "Epoch 7, Loss: 0.017521260306239128\n",
      "Epoch 10, Loss: 0.018322844058275223\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1492770811876184, feed_forward_dim=1024, head_dim=16, lr=0.0003613314717569919, num_heads=2, num_layers=4; total time=   1.4s\n",
      "Epoch 10, Loss: 0.021766653284430504\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1492770811876184, feed_forward_dim=1024, head_dim=16, lr=0.0003613314717569919, num_heads=2, num_layers=4; total time=   1.4s\n",
      "Epoch 8, Loss: 0.051467180252075195\n",
      "Epoch 9, Loss: 0.0617944672703743\n",
      "Epoch 8, Loss: 0.05039704963564873\n",
      "Epoch 9, Loss: 0.011065677739679813\n",
      "Epoch 10, Loss: 0.0659717321395874\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1492770811876184, feed_forward_dim=1024, head_dim=16, lr=0.0003613314717569919, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Epoch 9, Loss: 0.08919527381658554\n",
      "Epoch 10, Loss: 0.020201576873660088\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1492770811876184, feed_forward_dim=1024, head_dim=16, lr=0.0003613314717569919, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.09048377722501755\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1492770811876184, feed_forward_dim=1024, head_dim=16, lr=0.0003613314717569919, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.05470166727900505\n",
      "Epoch 1, Loss: 1.9269607067108154\n",
      "Epoch 1, Loss: 0.030791716650128365\n",
      "Epoch 1, Loss: 0.8172330856323242\n",
      "Epoch 2, Loss: 0.2672523260116577\n",
      "Epoch 1, Loss: 0.6735117435455322\n",
      "Epoch 1, Loss: 0.15934981405735016\n",
      "Epoch 1, Loss: 1.152620792388916\n",
      "Epoch 2, Loss: 0.4115242063999176\n",
      "Epoch 1, Loss: 0.23346130549907684\n",
      "Epoch 3, Loss: 0.04214268550276756\n",
      "Epoch 2, Loss: 0.5122934579849243\n",
      "Epoch 1, Loss: 3.2592098712921143\n",
      "Epoch 2, Loss: 0.08738972246646881\n",
      "Epoch 4, Loss: 0.06730614602565765\n",
      "Epoch 2, Loss: 0.12048782408237457\n",
      "Epoch 3, Loss: 0.046855900436639786\n",
      "Epoch 1, Loss: 2.152283191680908\n",
      "Epoch 2, Loss: 0.04574042931199074\n",
      "Epoch 2, Loss: 0.2618221640586853\n",
      "Epoch 3, Loss: 0.016191568225622177\n",
      "Epoch 3, Loss: 0.20752492547035217\n",
      "Epoch 1, Loss: 0.267551451921463\n",
      "Epoch 2, Loss: 0.3607587516307831\n",
      "Epoch 5, Loss: 0.1337442398071289\n",
      "Epoch 1, Loss: 0.7270136475563049\n",
      "Epoch 2, Loss: 1.6277527809143066\n",
      "Epoch 3, Loss: 0.11444298177957535\n",
      "Epoch 3, Loss: 0.09673965722322464\n",
      "Epoch 4, Loss: 0.07696834951639175\n",
      "Epoch 4, Loss: 0.15102234482765198\n",
      "Epoch 3, Loss: 0.25842219591140747\n",
      "Epoch 2, Loss: 0.533640444278717\n",
      "Epoch 4, Loss: 0.3488592803478241\n",
      "Epoch 6, Loss: 0.07000521570444107\n",
      "Epoch 3, Loss: 0.15673203766345978\n",
      "Epoch 2, Loss: 0.08173979073762894\n",
      "Epoch 5, Loss: 0.39844247698783875\n",
      "Epoch 4, Loss: 0.015054410323500633\n",
      "Epoch 5, Loss: 0.2748144865036011\n",
      "Epoch 4, Loss: 0.32132938504219055\n",
      "Epoch 7, Loss: 0.014729048125445843\n",
      "Epoch 5, Loss: 0.19094344973564148\n",
      "Epoch 3, Loss: 0.5904015898704529\n",
      "Epoch 2, Loss: 0.1239839643239975\n",
      "Epoch 4, Loss: 0.2951256334781647\n",
      "Epoch 3, Loss: 0.05290769785642624\n",
      "Epoch 6, Loss: 0.4726259708404541\n",
      "Epoch 4, Loss: 0.08003336936235428\n",
      "Epoch 3, Loss: 0.18259717524051666\n",
      "Epoch 8, Loss: 0.024874528869986534\n",
      "Epoch 6, Loss: 0.1332690715789795\n",
      "Epoch 5, Loss: 0.18265360593795776\n",
      "Epoch 5, Loss: 0.02710343711078167\n",
      "Epoch 6, Loss: 0.13653822243213654\n",
      "Epoch 5, Loss: 0.3967123031616211\n",
      "Epoch 3, Loss: 0.3146456182003021\n",
      "Epoch 7, Loss: 0.40350866317749023\n",
      "Epoch 4, Loss: 0.14188365638256073\n",
      "Epoch 5, Loss: 0.12611427903175354\n",
      "Epoch 4, Loss: 0.2515237331390381\n",
      "Epoch 9, Loss: 0.05573165416717529\n",
      "Epoch 7, Loss: 0.03846510499715805\n",
      "Epoch 6, Loss: 0.06849494576454163\n",
      "Epoch 6, Loss: 0.047354694455862045\n",
      "Epoch 4, Loss: 0.10410264879465103\n",
      "Epoch 7, Loss: 0.04336502403020859\n",
      "Epoch 8, Loss: 0.2671544849872589\n",
      "Epoch 10, Loss: 0.05997926741838455\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.18215282282691247, feed_forward_dim=256, head_dim=32, lr=0.00038407615066384117, num_heads=2, num_layers=4; total time=   1.0s\n",
      "Epoch 5, Loss: 0.12156780064105988\n",
      "Epoch 4, Loss: 0.3697985112667084\n",
      "Epoch 6, Loss: 0.33441269397735596\n",
      "Epoch 8, Loss: 0.0064580789767205715\n",
      "Epoch 6, Loss: 0.10889365524053574\n",
      "Epoch 7, Loss: 0.020401369780302048\n",
      "Epoch 7, Loss: 0.0586300864815712\n",
      "Epoch 8, Loss: 0.034749019891023636\n",
      "Epoch 5, Loss: 0.49365684390068054\n",
      "Epoch 9, Loss: 0.134012833237648\n",
      "Epoch 5, Loss: 0.02261587604880333\n",
      "Epoch 6, Loss: 0.2983608543872833\n",
      "Epoch 8, Loss: 0.021617457270622253\n",
      "Epoch 9, Loss: 0.04321533441543579\n",
      "Epoch 7, Loss: 0.04355541244149208\n",
      "Epoch 8, Loss: 0.07058492302894592\n",
      "Epoch 9, Loss: 0.08160383254289627\n",
      "Epoch 7, Loss: 0.2088889330625534\n",
      "Epoch 10, Loss: 0.04357431083917618\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.18215282282691247, feed_forward_dim=256, head_dim=32, lr=0.00038407615066384117, num_heads=2, num_layers=4; total time=   1.2s\n",
      "Epoch 6, Loss: 0.5374836921691895\n",
      "Epoch 5, Loss: 0.23180991411209106\n",
      "Epoch 9, Loss: 0.00659900950267911\n",
      "Epoch 8, Loss: 0.01741303876042366\n",
      "Epoch 9, Loss: 0.11740358918905258\n",
      "Epoch 10, Loss: 0.11871795356273651\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.18215282282691247, feed_forward_dim=256, head_dim=32, lr=0.00038407615066384117, num_heads=2, num_layers=4; total time=   1.3s\n",
      "Epoch 10, Loss: 0.0838606059551239\n",
      "Epoch 7, Loss: 0.4505263566970825\n",
      "Epoch 6, Loss: 0.02681979537010193\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.18215282282691247, feed_forward_dim=256, head_dim=32, lr=0.00038407615066384117, num_heads=2, num_layers=4; total time=   1.3s\n",
      "Epoch 8, Loss: 0.10103466361761093\n",
      "Epoch 10, Loss: 0.0220619048923254\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.18215282282691247, feed_forward_dim=256, head_dim=32, lr=0.00038407615066384117, num_heads=2, num_layers=4; total time=   1.4s\n",
      "Epoch 10, Loss: 0.11538729816675186\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.18215282282691247, feed_forward_dim=256, head_dim=32, lr=0.00038407615066384117, num_heads=2, num_layers=4; total time=   1.4s\n",
      "Epoch 7, Loss: 0.4279080331325531\n",
      "Epoch 9, Loss: 0.03466365113854408\n",
      "Epoch 6, Loss: 0.09296751767396927\n",
      "Epoch 8, Loss: 0.4996975362300873\n",
      "Epoch 7, Loss: 0.06476999819278717\n",
      "Epoch 9, Loss: 0.05218072235584259\n",
      "Epoch 10, Loss: 0.05035990849137306\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.18215282282691247, feed_forward_dim=256, head_dim=32, lr=0.00038407615066384117, num_heads=2, num_layers=4; total time=   1.4s\n",
      "Epoch 8, Loss: 0.2663705348968506\n",
      "Epoch 9, Loss: 0.4586407542228699\n",
      "Epoch 7, Loss: 0.04637540876865387\n",
      "Epoch 8, Loss: 0.06848666816949844\n",
      "Epoch 10, Loss: 0.05754521116614342\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.18215282282691247, feed_forward_dim=256, head_dim=32, lr=0.00038407615066384117, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Epoch 9, Loss: 0.12192729115486145\n",
      "Epoch 10, Loss: 0.3615732192993164\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.18215282282691247, feed_forward_dim=256, head_dim=32, lr=0.00038407615066384117, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Epoch 8, Loss: 0.08426220715045929\n",
      "Epoch 9, Loss: 0.03624372184276581\n",
      "Epoch 10, Loss: 0.03607087954878807\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.18215282282691247, feed_forward_dim=256, head_dim=32, lr=0.00038407615066384117, num_heads=2, num_layers=4; total time=   1.6s\n",
      "Epoch 9, Loss: 0.13160116970539093\n",
      "Epoch 10, Loss: 0.007749307435005903\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.18215282282691247, feed_forward_dim=256, head_dim=32, lr=0.00038407615066384117, num_heads=2, num_layers=4; total time=   1.6s\n",
      "Epoch 10, Loss: 0.13025696575641632\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.18215282282691247, feed_forward_dim=256, head_dim=32, lr=0.00038407615066384117, num_heads=2, num_layers=4; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.19818004965782166\n",
      "Epoch 1, Loss: 1.4121203422546387\n",
      "Epoch 1, Loss: 1.5803402662277222\n",
      "Epoch 1, Loss: 0.08903779834508896\n",
      "Epoch 2, Loss: 0.16622111201286316\n",
      "Epoch 1, Loss: 1.110775351524353\n",
      "Epoch 1, Loss: 0.018468312919139862\n",
      "Epoch 2, Loss: 1.2042566537857056\n",
      "Epoch 1, Loss: 0.01499274279922247\n",
      "Epoch 2, Loss: 1.3776755332946777\n",
      "Epoch 3, Loss: 0.14812403917312622\n",
      "Epoch 2, Loss: 0.0671657919883728\n",
      "Epoch 1, Loss: 1.0643277168273926\n",
      "Epoch 2, Loss: 0.9453113675117493\n",
      "Epoch 1, Loss: 0.17043407261371613\n",
      "Epoch 3, Loss: 1.0232490301132202\n",
      "Epoch 1, Loss: 2.1041197776794434\n",
      "Epoch 2, Loss: 0.012950227595865726\n",
      "Epoch 4, Loss: 0.13905204832553864\n",
      "Epoch 3, Loss: 1.19412100315094\n",
      "Epoch 2, Loss: 0.011316242627799511\n",
      "Epoch 3, Loss: 0.054537102580070496\n",
      "Epoch 1, Loss: 0.3298851251602173\n",
      "Epoch 5, Loss: 0.12769876420497894\n",
      "Epoch 4, Loss: 0.853679895401001\n",
      "Epoch 1, Loss: 0.04459084942936897\n",
      "Epoch 2, Loss: 0.8865147233009338\n",
      "Epoch 3, Loss: 0.7922532558441162\n",
      "Epoch 4, Loss: 1.0188748836517334\n",
      "Epoch 2, Loss: 0.13189302384853363\n",
      "Epoch 3, Loss: 0.014256129041314125\n",
      "Epoch 6, Loss: 0.12432891875505447\n",
      "Epoch 4, Loss: 0.05231339856982231\n",
      "Epoch 2, Loss: 1.8574203252792358\n",
      "Epoch 5, Loss: 0.7014988660812378\n",
      "Epoch 3, Loss: 0.008447523228824139\n",
      "Epoch 3, Loss: 0.7266819477081299\n",
      "Epoch 5, Loss: 0.8619481325149536\n",
      "Epoch 4, Loss: 0.6491523385047913\n",
      "Epoch 7, Loss: 0.11315818130970001\n",
      "Epoch 2, Loss: 0.23504804074764252\n",
      "Epoch 4, Loss: 0.011469423770904541\n",
      "Epoch 2, Loss: 0.03710626810789108\n",
      "Epoch 5, Loss: 0.05189290642738342\n",
      "Epoch 4, Loss: 0.006658270489424467\n",
      "Epoch 6, Loss: 0.5685953497886658\n",
      "Epoch 3, Loss: 0.1056935042142868\n",
      "Epoch 8, Loss: 0.10054139792919159\n",
      "Epoch 6, Loss: 0.731795072555542\n",
      "Epoch 3, Loss: 1.623225450515747\n",
      "Epoch 4, Loss: 0.5906180739402771\n",
      "Epoch 5, Loss: 0.5246379971504211\n",
      "Epoch 5, Loss: 0.008468271233141422\n",
      "Epoch 3, Loss: 0.15862451493740082\n",
      "Epoch 3, Loss: 0.028315946459770203\n",
      "Epoch 6, Loss: 0.052499741315841675\n",
      "Epoch 7, Loss: 0.4507729709148407\n",
      "Epoch 9, Loss: 0.09066218137741089\n",
      "Epoch 5, Loss: 0.0053536416962742805\n",
      "Epoch 4, Loss: 0.08974750339984894\n",
      "Epoch 7, Loss: 0.6008061170578003\n",
      "Epoch 4, Loss: 1.418601393699646\n",
      "Epoch 5, Loss: 0.46853742003440857\n",
      "Epoch 6, Loss: 0.0074929241091012955\n",
      "Epoch 7, Loss: 0.0504833459854126\n",
      "Epoch 6, Loss: 0.417216956615448\n",
      "Epoch 8, Loss: 0.351330041885376\n",
      "Epoch 4, Loss: 0.09667851030826569\n",
      "Epoch 10, Loss: 0.08069092780351639\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.2798782408124965, feed_forward_dim=256, head_dim=8, lr=5e-05, num_heads=8, num_layers=4; total time=   1.0s\n",
      "Epoch 6, Loss: 0.004590265452861786\n",
      "Epoch 4, Loss: 0.02295277640223503\n",
      "Epoch 8, Loss: 0.49058011174201965\n",
      "Epoch 7, Loss: 0.0072280229069292545\n",
      "Epoch 5, Loss: 1.2238450050354004\n",
      "Epoch 6, Loss: 0.3699849247932434\n",
      "Epoch 8, Loss: 0.0439239963889122\n",
      "Epoch 5, Loss: 0.08321481198072433\n",
      "Epoch 9, Loss: 0.26651066541671753\n",
      "Epoch 7, Loss: 0.3244410455226898\n",
      "Epoch 9, Loss: 0.39819982647895813\n",
      "Epoch 7, Loss: 0.004290311597287655\n",
      "Epoch 10, Loss: 0.19478173553943634\n",
      "Epoch 5, Loss: 0.05061883106827736\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.2798782408124965, feed_forward_dim=256, head_dim=8, lr=5e-05, num_heads=8, num_layers=4; total time=   1.2s\n",
      "Epoch 5, Loss: 0.0182116087526083\n",
      "Epoch 10, Loss: 0.3218180239200592\n",
      "Epoch 6, Loss: 1.0472441911697388\n",
      "Epoch 8, Loss: 0.007669846061617136\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.2798782408124965, feed_forward_dim=256, head_dim=8, lr=5e-05, num_heads=8, num_layers=4; total time=   1.2s\n",
      "Epoch 8, Loss: 0.24335895478725433\n",
      "Epoch 9, Loss: 0.04089764133095741\n",
      "Epoch 6, Loss: 0.08346641063690186\n",
      "Epoch 7, Loss: 0.2838108539581299\n",
      "Epoch 8, Loss: 0.004103619605302811\n",
      "Epoch 9, Loss: 0.1787177473306656\n",
      "Epoch 9, Loss: 0.006254630163311958\n",
      "Epoch 6, Loss: 0.023333629593253136\n",
      "Epoch 6, Loss: 0.015312395058572292\n",
      "Epoch 10, Loss: 0.035844434052705765\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.2798782408124965, feed_forward_dim=256, head_dim=8, lr=5e-05, num_heads=8, num_layers=4; total time=   1.3s\n",
      "Epoch 7, Loss: 0.8932093381881714\n",
      "Epoch 9, Loss: 0.004342030733823776\n",
      "Epoch 7, Loss: 0.08463697135448456\n",
      "Epoch 10, Loss: 0.005808040499687195\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.2798782408124965, feed_forward_dim=256, head_dim=8, lr=5e-05, num_heads=8, num_layers=4; total time=   1.4s\n",
      "Epoch 8, Loss: 0.22083477675914764\n",
      "Epoch 10, Loss: 0.13018041849136353\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.2798782408124965, feed_forward_dim=256, head_dim=8, lr=5e-05, num_heads=8, num_layers=4; total time=   1.4s\n",
      "Epoch 7, Loss: 0.008078718557953835\n",
      "Epoch 8, Loss: 0.7469885945320129\n",
      "Epoch 7, Loss: 0.011407194659113884\n",
      "Epoch 8, Loss: 0.0890309289097786\n",
      "Epoch 10, Loss: 0.0047548492439091206\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.2798782408124965, feed_forward_dim=256, head_dim=8, lr=5e-05, num_heads=8, num_layers=4; total time=   1.5s\n",
      "Epoch 9, Loss: 0.17097701132297516\n",
      "Epoch 9, Loss: 0.6318901777267456\n",
      "Epoch 8, Loss: 0.004110507667064667\n",
      "Epoch 9, Loss: 0.08484221249818802\n",
      "Epoch 8, Loss: 0.009466920047998428\n",
      "Epoch 10, Loss: 0.13848605751991272\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.2798782408124965, feed_forward_dim=256, head_dim=8, lr=5e-05, num_heads=8, num_layers=4; total time=   1.6s\n",
      "Epoch 10, Loss: 0.5243600010871887\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.2798782408124965, feed_forward_dim=256, head_dim=8, lr=5e-05, num_heads=8, num_layers=4; total time=   1.6s\n",
      "Epoch 9, Loss: 0.008861629292368889\n",
      "Epoch 10, Loss: 0.08411960303783417\n",
      "Epoch 9, Loss: 0.008203205652534962\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.2798782408124965, feed_forward_dim=256, head_dim=8, lr=5e-05, num_heads=8, num_layers=4; total time=   1.7s\n",
      "Epoch 10, Loss: 0.017759427428245544\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.2798782408124965, feed_forward_dim=256, head_dim=8, lr=5e-05, num_heads=8, num_layers=4; total time=   1.7s\n",
      "Epoch 10, Loss: 0.008024598471820354\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.2798782408124965, feed_forward_dim=256, head_dim=8, lr=5e-05, num_heads=8, num_layers=4; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 1.4254417419433594\n",
      "Epoch 1, Loss: 0.03969823941588402\n",
      "Epoch 1, Loss: 0.1278894990682602\n",
      "Epoch 1, Loss: 0.2227691113948822\n",
      "Epoch 2, Loss: 0.05437131226062775\n",
      "Epoch 1, Loss: 0.26144179701805115\n",
      "Epoch 2, Loss: 0.8775407075881958\n",
      "Epoch 1, Loss: 0.20605088770389557\n",
      "Epoch 2, Loss: 0.05196892470121384\n",
      "Epoch 2, Loss: 0.03364218771457672\n",
      "Epoch 1, Loss: 0.09490267187356949\n",
      "Epoch 1, Loss: 0.026463456451892853\n",
      "Epoch 3, Loss: 0.48822084069252014\n",
      "Epoch 1, Loss: 0.07423222810029984\n",
      "Epoch 3, Loss: 0.023997263982892036\n",
      "Epoch 1, Loss: 0.0953260064125061\n",
      "Epoch 3, Loss: 0.062269262969493866\n",
      "Epoch 2, Loss: 0.1442013680934906\n",
      "Epoch 1, Loss: 0.535239577293396\n",
      "Epoch 3, Loss: 0.037248361855745316\n",
      "Epoch 2, Loss: 0.06190643459558487\n",
      "Epoch 2, Loss: 0.08989240229129791\n",
      "Epoch 2, Loss: 0.0378708690404892\n",
      "Epoch 1, Loss: 0.166141077876091\n",
      "Epoch 4, Loss: 0.2539515495300293\n",
      "Epoch 4, Loss: 0.02189646102488041\n",
      "Epoch 2, Loss: 0.005641249008476734\n",
      "Epoch 4, Loss: 0.06646622717380524\n",
      "Epoch 2, Loss: 0.048740096390247345\n",
      "Epoch 3, Loss: 0.14714224636554718\n",
      "Epoch 3, Loss: 0.06828554719686508\n",
      "Epoch 4, Loss: 0.08437055349349976\n",
      "Epoch 2, Loss: 0.19917678833007812\n",
      "Epoch 5, Loss: 0.1466641128063202\n",
      "Epoch 5, Loss: 0.026722166687250137\n",
      "Epoch 5, Loss: 0.036688465625047684\n",
      "Epoch 3, Loss: 0.06262461841106415\n",
      "Epoch 3, Loss: 0.021900352090597153\n",
      "Epoch 2, Loss: 0.05159582570195198\n",
      "Epoch 3, Loss: 0.07123973220586777\n",
      "Epoch 4, Loss: 0.1607915312051773\n",
      "Epoch 3, Loss: 0.023841559886932373\n",
      "Epoch 6, Loss: 0.1408296525478363\n",
      "Epoch 4, Loss: 0.10380438715219498\n",
      "Epoch 5, Loss: 0.09652046859264374\n",
      "Epoch 6, Loss: 0.01643523946404457\n",
      "Epoch 6, Loss: 0.012527401559054852\n",
      "Epoch 4, Loss: 0.04359949007630348\n",
      "Epoch 7, Loss: 0.18437854945659637\n",
      "Epoch 3, Loss: 0.05311909317970276\n",
      "Epoch 4, Loss: 0.006456948351114988\n",
      "Epoch 6, Loss: 0.0710086077451706\n",
      "Epoch 7, Loss: 0.009116384200751781\n",
      "Epoch 5, Loss: 0.09324458986520767\n",
      "Epoch 5, Loss: 0.14096924662590027\n",
      "Epoch 7, Loss: 0.013173702172935009\n",
      "Epoch 4, Loss: 0.051900457590818405\n",
      "Epoch 3, Loss: 0.06469319015741348\n",
      "Epoch 8, Loss: 0.24059683084487915\n",
      "Epoch 4, Loss: 0.03809930384159088\n",
      "Epoch 8, Loss: 0.02602316625416279\n",
      "Epoch 7, Loss: 0.036921676248311996\n",
      "Epoch 5, Loss: 0.03903166577219963\n",
      "Epoch 5, Loss: 0.01783282309770584\n",
      "Epoch 4, Loss: 0.06668809056282043\n",
      "Epoch 9, Loss: 0.27210572361946106\n",
      "Epoch 6, Loss: 0.05967361107468605\n",
      "Epoch 6, Loss: 0.1071983128786087\n",
      "Epoch 8, Loss: 0.013100706040859222\n",
      "Epoch 5, Loss: 0.03107030689716339\n",
      "Epoch 9, Loss: 0.03299903869628906\n",
      "Epoch 5, Loss: 0.025921911001205444\n",
      "Epoch 4, Loss: 0.08996663987636566\n",
      "Epoch 8, Loss: 0.016234077513217926\n",
      "Epoch 10, Loss: 0.2795741856098175\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3082906219746486, feed_forward_dim=512, head_dim=8, lr=0.00015999339335411817, num_heads=4, num_layers=4; total time=   1.1s\n",
      "Epoch 9, Loss: 0.01805162988603115\n",
      "Epoch 6, Loss: 0.03159872069954872\n",
      "Epoch 6, Loss: 0.02028842456638813\n",
      "Epoch 5, Loss: 0.13890136778354645\n",
      "Epoch 10, Loss: 0.025013206526637077\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3082906219746486, feed_forward_dim=512, head_dim=8, lr=0.00015999339335411817, num_heads=4, num_layers=4; total time=   1.1s\n",
      "Epoch 7, Loss: 0.08287205547094345\n",
      "Epoch 7, Loss: 0.032767653465270996\n",
      "Epoch 6, Loss: 0.026933282613754272\n",
      "Epoch 10, Loss: 0.012839370407164097\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3082906219746486, feed_forward_dim=512, head_dim=8, lr=0.00015999339335411817, num_heads=4, num_layers=4; total time=   1.1s\n",
      "Epoch 6, Loss: 0.009341875091195107\n",
      "Epoch 8, Loss: 0.026010975241661072\n",
      "Epoch 7, Loss: 0.019751807674765587\n",
      "Epoch 7, Loss: 0.010495862923562527\n",
      "Epoch 5, Loss: 0.07304226607084274\n",
      "Epoch 9, Loss: 0.015496271662414074\n",
      "Epoch 6, Loss: 0.17384657263755798\n",
      "Epoch 8, Loss: 0.07264827191829681\n",
      "Epoch 7, Loss: 0.03181305155158043\n",
      "Epoch 9, Loss: 0.0342545360326767\n",
      "Epoch 10, Loss: 0.026539528742432594\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3082906219746486, feed_forward_dim=512, head_dim=8, lr=0.00015999339335411817, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 7, Loss: 0.0026757705491036177\n",
      "Epoch 8, Loss: 0.013907759450376034\n",
      "Epoch 9, Loss: 0.07440729439258575\n",
      "Epoch 6, Loss: 0.043532710522413254\n",
      "Epoch 7, Loss: 0.15638986229896545\n",
      "Epoch 8, Loss: 0.0058786761946976185\n",
      "Epoch 10, Loss: 0.04298592731356621\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3082906219746486, feed_forward_dim=512, head_dim=8, lr=0.00015999339335411817, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 8, Loss: 0.030524061992764473\n",
      "Epoch 10, Loss: 0.07479273527860641\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3082906219746486, feed_forward_dim=512, head_dim=8, lr=0.00015999339335411817, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 8, Loss: 0.007610931061208248\n",
      "Epoch 9, Loss: 0.014988555572926998\n",
      "Epoch 7, Loss: 0.024051547050476074\n",
      "Epoch 9, Loss: 0.011374186724424362\n",
      "Epoch 8, Loss: 0.10897660255432129\n",
      "Epoch 9, Loss: 0.020829524844884872\n",
      "Epoch 10, Loss: 0.013775576837360859\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3082906219746486, feed_forward_dim=512, head_dim=8, lr=0.00015999339335411817, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 9, Loss: 0.015709497034549713\n",
      "Epoch 10, Loss: 0.014786286279559135\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3082906219746486, feed_forward_dim=512, head_dim=8, lr=0.00015999339335411817, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 9, Loss: 0.061964500695466995\n",
      "Epoch 8, Loss: 0.024399807676672935\n",
      "Epoch 10, Loss: 0.012829252518713474\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3082906219746486, feed_forward_dim=512, head_dim=8, lr=0.00015999339335411817, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 10, Loss: 0.017547346651554108\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3082906219746486, feed_forward_dim=512, head_dim=8, lr=0.00015999339335411817, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.028566505759954453\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3082906219746486, feed_forward_dim=512, head_dim=8, lr=0.00015999339335411817, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Epoch 9, Loss: 0.03219345211982727\n",
      "Epoch 10, Loss: 0.03680812940001488\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3082906219746486, feed_forward_dim=512, head_dim=8, lr=0.00015999339335411817, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.4375700354576111\n",
      "Epoch 1, Loss: 0.18732717633247375\n",
      "Epoch 1, Loss: 0.12475015968084335\n",
      "Epoch 1, Loss: 0.6533393263816833\n",
      "Epoch 1, Loss: 0.19309145212173462\n",
      "Epoch 1, Loss: 0.6325543522834778\n",
      "Epoch 2, Loss: 0.101128488779068\n",
      "Epoch 1, Loss: 1.074356198310852\n",
      "Epoch 2, Loss: 0.14336372911930084\n",
      "Epoch 3, Loss: 0.02610996924340725\n",
      "Epoch 1, Loss: 1.5013551712036133\n",
      "Epoch 2, Loss: 0.13950344920158386\n",
      "Epoch 2, Loss: 0.11497979611158371\n",
      "Epoch 2, Loss: 0.1912459433078766\n",
      "Epoch 2, Loss: 0.25513479113578796\n",
      "Epoch 1, Loss: 0.29645299911499023\n",
      "Epoch 3, Loss: 0.1108202189207077\n",
      "Epoch 2, Loss: 0.44560766220092773\n",
      "Epoch 1, Loss: 0.4129575192928314\n",
      "Epoch 4, Loss: 0.11501897871494293\n",
      "Epoch 3, Loss: 0.1298564374446869\n",
      "Epoch 1, Loss: 1.0149046182632446\n",
      "Epoch 2, Loss: 0.6870477199554443\n",
      "Epoch 3, Loss: 0.06039377301931381\n",
      "Epoch 5, Loss: 0.16388869285583496\n",
      "Epoch 3, Loss: 0.06448464840650558\n",
      "Epoch 3, Loss: 0.07110652327537537\n",
      "Epoch 4, Loss: 0.06942512094974518\n",
      "Epoch 1, Loss: 0.6101570129394531\n",
      "Epoch 2, Loss: 0.037298183888196945\n",
      "Epoch 2, Loss: 0.09166247397661209\n",
      "Epoch 4, Loss: 0.08722323179244995\n",
      "Epoch 3, Loss: 0.11912115663290024\n",
      "Epoch 3, Loss: 0.21290434896945953\n",
      "Epoch 6, Loss: 0.1325439065694809\n",
      "Epoch 5, Loss: 0.05221281573176384\n",
      "Epoch 4, Loss: 0.13243550062179565\n",
      "Epoch 4, Loss: 0.05739738792181015\n",
      "Epoch 4, Loss: 0.06964652985334396\n",
      "Epoch 2, Loss: 0.42546239495277405\n",
      "Epoch 3, Loss: 0.05656524747610092\n",
      "Epoch 3, Loss: 0.03906286880373955\n",
      "Epoch 5, Loss: 0.05983825773000717\n",
      "Epoch 7, Loss: 0.06953903287649155\n",
      "Epoch 6, Loss: 0.04203053563833237\n",
      "Epoch 4, Loss: 0.060664545744657516\n",
      "Epoch 5, Loss: 0.214749276638031\n",
      "Epoch 2, Loss: 0.2195146530866623\n",
      "Epoch 4, Loss: 0.03569789603352547\n",
      "Epoch 5, Loss: 0.0451689288020134\n",
      "Epoch 3, Loss: 0.1545356959104538\n",
      "Epoch 6, Loss: 0.054286401718854904\n",
      "Epoch 8, Loss: 0.021765079349279404\n",
      "Epoch 4, Loss: 0.1258758306503296\n",
      "Epoch 5, Loss: 0.14257247745990753\n",
      "Epoch 7, Loss: 0.02894403599202633\n",
      "Epoch 6, Loss: 0.023535583168268204\n",
      "Epoch 9, Loss: 0.00873816478997469\n",
      "Epoch 4, Loss: 0.11660083383321762\n",
      "Epoch 5, Loss: 0.16314555704593658\n",
      "Epoch 6, Loss: 0.21760864555835724\n",
      "Epoch 5, Loss: 0.07791756093502045\n",
      "Epoch 7, Loss: 0.048635393381118774\n",
      "Epoch 4, Loss: 0.12111116200685501\n",
      "Epoch 3, Loss: 0.12985289096832275\n",
      "Epoch 8, Loss: 0.016389956697821617\n",
      "Epoch 10, Loss: 0.02383718080818653\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2750979216672352, feed_forward_dim=256, head_dim=8, lr=0.00021449563756444756, num_heads=2, num_layers=4; total time=   0.9s\n",
      "Epoch 7, Loss: 0.017044978216290474\n",
      "Epoch 5, Loss: 0.10915069282054901\n",
      "Epoch 6, Loss: 0.19217728078365326\n",
      "Epoch 6, Loss: 0.2611662745475769\n",
      "Epoch 6, Loss: 0.2008603811264038\n",
      "Epoch 8, Loss: 0.033295996487140656\n",
      "Epoch 9, Loss: 0.013709867373108864\n",
      "Epoch 7, Loss: 0.1649269163608551\n",
      "Epoch 8, Loss: 0.017589634284377098\n",
      "Epoch 5, Loss: 0.2057744264602661\n",
      "Epoch 4, Loss: 0.20809075236320496\n",
      "Epoch 5, Loss: 0.16067534685134888\n",
      "Epoch 6, Loss: 0.055589497089385986\n",
      "Epoch 9, Loss: 0.020242925733327866\n",
      "Epoch 10, Loss: 0.016180621460080147\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2750979216672352, feed_forward_dim=256, head_dim=8, lr=0.00021449563756444756, num_heads=2, num_layers=4; total time=   1.1s\n",
      "Epoch 9, Loss: 0.013919714838266373\n",
      "Epoch 7, Loss: 0.2989672124385834\n",
      "Epoch 7, Loss: 0.18693740665912628\n",
      "Epoch 8, Loss: 0.09477125853300095\n",
      "Epoch 7, Loss: 0.2827516198158264\n",
      "Epoch 10, Loss: 0.016553644090890884\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2750979216672352, feed_forward_dim=256, head_dim=8, lr=0.00021449563756444756, num_heads=2, num_layers=4; total time=   1.1s\n",
      "Epoch 5, Loss: 0.2532556653022766\n",
      "Epoch 6, Loss: 0.276169091463089\n",
      "Epoch 7, Loss: 0.013995886780321598\n",
      "Epoch 8, Loss: 0.14095816016197205\n",
      "Epoch 9, Loss: 0.04613471403717995\n",
      "Epoch 10, Loss: 0.009013736620545387\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2750979216672352, feed_forward_dim=256, head_dim=8, lr=0.00021449563756444756, num_heads=2, num_layers=4; total time=   1.2s\n",
      "Epoch 8, Loss: 0.3224111795425415\n",
      "Epoch 6, Loss: 0.13683974742889404\n",
      "Epoch 8, Loss: 0.23637525737285614\n",
      "Epoch 9, Loss: 0.08645930886268616\n",
      "Epoch 8, Loss: 0.007875533774495125\n",
      "Epoch 10, Loss: 0.028517544269561768\n",
      "Epoch 6, Loss: 0.2245236486196518\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2750979216672352, feed_forward_dim=256, head_dim=8, lr=0.00021449563756444756, num_heads=2, num_layers=4; total time=   1.2s\n",
      "Epoch 9, Loss: 0.28631144762039185\n",
      "Epoch 7, Loss: 0.2789074182510376\n",
      "Epoch 7, Loss: 0.08371153473854065\n",
      "Epoch 10, Loss: 0.042614780366420746\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2750979216672352, feed_forward_dim=256, head_dim=8, lr=0.00021449563756444756, num_heads=2, num_layers=4; total time=   1.3s\n",
      "Epoch 9, Loss: 0.1615772247314453\n",
      "Epoch 9, Loss: 0.026429440826177597\n",
      "Epoch 10, Loss: 0.21948912739753723\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2750979216672352, feed_forward_dim=256, head_dim=8, lr=0.00021449563756444756, num_heads=2, num_layers=4; total time=   1.3s\n",
      "Epoch 7, Loss: 0.15515221655368805\n",
      "Epoch 8, Loss: 0.23264677822589874\n",
      "Epoch 8, Loss: 0.03557777777314186\n",
      "Epoch 10, Loss: 0.08895961940288544\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2750979216672352, feed_forward_dim=256, head_dim=8, lr=0.00021449563756444756, num_heads=2, num_layers=4; total time=   1.4s\n",
      "Epoch 10, Loss: 0.04570543393492699\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2750979216672352, feed_forward_dim=256, head_dim=8, lr=0.00021449563756444756, num_heads=2, num_layers=4; total time=   1.3s\n",
      "Epoch 8, Loss: 0.09560448676347733\n",
      "Epoch 9, Loss: 0.014855977147817612\n",
      "Epoch 9, Loss: 0.16382206976413727\n",
      "Epoch 9, Loss: 0.0634857639670372\n",
      "Epoch 10, Loss: 0.020667674019932747\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2750979216672352, feed_forward_dim=256, head_dim=8, lr=0.00021449563756444756, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.09830790758132935\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2750979216672352, feed_forward_dim=256, head_dim=8, lr=0.00021449563756444756, num_heads=2, num_layers=4; total time=   1.4s\n",
      "Epoch 10, Loss: 0.062271103262901306\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2750979216672352, feed_forward_dim=256, head_dim=8, lr=0.00021449563756444756, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 2.5807676315307617\n",
      "Epoch 1, Loss: 0.4956885874271393\n",
      "Epoch 1, Loss: 0.6616185307502747\n",
      "Epoch 2, Loss: 1.4510072469711304\n",
      "Epoch 1, Loss: 0.042186189442873\n",
      "Epoch 1, Loss: 0.6719682216644287\n",
      "Epoch 1, Loss: 0.22015449404716492\n",
      "Epoch 2, Loss: 0.15380558371543884\n",
      "Epoch 2, Loss: 0.0858452320098877\n",
      "Epoch 1, Loss: 0.8810682892799377\n",
      "Epoch 3, Loss: 0.6676182150840759\n",
      "Epoch 1, Loss: 0.26852214336395264\n",
      "Epoch 2, Loss: 0.11437031626701355\n",
      "Epoch 2, Loss: 0.1801702231168747\n",
      "Epoch 3, Loss: 0.1761348396539688\n",
      "Epoch 4, Loss: 0.23326407372951508\n",
      "Epoch 1, Loss: 0.3660520911216736\n",
      "Epoch 2, Loss: 0.09770351648330688\n",
      "Epoch 3, Loss: 0.06579018384218216\n",
      "Epoch 1, Loss: 0.07634574174880981\n",
      "Epoch 1, Loss: 1.8610531091690063\n",
      "Epoch 1, Loss: 0.19748567044734955\n",
      "Epoch 2, Loss: 0.29833322763442993\n",
      "Epoch 3, Loss: 0.027792293578386307\n",
      "Epoch 5, Loss: 0.0931740254163742\n",
      "Epoch 3, Loss: 0.044471364468336105\n",
      "Epoch 4, Loss: 0.23739716410636902\n",
      "Epoch 3, Loss: 0.13540756702423096\n",
      "Epoch 4, Loss: 0.2245519757270813\n",
      "Epoch 2, Loss: 0.01832074113190174\n",
      "Epoch 2, Loss: 0.06601450592279434\n",
      "Epoch 2, Loss: 0.14171387255191803\n",
      "Epoch 3, Loss: 0.10324602574110031\n",
      "Epoch 6, Loss: 0.14942505955696106\n",
      "Epoch 2, Loss: 0.9716585874557495\n",
      "Epoch 4, Loss: 0.038380078971385956\n",
      "Epoch 2, Loss: 0.13637354969978333\n",
      "Epoch 5, Loss: 0.19263802468776703\n",
      "Epoch 3, Loss: 0.12831203639507294\n",
      "Epoch 5, Loss: 0.250810444355011\n",
      "Epoch 4, Loss: 0.11381197720766068\n",
      "Epoch 3, Loss: 0.10916146636009216\n",
      "Epoch 7, Loss: 0.2822358012199402\n",
      "Epoch 4, Loss: 0.16171330213546753\n",
      "Epoch 4, Loss: 0.13247725367546082\n",
      "Epoch 3, Loss: 0.4129321277141571\n",
      "Epoch 6, Loss: 0.11425407975912094\n",
      "Epoch 5, Loss: 0.05832064151763916\n",
      "Epoch 4, Loss: 0.14498423039913177\n",
      "Epoch 3, Loss: 0.049287647008895874\n",
      "Epoch 5, Loss: 0.06289299577474594\n",
      "Epoch 6, Loss: 0.17630505561828613\n",
      "Epoch 8, Loss: 0.3850816786289215\n",
      "Epoch 3, Loss: 0.14158430695533752\n",
      "Epoch 5, Loss: 0.2587830424308777\n",
      "Epoch 6, Loss: 0.0328252874314785\n",
      "Epoch 5, Loss: 0.21948984265327454\n",
      "Epoch 7, Loss: 0.05492551252245903\n",
      "Epoch 7, Loss: 0.07857499271631241\n",
      "Epoch 5, Loss: 0.07216157019138336\n",
      "Epoch 4, Loss: 0.17714151740074158\n",
      "Epoch 6, Loss: 0.035763293504714966\n",
      "Epoch 4, Loss: 0.05658145248889923\n",
      "Epoch 6, Loss: 0.21469245851039886\n",
      "Epoch 9, Loss: 0.43012478947639465\n",
      "Epoch 6, Loss: 0.286077082157135\n",
      "Epoch 7, Loss: 0.009668128564953804\n",
      "Epoch 8, Loss: 0.04171924665570259\n",
      "Epoch 4, Loss: 0.1814950853586197\n",
      "Epoch 4, Loss: 0.07803449779748917\n",
      "Epoch 8, Loss: 0.02002953551709652\n",
      "Epoch 10, Loss: 0.4099312722682953\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.2251919167372792, feed_forward_dim=1024, head_dim=32, lr=0.0002533710904209484, num_heads=2, num_layers=4; total time=   1.0s\n",
      "Epoch 7, Loss: 0.039330001920461655\n",
      "Epoch 5, Loss: 0.07143733650445938\n",
      "Epoch 7, Loss: 0.23533612489700317\n",
      "Epoch 5, Loss: 0.14409734308719635\n",
      "Epoch 6, Loss: 0.018918009474873543\n",
      "Epoch 7, Loss: 0.15465207397937775\n",
      "Epoch 9, Loss: 0.05950533598661423\n",
      "Epoch 9, Loss: 0.017361408099532127\n",
      "Epoch 8, Loss: 0.0165789145976305\n",
      "Epoch 8, Loss: 0.04842051863670349\n",
      "Epoch 5, Loss: 0.1912258267402649\n",
      "Epoch 8, Loss: 0.16278107464313507\n",
      "Epoch 10, Loss: 0.0741375982761383\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.2251919167372792, feed_forward_dim=1024, head_dim=32, lr=0.0002533710904209484, num_heads=2, num_layers=4; total time=   1.2s\n",
      "Epoch 5, Loss: 0.0477520115673542\n",
      "Epoch 7, Loss: 0.024488965049386024\n",
      "Epoch 6, Loss: 0.041214704513549805\n",
      "Epoch 6, Loss: 0.0736825093626976\n",
      "Epoch 9, Loss: 0.03116069734096527\n",
      "Epoch 10, Loss: 0.04970087856054306\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.2251919167372792, feed_forward_dim=1024, head_dim=32, lr=0.0002533710904209484, num_heads=2, num_layers=4; total time=   1.2s\n",
      "Epoch 8, Loss: 0.0842222198843956\n",
      "Epoch 9, Loss: 0.04144945740699768\n",
      "Epoch 10, Loss: 0.027772650122642517\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.2251919167372792, feed_forward_dim=1024, head_dim=32, lr=0.0002533710904209484, num_heads=2, num_layers=4; total time=   1.2s\n",
      "Epoch 6, Loss: 0.30472058057785034\n",
      "Epoch 6, Loss: 0.05670629069209099\n",
      "Epoch 7, Loss: 0.015851367264986038\n",
      "Epoch 9, Loss: 0.09271964430809021\n",
      "Epoch 9, Loss: 0.03610660880804062\n",
      "Epoch 7, Loss: 0.03099784255027771\n",
      "Epoch 10, Loss: 0.023312034085392952\n",
      "Epoch 8, Loss: 0.05488351732492447\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.2251919167372792, feed_forward_dim=1024, head_dim=32, lr=0.0002533710904209484, num_heads=2, num_layers=4; total time=   1.2s\n",
      "Epoch 10, Loss: 0.022775297984480858\n",
      "Epoch 7, Loss: 0.05434136092662811\n",
      "Epoch 8, Loss: 0.022028204053640366\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.2251919167372792, feed_forward_dim=1024, head_dim=32, lr=0.0002533710904209484, num_heads=2, num_layers=4; total time=   1.3s\n",
      "Epoch 7, Loss: 0.39025068283081055\n",
      "Epoch 8, Loss: 0.030200166627764702\n",
      "Epoch 9, Loss: 0.06898533552885056\n",
      "Epoch 10, Loss: 0.04907003045082092\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.2251919167372792, feed_forward_dim=1024, head_dim=32, lr=0.0002533710904209484, num_heads=2, num_layers=4; total time=   1.3s\n",
      "Epoch 10, Loss: 0.0555248036980629\n",
      "Epoch 9, Loss: 0.035233814269304276\n",
      "Epoch 9, Loss: 0.05311514809727669\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.2251919167372792, feed_forward_dim=1024, head_dim=32, lr=0.0002533710904209484, num_heads=2, num_layers=4; total time=   1.4s\n",
      "Epoch 8, Loss: 0.4052116870880127\n",
      "Epoch 8, Loss: 0.03481345623731613\n",
      "Epoch 10, Loss: 0.07083580642938614\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.2251919167372792, feed_forward_dim=1024, head_dim=32, lr=0.0002533710904209484, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.02832970954477787\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.2251919167372792, feed_forward_dim=1024, head_dim=32, lr=0.0002533710904209484, num_heads=2, num_layers=4; total time=   1.4s\n",
      "Epoch 9, Loss: 0.3610139787197113\n",
      "Epoch 9, Loss: 0.016147078946232796\n",
      "Epoch 10, Loss: 0.27877306938171387\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.2251919167372792, feed_forward_dim=1024, head_dim=32, lr=0.0002533710904209484, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.016747966408729553\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.2251919167372792, feed_forward_dim=1024, head_dim=32, lr=0.0002533710904209484, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.435144305229187\n",
      "Epoch 1, Loss: 1.0639158487319946\n",
      "Epoch 1, Loss: 2.6383559703826904\n",
      "Epoch 2, Loss: 0.259673148393631\n",
      "Epoch 1, Loss: 1.625880479812622\n",
      "Epoch 1, Loss: 0.06534367054700851\n",
      "Epoch 1, Loss: 0.9195724129676819\n",
      "Epoch 2, Loss: 0.6970808506011963\n",
      "Epoch 3, Loss: 0.1521146148443222\n",
      "Epoch 1, Loss: 0.1518678218126297\n",
      "Epoch 1, Loss: 0.08326882869005203\n",
      "Epoch 2, Loss: 1.16436767578125\n",
      "Epoch 2, Loss: 1.9597467184066772\n",
      "Epoch 1, Loss: 0.03220579773187637\n",
      "Epoch 4, Loss: 0.11178217083215714\n",
      "Epoch 2, Loss: 0.02074268087744713\n",
      "Epoch 3, Loss: 0.4170665740966797\n",
      "Epoch 2, Loss: 0.5710620880126953\n",
      "Epoch 1, Loss: 0.23577874898910522\n",
      "Epoch 1, Loss: 0.06075044721364975\n",
      "Epoch 3, Loss: 0.7735946178436279\n",
      "Epoch 3, Loss: 1.3896934986114502\n",
      "Epoch 5, Loss: 0.11219697445631027\n",
      "Epoch 2, Loss: 0.12487274408340454\n",
      "Epoch 2, Loss: 0.0425756461918354\n",
      "Epoch 2, Loss: 0.022034164518117905\n",
      "Epoch 1, Loss: 0.6350098848342896\n",
      "Epoch 3, Loss: 0.0381215400993824\n",
      "Epoch 4, Loss: 0.46184882521629333\n",
      "Epoch 4, Loss: 0.20790687203407288\n",
      "Epoch 6, Loss: 0.13055726885795593\n",
      "Epoch 3, Loss: 0.3264276385307312\n",
      "Epoch 2, Loss: 0.044356293976306915\n",
      "Epoch 3, Loss: 0.09452235698699951\n",
      "Epoch 4, Loss: 0.9156402349472046\n",
      "Epoch 2, Loss: 0.15257950127124786\n",
      "Epoch 3, Loss: 0.05171377956867218\n",
      "Epoch 4, Loss: 0.038013920187950134\n",
      "Epoch 7, Loss: 0.1417751908302307\n",
      "Epoch 5, Loss: 0.07761436700820923\n",
      "Epoch 3, Loss: 0.023197228088974953\n",
      "Epoch 5, Loss: 0.24396082758903503\n",
      "Epoch 2, Loss: 0.37306612730026245\n",
      "Epoch 4, Loss: 0.16060581803321838\n",
      "Epoch 3, Loss: 0.031024422496557236\n",
      "Epoch 5, Loss: 0.5479191541671753\n",
      "Epoch 4, Loss: 0.07667239755392075\n",
      "Epoch 8, Loss: 0.1412990242242813\n",
      "Epoch 5, Loss: 0.02241429127752781\n",
      "Epoch 4, Loss: 0.014224745333194733\n",
      "Epoch 4, Loss: 0.05371031537652016\n",
      "Epoch 6, Loss: 0.013975771144032478\n",
      "Epoch 3, Loss: 0.12611854076385498\n",
      "Epoch 6, Loss: 0.2942902743816376\n",
      "Epoch 9, Loss: 0.12326445430517197\n",
      "Epoch 3, Loss: 0.18886132538318634\n",
      "Epoch 5, Loss: 0.08007781952619553\n",
      "Epoch 6, Loss: 0.11086144298315048\n",
      "Epoch 5, Loss: 0.05806500092148781\n",
      "Epoch 6, Loss: 0.011059512384235859\n",
      "Epoch 4, Loss: 0.02403920143842697\n",
      "Epoch 7, Loss: 0.00660138251259923\n",
      "Epoch 5, Loss: 0.008845649659633636\n",
      "Epoch 7, Loss: 0.14436796307563782\n",
      "Epoch 10, Loss: 0.09997307509183884\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.15001056908335908, feed_forward_dim=1024, head_dim=8, lr=0.0001112244133886503, num_heads=4, num_layers=1; total time=   0.9s\n",
      "Epoch 4, Loss: 0.1293436884880066\n",
      "Epoch 6, Loss: 0.06563614308834076\n",
      "Epoch 5, Loss: 0.04130995273590088\n",
      "Epoch 8, Loss: 0.034709326922893524\n",
      "Epoch 6, Loss: 0.04525633156299591\n",
      "Epoch 4, Loss: 0.06795226037502289\n",
      "Epoch 7, Loss: 0.012355100363492966\n",
      "Epoch 5, Loss: 0.015274258330464363\n",
      "Epoch 7, Loss: 0.049221254885196686\n",
      "Epoch 8, Loss: 0.08570633083581924\n",
      "Epoch 6, Loss: 0.009663772769272327\n",
      "Epoch 9, Loss: 0.07866750657558441\n",
      "Epoch 7, Loss: 0.09300047159194946\n",
      "Epoch 5, Loss: 0.1296222060918808\n",
      "Epoch 8, Loss: 0.01883404701948166\n",
      "Epoch 6, Loss: 0.029738642275333405\n",
      "Epoch 7, Loss: 0.03502513840794563\n",
      "Epoch 9, Loss: 0.09720470756292343\n",
      "Epoch 8, Loss: 0.046727504581213\n",
      "Epoch 5, Loss: 0.01378555316478014\n",
      "Epoch 10, Loss: 0.11761894077062607\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.15001056908335908, feed_forward_dim=1024, head_dim=8, lr=0.0001112244133886503, num_heads=4, num_layers=1; total time=   1.1s\n",
      "Epoch 6, Loss: 0.01094895787537098\n",
      "Epoch 7, Loss: 0.009695985354483128\n",
      "Epoch 8, Loss: 0.1344517171382904\n",
      "Epoch 9, Loss: 0.017769871279597282\n",
      "Epoch 9, Loss: 0.08071216940879822\n",
      "Epoch 7, Loss: 0.02439640276134014\n",
      "Epoch 10, Loss: 0.15384472906589508\n",
      "Epoch 6, Loss: 0.12243162840604782\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.15001056908335908, feed_forward_dim=1024, head_dim=8, lr=0.0001112244133886503, num_heads=4, num_layers=1; total time=   1.2s\n",
      "Epoch 8, Loss: 0.029817523434758186\n",
      "Epoch 6, Loss: 0.013200497254729271\n",
      "Epoch 9, Loss: 0.1712428778409958\n",
      "Epoch 8, Loss: 0.006426789797842503\n",
      "Epoch 10, Loss: 0.01148965023458004\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.15001056908335908, feed_forward_dim=1024, head_dim=8, lr=0.0001112244133886503, num_heads=4, num_layers=1; total time=   1.3s\n",
      "Epoch 7, Loss: 0.010482493788003922\n",
      "Epoch 10, Loss: 0.12942101061344147\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.15001056908335908, feed_forward_dim=1024, head_dim=8, lr=0.0001112244133886503, num_heads=4, num_layers=1; total time=   1.3s\n",
      "Epoch 8, Loss: 0.027098990976810455\n",
      "Epoch 7, Loss: 0.10331849008798599\n",
      "Epoch 9, Loss: 0.025354182347655296\n",
      "Epoch 10, Loss: 0.1863873302936554\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.15001056908335908, feed_forward_dim=1024, head_dim=8, lr=0.0001112244133886503, num_heads=4, num_layers=1; total time=   1.3s\n",
      "Epoch 9, Loss: 0.004209245555102825\n",
      "Epoch 8, Loss: 0.009387620724737644\n",
      "Epoch 7, Loss: 0.043905626982450485\n",
      "Epoch 9, Loss: 0.02767833136022091\n",
      "Epoch 10, Loss: 0.02557537518441677\n",
      "Epoch 8, Loss: 0.08306442201137543\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.15001056908335908, feed_forward_dim=1024, head_dim=8, lr=0.0001112244133886503, num_heads=4, num_layers=1; total time=   1.4s\n",
      "Epoch 10, Loss: 0.005369611084461212\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.15001056908335908, feed_forward_dim=1024, head_dim=8, lr=0.0001112244133886503, num_heads=4, num_layers=1; total time=   1.4s\n",
      "Epoch 9, Loss: 0.011169778183102608\n",
      "Epoch 10, Loss: 0.025077413767576218\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.15001056908335908, feed_forward_dim=1024, head_dim=8, lr=0.0001112244133886503, num_heads=4, num_layers=1; total time=   1.5s\n",
      "Epoch 8, Loss: 0.08358874171972275\n",
      "Epoch 9, Loss: 0.06783460080623627\n",
      "Epoch 10, Loss: 0.013203960843384266\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.15001056908335908, feed_forward_dim=1024, head_dim=8, lr=0.0001112244133886503, num_heads=4, num_layers=1; total time=   1.5s\n",
      "Epoch 9, Loss: 0.11098645627498627\n",
      "Epoch 10, Loss: 0.0598008930683136\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.15001056908335908, feed_forward_dim=1024, head_dim=8, lr=0.0001112244133886503, num_heads=4, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.12014426290988922\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.15001056908335908, feed_forward_dim=1024, head_dim=8, lr=0.0001112244133886503, num_heads=4, num_layers=1; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.2866670489311218\n",
      "Epoch 1, Loss: 0.09311190992593765\n",
      "Epoch 1, Loss: 0.18607939779758453\n",
      "Epoch 2, Loss: 0.013977876864373684\n",
      "Epoch 1, Loss: 0.4208061397075653\n",
      "Epoch 1, Loss: 0.27371013164520264\n",
      "Epoch 2, Loss: 0.0921025276184082\n",
      "Epoch 1, Loss: 0.0972859114408493\n",
      "Epoch 2, Loss: 0.030076637864112854\n",
      "Epoch 1, Loss: 0.30350708961486816\n",
      "Epoch 3, Loss: 0.1207115426659584\n",
      "Epoch 2, Loss: 0.049070168286561966\n",
      "Epoch 2, Loss: 0.04450172185897827\n",
      "Epoch 4, Loss: 0.14950081706047058\n",
      "Epoch 1, Loss: 0.13862089812755585\n",
      "Epoch 2, Loss: 0.018605858087539673\n",
      "Epoch 3, Loss: 0.07147981971502304\n",
      "Epoch 3, Loss: 0.1219116598367691\n",
      "Epoch 1, Loss: 1.9533940553665161\n",
      "Epoch 1, Loss: 0.11271142959594727\n",
      "Epoch 2, Loss: 0.006165418773889542\n",
      "Epoch 1, Loss: 0.16782420873641968\n",
      "Epoch 4, Loss: 0.009102449752390385\n",
      "Epoch 1, Loss: 0.1867271512746811\n",
      "Epoch 3, Loss: 0.10997026413679123\n",
      "Epoch 5, Loss: 0.08094543218612671\n",
      "Epoch 2, Loss: 0.11296568065881729\n",
      "Epoch 4, Loss: 0.0925263911485672\n",
      "Epoch 3, Loss: 0.024996619671583176\n",
      "Epoch 3, Loss: 0.09586332738399506\n",
      "Epoch 3, Loss: 0.13087087869644165\n",
      "Epoch 5, Loss: 0.02475186437368393\n",
      "Epoch 2, Loss: 0.8805427551269531\n",
      "Epoch 2, Loss: 0.18928785622119904\n",
      "Epoch 4, Loss: 0.18719376623630524\n",
      "Epoch 2, Loss: 0.124205581843853\n",
      "Epoch 6, Loss: 0.019059909507632256\n",
      "Epoch 5, Loss: 0.02953604981303215\n",
      "Epoch 2, Loss: 0.109761543571949\n",
      "Epoch 4, Loss: 0.14043894410133362\n",
      "Epoch 6, Loss: 0.05110633373260498\n",
      "Epoch 3, Loss: 0.07719681411981583\n",
      "Epoch 4, Loss: 0.15820878744125366\n",
      "Epoch 4, Loss: 0.01489293109625578\n",
      "Epoch 7, Loss: 0.011512704193592072\n",
      "Epoch 3, Loss: 0.23857499659061432\n",
      "Epoch 5, Loss: 0.14828915894031525\n",
      "Epoch 3, Loss: 0.06009192019701004\n",
      "Epoch 6, Loss: 0.015194686129689217\n",
      "Epoch 7, Loss: 0.035882044583559036\n",
      "Epoch 5, Loss: 0.09336572140455246\n",
      "Epoch 3, Loss: 0.12441082298755646\n",
      "Epoch 4, Loss: 0.06463110446929932\n",
      "Epoch 3, Loss: 0.13909824192523956\n",
      "Epoch 8, Loss: 0.04204129800200462\n",
      "Epoch 5, Loss: 0.08515099436044693\n",
      "Epoch 6, Loss: 0.06725753098726273\n",
      "Epoch 5, Loss: 0.00954204797744751\n",
      "Epoch 7, Loss: 0.04316331073641777\n",
      "Epoch 8, Loss: 0.010562038980424404\n",
      "Epoch 4, Loss: 0.018681397661566734\n",
      "Epoch 4, Loss: 0.04213174432516098\n",
      "Epoch 9, Loss: 0.06797783821821213\n",
      "Epoch 6, Loss: 0.03285853564739227\n",
      "Epoch 6, Loss: 0.016763852909207344\n",
      "Epoch 4, Loss: 0.05663369223475456\n",
      "Epoch 4, Loss: 0.08074459433555603\n",
      "Epoch 5, Loss: 0.03926032781600952\n",
      "Epoch 6, Loss: 0.015530863776803017\n",
      "Epoch 7, Loss: 0.016855943948030472\n",
      "Epoch 9, Loss: 0.008516262285411358\n",
      "Epoch 8, Loss: 0.05806392803788185\n",
      "Epoch 10, Loss: 0.06019050255417824\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.22975421786250394, feed_forward_dim=512, head_dim=32, lr=0.0003001635968504174, num_heads=2, num_layers=2; total time=   1.0s\n",
      "Epoch 5, Loss: 0.07104586809873581\n",
      "Epoch 5, Loss: 0.10345742851495743\n",
      "Epoch 7, Loss: 0.011278502643108368\n",
      "Epoch 7, Loss: 0.009352259337902069\n",
      "Epoch 10, Loss: 0.02208850532770157\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.22975421786250394, feed_forward_dim=512, head_dim=32, lr=0.0003001635968504174, num_heads=2, num_layers=2; total time=   1.0s\n",
      "Epoch 7, Loss: 0.01696326769888401\n",
      "Epoch 6, Loss: 0.03344881162047386\n",
      "Epoch 9, Loss: 0.04607107862830162\n",
      "Epoch 5, Loss: 0.046590324491262436\n",
      "Epoch 8, Loss: 0.01636742614209652\n",
      "Epoch 5, Loss: 0.041744355112314224\n",
      "Epoch 8, Loss: 0.029594911262392998\n",
      "Epoch 9, Loss: 0.046311624348163605\n",
      "Epoch 10, Loss: 0.021847141906619072\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.22975421786250394, feed_forward_dim=512, head_dim=32, lr=0.0003001635968504174, num_heads=2, num_layers=2; total time=   1.1s\n",
      "Epoch 6, Loss: 0.27901458740234375\n",
      "Epoch 8, Loss: 0.0424598827958107\n",
      "Epoch 8, Loss: 0.016242336481809616\n",
      "Epoch 6, Loss: 0.045557573437690735\n",
      "Epoch 7, Loss: 0.025267550721764565\n",
      "Epoch 6, Loss: 0.059234797954559326\n",
      "Epoch 10, Loss: 0.06843524426221848\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.22975421786250394, feed_forward_dim=512, head_dim=32, lr=0.0003001635968504174, num_heads=2, num_layers=2; total time=   1.2s\n",
      "Epoch 9, Loss: 0.055054254829883575\n",
      "Epoch 6, Loss: 0.057821597903966904\n",
      "Epoch 7, Loss: 0.3783442974090576\n",
      "Epoch 9, Loss: 0.017913533374667168\n",
      "Epoch 9, Loss: 0.06946760416030884\n",
      "Epoch 7, Loss: 0.012317478656768799\n",
      "Epoch 7, Loss: 0.05061562731862068\n",
      "Epoch 10, Loss: 0.05919992923736572\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.22975421786250394, feed_forward_dim=512, head_dim=32, lr=0.0003001635968504174, num_heads=2, num_layers=2; total time=   1.3s\n",
      "Epoch 8, Loss: 0.015068315900862217\n",
      "Epoch 7, Loss: 0.06453549116849899\n",
      "Epoch 8, Loss: 0.38050392270088196\n",
      "Epoch 10, Loss: 0.01286970917135477\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.22975421786250394, feed_forward_dim=512, head_dim=32, lr=0.0003001635968504174, num_heads=2, num_layers=2; total time=   1.3s\n",
      "Epoch 10, Loss: 0.06314464658498764\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.22975421786250394, feed_forward_dim=512, head_dim=32, lr=0.0003001635968504174, num_heads=2, num_layers=2; total time=   1.3s\n",
      "Epoch 8, Loss: 0.017012713477015495\n",
      "Epoch 8, Loss: 0.022807395085692406\n",
      "Epoch 9, Loss: 0.014738347381353378\n",
      "Epoch 9, Loss: 0.31253841519355774\n",
      "Epoch 8, Loss: 0.0459328293800354\n",
      "Epoch 9, Loss: 0.03811859339475632\n",
      "Epoch 9, Loss: 0.01356468815356493\n",
      "Epoch 10, Loss: 0.013233781792223454\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.22975421786250394, feed_forward_dim=512, head_dim=32, lr=0.0003001635968504174, num_heads=2, num_layers=2; total time=   1.4s\n",
      "Epoch 10, Loss: 0.21922200918197632\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.22975421786250394, feed_forward_dim=512, head_dim=32, lr=0.0003001635968504174, num_heads=2, num_layers=2; total time=   1.4s\n",
      "Epoch 9, Loss: 0.022565530613064766\n",
      "Epoch 10, Loss: 0.03712272644042969\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.22975421786250394, feed_forward_dim=512, head_dim=32, lr=0.0003001635968504174, num_heads=2, num_layers=2; total time=   1.4s\n",
      "Epoch 10, Loss: 0.025559406727552414\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.22975421786250394, feed_forward_dim=512, head_dim=32, lr=0.0003001635968504174, num_heads=2, num_layers=2; total time=   1.4s\n",
      "Epoch 10, Loss: 0.017627926543354988\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.22975421786250394, feed_forward_dim=512, head_dim=32, lr=0.0003001635968504174, num_heads=2, num_layers=2; total time=   1.4s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.6673134565353394\n",
      "Epoch 1, Loss: 0.5528558492660522\n",
      "Epoch 1, Loss: 1.3944207429885864\n",
      "Epoch 1, Loss: 2.9386487007141113\n",
      "Epoch 1, Loss: 0.4003675878047943\n",
      "Epoch 1, Loss: 0.1927180290222168\n",
      "Epoch 2, Loss: 0.5416979193687439\n",
      "Epoch 2, Loss: 0.44255974888801575\n",
      "Epoch 1, Loss: 0.19465044140815735\n",
      "Epoch 2, Loss: 1.2093844413757324\n",
      "Epoch 2, Loss: 2.672295093536377\n",
      "Epoch 3, Loss: 0.4391385614871979\n",
      "Epoch 1, Loss: 0.05737151950597763\n",
      "Epoch 2, Loss: 0.3106946647167206\n",
      "Epoch 3, Loss: 0.339166522026062\n",
      "Epoch 2, Loss: 0.14741624891757965\n",
      "Epoch 3, Loss: 1.0408971309661865\n",
      "Epoch 3, Loss: 2.423475503921509\n",
      "Epoch 2, Loss: 0.13822808861732483\n",
      "Epoch 1, Loss: 1.4412626028060913\n",
      "Epoch 4, Loss: 0.3566313087940216\n",
      "Epoch 1, Loss: 0.6991521716117859\n",
      "Epoch 1, Loss: 1.2450164556503296\n",
      "Epoch 2, Loss: 0.03802696615457535\n",
      "Epoch 3, Loss: 0.2383381724357605\n",
      "Epoch 1, Loss: 0.07018440216779709\n",
      "Epoch 4, Loss: 0.8818747401237488\n",
      "Epoch 4, Loss: 0.25258857011795044\n",
      "Epoch 4, Loss: 2.166529417037964\n",
      "Epoch 5, Loss: 0.28272557258605957\n",
      "Epoch 3, Loss: 0.11408878862857819\n",
      "Epoch 3, Loss: 0.09478588402271271\n",
      "Epoch 2, Loss: 1.2305388450622559\n",
      "Epoch 2, Loss: 0.5773343443870544\n",
      "Epoch 4, Loss: 0.17931252717971802\n",
      "Epoch 5, Loss: 0.18296031653881073\n",
      "Epoch 3, Loss: 0.030258899554610252\n",
      "Epoch 5, Loss: 0.7426902651786804\n",
      "Epoch 2, Loss: 1.0627399682998657\n",
      "Epoch 2, Loss: 0.030185522511601448\n",
      "Epoch 6, Loss: 0.22616514563560486\n",
      "Epoch 5, Loss: 1.9471436738967896\n",
      "Epoch 4, Loss: 0.09453663229942322\n",
      "Epoch 4, Loss: 0.06779037415981293\n",
      "Epoch 6, Loss: 0.6145346164703369\n",
      "Epoch 5, Loss: 0.13348789513111115\n",
      "Epoch 3, Loss: 1.05118989944458\n",
      "Epoch 6, Loss: 0.13074830174446106\n",
      "Epoch 4, Loss: 0.030682073906064034\n",
      "Epoch 7, Loss: 0.18666872382164001\n",
      "Epoch 3, Loss: 0.46633800864219666\n",
      "Epoch 5, Loss: 0.08617493510246277\n",
      "Epoch 6, Loss: 1.7338045835494995\n",
      "Epoch 3, Loss: 0.01441941037774086\n",
      "Epoch 7, Loss: 0.5034285187721252\n",
      "Epoch 8, Loss: 0.1593354493379593\n",
      "Epoch 7, Loss: 0.09138321131467819\n",
      "Epoch 3, Loss: 0.8957732915878296\n",
      "Epoch 4, Loss: 0.8749495148658752\n",
      "Epoch 6, Loss: 0.1027979925274849\n",
      "Epoch 5, Loss: 0.056360725313425064\n",
      "Epoch 5, Loss: 0.03240065649151802\n",
      "Epoch 8, Loss: 0.40506085753440857\n",
      "Epoch 7, Loss: 1.532657265663147\n",
      "Epoch 4, Loss: 0.3728645443916321\n",
      "Epoch 9, Loss: 0.13735440373420715\n",
      "Epoch 6, Loss: 0.0863531306385994\n",
      "Epoch 4, Loss: 0.7463956475257874\n",
      "Epoch 7, Loss: 0.08433470129966736\n",
      "Epoch 9, Loss: 0.31811845302581787\n",
      "Epoch 4, Loss: 0.018052147701382637\n",
      "Epoch 8, Loss: 0.06454456597566605\n",
      "Epoch 10, Loss: 0.1289433240890503\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2709587307996788, feed_forward_dim=1024, head_dim=32, lr=5e-05, num_heads=8, num_layers=2; total time=   1.0s\n",
      "Epoch 6, Loss: 0.031087398529052734\n",
      "Epoch 8, Loss: 1.3475855588912964\n",
      "Epoch 5, Loss: 0.7268671989440918\n",
      "Epoch 6, Loss: 0.05508055537939072\n",
      "Epoch 5, Loss: 0.29236942529678345\n",
      "Epoch 8, Loss: 0.0778992623090744\n",
      "Epoch 10, Loss: 0.2383483648300171\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2709587307996788, feed_forward_dim=1024, head_dim=32, lr=5e-05, num_heads=8, num_layers=2; total time=   1.0s\n",
      "Epoch 7, Loss: 0.08899053931236267\n",
      "Epoch 9, Loss: 0.05055462568998337\n",
      "Epoch 9, Loss: 1.1878504753112793\n",
      "Epoch 5, Loss: 0.609478771686554\n",
      "Epoch 7, Loss: 0.028669146820902824\n",
      "Epoch 7, Loss: 0.06037350371479988\n",
      "Epoch 5, Loss: 0.026327360421419144\n",
      "Epoch 9, Loss: 0.07528042793273926\n",
      "Epoch 10, Loss: 0.04602247104048729\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2709587307996788, feed_forward_dim=1024, head_dim=32, lr=5e-05, num_heads=8, num_layers=2; total time=   1.1s\n",
      "Epoch 6, Loss: 0.5872664451599121\n",
      "Epoch 8, Loss: 0.09125891327857971\n",
      "Epoch 10, Loss: 1.0284067392349243\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2709587307996788, feed_forward_dim=1024, head_dim=32, lr=5e-05, num_heads=8, num_layers=2; total time=   1.1s\n",
      "Epoch 6, Loss: 0.22672206163406372\n",
      "Epoch 8, Loss: 0.06629293411970139\n",
      "Epoch 8, Loss: 0.0239168219268322\n",
      "Epoch 10, Loss: 0.08212440460920334\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2709587307996788, feed_forward_dim=1024, head_dim=32, lr=5e-05, num_heads=8, num_layers=2; total time=   1.1s\n",
      "Epoch 6, Loss: 0.030922118574380875\n",
      "Epoch 6, Loss: 0.4941115081310272\n",
      "Epoch 9, Loss: 0.09277047216892242\n",
      "Epoch 7, Loss: 0.4720250070095062\n",
      "Epoch 9, Loss: 0.07098540663719177\n",
      "Epoch 9, Loss: 0.019748106598854065\n",
      "Epoch 7, Loss: 0.17024512588977814\n",
      "Epoch 7, Loss: 0.028192665427923203\n",
      "Epoch 8, Loss: 0.3717820644378662\n",
      "Epoch 7, Loss: 0.3950066566467285\n",
      "Epoch 10, Loss: 0.06992572546005249\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2709587307996788, feed_forward_dim=1024, head_dim=32, lr=5e-05, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 10, Loss: 0.08757899701595306\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2709587307996788, feed_forward_dim=1024, head_dim=32, lr=5e-05, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 10, Loss: 0.017421545460820198\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2709587307996788, feed_forward_dim=1024, head_dim=32, lr=5e-05, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 8, Loss: 0.12894193828105927\n",
      "Epoch 9, Loss: 0.2795538604259491\n",
      "Epoch 8, Loss: 0.31016483902931213\n",
      "Epoch 8, Loss: 0.02374602109193802\n",
      "Epoch 9, Loss: 0.09857109189033508\n",
      "Epoch 10, Loss: 0.21070019900798798\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2709587307996788, feed_forward_dim=1024, head_dim=32, lr=5e-05, num_heads=8, num_layers=2; total time=   1.4s\n",
      "Epoch 9, Loss: 0.23883362114429474\n",
      "Epoch 9, Loss: 0.01650628075003624\n",
      "Epoch 10, Loss: 0.0770634338259697\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2709587307996788, feed_forward_dim=1024, head_dim=32, lr=5e-05, num_heads=8, num_layers=2; total time=   1.4s\n",
      "Epoch 10, Loss: 0.18310081958770752\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2709587307996788, feed_forward_dim=1024, head_dim=32, lr=5e-05, num_heads=8, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.013103265315294266\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2709587307996788, feed_forward_dim=1024, head_dim=32, lr=5e-05, num_heads=8, num_layers=2; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.1691703200340271\n",
      "Epoch 1, Loss: 0.9641867280006409\n",
      "Epoch 1, Loss: 0.0951390415430069\n",
      "Epoch 1, Loss: 1.3628774881362915\n",
      "Epoch 1, Loss: 0.06001388281583786\n",
      "Epoch 2, Loss: 0.12591330707073212\n",
      "Epoch 1, Loss: 0.42383357882499695\n",
      "Epoch 1, Loss: 1.4970703125\n",
      "Epoch 2, Loss: 0.06256314367055893\n",
      "Epoch 2, Loss: 1.1765694618225098\n",
      "Epoch 3, Loss: 0.09465926885604858\n",
      "Epoch 2, Loss: 0.7928445935249329\n",
      "Epoch 1, Loss: 0.09781033545732498\n",
      "Epoch 1, Loss: 0.10113876312971115\n",
      "Epoch 3, Loss: 0.04176352918148041\n",
      "Epoch 4, Loss: 0.07479045540094376\n",
      "Epoch 2, Loss: 0.30814725160598755\n",
      "Epoch 1, Loss: 0.1291002631187439\n",
      "Epoch 2, Loss: 1.29660964012146\n",
      "Epoch 2, Loss: 0.04944257065653801\n",
      "Epoch 2, Loss: 0.07971972227096558\n",
      "Epoch 5, Loss: 0.06374366581439972\n",
      "Epoch 3, Loss: 0.9994314312934875\n",
      "Epoch 4, Loss: 0.034317292273044586\n",
      "Epoch 3, Loss: 0.2122812271118164\n",
      "Epoch 1, Loss: 0.1431710124015808\n",
      "Epoch 3, Loss: 0.6534172296524048\n",
      "Epoch 3, Loss: 1.1105397939682007\n",
      "Epoch 2, Loss: 0.11334612220525742\n",
      "Epoch 1, Loss: 0.05216675251722336\n",
      "Epoch 3, Loss: 0.0727827250957489\n",
      "Epoch 2, Loss: 0.0906665027141571\n",
      "Epoch 4, Loss: 0.84257972240448\n",
      "Epoch 4, Loss: 0.5293025970458984\n",
      "Epoch 6, Loss: 0.06297110766172409\n",
      "Epoch 3, Loss: 0.04715512692928314\n",
      "Epoch 4, Loss: 0.9475114345550537\n",
      "Epoch 5, Loss: 0.03691863268613815\n",
      "Epoch 2, Loss: 0.11255698651075363\n",
      "Epoch 3, Loss: 0.10391684621572495\n",
      "Epoch 4, Loss: 0.1352321356534958\n",
      "Epoch 5, Loss: 0.7025050520896912\n",
      "Epoch 2, Loss: 0.03416614979505539\n",
      "Epoch 3, Loss: 0.08392956107854843\n",
      "Epoch 7, Loss: 0.06317808479070663\n",
      "Epoch 5, Loss: 0.4275224804878235\n",
      "Epoch 4, Loss: 0.06846737861633301\n",
      "Epoch 4, Loss: 0.04505327716469765\n",
      "Epoch 6, Loss: 0.039260491728782654\n",
      "Epoch 6, Loss: 0.5807133316993713\n",
      "Epoch 8, Loss: 0.06335293501615524\n",
      "Epoch 5, Loss: 0.08004691451787949\n",
      "Epoch 6, Loss: 0.34117069840431213\n",
      "Epoch 3, Loss: 0.028619136661291122\n",
      "Epoch 5, Loss: 0.7916090488433838\n",
      "Epoch 3, Loss: 0.09342564642429352\n",
      "Epoch 4, Loss: 0.10075438767671585\n",
      "Epoch 4, Loss: 0.07992615550756454\n",
      "Epoch 5, Loss: 0.03973982855677605\n",
      "Epoch 5, Loss: 0.06297764927148819\n",
      "Epoch 9, Loss: 0.06221570447087288\n",
      "Epoch 7, Loss: 0.04275110363960266\n",
      "Epoch 7, Loss: 0.2785392105579376\n",
      "Epoch 6, Loss: 0.042976222932338715\n",
      "Epoch 7, Loss: 0.47662854194641113\n",
      "Epoch 6, Loss: 0.6518537998199463\n",
      "Epoch 10, Loss: 0.06296120584011078\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1281515250179981, feed_forward_dim=256, head_dim=8, lr=5e-05, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 6, Loss: 0.03491171449422836\n",
      "Epoch 5, Loss: 0.07244082540273666\n",
      "Epoch 5, Loss: 0.09522475302219391\n",
      "Epoch 8, Loss: 0.22884081304073334\n",
      "Epoch 8, Loss: 0.0406358540058136\n",
      "Epoch 4, Loss: 0.0828462466597557\n",
      "Epoch 4, Loss: 0.02965262532234192\n",
      "Epoch 6, Loss: 0.05608007684350014\n",
      "Epoch 7, Loss: 0.020297084003686905\n",
      "Epoch 8, Loss: 0.3855402171611786\n",
      "Epoch 7, Loss: 0.5343928337097168\n",
      "Epoch 7, Loss: 0.031062861904501915\n",
      "Epoch 9, Loss: 0.03485310450196266\n",
      "Epoch 9, Loss: 0.20323729515075684\n",
      "Epoch 6, Loss: 0.06645011901855469\n",
      "Epoch 6, Loss: 0.08786064386367798\n",
      "Epoch 8, Loss: 0.011481769382953644\n",
      "Epoch 5, Loss: 0.08090899884700775\n",
      "Epoch 9, Loss: 0.31714823842048645\n",
      "Epoch 7, Loss: 0.05030835047364235\n",
      "Epoch 5, Loss: 0.0299308430403471\n",
      "Epoch 8, Loss: 0.42595094442367554\n",
      "Epoch 10, Loss: 0.030659012496471405\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1281515250179981, feed_forward_dim=256, head_dim=8, lr=5e-05, num_heads=8, num_layers=2; total time=   1.6s\n",
      "Epoch 8, Loss: 0.02796941064298153\n",
      "Epoch 10, Loss: 0.18626990914344788\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1281515250179981, feed_forward_dim=256, head_dim=8, lr=5e-05, num_heads=8, num_layers=2; total time=   1.6s\n",
      "Epoch 7, Loss: 0.05996028706431389\n",
      "Epoch 10, Loss: 0.2620703876018524\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1281515250179981, feed_forward_dim=256, head_dim=8, lr=5e-05, num_heads=8, num_layers=2; total time=   1.7s\n",
      "Epoch 7, Loss: 0.08311530202627182\n",
      "Epoch 9, Loss: 0.014324240386486053\n",
      "Epoch 9, Loss: 0.3359174132347107\n",
      "Epoch 9, Loss: 0.025544339790940285\n",
      "Epoch 6, Loss: 0.07841584831476212\n",
      "Epoch 8, Loss: 0.04432542622089386\n",
      "Epoch 6, Loss: 0.027703844010829926\n",
      "Epoch 8, Loss: 0.05397634208202362\n",
      "Epoch 10, Loss: 0.02457507885992527\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1281515250179981, feed_forward_dim=256, head_dim=8, lr=5e-05, num_heads=8, num_layers=2; total time=   1.8s\n",
      "Epoch 10, Loss: 0.023659024387598038\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1281515250179981, feed_forward_dim=256, head_dim=8, lr=5e-05, num_heads=8, num_layers=2; total time=   1.8s\n",
      "Epoch 10, Loss: 0.25877389311790466\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1281515250179981, feed_forward_dim=256, head_dim=8, lr=5e-05, num_heads=8, num_layers=2; total time=   1.8s\n",
      "Epoch 8, Loss: 0.074381023645401\n",
      "Epoch 9, Loss: 0.037976428866386414\n",
      "Epoch 9, Loss: 0.04990493506193161\n",
      "Epoch 7, Loss: 0.022987106814980507\n",
      "Epoch 7, Loss: 0.07336162775754929\n",
      "Epoch 9, Loss: 0.06976223737001419\n",
      "Epoch 8, Loss: 0.01853795163333416\n",
      "Epoch 10, Loss: 0.03635018691420555\n",
      "Epoch 10, Loss: 0.04681786522269249\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1281515250179981, feed_forward_dim=256, head_dim=8, lr=5e-05, num_heads=8, num_layers=2; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1281515250179981, feed_forward_dim=256, head_dim=8, lr=5e-05, num_heads=8, num_layers=2; total time=   2.0s\n",
      "Epoch 8, Loss: 0.06839127093553543\n",
      "Epoch 10, Loss: 0.06435076147317886\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1281515250179981, feed_forward_dim=256, head_dim=8, lr=5e-05, num_heads=8, num_layers=2; total time=   2.0s\n",
      "Epoch 9, Loss: 0.015434292145073414\n",
      "Epoch 9, Loss: 0.061387136578559875\n",
      "Epoch 10, Loss: 0.013686943799257278\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1281515250179981, feed_forward_dim=256, head_dim=8, lr=5e-05, num_heads=8, num_layers=2; total time=   2.0s\n",
      "Epoch 10, Loss: 0.053434841334819794\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1281515250179981, feed_forward_dim=256, head_dim=8, lr=5e-05, num_heads=8, num_layers=2; total time=   2.1s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 1.745473027229309\n",
      "Epoch 1, Loss: 0.5758441686630249\n",
      "Epoch 1, Loss: 0.2672913670539856\n",
      "Epoch 1, Loss: 0.02896430343389511\n",
      "Epoch 1, Loss: 0.9172981381416321\n",
      "Epoch 2, Loss: 1.5261212587356567\n",
      "Epoch 2, Loss: 0.4814927875995636\n",
      "Epoch 1, Loss: 0.49268051981925964\n",
      "Epoch 2, Loss: 0.20407286286354065\n",
      "Epoch 1, Loss: 1.3423088788986206\n",
      "Epoch 2, Loss: 0.7530213594436646\n",
      "Epoch 2, Loss: 0.02128097042441368\n",
      "Epoch 3, Loss: 1.3185372352600098\n",
      "Epoch 1, Loss: 1.2751054763793945\n",
      "Epoch 3, Loss: 0.4022758901119232\n",
      "Epoch 1, Loss: 0.6125953197479248\n",
      "Epoch 3, Loss: 0.15621338784694672\n",
      "Epoch 1, Loss: 0.6357632279396057\n",
      "Epoch 2, Loss: 0.3791532814502716\n",
      "Epoch 3, Loss: 0.020873574540019035\n",
      "Epoch 3, Loss: 0.6097153425216675\n",
      "Epoch 4, Loss: 1.136781096458435\n",
      "Epoch 2, Loss: 1.1539679765701294\n",
      "Epoch 4, Loss: 0.3285699784755707\n",
      "Epoch 2, Loss: 1.087905764579773\n",
      "Epoch 1, Loss: 0.4868515133857727\n",
      "Epoch 4, Loss: 0.12967024743556976\n",
      "Epoch 2, Loss: 0.4721294045448303\n",
      "Epoch 5, Loss: 0.965865433216095\n",
      "Epoch 1, Loss: 0.26198306679725647\n",
      "Epoch 2, Loss: 0.5377497673034668\n",
      "Epoch 3, Loss: 0.2851668894290924\n",
      "Epoch 4, Loss: 0.02117648348212242\n",
      "Epoch 4, Loss: 0.4801136255264282\n",
      "Epoch 5, Loss: 0.27204713225364685\n",
      "Epoch 3, Loss: 0.9235295057296753\n",
      "Epoch 6, Loss: 0.8199115991592407\n",
      "Epoch 5, Loss: 0.11380137503147125\n",
      "Epoch 3, Loss: 0.9851577281951904\n",
      "Epoch 6, Loss: 0.22705917060375214\n",
      "Epoch 2, Loss: 0.379912406206131\n",
      "Epoch 3, Loss: 0.3533018231391907\n",
      "Epoch 5, Loss: 0.018426522612571716\n",
      "Epoch 3, Loss: 0.44694259762763977\n",
      "Epoch 4, Loss: 0.20696428418159485\n",
      "Epoch 7, Loss: 0.6727763414382935\n",
      "Epoch 2, Loss: 0.18744324147701263\n",
      "Epoch 6, Loss: 0.10821393132209778\n",
      "Epoch 4, Loss: 0.7689502835273743\n",
      "Epoch 5, Loss: 0.36634361743927\n",
      "Epoch 7, Loss: 0.18686430156230927\n",
      "Epoch 4, Loss: 0.2511189877986908\n",
      "Epoch 4, Loss: 0.8335543870925903\n",
      "Epoch 6, Loss: 0.014862979762256145\n",
      "Epoch 8, Loss: 0.5478965640068054\n",
      "Epoch 7, Loss: 0.1118726059794426\n",
      "Epoch 3, Loss: 0.29049214720726013\n",
      "Epoch 6, Loss: 0.27662503719329834\n",
      "Epoch 4, Loss: 0.3671536147594452\n",
      "Epoch 8, Loss: 0.157623752951622\n",
      "Epoch 5, Loss: 0.14363805949687958\n",
      "Epoch 3, Loss: 0.1289919912815094\n",
      "Epoch 7, Loss: 0.013971270062029362\n",
      "Epoch 5, Loss: 0.6322222352027893\n",
      "Epoch 8, Loss: 0.11656070500612259\n",
      "Epoch 9, Loss: 0.4457958936691284\n",
      "Epoch 9, Loss: 0.13871848583221436\n",
      "Epoch 5, Loss: 0.691663920879364\n",
      "Epoch 6, Loss: 0.09874028712511063\n",
      "Epoch 5, Loss: 0.17272526025772095\n",
      "Epoch 7, Loss: 0.20301513373851776\n",
      "Epoch 4, Loss: 0.22514119744300842\n",
      "Epoch 5, Loss: 0.29844051599502563\n",
      "Epoch 9, Loss: 0.1161312535405159\n",
      "Epoch 10, Loss: 0.35911479592323303\n",
      "Epoch 10, Loss: 0.12563878297805786\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=512, head_dim=8, lr=5e-05, num_heads=4, num_layers=2; total time=   1.1s\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=512, head_dim=8, lr=5e-05, num_heads=4, num_layers=2; total time=   1.1s\n",
      "Epoch 8, Loss: 0.012868457473814487\n",
      "Epoch 6, Loss: 0.511981189250946\n",
      "Epoch 6, Loss: 0.5669994950294495\n",
      "Epoch 4, Loss: 0.08342739939689636\n",
      "Epoch 6, Loss: 0.11002306640148163\n",
      "Epoch 5, Loss: 0.17320112884044647\n",
      "Epoch 7, Loss: 0.06597012281417847\n",
      "Epoch 6, Loss: 0.23748643696308136\n",
      "Epoch 8, Loss: 0.14903001487255096\n",
      "Epoch 9, Loss: 0.01266404613852501\n",
      "Epoch 10, Loss: 0.11404754966497421\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=512, head_dim=8, lr=5e-05, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 7, Loss: 0.4597318768501282\n",
      "Epoch 7, Loss: 0.3974563479423523\n",
      "Epoch 5, Loss: 0.053236059844493866\n",
      "Epoch 9, Loss: 0.10889297723770142\n",
      "Epoch 7, Loss: 0.1867869347333908\n",
      "Epoch 8, Loss: 0.044952865689992905\n",
      "Epoch 10, Loss: 0.011662987992167473\n",
      "Epoch 7, Loss: 0.06463391333818436\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=512, head_dim=8, lr=5e-05, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 6, Loss: 0.13913142681121826\n",
      "Epoch 8, Loss: 0.37186679244041443\n",
      "Epoch 10, Loss: 0.08011311292648315\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=512, head_dim=8, lr=5e-05, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 9, Loss: 0.035665079951286316\n",
      "Epoch 8, Loss: 0.3053906261920929\n",
      "Epoch 8, Loss: 0.14818477630615234\n",
      "Epoch 7, Loss: 0.11823828518390656\n",
      "Epoch 6, Loss: 0.038033802062273026\n",
      "Epoch 8, Loss: 0.037709791213274\n",
      "Epoch 9, Loss: 0.29825273156166077\n",
      "Epoch 10, Loss: 0.03519206866621971\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=512, head_dim=8, lr=5e-05, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 9, Loss: 0.22920069098472595\n",
      "Epoch 9, Loss: 0.11822417378425598\n",
      "Epoch 10, Loss: 0.24149955809116364\n",
      "Epoch 8, Loss: 0.1088421642780304\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=512, head_dim=8, lr=5e-05, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 7, Loss: 0.031010547652840614\n",
      "Epoch 9, Loss: 0.02280511148273945\n",
      "Epoch 10, Loss: 0.16405360400676727\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=512, head_dim=8, lr=5e-05, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.09610452502965927\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=512, head_dim=8, lr=5e-05, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 0.10773425549268723\n",
      "Epoch 8, Loss: 0.03435401991009712\n",
      "Epoch 10, Loss: 0.020457325503230095\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=512, head_dim=8, lr=5e-05, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.11165720969438553\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=512, head_dim=8, lr=5e-05, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 0.041107356548309326\n",
      "Epoch 10, Loss: 0.04913383722305298\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=512, head_dim=8, lr=5e-05, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.5290166139602661\n",
      "Epoch 1, Loss: 1.2106437683105469\n",
      "Epoch 1, Loss: 0.010365745984017849\n",
      "Epoch 1, Loss: 0.8793261647224426\n",
      "Epoch 1, Loss: 0.5537407398223877\n",
      "Epoch 2, Loss: 0.3409799337387085\n",
      "Epoch 1, Loss: 1.4441171884536743\n",
      "Epoch 1, Loss: 1.2202105522155762\n",
      "Epoch 2, Loss: 0.9015054106712341\n",
      "Epoch 2, Loss: 0.013935879804193974\n",
      "Epoch 1, Loss: 0.13289062678813934\n",
      "Epoch 2, Loss: 0.3310481607913971\n",
      "Epoch 2, Loss: 0.6388972401618958\n",
      "Epoch 3, Loss: 0.20311221480369568\n",
      "Epoch 1, Loss: 0.10033849626779556\n",
      "Epoch 3, Loss: 0.651623010635376\n",
      "Epoch 3, Loss: 0.009034167043864727\n",
      "Epoch 2, Loss: 1.1181979179382324\n",
      "Epoch 1, Loss: 0.01853075437247753\n",
      "Epoch 2, Loss: 0.9135527014732361\n",
      "Epoch 1, Loss: 0.10619530826807022\n",
      "Epoch 2, Loss: 0.11081957072019577\n",
      "Epoch 1, Loss: 0.3469909727573395\n",
      "Epoch 4, Loss: 0.11047787964344025\n",
      "Epoch 4, Loss: 0.0061658709309995174\n",
      "Epoch 3, Loss: 0.4359770715236664\n",
      "Epoch 2, Loss: 0.045843157917261124\n",
      "Epoch 3, Loss: 0.17822302877902985\n",
      "Epoch 4, Loss: 0.44341543316841125\n",
      "Epoch 3, Loss: 0.8372803330421448\n",
      "Epoch 3, Loss: 0.6478992700576782\n",
      "Epoch 3, Loss: 0.09541221708059311\n",
      "Epoch 4, Loss: 0.08925739675760269\n",
      "Epoch 2, Loss: 0.07679278403520584\n",
      "Epoch 2, Loss: 0.16975665092468262\n",
      "Epoch 2, Loss: 0.024759016931056976\n",
      "Epoch 3, Loss: 0.040605317801237106\n",
      "Epoch 5, Loss: 0.06914395838975906\n",
      "Epoch 4, Loss: 0.28713637590408325\n",
      "Epoch 5, Loss: 0.009482517838478088\n",
      "Epoch 5, Loss: 0.30113279819488525\n",
      "Epoch 4, Loss: 0.4410218298435211\n",
      "Epoch 5, Loss: 0.060148872435092926\n",
      "Epoch 5, Loss: 0.1856537163257599\n",
      "Epoch 6, Loss: 0.008816324174404144\n",
      "Epoch 6, Loss: 0.06233746185898781\n",
      "Epoch 4, Loss: 0.599238395690918\n",
      "Epoch 4, Loss: 0.07884678244590759\n",
      "Epoch 4, Loss: 0.05264227092266083\n",
      "Epoch 3, Loss: 0.06820408999919891\n",
      "Epoch 3, Loss: 0.013031214475631714\n",
      "Epoch 3, Loss: 0.05695342645049095\n",
      "Epoch 6, Loss: 0.21265189349651337\n",
      "Epoch 7, Loss: 0.006387912202626467\n",
      "Epoch 7, Loss: 0.08005326241254807\n",
      "Epoch 5, Loss: 0.2894269824028015\n",
      "Epoch 6, Loss: 0.12619717419147491\n",
      "Epoch 6, Loss: 0.06973419338464737\n",
      "Epoch 5, Loss: 0.40545785427093506\n",
      "Epoch 8, Loss: 0.10077270120382309\n",
      "Epoch 7, Loss: 0.16691359877586365\n",
      "Epoch 8, Loss: 0.005701835732907057Epoch 4, Loss: 0.012808005325496197\n",
      "\n",
      "Epoch 5, Loss: 0.05158737301826477\n",
      "Epoch 5, Loss: 0.06279060989618301\n",
      "Epoch 4, Loss: 0.061008282005786896\n",
      "Epoch 4, Loss: 0.010137980803847313\n",
      "Epoch 6, Loss: 0.1809975951910019\n",
      "Epoch 7, Loss: 0.10354693979024887\n",
      "Epoch 7, Loss: 0.10118960589170456\n",
      "Epoch 9, Loss: 0.11718322336673737\n",
      "Epoch 6, Loss: 0.2618311643600464\n",
      "Epoch 8, Loss: 0.16983358561992645\n",
      "Epoch 9, Loss: 0.007374984212219715\n",
      "Epoch 6, Loss: 0.04053923487663269\n",
      "Epoch 6, Loss: 0.05196414515376091\n",
      "Epoch 8, Loss: 0.12574398517608643\n",
      "Epoch 10, Loss: 0.12081725150346756\n",
      "Epoch 10, Loss: 0.006874301936477423\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1901422431767955, feed_forward_dim=256, head_dim=8, lr=8.908313426610931e-05, num_heads=4, num_layers=2; total time=   1.1s\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1901422431767955, feed_forward_dim=256, head_dim=8, lr=8.908313426610931e-05, num_heads=4, num_layers=2; total time=   1.1s\n",
      "Epoch 5, Loss: 0.0508987233042717\n",
      "Epoch 5, Loss: 0.014220083132386208\n",
      "Epoch 9, Loss: 0.18967239558696747\n",
      "Epoch 8, Loss: 0.1095927357673645\n",
      "Epoch 7, Loss: 0.11839023977518082\n",
      "Epoch 7, Loss: 0.15697892010211945\n",
      "Epoch 5, Loss: 0.015984956175088882\n",
      "Epoch 9, Loss: 0.13950073719024658\n",
      "Epoch 7, Loss: 0.027293313294649124\n",
      "Epoch 7, Loss: 0.04280894994735718\n",
      "Epoch 10, Loss: 0.2228948175907135\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1901422431767955, feed_forward_dim=256, head_dim=8, lr=8.908313426610931e-05, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 6, Loss: 0.037095412611961365\n",
      "Epoch 8, Loss: 0.09059558808803558\n",
      "Epoch 8, Loss: 0.09480596333742142\n",
      "Epoch 9, Loss: 0.12740972638130188\n",
      "Epoch 6, Loss: 0.011419839225709438\n",
      "Epoch 10, Loss: 0.13600043952465057\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1901422431767955, feed_forward_dim=256, head_dim=8, lr=8.908313426610931e-05, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 6, Loss: 0.049092553555965424\n",
      "Epoch 8, Loss: 0.034120772033929825\n",
      "Epoch 9, Loss: 0.056224722415208817\n",
      "Epoch 10, Loss: 0.1523459255695343\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1901422431767955, feed_forward_dim=256, head_dim=8, lr=8.908313426610931e-05, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 9, Loss: 0.09334728121757507\n",
      "Epoch 8, Loss: 0.021395698189735413\n",
      "Epoch 7, Loss: 0.028831612318754196\n",
      "Epoch 9, Loss: 0.025331584736704826\n",
      "Epoch 10, Loss: 0.04836135730147362\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1901422431767955, feed_forward_dim=256, head_dim=8, lr=8.908313426610931e-05, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 7, Loss: 0.08025296032428741\n",
      "Epoch 7, Loss: 0.00918919499963522\n",
      "Epoch 10, Loss: 0.11606120318174362\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1901422431767955, feed_forward_dim=256, head_dim=8, lr=8.908313426610931e-05, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 9, Loss: 0.02072340063750744\n",
      "Epoch 8, Loss: 0.02376377210021019\n",
      "Epoch 10, Loss: 0.01941731572151184\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1901422431767955, feed_forward_dim=256, head_dim=8, lr=8.908313426610931e-05, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 8, Loss: 0.08794218301773071\n",
      "Epoch 8, Loss: 0.010592445731163025\n",
      "Epoch 10, Loss: 0.021757012233138084\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1901422431767955, feed_forward_dim=256, head_dim=8, lr=8.908313426610931e-05, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 0.02086200937628746\n",
      "Epoch 9, Loss: 0.011707284487783909\n",
      "Epoch 9, Loss: 0.0770384892821312\n",
      "Epoch 10, Loss: 0.018377287313342094\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1901422431767955, feed_forward_dim=256, head_dim=8, lr=8.908313426610931e-05, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.0105595663189888\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1901422431767955, feed_forward_dim=256, head_dim=8, lr=8.908313426610931e-05, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.05449428781867027\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1901422431767955, feed_forward_dim=256, head_dim=8, lr=8.908313426610931e-05, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 1.559112787246704\n",
      "Epoch 1, Loss: 0.42383506894111633\n",
      "Epoch 1, Loss: 0.057313669472932816\n",
      "Epoch 1, Loss: 0.50204998254776\n",
      "Epoch 1, Loss: 0.062324341386556625\n",
      "Epoch 2, Loss: 1.382022500038147\n",
      "Epoch 2, Loss: 0.05098598077893257\n",
      "Epoch 1, Loss: 0.37102752923965454\n",
      "Epoch 2, Loss: 0.33828020095825195\n",
      "Epoch 1, Loss: 0.7653145790100098\n",
      "Epoch 2, Loss: 0.3851645290851593\n",
      "Epoch 3, Loss: 1.218916654586792\n",
      "Epoch 1, Loss: 0.6036245226860046\n",
      "Epoch 1, Loss: 2.8192946910858154\n",
      "Epoch 2, Loss: 0.05697555094957352\n",
      "Epoch 2, Loss: 0.2786993682384491\n",
      "Epoch 3, Loss: 0.04611608386039734\n",
      "Epoch 3, Loss: 0.2661241888999939\n",
      "Epoch 1, Loss: 0.10688924789428711\n",
      "Epoch 2, Loss: 0.6081081628799438\n",
      "Epoch 4, Loss: 1.0640754699707031\n",
      "Epoch 1, Loss: 0.7904393076896667\n",
      "Epoch 3, Loss: 0.05273105949163437\n",
      "Epoch 3, Loss: 0.29547733068466187\n",
      "Epoch 2, Loss: 2.564844846725464\n",
      "Epoch 4, Loss: 0.20975257456302643\n",
      "Epoch 1, Loss: 0.5839800238609314\n",
      "Epoch 4, Loss: 0.04092060774564743\n",
      "Epoch 2, Loss: 0.4671894311904907\n",
      "Epoch 3, Loss: 0.20231516659259796\n",
      "Epoch 3, Loss: 0.47163257002830505\n",
      "Epoch 2, Loss: 0.06041685491800308\n",
      "Epoch 5, Loss: 0.9253783822059631\n",
      "Epoch 4, Loss: 0.2178553342819214\n",
      "Epoch 5, Loss: 0.16115917265415192\n",
      "Epoch 5, Loss: 0.03486669063568115\n",
      "Epoch 4, Loss: 0.04770498350262642\n",
      "Epoch 3, Loss: 0.3438095152378082\n",
      "Epoch 2, Loss: 0.6382975578308105\n",
      "Epoch 6, Loss: 0.7919501662254333\n",
      "Epoch 2, Loss: 0.48253268003463745\n",
      "Epoch 3, Loss: 2.3118088245391846\n",
      "Epoch 4, Loss: 0.13829286396503448\n",
      "Epoch 4, Loss: 0.351232647895813\n",
      "Epoch 3, Loss: 0.034832414239645004\n",
      "Epoch 6, Loss: 0.1295417696237564\n",
      "Epoch 6, Loss: 0.03254595771431923\n",
      "Epoch 5, Loss: 0.1552230268716812\n",
      "Epoch 7, Loss: 0.6759607195854187\n",
      "Epoch 5, Loss: 0.04269109666347504\n",
      "Epoch 3, Loss: 0.5055941939353943\n",
      "Epoch 5, Loss: 0.08998104184865952\n",
      "Epoch 4, Loss: 2.0863759517669678\n",
      "Epoch 7, Loss: 0.11137531697750092\n",
      "Epoch 4, Loss: 0.24931181967258453\n",
      "Epoch 6, Loss: 0.0399174727499485\n",
      "Epoch 6, Loss: 0.11332140117883682\n",
      "Epoch 8, Loss: 0.56171715259552\n",
      "Epoch 7, Loss: 0.029275357723236084\n",
      "Epoch 5, Loss: 0.2557092308998108\n",
      "Epoch 4, Loss: 0.024272587150335312\n",
      "Epoch 3, Loss: 0.39624476432800293\n",
      "Epoch 8, Loss: 0.09987205266952515\n",
      "Epoch 5, Loss: 1.8657264709472656\n",
      "Epoch 5, Loss: 0.16922807693481445\n",
      "Epoch 9, Loss: 0.47778090834617615\n",
      "Epoch 7, Loss: 0.03491697460412979\n",
      "Epoch 4, Loss: 0.38747918605804443\n",
      "Epoch 7, Loss: 0.08602435886859894\n",
      "Epoch 6, Loss: 0.053347740322351456\n",
      "Epoch 8, Loss: 0.026482708752155304\n",
      "Epoch 9, Loss: 0.0989295169711113\n",
      "Epoch 6, Loss: 0.17545588314533234\n",
      "Epoch 5, Loss: 0.026165591552853584\n",
      "Epoch 4, Loss: 0.32127952575683594\n",
      "Epoch 8, Loss: 0.03288717567920685\n",
      "Epoch 8, Loss: 0.07124705612659454\n",
      "Epoch 10, Loss: 0.39370518922805786\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.14701167858465872, feed_forward_dim=512, head_dim=16, lr=5e-05, num_heads=4, num_layers=1; total time=   1.1s\n",
      "Epoch 6, Loss: 0.10825113207101822\n",
      "Epoch 9, Loss: 0.02200266905128956\n",
      "Epoch 7, Loss: 0.03276759758591652\n",
      "Epoch 6, Loss: 1.6570199728012085\n",
      "Epoch 5, Loss: 0.29176872968673706\n",
      "Epoch 10, Loss: 0.10339164733886719\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.14701167858465872, feed_forward_dim=512, head_dim=16, lr=5e-05, num_heads=4, num_layers=1; total time=   1.1s\n",
      "Epoch 7, Loss: 0.11392775923013687\n",
      "Epoch 9, Loss: 0.02934158220887184\n",
      "Epoch 9, Loss: 0.06660869717597961\n",
      "Epoch 10, Loss: 0.018776284530758858\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.14701167858465872, feed_forward_dim=512, head_dim=16, lr=5e-05, num_heads=4, num_layers=1; total time=   1.2s\n",
      "Epoch 6, Loss: 0.03259675204753876\n",
      "Epoch 8, Loss: 0.022534197196364403\n",
      "Epoch 5, Loss: 0.2559361159801483\n",
      "Epoch 7, Loss: 1.458096981048584\n",
      "Epoch 7, Loss: 0.06541475653648376\n",
      "Epoch 10, Loss: 0.02652640827000141\n",
      "Epoch 8, Loss: 0.0724300667643547\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.14701167858465872, feed_forward_dim=512, head_dim=16, lr=5e-05, num_heads=4, num_layers=1; total time=   1.3s\n",
      "Epoch 6, Loss: 0.20846666395664215\n",
      "Epoch 10, Loss: 0.0720018595457077\n",
      "Epoch 9, Loss: 0.02069295011460781\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.14701167858465872, feed_forward_dim=512, head_dim=16, lr=5e-05, num_heads=4, num_layers=1; total time=   1.3s\n",
      "Epoch 7, Loss: 0.0368032306432724\n",
      "Epoch 8, Loss: 1.2711576223373413\n",
      "Epoch 6, Loss: 0.20050588250160217\n",
      "Epoch 9, Loss: 0.04386294633150101\n",
      "Epoch 8, Loss: 0.03672925755381584\n",
      "Epoch 7, Loss: 0.14546944200992584\n",
      "Epoch 9, Loss: 1.1044235229492188\n",
      "Epoch 10, Loss: 0.02495812438428402\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.14701167858465872, feed_forward_dim=512, head_dim=16, lr=5e-05, num_heads=4, num_layers=1; total time=   1.4s\n",
      "Epoch 10, Loss: 0.030234823003411293\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.14701167858465872, feed_forward_dim=512, head_dim=16, lr=5e-05, num_heads=4, num_layers=1; total time=   1.4s\n",
      "Epoch 8, Loss: 0.037329934537410736\n",
      "Epoch 7, Loss: 0.15440209209918976\n",
      "Epoch 9, Loss: 0.02395927906036377\n",
      "Epoch 8, Loss: 0.09945705533027649\n",
      "Epoch 10, Loss: 0.9521484375\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.14701167858465872, feed_forward_dim=512, head_dim=16, lr=5e-05, num_heads=4, num_layers=1; total time=   1.4s\n",
      "Epoch 9, Loss: 0.03514118492603302\n",
      "Epoch 8, Loss: 0.11915392428636551\n",
      "Epoch 10, Loss: 0.02142302319407463\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.14701167858465872, feed_forward_dim=512, head_dim=16, lr=5e-05, num_heads=4, num_layers=1; total time=   1.5s\n",
      "Epoch 9, Loss: 0.06435778737068176\n",
      "Epoch 10, Loss: 0.028550885617733\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.14701167858465872, feed_forward_dim=512, head_dim=16, lr=5e-05, num_heads=4, num_layers=1; total time=   1.6s\n",
      "Epoch 9, Loss: 0.09231960773468018\n",
      "Epoch 10, Loss: 0.043685879558324814\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.14701167858465872, feed_forward_dim=512, head_dim=16, lr=5e-05, num_heads=4, num_layers=1; total time=   1.6s\n",
      "Epoch 10, Loss: 0.07248831540346146\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.14701167858465872, feed_forward_dim=512, head_dim=16, lr=5e-05, num_heads=4, num_layers=1; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.5301946401596069\n",
      "Epoch 1, Loss: 2.329296350479126\n",
      "Epoch 1, Loss: 0.22585511207580566\n",
      "Epoch 1, Loss: 0.2398613691329956\n",
      "Epoch 2, Loss: 0.41803547739982605\n",
      "Epoch 1, Loss: 0.06512556970119476\n",
      "Epoch 2, Loss: 2.0503127574920654\n",
      "Epoch 1, Loss: 0.053324609994888306\n",
      "Epoch 1, Loss: 0.5991551876068115\n",
      "Epoch 2, Loss: 0.17816996574401855\n",
      "Epoch 3, Loss: 0.31815335154533386\n",
      "Epoch 1, Loss: 0.8606974482536316\n",
      "Epoch 1, Loss: 0.4843481183052063\n",
      "Epoch 2, Loss: 0.1872403770685196\n",
      "Epoch 1, Loss: 0.5406197905540466\n",
      "Epoch 1, Loss: 0.467133104801178\n",
      "Epoch 3, Loss: 1.7866328954696655\n",
      "Epoch 1, Loss: 0.012702922336757183\n",
      "Epoch 2, Loss: 0.0345943309366703\n",
      "Epoch 2, Loss: 0.05736420676112175\n",
      "Epoch 3, Loss: 0.15397153794765472\n",
      "Epoch 2, Loss: 0.467619389295578\n",
      "Epoch 2, Loss: 0.7290193438529968\n",
      "Epoch 4, Loss: 0.23402445018291473\n",
      "Epoch 4, Loss: 1.548600435256958\n",
      "Epoch 2, Loss: 0.3993498980998993\n",
      "Epoch 2, Loss: 0.3641343414783478\n",
      "Epoch 4, Loss: 0.14199182391166687\n",
      "Epoch 3, Loss: 0.030262023210525513\n",
      "Epoch 2, Loss: 0.41876131296157837\n",
      "Epoch 3, Loss: 0.15235961973667145\n",
      "Epoch 3, Loss: 0.05162917077541351\n",
      "Epoch 2, Loss: 0.005317384377121925\n",
      "Epoch 3, Loss: 0.6190023422241211\n",
      "Epoch 5, Loss: 0.16620774567127228\n",
      "Epoch 5, Loss: 0.13748610019683838\n",
      "Epoch 4, Loss: 0.032464832067489624\n",
      "Epoch 3, Loss: 0.32320305705070496\n",
      "Epoch 3, Loss: 0.27459976077079773\n",
      "Epoch 5, Loss: 1.3191968202590942\n",
      "Epoch 4, Loss: 0.04519474878907204\n",
      "Epoch 3, Loss: 0.31280747056007385\n",
      "Epoch 3, Loss: 0.35990485548973083\n",
      "Epoch 3, Loss: 0.008448689244687557\n",
      "Epoch 4, Loss: 0.12969398498535156\n",
      "Epoch 6, Loss: 0.11192714422941208\n",
      "Epoch 6, Loss: 1.1085264682769775\n",
      "Epoch 4, Loss: 0.2533310353755951\n",
      "Epoch 6, Loss: 0.12645551562309265\n",
      "Epoch 4, Loss: 0.20139475166797638\n",
      "Epoch 7, Loss: 0.06790555268526077\n",
      "Epoch 7, Loss: 0.9207121133804321\n",
      "Epoch 4, Loss: 0.5154803991317749\n",
      "Epoch 4, Loss: 0.26894861459732056\n",
      "Epoch 5, Loss: 0.03894417732954025\n",
      "Epoch 5, Loss: 0.11724281311035156\n",
      "Epoch 5, Loss: 0.032648440450429916\n",
      "Epoch 8, Loss: 0.04129501059651375\n",
      "Epoch 5, Loss: 0.19622674584388733\n",
      "Epoch 7, Loss: 0.11671510338783264\n",
      "Epoch 4, Loss: 0.2246849536895752\n",
      "Epoch 5, Loss: 0.20809412002563477\n",
      "Epoch 6, Loss: 0.11212527006864548\n",
      "Epoch 4, Loss: 0.009400837123394012\n",
      "Epoch 6, Loss: 0.033516496419906616\n",
      "Epoch 6, Loss: 0.029769819229841232\n",
      "Epoch 8, Loss: 0.7595627903938293\n",
      "Epoch 9, Loss: 0.024511942639946938\n",
      "Epoch 5, Loss: 0.4196467399597168\n",
      "Epoch 5, Loss: 0.1415412276983261\n",
      "Epoch 8, Loss: 0.10114458948373795\n",
      "Epoch 7, Loss: 0.029424430802464485\n",
      "Epoch 7, Loss: 0.1104770079255104\n",
      "Epoch 6, Loss: 0.1492699831724167\n",
      "Epoch 5, Loss: 0.1524202823638916\n",
      "Epoch 5, Loss: 0.00671683344990015\n",
      "Epoch 7, Loss: 0.02529834397137165\n",
      "Epoch 10, Loss: 0.01749507151544094\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3983868068599058, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 9, Loss: 0.6121240854263306\n",
      "Epoch 6, Loss: 0.16256417334079742\n",
      "Epoch 6, Loss: 0.3409178555011749\n",
      "Epoch 9, Loss: 0.08938834071159363\n",
      "Epoch 8, Loss: 0.025519773364067078\n",
      "Epoch 10, Loss: 0.4821959137916565\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3983868068599058, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 8, Loss: 0.10999792814254761\n",
      "Epoch 7, Loss: 0.11023838818073273\n",
      "Epoch 6, Loss: 0.09556236863136292\n",
      "Epoch 6, Loss: 0.005102337803691626\n",
      "Epoch 8, Loss: 0.02160102315247059\n",
      "Epoch 7, Loss: 0.13914160430431366\n",
      "Epoch 6, Loss: 0.10169871896505356\n",
      "Epoch 10, Loss: 0.07921595126390457\n",
      "Epoch 7, Loss: 0.26886624097824097\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3983868068599058, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=8, num_layers=3; total time=   1.6s\n",
      "Epoch 9, Loss: 0.10933313518762589\n",
      "Epoch 9, Loss: 0.021377699449658394\n",
      "Epoch 9, Loss: 0.018769070506095886\n",
      "Epoch 7, Loss: 0.06356284022331238\n",
      "Epoch 8, Loss: 0.07865860313177109\n",
      "Epoch 8, Loss: 0.12638868391513824\n",
      "Epoch 10, Loss: 0.01813107542693615\n",
      "Epoch 7, Loss: 0.005843162536621094\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3983868068599058, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=8, num_layers=3; total time=   1.7s\n",
      "Epoch 8, Loss: 0.21115747094154358\n",
      "Epoch 10, Loss: 0.10268807411193848\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3983868068599058, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=8, num_layers=3; total time=   1.8s\n",
      "Epoch 7, Loss: 0.06434687972068787\n",
      "Epoch 9, Loss: 0.05666430667042732\n",
      "Epoch 10, Loss: 0.017654195427894592\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3983868068599058, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=8, num_layers=3; total time=   1.8s\n",
      "Epoch 8, Loss: 0.04286576062440872\n",
      "Epoch 9, Loss: 0.1273171305656433\n",
      "Epoch 9, Loss: 0.1623392254114151\n",
      "Epoch 8, Loss: 0.0072172172367572784\n",
      "Epoch 10, Loss: 0.0425274521112442\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3983868068599058, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=8, num_layers=3; total time=   1.9s\n",
      "Epoch 8, Loss: 0.042130228132009506\n",
      "Epoch 9, Loss: 0.03313609957695007\n",
      "Epoch 10, Loss: 0.13298822939395905\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3983868068599058, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=8, num_layers=3; total time=   2.0s\n",
      "Epoch 10, Loss: 0.12306226044893265\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3983868068599058, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=8, num_layers=3; total time=   2.0s\n",
      "Epoch 9, Loss: 0.006866466253995895\n",
      "Epoch 9, Loss: 0.032854147255420685\n",
      "Epoch 10, Loss: 0.029734790325164795\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3983868068599058, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=8, num_layers=3; total time=   2.1s\n",
      "Epoch 10, Loss: 0.006190899759531021\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3983868068599058, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=8, num_layers=3; total time=   2.1s\n",
      "Epoch 10, Loss: 0.035290684551000595\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3983868068599058, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=8, num_layers=3; total time=   2.1s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.38645198941230774\n",
      "Epoch 1, Loss: 0.2351911962032318\n",
      "Epoch 2, Loss: 0.11525135487318039\n",
      "Epoch 2, Loss: 0.056723255664110184\n",
      "Epoch 1, Loss: 0.35425227880477905\n",
      "Epoch 1, Loss: 0.49628862738609314\n",
      "Epoch 1, Loss: 0.3919294774532318\n",
      "Epoch 1, Loss: 0.010407214984297752\n",
      "Epoch 3, Loss: 0.04500453546643257\n",
      "Epoch 3, Loss: 0.07213490456342697\n",
      "Epoch 2, Loss: 0.22459757328033447\n",
      "Epoch 1, Loss: 0.11218824237585068\n",
      "Epoch 1, Loss: 0.37297481298446655\n",
      "Epoch 2, Loss: 0.2456042766571045\n",
      "Epoch 2, Loss: 0.1016760990023613\n",
      "Epoch 1, Loss: 0.13689380884170532\n",
      "Epoch 4, Loss: 0.11559418588876724\n",
      "Epoch 4, Loss: 0.10076568275690079\n",
      "Epoch 1, Loss: 0.761396050453186\n",
      "Epoch 3, Loss: 0.08382198214530945\n",
      "Epoch 2, Loss: 0.055654555559158325\n",
      "Epoch 2, Loss: 0.04772892966866493\n",
      "Epoch 1, Loss: 0.25475963950157166\n",
      "Epoch 1, Loss: 0.7152167558670044\n",
      "Epoch 3, Loss: 0.0070377434603869915\n",
      "Epoch 2, Loss: 0.12914587557315826\n",
      "Epoch 3, Loss: 0.22062404453754425\n",
      "Epoch 5, Loss: 0.08935161679983139\n",
      "Epoch 5, Loss: 0.14890697598457336\n",
      "Epoch 4, Loss: 0.05317221209406853\n",
      "Epoch 3, Loss: 0.06542305648326874\n",
      "Epoch 3, Loss: 0.008359272964298725\n",
      "Epoch 4, Loss: 0.04648544639348984\n",
      "Epoch 2, Loss: 0.3437178134918213\n",
      "Epoch 3, Loss: 0.0948815569281578\n",
      "Epoch 6, Loss: 0.04666954278945923\n",
      "Epoch 2, Loss: 0.03594315052032471\n",
      "Epoch 4, Loss: 0.18955354392528534\n",
      "Epoch 2, Loss: 0.11578187346458435\n",
      "Epoch 6, Loss: 0.13814157247543335\n",
      "Epoch 5, Loss: 0.08852528780698776\n",
      "Epoch 2, Loss: 0.34382569789886475\n",
      "Epoch 5, Loss: 0.10914415866136551\n",
      "Epoch 4, Loss: 0.0642680898308754\n",
      "Epoch 4, Loss: 0.14992834627628326\n",
      "Epoch 4, Loss: 0.016422701999545097\n",
      "Epoch 7, Loss: 0.018964936956763268\n",
      "Epoch 7, Loss: 0.09365206211805344\n",
      "Epoch 3, Loss: 0.12485352158546448\n",
      "Epoch 5, Loss: 0.1397060602903366\n",
      "Epoch 3, Loss: 0.07988687604665756\n",
      "Epoch 6, Loss: 0.13091407716274261\n",
      "Epoch 3, Loss: 0.12323089689016342\n",
      "Epoch 8, Loss: 0.018239228054881096\n",
      "Epoch 5, Loss: 0.0306899044662714\n",
      "Epoch 8, Loss: 0.049887195229530334\n",
      "Epoch 5, Loss: 0.17652341723442078\n",
      "Epoch 5, Loss: 0.04137532413005829\n",
      "Epoch 6, Loss: 0.12405634671449661\n",
      "Epoch 6, Loss: 0.09815853089094162\n",
      "Epoch 7, Loss: 0.1492331326007843\n",
      "Epoch 3, Loss: 0.21025864779949188\n",
      "Epoch 9, Loss: 0.03342559188604355\n",
      "Epoch 4, Loss: 0.08329533785581589\n",
      "Epoch 4, Loss: 0.08091755211353302\n",
      "Epoch 9, Loss: 0.024935809895396233\n",
      "Epoch 6, Loss: 0.1401810199022293\n",
      "Epoch 6, Loss: 0.018883325159549713\n",
      "Epoch 10, Loss: 0.04472893849015236\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.24745960229780098, feed_forward_dim=128, head_dim=16, lr=0.00016735777288389358, num_heads=8, num_layers=2; total time=   0.9s\n",
      "Epoch 7, Loss: 0.0768270343542099\n",
      "Epoch 6, Loss: 0.025047078728675842\n",
      "Epoch 8, Loss: 0.1380622833967209\n",
      "Epoch 4, Loss: 0.13612112402915955\n",
      "Epoch 7, Loss: 0.09603209793567657\n",
      "Epoch 10, Loss: 0.022677486762404442\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.24745960229780098, feed_forward_dim=128, head_dim=16, lr=0.00016735777288389358, num_heads=8, num_layers=2; total time=   1.0s\n",
      "Epoch 7, Loss: 0.09118814766407013\n",
      "Epoch 5, Loss: 0.049750976264476776\n",
      "Epoch 5, Loss: 0.1418738216161728\n",
      "Epoch 8, Loss: 0.0672060176730156\n",
      "Epoch 9, Loss: 0.10979899019002914\n",
      "Epoch 7, Loss: 0.00589459715411067\n",
      "Epoch 4, Loss: 0.2313692420721054\n",
      "Epoch 8, Loss: 0.05968809872865677\n",
      "Epoch 7, Loss: 0.02123052254319191\n",
      "Epoch 5, Loss: 0.11119840294122696\n",
      "Epoch 8, Loss: 0.05515782907605171\n",
      "Epoch 9, Loss: 0.05904719978570938\n",
      "Epoch 10, Loss: 0.07838630676269531\n",
      "Epoch 6, Loss: 0.026098499074578285\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.24745960229780098, feed_forward_dim=128, head_dim=16, lr=0.00016735777288389358, num_heads=8, num_layers=2; total time=   1.1s\n",
      "Epoch 8, Loss: 0.007394349202513695\n",
      "Epoch 9, Loss: 0.024519555270671844\n",
      "Epoch 8, Loss: 0.027410263195633888\n",
      "Epoch 6, Loss: 0.20419755578041077\n",
      "Epoch 10, Loss: 0.048137009143829346\n",
      "Epoch 5, Loss: 0.2639491558074951\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.24745960229780098, feed_forward_dim=128, head_dim=16, lr=0.00016735777288389358, num_heads=8, num_layers=2; total time=   1.2s\n",
      "Epoch 6, Loss: 0.07101569324731827\n",
      "Epoch 9, Loss: 0.04278736561536789\n",
      "Epoch 7, Loss: 0.029032917693257332\n",
      "Epoch 9, Loss: 0.015777915716171265\n",
      "Epoch 10, Loss: 0.0067887576296925545\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.24745960229780098, feed_forward_dim=128, head_dim=16, lr=0.00016735777288389358, num_heads=8, num_layers=2; total time=   1.2s\n",
      "Epoch 9, Loss: 0.02784687466919422\n",
      "Epoch 6, Loss: 0.2553941011428833\n",
      "Epoch 7, Loss: 0.044571079313755035\n",
      "Epoch 10, Loss: 0.05055687949061394\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.24745960229780098, feed_forward_dim=128, head_dim=16, lr=0.00016735777288389358, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 7, Loss: 0.21617990732192993\n",
      "Epoch 8, Loss: 0.043190013617277145\n",
      "Epoch 10, Loss: 0.017249999567866325\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.24745960229780098, feed_forward_dim=128, head_dim=16, lr=0.00016735777288389358, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 7, Loss: 0.20498637855052948\n",
      "Epoch 8, Loss: 0.03948002681136131\n",
      "Epoch 10, Loss: 0.02126690372824669\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.24745960229780098, feed_forward_dim=128, head_dim=16, lr=0.00016735777288389358, num_heads=8, num_layers=2; total time=   1.4s\n",
      "Epoch 8, Loss: 0.19112160801887512\n",
      "Epoch 9, Loss: 0.045080821961164474\n",
      "Epoch 8, Loss: 0.14046457409858704\n",
      "Epoch 9, Loss: 0.045014556497335434\n",
      "Epoch 9, Loss: 0.1364976465702057\n",
      "Epoch 10, Loss: 0.034043990075588226\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.24745960229780098, feed_forward_dim=128, head_dim=16, lr=0.00016735777288389358, num_heads=8, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.046764735132455826\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.24745960229780098, feed_forward_dim=128, head_dim=16, lr=0.00016735777288389358, num_heads=8, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 0.08782296627759933\n",
      "Epoch 10, Loss: 0.08309715241193771\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.24745960229780098, feed_forward_dim=128, head_dim=16, lr=0.00016735777288389358, num_heads=8, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.05926000699400902\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.24745960229780098, feed_forward_dim=128, head_dim=16, lr=0.00016735777288389358, num_heads=8, num_layers=2; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.9313446879386902\n",
      "Epoch 1, Loss: 0.049239397048950195\n",
      "Epoch 1, Loss: 0.40545591711997986\n",
      "Epoch 1, Loss: 0.04744341969490051\n",
      "Epoch 2, Loss: 0.8085134625434875\n",
      "Epoch 1, Loss: 0.054141707718372345\n",
      "Epoch 2, Loss: 0.023446369916200638\n",
      "Epoch 1, Loss: 0.12424718588590622\n",
      "Epoch 2, Loss: 0.29578888416290283\n",
      "Epoch 1, Loss: 0.04554828256368637\n",
      "Epoch 2, Loss: 0.02993706427514553\n",
      "Epoch 3, Loss: 0.6927772760391235\n",
      "Epoch 1, Loss: 0.327420175075531\n",
      "Epoch 1, Loss: 0.07206417620182037\n",
      "Epoch 2, Loss: 0.04279511794447899\n",
      "Epoch 3, Loss: 0.009603755548596382\n",
      "Epoch 2, Loss: 0.09194843471050262\n",
      "Epoch 3, Loss: 0.2021419256925583\n",
      "Epoch 1, Loss: 1.1146105527877808\n",
      "Epoch 3, Loss: 0.02610062062740326\n",
      "Epoch 2, Loss: 0.017697645351290703\n",
      "Epoch 4, Loss: 0.5942631959915161\n",
      "Epoch 1, Loss: 1.425614833831787\n",
      "Epoch 4, Loss: 0.005669419188052416\n",
      "Epoch 1, Loss: 0.15341812372207642\n",
      "Epoch 3, Loss: 0.03736069053411484\n",
      "Epoch 2, Loss: 0.26098212599754333\n",
      "Epoch 2, Loss: 0.06092076003551483\n",
      "Epoch 4, Loss: 0.13102099299430847\n",
      "Epoch 3, Loss: 0.07378789037466049\n",
      "Epoch 5, Loss: 0.5154643654823303\n",
      "Epoch 4, Loss: 0.0266426894813776\n",
      "Epoch 5, Loss: 0.00866471417248249\n",
      "Epoch 2, Loss: 0.9284772872924805\n",
      "Epoch 3, Loss: 0.00622936524450779\n",
      "Epoch 2, Loss: 1.2642474174499512\n",
      "Epoch 6, Loss: 0.4353960454463959\n",
      "Epoch 4, Loss: 0.03402981907129288\n",
      "Epoch 5, Loss: 0.0785713866353035\n",
      "Epoch 2, Loss: 0.10296899080276489\n",
      "Epoch 3, Loss: 0.2053021639585495\n",
      "Epoch 6, Loss: 0.012940815649926662\n",
      "Epoch 4, Loss: 0.06747625768184662\n",
      "Epoch 5, Loss: 0.0265819001942873\n",
      "Epoch 3, Loss: 0.05010265111923218\n",
      "Epoch 7, Loss: 0.37882086634635925\n",
      "Epoch 4, Loss: 0.00708645349368453\n",
      "Epoch 3, Loss: 0.7573297023773193\n",
      "Epoch 3, Loss: 1.1132254600524902\n",
      "Epoch 7, Loss: 0.015095132403075695\n",
      "Epoch 5, Loss: 0.029372140765190125\n",
      "Epoch 6, Loss: 0.0435270257294178\n",
      "Epoch 4, Loss: 0.1658099740743637\n",
      "Epoch 6, Loss: 0.023263147100806236\n",
      "Epoch 8, Loss: 0.33247461915016174\n",
      "Epoch 5, Loss: 0.014021109789609909\n",
      "Epoch 3, Loss: 0.06621827185153961\n",
      "Epoch 5, Loss: 0.06438872963190079\n",
      "Epoch 4, Loss: 0.04173433780670166\n",
      "Epoch 4, Loss: 0.6081881523132324\n",
      "Epoch 8, Loss: 0.014768806286156178\n",
      "Epoch 6, Loss: 0.023123394697904587\n",
      "Epoch 7, Loss: 0.02502363920211792\n",
      "Epoch 9, Loss: 0.2973824739456177\n",
      "Epoch 7, Loss: 0.018185779452323914\n",
      "Epoch 6, Loss: 0.01789984293282032\n",
      "Epoch 6, Loss: 0.06308478862047195\n",
      "Epoch 5, Loss: 0.13657501339912415\n",
      "Epoch 9, Loss: 0.011879093013703823\n",
      "Epoch 4, Loss: 0.042675334960222244\n",
      "Epoch 4, Loss: 0.9743297696113586\n",
      "Epoch 10, Loss: 0.27340540289878845\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1550496523669898, feed_forward_dim=256, head_dim=8, lr=5.001954492658822e-05, num_heads=2, num_layers=2; total time=   1.1s\n",
      "Epoch 8, Loss: 0.01886071264743805\n",
      "Epoch 8, Loss: 0.01423211395740509\n",
      "Epoch 5, Loss: 0.03409253805875778\n",
      "Epoch 5, Loss: 0.4730582535266876\n",
      "Epoch 7, Loss: 0.06291703879833221\n",
      "Epoch 7, Loss: 0.019217725843191147\n",
      "Epoch 10, Loss: 0.008750604465603828\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1550496523669898, feed_forward_dim=256, head_dim=8, lr=5.001954492658822e-05, num_heads=2, num_layers=2; total time=   1.2s\n",
      "Epoch 7, Loss: 0.01708332449197769\n",
      "Epoch 6, Loss: 0.11904565989971161\n",
      "Epoch 9, Loss: 0.022381028160452843\n",
      "Epoch 5, Loss: 0.03034340776503086\n",
      "Epoch 9, Loss: 0.01211401168256998\n",
      "Epoch 6, Loss: 0.0276237353682518\n",
      "Epoch 5, Loss: 0.8442426919937134\n",
      "Epoch 8, Loss: 0.05727440118789673\n",
      "Epoch 8, Loss: 0.0168478824198246\n",
      "Epoch 6, Loss: 0.3610974848270416\n",
      "Epoch 8, Loss: 0.012899165041744709\n",
      "Epoch 10, Loss: 0.03273245319724083\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1550496523669898, feed_forward_dim=256, head_dim=8, lr=5.001954492658822e-05, num_heads=2, num_layers=2; total time=   1.4s\n",
      "Epoch 7, Loss: 0.1102961078286171\n",
      "Epoch 10, Loss: 0.010902677662670612\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1550496523669898, feed_forward_dim=256, head_dim=8, lr=5.001954492658822e-05, num_heads=2, num_layers=2; total time=   1.4s\n",
      "Epoch 6, Loss: 0.02696234919130802\n",
      "Epoch 7, Loss: 0.022692320868372917\n",
      "Epoch 9, Loss: 0.050426583737134933\n",
      "Epoch 9, Loss: 0.014386747032403946\n",
      "Epoch 6, Loss: 0.7278767824172974\n",
      "Epoch 9, Loss: 0.007996129803359509\n",
      "Epoch 7, Loss: 0.26488709449768066\n",
      "Epoch 10, Loss: 0.013111378997564316\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1550496523669898, feed_forward_dim=256, head_dim=8, lr=5.001954492658822e-05, num_heads=2, num_layers=2; total time=   1.5s\n",
      "Epoch 8, Loss: 0.10673609375953674\n",
      "Epoch 10, Loss: 0.04276011884212494\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1550496523669898, feed_forward_dim=256, head_dim=8, lr=5.001954492658822e-05, num_heads=2, num_layers=2; total time=   1.5s\n",
      "Epoch 8, Loss: 0.01805802434682846\n",
      "Epoch 7, Loss: 0.6221483945846558\n",
      "Epoch 7, Loss: 0.03070610947906971\n",
      "Epoch 10, Loss: 0.00569486478343606\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1550496523669898, feed_forward_dim=256, head_dim=8, lr=5.001954492658822e-05, num_heads=2, num_layers=2; total time=   1.6s\n",
      "Epoch 8, Loss: 0.18623213469982147\n",
      "Epoch 9, Loss: 0.014450641348958015\n",
      "Epoch 9, Loss: 0.10967085510492325\n",
      "Epoch 8, Loss: 0.5304010510444641\n",
      "Epoch 8, Loss: 0.036383435130119324\n",
      "Epoch 9, Loss: 0.12744122743606567\n",
      "Epoch 10, Loss: 0.11004327982664108\n",
      "Epoch 10, Loss: 0.012700355611741543\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1550496523669898, feed_forward_dim=256, head_dim=8, lr=5.001954492658822e-05, num_heads=2, num_layers=2; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1550496523669898, feed_forward_dim=256, head_dim=8, lr=5.001954492658822e-05, num_heads=2, num_layers=2; total time=   1.8s\n",
      "Epoch 9, Loss: 0.4480624198913574\n",
      "Epoch 9, Loss: 0.04112842306494713\n",
      "Epoch 10, Loss: 0.08363387733697891\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1550496523669898, feed_forward_dim=256, head_dim=8, lr=5.001954492658822e-05, num_heads=2, num_layers=2; total time=   1.8s\n",
      "Epoch 10, Loss: 0.37514743208885193\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1550496523669898, feed_forward_dim=256, head_dim=8, lr=5.001954492658822e-05, num_heads=2, num_layers=2; total time=   1.8s\n",
      "Epoch 10, Loss: 0.044500887393951416\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1550496523669898, feed_forward_dim=256, head_dim=8, lr=5.001954492658822e-05, num_heads=2, num_layers=2; total time=   1.8s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 1.7956254482269287\n",
      "Epoch 1, Loss: 0.3316420614719391\n",
      "Epoch 1, Loss: 1.6392536163330078\n",
      "Epoch 2, Loss: 0.4578566253185272\n",
      "Epoch 1, Loss: 0.1461067646741867\n",
      "Epoch 2, Loss: 0.0773724839091301\n",
      "Epoch 1, Loss: 1.8330917358398438\n",
      "Epoch 1, Loss: 1.2334157228469849\n",
      "Epoch 1, Loss: 1.404099464416504\n",
      "Epoch 2, Loss: 0.46879518032073975\n",
      "Epoch 1, Loss: 1.7458828687667847\n",
      "Epoch 3, Loss: 0.020426608622074127\n",
      "Epoch 3, Loss: 0.21228362619876862\n",
      "Epoch 2, Loss: 0.3360990881919861\n",
      "Epoch 2, Loss: 0.41047143936157227\n",
      "Epoch 1, Loss: 0.5907135605812073\n",
      "Epoch 1, Loss: 0.6011629104614258\n",
      "Epoch 3, Loss: 0.07032233476638794\n",
      "Epoch 1, Loss: 0.09087739884853363\n",
      "Epoch 2, Loss: 0.23265139758586884\n",
      "Epoch 4, Loss: 0.1942305862903595\n",
      "Epoch 1, Loss: 0.3397912085056305\n",
      "Epoch 2, Loss: 0.22233110666275024\n",
      "Epoch 4, Loss: 0.12796750664710999\n",
      "Epoch 3, Loss: 0.09117994457483292\n",
      "Epoch 2, Loss: 0.3851637542247772\n",
      "Epoch 3, Loss: 0.10761315375566483\n",
      "Epoch 5, Loss: 0.40758034586906433\n",
      "Epoch 2, Loss: 0.05008222162723541\n",
      "Epoch 4, Loss: 0.19907177984714508\n",
      "Epoch 2, Loss: 0.07820127159357071\n",
      "Epoch 3, Loss: 0.12079457938671112\n",
      "Epoch 5, Loss: 0.029183778911828995\n",
      "Epoch 3, Loss: 0.06113557890057564\n",
      "Epoch 2, Loss: 0.29549509286880493\n",
      "Epoch 4, Loss: 0.10078204423189163\n",
      "Epoch 2, Loss: 0.2284386307001114\n",
      "Epoch 5, Loss: 0.4080089032649994\n",
      "Epoch 6, Loss: 0.43262115120887756\n",
      "Epoch 4, Loss: 0.38472747802734375\n",
      "Epoch 3, Loss: 0.06562045961618423\n",
      "Epoch 6, Loss: 0.026491926982998848\n",
      "Epoch 4, Loss: 0.33312276005744934\n",
      "Epoch 3, Loss: 0.2517886459827423\n",
      "Epoch 4, Loss: 0.34554776549339294\n",
      "Epoch 7, Loss: 0.3278604745864868\n",
      "Epoch 5, Loss: 0.15644684433937073\n",
      "Epoch 6, Loss: 0.4558860957622528\n",
      "Epoch 3, Loss: 0.23512281477451324\n",
      "Epoch 3, Loss: 0.03906887769699097\n",
      "Epoch 7, Loss: 0.0678567960858345\n",
      "Epoch 3, Loss: 0.21215759217739105\n",
      "Epoch 5, Loss: 0.5528794527053833\n",
      "Epoch 4, Loss: 0.30115610361099243\n",
      "Epoch 8, Loss: 0.18443965911865234\n",
      "Epoch 5, Loss: 0.44631287455558777\n",
      "Epoch 4, Loss: 0.30363211035728455\n",
      "Epoch 5, Loss: 0.40995290875434875\n",
      "Epoch 6, Loss: 0.10659115761518478\n",
      "Epoch 8, Loss: 0.07594180107116699\n",
      "Epoch 7, Loss: 0.36990487575531006\n",
      "Epoch 9, Loss: 0.06920468062162399\n",
      "Epoch 6, Loss: 0.4931448698043823\n",
      "Epoch 4, Loss: 0.29376420378685\n",
      "Epoch 4, Loss: 0.11303668469190598\n",
      "Epoch 5, Loss: 0.4744820296764374\n",
      "Epoch 6, Loss: 0.3378557860851288\n",
      "Epoch 4, Loss: 0.10472436994314194\n",
      "Epoch 8, Loss: 0.23875325918197632\n",
      "Epoch 7, Loss: 0.03682179003953934\n",
      "Epoch 9, Loss: 0.04604106396436691\n",
      "Epoch 10, Loss: 0.01213117502629757\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.3385686012177715, feed_forward_dim=128, head_dim=16, lr=0.0003845558716502858, num_heads=4, num_layers=2; total time=   1.1s\n",
      "Epoch 5, Loss: 0.17163366079330444\n",
      "Epoch 6, Loss: 0.34962397813796997\n",
      "Epoch 7, Loss: 0.32970353960990906\n",
      "Epoch 10, Loss: 0.013136535882949829\n",
      "Epoch 9, Loss: 0.12086159735918045\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.3385686012177715, feed_forward_dim=128, head_dim=16, lr=0.0003845558716502858, num_heads=4, num_layers=2; total time=   1.1s\n",
      "Epoch 5, Loss: 0.1919611096382141\n",
      "Epoch 7, Loss: 0.2112530618906021\n",
      "Epoch 5, Loss: 0.14421430230140686\n",
      "Epoch 6, Loss: 0.4484856426715851\n",
      "Epoch 8, Loss: 0.02782747894525528\n",
      "Epoch 5, Loss: 0.05716123431921005\n",
      "Epoch 7, Loss: 0.19139428436756134\n",
      "Epoch 6, Loss: 0.04840388894081116\n",
      "Epoch 8, Loss: 0.16153064370155334\n",
      "Epoch 8, Loss: 0.10103338956832886\n",
      "Epoch 10, Loss: 0.04952188581228256\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.3385686012177715, feed_forward_dim=128, head_dim=16, lr=0.0003845558716502858, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 6, Loss: 0.07639961689710617\n",
      "Epoch 7, Loss: 0.31774747371673584\n",
      "Epoch 6, Loss: 0.053791824728250504\n",
      "Epoch 9, Loss: 0.06312496215105057\n",
      "Epoch 9, Loss: 0.06161476671695709\n",
      "Epoch 6, Loss: 0.06987838447093964\n",
      "Epoch 8, Loss: 0.06873507052659988\n",
      "Epoch 7, Loss: 0.02036084048449993\n",
      "Epoch 9, Loss: 0.04995414614677429\n",
      "Epoch 7, Loss: 0.03797910735011101\n",
      "Epoch 10, Loss: 0.07251778990030289\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.3385686012177715, feed_forward_dim=128, head_dim=16, lr=0.0003845558716502858, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 10, Loss: 0.03650495409965515\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.3385686012177715, feed_forward_dim=128, head_dim=16, lr=0.0003845558716502858, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 7, Loss: 0.006788494531065226\n",
      "Epoch 8, Loss: 0.17319834232330322\n",
      "Epoch 9, Loss: 0.015380388125777245\n",
      "Epoch 8, Loss: 0.06924187391996384\n",
      "Epoch 8, Loss: 0.06525491178035736\n",
      "Epoch 7, Loss: 0.06662381440401077\n",
      "Epoch 10, Loss: 0.053400442004203796\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.3385686012177715, feed_forward_dim=128, head_dim=16, lr=0.0003845558716502858, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 8, Loss: 0.03913571685552597\n",
      "Epoch 9, Loss: 0.06904634088277817\n",
      "Epoch 10, Loss: 0.029883673414587975\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.3385686012177715, feed_forward_dim=128, head_dim=16, lr=0.0003845558716502858, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 0.1128338947892189\n",
      "Epoch 9, Loss: 0.1064702570438385\n",
      "Epoch 8, Loss: 0.035775311291217804\n",
      "Epoch 10, Loss: 0.02841118909418583\n",
      "Epoch 9, Loss: 0.07188564538955688\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.3385686012177715, feed_forward_dim=128, head_dim=16, lr=0.0003845558716502858, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.10969024896621704\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.3385686012177715, feed_forward_dim=128, head_dim=16, lr=0.0003845558716502858, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.11464711278676987\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.3385686012177715, feed_forward_dim=128, head_dim=16, lr=0.0003845558716502858, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 9, Loss: 0.01248844899237156\n",
      "Epoch 10, Loss: 0.05687671899795532\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.3385686012177715, feed_forward_dim=128, head_dim=16, lr=0.0003845558716502858, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.01946237124502659\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.3385686012177715, feed_forward_dim=128, head_dim=16, lr=0.0003845558716502858, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.5655373930931091\n",
      "Epoch 1, Loss: 0.1046062707901001\n",
      "Epoch 1, Loss: 1.1808844804763794\n",
      "Epoch 2, Loss: 0.4510243237018585\n",
      "Epoch 1, Loss: 0.32478174567222595\n",
      "Epoch 2, Loss: 0.0653037577867508\n",
      "Epoch 2, Loss: 1.0274741649627686\n",
      "Epoch 3, Loss: 0.35918307304382324\n",
      "Epoch 2, Loss: 0.28298836946487427\n",
      "Epoch 3, Loss: 0.03892182186245918\n",
      "Epoch 1, Loss: 0.16984814405441284\n",
      "Epoch 4, Loss: 0.27925238013267517\n",
      "Epoch 3, Loss: 0.8785755634307861\n",
      "Epoch 1, Loss: 1.3744577169418335\n",
      "Epoch 3, Loss: 0.2521929442882538\n",
      "Epoch 1, Loss: 0.7426273822784424\n",
      "Epoch 1, Loss: 0.07079681009054184\n",
      "Epoch 4, Loss: 0.028968151658773422\n",
      "Epoch 2, Loss: 0.11162522435188293\n",
      "Epoch 1, Loss: 0.24569690227508545\n",
      "Epoch 5, Loss: 0.21755515038967133\n",
      "Epoch 4, Loss: 0.7498986124992371\n",
      "Epoch 4, Loss: 0.23223532736301422\n",
      "Epoch 5, Loss: 0.028988666832447052\n",
      "Epoch 1, Loss: 0.011225301772356033\n",
      "Epoch 2, Loss: 0.06521358340978622\n",
      "Epoch 1, Loss: 1.5272120237350464\n",
      "Epoch 2, Loss: 1.1398440599441528\n",
      "Epoch 1, Loss: 0.21155637502670288\n",
      "Epoch 6, Loss: 0.17233075201511383\n",
      "Epoch 5, Loss: 0.6270492076873779\n",
      "Epoch 3, Loss: 0.0662754625082016\n",
      "Epoch 2, Loss: 0.6235882043838501\n",
      "Epoch 5, Loss: 0.21167093515396118\n",
      "Epoch 6, Loss: 0.03397464007139206\n",
      "Epoch 2, Loss: 0.1839054822921753\n",
      "Epoch 3, Loss: 0.057473111897706985\n",
      "Epoch 3, Loss: 0.9188383221626282\n",
      "Epoch 2, Loss: 0.010184356942772865\n",
      "Epoch 3, Loss: 0.5077462196350098\n",
      "Epoch 2, Loss: 1.3495588302612305\n",
      "Epoch 2, Loss: 0.16997689008712769\n",
      "Epoch 4, Loss: 0.038575347512960434\n",
      "Epoch 6, Loss: 0.5259706974029541\n",
      "Epoch 7, Loss: 0.038848116993904114\n",
      "Epoch 7, Loss: 0.14153003692626953\n",
      "Epoch 6, Loss: 0.20037376880645752\n",
      "Epoch 4, Loss: 0.05260567367076874\n",
      "Epoch 3, Loss: 0.1349048614501953\n",
      "Epoch 4, Loss: 0.7363120913505554\n",
      "Epoch 8, Loss: 0.041867297142744064\n",
      "Epoch 3, Loss: 1.1825779676437378\n",
      "Epoch 8, Loss: 0.12628173828125\n",
      "Epoch 7, Loss: 0.1865561306476593\n",
      "Epoch 4, Loss: 0.4129605293273926\n",
      "Epoch 5, Loss: 0.024410927668213844\n",
      "Epoch 3, Loss: 0.008873728103935719\n",
      "Epoch 7, Loss: 0.433103084564209\n",
      "Epoch 5, Loss: 0.04803689941763878\n",
      "Epoch 9, Loss: 0.03819050267338753\n",
      "Epoch 9, Loss: 0.11978567391633987\n",
      "Epoch 3, Loss: 0.13927142322063446\n",
      "Epoch 4, Loss: 0.09868154674768448\n",
      "Epoch 5, Loss: 0.5652322769165039\n",
      "Epoch 8, Loss: 0.17345118522644043\n",
      "Epoch 6, Loss: 0.022687548771500587\n",
      "Epoch 8, Loss: 0.3552323579788208\n",
      "Epoch 5, Loss: 0.3227057456970215\n",
      "Epoch 4, Loss: 1.0295366048812866\n",
      "Epoch 10, Loss: 0.03291512653231621\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1769919176121551, feed_forward_dim=512, head_dim=32, lr=5.016575071962374e-05, num_heads=2, num_layers=2; total time=   1.1s\n",
      "Epoch 6, Loss: 0.041320182383060455\n",
      "Epoch 4, Loss: 0.0075891450978815556\n",
      "Epoch 10, Loss: 0.11918485164642334\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1769919176121551, feed_forward_dim=512, head_dim=32, lr=5.016575071962374e-05, num_heads=2, num_layers=2; total time=   1.1s\n",
      "Epoch 9, Loss: 0.16042105853557587\n",
      "Epoch 5, Loss: 0.07485102862119675\n",
      "Epoch 9, Loss: 0.29003217816352844\n",
      "Epoch 7, Loss: 0.027124503627419472\n",
      "Epoch 6, Loss: 0.24619974195957184\n",
      "Epoch 6, Loss: 0.42368730902671814\n",
      "Epoch 4, Loss: 0.11533094942569733\n",
      "Epoch 5, Loss: 0.8918154239654541\n",
      "Epoch 7, Loss: 0.037728115916252136\n",
      "Epoch 10, Loss: 0.14513415098190308\n",
      "Epoch 5, Loss: 0.007340018637478352\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1769919176121551, feed_forward_dim=512, head_dim=32, lr=5.016575071962374e-05, num_heads=2, num_layers=2; total time=   1.2s\n",
      "Epoch 10, Loss: 0.2339322715997696\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1769919176121551, feed_forward_dim=512, head_dim=32, lr=5.016575071962374e-05, num_heads=2, num_layers=2; total time=   1.2s\n",
      "Epoch 6, Loss: 0.062041863799095154\n",
      "Epoch 7, Loss: 0.3022981584072113\n",
      "Epoch 8, Loss: 0.03621390834450722\n",
      "Epoch 7, Loss: 0.18336305022239685\n",
      "Epoch 6, Loss: 0.7596662640571594\n",
      "Epoch 5, Loss: 0.10055047273635864\n",
      "Epoch 8, Loss: 0.034076083451509476\n",
      "Epoch 7, Loss: 0.05756068229675293\n",
      "Epoch 9, Loss: 0.04192177206277847\n",
      "Epoch 6, Loss: 0.006427549757063389\n",
      "Epoch 8, Loss: 0.20915313065052032\n",
      "Epoch 8, Loss: 0.13462772965431213\n",
      "Epoch 7, Loss: 0.6473191380500793\n",
      "Epoch 9, Loss: 0.030382772907614708\n",
      "Epoch 6, Loss: 0.0921793282032013\n",
      "Epoch 10, Loss: 0.04428135231137276\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1769919176121551, feed_forward_dim=512, head_dim=32, lr=5.016575071962374e-05, num_heads=2, num_layers=2; total time=   1.3s\n",
      "Epoch 8, Loss: 0.05883258581161499\n",
      "Epoch 9, Loss: 0.13478520512580872\n",
      "Epoch 10, Loss: 0.026725998148322105\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1769919176121551, feed_forward_dim=512, head_dim=32, lr=5.016575071962374e-05, num_heads=2, num_layers=2; total time=   1.4s\n",
      "Epoch 7, Loss: 0.00564064783975482\n",
      "Epoch 9, Loss: 0.09271936118602753\n",
      "Epoch 8, Loss: 0.5423839688301086\n",
      "Epoch 9, Loss: 0.06423978507518768\n",
      "Epoch 10, Loss: 0.08116024732589722\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1769919176121551, feed_forward_dim=512, head_dim=32, lr=5.016575071962374e-05, num_heads=2, num_layers=2; total time=   1.4s\n",
      "Epoch 7, Loss: 0.08624089509248734\n",
      "Epoch 10, Loss: 0.062474220991134644\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1769919176121551, feed_forward_dim=512, head_dim=32, lr=5.016575071962374e-05, num_heads=2, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 0.4475312829017639\n",
      "Epoch 8, Loss: 0.005303143057972193\n",
      "Epoch 10, Loss: 0.07004271447658539\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1769919176121551, feed_forward_dim=512, head_dim=32, lr=5.016575071962374e-05, num_heads=2, num_layers=2; total time=   1.5s\n",
      "Epoch 8, Loss: 0.08477533608675003\n",
      "Epoch 10, Loss: 0.3718969225883484\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1769919176121551, feed_forward_dim=512, head_dim=32, lr=5.016575071962374e-05, num_heads=2, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 0.005262270104140043\n",
      "Epoch 9, Loss: 0.08319439738988876\n",
      "Epoch 10, Loss: 0.005401705391705036\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1769919176121551, feed_forward_dim=512, head_dim=32, lr=5.016575071962374e-05, num_heads=2, num_layers=2; total time=   1.7s\n",
      "Epoch 10, Loss: 0.07962919771671295\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1769919176121551, feed_forward_dim=512, head_dim=32, lr=5.016575071962374e-05, num_heads=2, num_layers=2; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 1.9539852142333984\n",
      "Epoch 1, Loss: 1.5949786901474\n",
      "Epoch 1, Loss: 0.06328021734952927\n",
      "Epoch 1, Loss: 0.24518857896327972\n",
      "Epoch 2, Loss: 1.5056573152542114\n",
      "Epoch 1, Loss: 1.191185712814331\n",
      "Epoch 2, Loss: 1.1916557550430298\n",
      "Epoch 1, Loss: 0.10246478021144867\n",
      "Epoch 2, Loss: 0.018155528232455254\n",
      "Epoch 1, Loss: 0.7966523766517639\n",
      "Epoch 1, Loss: 0.21015088260173798\n",
      "Epoch 3, Loss: 0.84284907579422\n",
      "Epoch 3, Loss: 1.1135820150375366\n",
      "Epoch 2, Loss: 0.0936577171087265\n",
      "Epoch 1, Loss: 0.3509916365146637\n",
      "Epoch 2, Loss: 0.814080536365509\n",
      "Epoch 2, Loss: 0.026085345074534416\n",
      "Epoch 3, Loss: 0.029392819851636887\n",
      "Epoch 2, Loss: 0.47806936502456665\n",
      "Epoch 4, Loss: 0.7979207634925842\n",
      "Epoch 1, Loss: 0.162246972322464\n",
      "Epoch 4, Loss: 0.5627089738845825\n",
      "Epoch 1, Loss: 0.13983190059661865\n",
      "Epoch 3, Loss: 0.02878224290907383\n",
      "Epoch 3, Loss: 0.5112630724906921\n",
      "Epoch 3, Loss: 0.03229859843850136\n",
      "Epoch 4, Loss: 0.03488646447658539\n",
      "Epoch 2, Loss: 0.14230671525001526\n",
      "Epoch 2, Loss: 0.16037841141223907\n",
      "Epoch 1, Loss: 0.30776992440223694\n",
      "Epoch 5, Loss: 0.5320445895195007\n",
      "Epoch 5, Loss: 0.35584917664527893\n",
      "Epoch 3, Loss: 0.25293228030204773\n",
      "Epoch 5, Loss: 0.022152721881866455\n",
      "Epoch 4, Loss: 0.04015970230102539\n",
      "Epoch 4, Loss: 0.28018537163734436\n",
      "Epoch 2, Loss: 0.07440230995416641\n",
      "Epoch 3, Loss: 0.1237216517329216\n",
      "Epoch 2, Loss: 0.0802994817495346\n",
      "Epoch 4, Loss: 0.052691809833049774\n",
      "Epoch 6, Loss: 0.34524857997894287\n",
      "Epoch 3, Loss: 0.07788710296154022\n",
      "Epoch 6, Loss: 0.20300620794296265\n",
      "Epoch 5, Loss: 0.07397958636283875\n",
      "Epoch 2, Loss: 0.12837383151054382\n",
      "Epoch 4, Loss: 0.11577361077070236\n",
      "Epoch 6, Loss: 0.010153349488973618\n",
      "Epoch 7, Loss: 0.21070869266986847\n",
      "Epoch 5, Loss: 0.048128217458724976\n",
      "Epoch 3, Loss: 0.06247498095035553\n",
      "Epoch 5, Loss: 0.12457537651062012\n",
      "Epoch 7, Loss: 0.10722681134939194\n",
      "Epoch 4, Loss: 0.1269332766532898\n",
      "Epoch 6, Loss: 0.08847546577453613\n",
      "Epoch 4, Loss: 0.08078783750534058\n",
      "Epoch 3, Loss: 0.08566372096538544\n",
      "Epoch 8, Loss: 0.05987459793686867\n",
      "Epoch 8, Loss: 0.13248182833194733\n",
      "Epoch 6, Loss: 0.03893718123435974\n",
      "Epoch 7, Loss: 0.006410098168998957\n",
      "Epoch 5, Loss: 0.05820433795452118\n",
      "Epoch 6, Loss: 0.027858611196279526\n",
      "Epoch 4, Loss: 0.07875111699104309\n",
      "Epoch 7, Loss: 0.0766603946685791\n",
      "Epoch 5, Loss: 0.12313181161880493\n",
      "Epoch 8, Loss: 0.011201714165508747\n",
      "Epoch 3, Loss: 0.06734499335289001\n",
      "Epoch 5, Loss: 0.11576547473669052\n",
      "Epoch 9, Loss: 0.09832055121660233\n",
      "Epoch 9, Loss: 0.05332962051033974\n",
      "Epoch 7, Loss: 0.014242171309888363\n",
      "Epoch 6, Loss: 0.060896843671798706\n",
      "Epoch 7, Loss: 0.008876015432178974\n",
      "Epoch 8, Loss: 0.05024281144142151\n",
      "Epoch 4, Loss: 0.08960849046707153\n",
      "Epoch 9, Loss: 0.014893442392349243\n",
      "Epoch 10, Loss: 0.09597904980182648\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3975377722433915, feed_forward_dim=128, head_dim=32, lr=0.00012386950859086604, num_heads=4, num_layers=4; total time=   1.0s\n",
      "Epoch 5, Loss: 0.07653506845235825\n",
      "Epoch 10, Loss: 0.07105673104524612\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3975377722433915, feed_forward_dim=128, head_dim=32, lr=0.00012386950859086604, num_heads=4, num_layers=4; total time=   1.0s\n",
      "Epoch 6, Loss: 0.10704655200242996\n",
      "Epoch 6, Loss: 0.13586847484111786\n",
      "Epoch 7, Loss: 0.09415175020694733\n",
      "Epoch 9, Loss: 0.02775723859667778\n",
      "Epoch 8, Loss: 0.020392101258039474\n",
      "Epoch 10, Loss: 0.012903929688036442\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3975377722433915, feed_forward_dim=128, head_dim=32, lr=0.00012386950859086604, num_heads=4, num_layers=4; total time=   1.1s\n",
      "Epoch 8, Loss: 0.011949206702411175\n",
      "Epoch 4, Loss: 0.08656017482280731\n",
      "Epoch 7, Loss: 0.08847622573375702\n",
      "Epoch 10, Loss: 0.014974855817854404\n",
      "Epoch 8, Loss: 0.1340433955192566\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3975377722433915, feed_forward_dim=128, head_dim=32, lr=0.00012386950859086604, num_heads=4, num_layers=4; total time=   1.1s\n",
      "Epoch 9, Loss: 0.054648686200380325\n",
      "Epoch 7, Loss: 0.12892043590545654\n",
      "Epoch 5, Loss: 0.07440364360809326\n",
      "Epoch 9, Loss: 0.01760307513177395\n",
      "Epoch 6, Loss: 0.05878373607993126\n",
      "Epoch 9, Loss: 0.16329550743103027\n",
      "Epoch 5, Loss: 0.11861971020698547\n",
      "Epoch 8, Loss: 0.07387441396713257\n",
      "Epoch 10, Loss: 0.09449068456888199\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3975377722433915, feed_forward_dim=128, head_dim=32, lr=0.00012386950859086604, num_heads=4, num_layers=4; total time=   1.2s\n",
      "Epoch 10, Loss: 0.023310057818889618\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3975377722433915, feed_forward_dim=128, head_dim=32, lr=0.00012386950859086604, num_heads=4, num_layers=4; total time=   1.2s\n",
      "Epoch 6, Loss: 0.053857866674661636\n",
      "Epoch 8, Loss: 0.1037631630897522\n",
      "Epoch 7, Loss: 0.03794018551707268\n",
      "Epoch 10, Loss: 0.1693798452615738\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3975377722433915, feed_forward_dim=128, head_dim=32, lr=0.00012386950859086604, num_heads=4, num_layers=4; total time=   1.2s\n",
      "Epoch 6, Loss: 0.12510770559310913\n",
      "Epoch 9, Loss: 0.06367143988609314\n",
      "Epoch 8, Loss: 0.024822713807225227\n",
      "Epoch 9, Loss: 0.07373515516519547\n",
      "Epoch 7, Loss: 0.04304550215601921\n",
      "Epoch 10, Loss: 0.05952253192663193\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3975377722433915, feed_forward_dim=128, head_dim=32, lr=0.00012386950859086604, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 7, Loss: 0.10182804614305496\n",
      "Epoch 10, Loss: 0.05130593851208687\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3975377722433915, feed_forward_dim=128, head_dim=32, lr=0.00012386950859086604, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 9, Loss: 0.022036977112293243\n",
      "Epoch 8, Loss: 0.04120737686753273\n",
      "Epoch 8, Loss: 0.07117519527673721\n",
      "Epoch 10, Loss: 0.0244129728525877\n",
      "Epoch 9, Loss: 0.040000345557928085\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3975377722433915, feed_forward_dim=128, head_dim=32, lr=0.00012386950859086604, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 9, Loss: 0.04452918469905853\n",
      "Epoch 10, Loss: 0.03637835383415222\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3975377722433915, feed_forward_dim=128, head_dim=32, lr=0.00012386950859086604, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.032063256949186325\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3975377722433915, feed_forward_dim=128, head_dim=32, lr=0.00012386950859086604, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.1483718305826187\n",
      "Epoch 1, Loss: 0.8677048087120056\n",
      "Epoch 1, Loss: 0.7837228775024414\n",
      "Epoch 1, Loss: 0.6247902512550354\n",
      "Epoch 2, Loss: 0.11516394466161728\n",
      "Epoch 1, Loss: 0.151839479804039\n",
      "Epoch 2, Loss: 0.7331869006156921\n",
      "Epoch 2, Loss: 0.6462307572364807\n",
      "Epoch 1, Loss: 1.7640020847320557\n",
      "Epoch 3, Loss: 0.09515831619501114\n",
      "Epoch 1, Loss: 0.4899718761444092\n",
      "Epoch 3, Loss: 0.6119447946548462\n",
      "Epoch 2, Loss: 0.5191905498504639\n",
      "Epoch 1, Loss: 0.385202556848526\n",
      "Epoch 1, Loss: 0.5991942286491394\n",
      "Epoch 2, Loss: 0.14388301968574524\n",
      "Epoch 1, Loss: 0.7628185153007507\n",
      "Epoch 4, Loss: 0.5053487420082092\n",
      "Epoch 3, Loss: 0.5282126665115356\n",
      "Epoch 1, Loss: 1.3829655647277832\n",
      "Epoch 2, Loss: 1.52700674533844\n",
      "Epoch 4, Loss: 0.08569809049367905\n",
      "Epoch 3, Loss: 0.43173688650131226\n",
      "Epoch 2, Loss: 0.38186708092689514\n",
      "Epoch 3, Loss: 0.12779800593852997\n",
      "Epoch 1, Loss: 0.07884839177131653\n",
      "Epoch 4, Loss: 0.4188864827156067\n",
      "Epoch 5, Loss: 0.4106404483318329\n",
      "Epoch 2, Loss: 0.4799557328224182\n",
      "Epoch 2, Loss: 0.32283881306648254\n",
      "Epoch 5, Loss: 0.07805692404508591\n",
      "Epoch 4, Loss: 0.35275909304618835\n",
      "Epoch 3, Loss: 1.3010761737823486\n",
      "Epoch 2, Loss: 0.6361347436904907\n",
      "Epoch 6, Loss: 0.3345627784729004\n",
      "Epoch 2, Loss: 1.1760320663452148\n",
      "Epoch 4, Loss: 0.12264802306890488\n",
      "Epoch 6, Loss: 0.07418366521596909\n",
      "Epoch 5, Loss: 0.32223761081695557\n",
      "Epoch 3, Loss: 0.29934772849082947\n",
      "Epoch 3, Loss: 0.3738185167312622\n",
      "Epoch 3, Loss: 0.26707541942596436\n",
      "Epoch 2, Loss: 0.0640396997332573\n",
      "Epoch 4, Loss: 1.085416555404663\n",
      "Epoch 5, Loss: 0.2777465879917145\n",
      "Epoch 7, Loss: 0.2718772292137146\n",
      "Epoch 7, Loss: 0.07031180709600449\n",
      "Epoch 5, Loss: 0.11046578735113144\n",
      "Epoch 6, Loss: 0.2457267791032791\n",
      "Epoch 3, Loss: 0.5274001359939575\n",
      "Epoch 4, Loss: 0.28722256422042847\n",
      "Epoch 3, Loss: 0.9941827654838562\n",
      "Epoch 5, Loss: 0.9008342623710632\n",
      "Epoch 8, Loss: 0.06601026654243469\n",
      "Epoch 4, Loss: 0.23518440127372742\n",
      "Epoch 8, Loss: 0.21964451670646667\n",
      "Epoch 4, Loss: 0.22786320745944977\n",
      "Epoch 6, Loss: 0.21720625460147858\n",
      "Epoch 6, Loss: 0.10349550098180771\n",
      "Epoch 3, Loss: 0.0573703795671463\n",
      "Epoch 7, Loss: 0.17812874913215637\n",
      "Epoch 9, Loss: 0.05959958955645561\n",
      "Epoch 9, Loss: 0.18275447189807892\n",
      "Epoch 5, Loss: 0.21732372045516968\n",
      "Epoch 4, Loss: 0.42305096983909607\n",
      "Epoch 5, Loss: 0.19365747272968292\n",
      "Epoch 6, Loss: 0.7376575469970703\n",
      "Epoch 4, Loss: 0.8207594156265259\n",
      "Epoch 7, Loss: 0.09379450231790543\n",
      "Epoch 7, Loss: 0.1641256958246231\n",
      "Epoch 10, Loss: 0.053732167929410934\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=8, num_layers=3; total time=   1.0s\n",
      "Epoch 8, Loss: 0.12473379075527191\n",
      "Epoch 5, Loss: 0.20008088648319244\n",
      "Epoch 4, Loss: 0.04730435460805893\n",
      "Epoch 10, Loss: 0.1532808095216751\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=8, num_layers=3; total time=   1.1s\n",
      "Epoch 8, Loss: 0.08805807679891586\n",
      "Epoch 5, Loss: 0.6689162850379944\n",
      "Epoch 7, Loss: 0.58619225025177\n",
      "Epoch 6, Loss: 0.1665290743112564\n",
      "Epoch 9, Loss: 0.08199366182088852\n",
      "Epoch 8, Loss: 0.1236688494682312\n",
      "Epoch 6, Loss: 0.16032512485980988\n",
      "Epoch 6, Loss: 0.18211278319358826\n",
      "Epoch 5, Loss: 0.3353155851364136\n",
      "Epoch 9, Loss: 0.0802028700709343\n",
      "Epoch 5, Loss: 0.03827071562409401\n",
      "Epoch 10, Loss: 0.05227147787809372\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=8, num_layers=3; total time=   1.2s\n",
      "Epoch 8, Loss: 0.46479591727256775\n",
      "Epoch 6, Loss: 0.5354896187782288\n",
      "Epoch 7, Loss: 0.17167696356773376\n",
      "Epoch 9, Loss: 0.08977854251861572\n",
      "Epoch 7, Loss: 0.15613383054733276\n",
      "Epoch 10, Loss: 0.07233825325965881\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=8, num_layers=3; total time=   1.2s\n",
      "Epoch 6, Loss: 0.2599903643131256\n",
      "Epoch 7, Loss: 0.11686557531356812\n",
      "Epoch 9, Loss: 0.35573500394821167\n",
      "Epoch 10, Loss: 0.06223231181502342\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 6, Loss: 0.03169199079275131\n",
      "Epoch 8, Loss: 0.16680599749088287\n",
      "Epoch 8, Loss: 0.15561708807945251\n",
      "Epoch 7, Loss: 0.41389578580856323\n",
      "Epoch 7, Loss: 0.19433943927288055\n",
      "Epoch 8, Loss: 0.08664344996213913\n",
      "Epoch 10, Loss: 0.2650666832923889\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.1632944494485855\n",
      "Epoch 9, Loss: 0.15757636725902557\n",
      "Epoch 8, Loss: 0.31243497133255005\n",
      "Epoch 9, Loss: 0.06767429411411285\n",
      "Epoch 8, Loss: 0.14441503584384918\n",
      "Epoch 7, Loss: 0.025361765176057816\n",
      "Epoch 10, Loss: 0.1632111370563507\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.16362951695919037\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 9, Loss: 0.2299083173274994\n",
      "Epoch 10, Loss: 0.06181639805436134\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 9, Loss: 0.10149094462394714\n",
      "Epoch 8, Loss: 0.021316468715667725\n",
      "Epoch 10, Loss: 0.15751582384109497\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.068875752389431\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=8, num_layers=3; total time=   1.6s\n",
      "Epoch 9, Loss: 0.016053710132837296\n",
      "Epoch 10, Loss: 0.012294144369661808\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=8, num_layers=3; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.2089097946882248\n",
      "Epoch 1, Loss: 0.7000298500061035\n",
      "Epoch 1, Loss: 0.6764965653419495\n",
      "Epoch 2, Loss: 0.4483669698238373\n",
      "Epoch 1, Loss: 0.2642635703086853\n",
      "Epoch 1, Loss: 0.18283280730247498\n",
      "Epoch 1, Loss: 2.6254889965057373\n",
      "Epoch 2, Loss: 0.4470459818840027\n",
      "Epoch 2, Loss: 0.10183396190404892\n",
      "Epoch 1, Loss: 1.2517645359039307\n",
      "Epoch 1, Loss: 1.8558059930801392\n",
      "Epoch 3, Loss: 0.17514419555664062\n",
      "Epoch 3, Loss: 0.41398581862449646\n",
      "Epoch 2, Loss: 0.19898608326911926\n",
      "Epoch 3, Loss: 0.4087468385696411\n",
      "Epoch 1, Loss: 1.3435758352279663\n",
      "Epoch 2, Loss: 0.30700093507766724\n",
      "Epoch 1, Loss: 0.963314414024353\n",
      "Epoch 4, Loss: 0.025480736047029495\n",
      "Epoch 2, Loss: 0.03445829078555107\n",
      "Epoch 1, Loss: 0.3600514829158783\n",
      "Epoch 2, Loss: 0.49641677737236023\n",
      "Epoch 4, Loss: 0.2883741557598114\n",
      "Epoch 4, Loss: 0.14156606793403625\n",
      "Epoch 3, Loss: 0.20949706435203552\n",
      "Epoch 3, Loss: 0.17698374390602112\n",
      "Epoch 2, Loss: 0.17887316644191742\n",
      "Epoch 1, Loss: 0.42520883679389954\n",
      "Epoch 5, Loss: 0.12284620106220245\n",
      "Epoch 2, Loss: 0.16790691018104553\n",
      "Epoch 3, Loss: 0.5078533291816711\n",
      "Epoch 3, Loss: 0.16226060688495636\n",
      "Epoch 5, Loss: 0.08226148784160614\n",
      "Epoch 5, Loss: 0.04646598920226097\n",
      "Epoch 4, Loss: 0.028281625360250473\n",
      "Epoch 2, Loss: 0.06777840852737427\n",
      "Epoch 2, Loss: 0.6629058122634888\n",
      "Epoch 4, Loss: 0.6243505477905273\n",
      "Epoch 6, Loss: 0.16093724966049194\n",
      "Epoch 3, Loss: 0.30733731389045715\n",
      "Epoch 4, Loss: 0.5239541530609131\n",
      "Epoch 3, Loss: 0.2579946219921112\n",
      "Epoch 2, Loss: 0.2307412028312683\n",
      "Epoch 6, Loss: 0.01837729848921299\n",
      "Epoch 7, Loss: 0.08841074258089066\n",
      "Epoch 4, Loss: 0.02600519172847271\n",
      "Epoch 5, Loss: 0.027540132403373718\n",
      "Epoch 5, Loss: 0.6487848162651062\n",
      "Epoch 6, Loss: 0.12061919271945953\n",
      "Epoch 3, Loss: 0.40918684005737305\n",
      "Epoch 4, Loss: 0.6155276298522949\n",
      "Epoch 3, Loss: 0.2350439876317978\n",
      "Epoch 8, Loss: 0.02061758190393448\n",
      "Epoch 7, Loss: 0.07964446395635605\n",
      "Epoch 6, Loss: 0.4398657977581024\n",
      "Epoch 6, Loss: 0.08531171083450317\n",
      "Epoch 5, Loss: 0.15416394174098969\n",
      "Epoch 7, Loss: 0.15698768198490143\n",
      "Epoch 4, Loss: 0.4544562101364136\n",
      "Epoch 3, Loss: 0.2889752686023712\n",
      "Epoch 5, Loss: 0.2418394684791565\n",
      "Epoch 9, Loss: 0.015455818735063076\n",
      "Epoch 4, Loss: 0.40042582154273987\n",
      "Epoch 8, Loss: 0.14430950582027435\n",
      "Epoch 7, Loss: 0.21042047441005707\n",
      "Epoch 7, Loss: 0.08494409173727036\n",
      "Epoch 8, Loss: 0.09339440613985062\n",
      "Epoch 5, Loss: 0.5141971111297607\n",
      "Epoch 10, Loss: 0.048864416778087616\n",
      "Epoch 6, Loss: 0.17293384671211243\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.28136855419336426, feed_forward_dim=128, head_dim=16, lr=0.0006064837310300905, num_heads=8, num_layers=3; total time=   1.1s\n",
      "Epoch 4, Loss: 0.0825398713350296\n",
      "Epoch 6, Loss: 0.03962250053882599\n",
      "Epoch 5, Loss: 0.36637362837791443\n",
      "Epoch 9, Loss: 0.13898830115795135\n",
      "Epoch 4, Loss: 0.12371959537267685\n",
      "Epoch 8, Loss: 0.06708309799432755\n",
      "Epoch 9, Loss: 0.026583489030599594\n",
      "Epoch 5, Loss: 0.18432170152664185\n",
      "Epoch 8, Loss: 0.04473959654569626\n",
      "Epoch 6, Loss: 0.2664073705673218\n",
      "Epoch 7, Loss: 0.07928876578807831\n",
      "Epoch 10, Loss: 0.08400832861661911\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.28136855419336426, feed_forward_dim=128, head_dim=16, lr=0.0006064837310300905, num_heads=8, num_layers=3; total time=   1.2s\n",
      "Epoch 7, Loss: 0.02590697444975376\n",
      "Epoch 6, Loss: 0.19822648167610168\n",
      "Epoch 5, Loss: 0.1843147873878479\n",
      "Epoch 9, Loss: 0.03057902492582798\n",
      "Epoch 10, Loss: 0.015590917319059372\n",
      "Epoch 9, Loss: 0.010393335483968258\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.28136855419336426, feed_forward_dim=128, head_dim=16, lr=0.0006064837310300905, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 5, Loss: 0.03578877076506615\n",
      "Epoch 8, Loss: 0.11716092377901077\n",
      "Epoch 6, Loss: 0.03760183975100517\n",
      "Epoch 8, Loss: 0.012097424827516079\n",
      "Epoch 6, Loss: 0.1832900196313858\n",
      "Epoch 10, Loss: 0.07034040987491608\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.28136855419336426, feed_forward_dim=128, head_dim=16, lr=0.0006064837310300905, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Epoch 7, Loss: 0.09285718202590942\n",
      "Epoch 7, Loss: 0.07317216694355011\n",
      "Epoch 10, Loss: 0.010125800967216492\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.28136855419336426, feed_forward_dim=128, head_dim=16, lr=0.0006064837310300905, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.02136184088885784\n",
      "Epoch 9, Loss: 0.18669942021369934\n",
      "Epoch 7, Loss: 0.03193721920251846\n",
      "Epoch 7, Loss: 0.07813439518213272\n",
      "Epoch 8, Loss: 0.03937886655330658\n",
      "Epoch 6, Loss: 0.06794922053813934\n",
      "Epoch 10, Loss: 0.06551611423492432\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.28136855419336426, feed_forward_dim=128, head_dim=16, lr=0.0006064837310300905, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 8, Loss: 0.044107697904109955\n",
      "Epoch 8, Loss: 0.09691061824560165\n",
      "Epoch 8, Loss: 0.015165611170232296\n",
      "Epoch 10, Loss: 0.18443714082241058\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.28136855419336426, feed_forward_dim=128, head_dim=16, lr=0.0006064837310300905, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 9, Loss: 0.068203866481781\n",
      "Epoch 7, Loss: 0.10669860243797302\n",
      "Epoch 9, Loss: 0.08661995083093643\n",
      "Epoch 9, Loss: 0.038968272507190704\n",
      "Epoch 9, Loss: 0.1415156126022339\n",
      "Epoch 10, Loss: 0.11478079110383987\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.28136855419336426, feed_forward_dim=128, head_dim=16, lr=0.0006064837310300905, num_heads=8, num_layers=3; total time=   1.6s\n",
      "Epoch 8, Loss: 0.08405990153551102\n",
      "Epoch 10, Loss: 0.1484030932188034\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.28136855419336426, feed_forward_dim=128, head_dim=16, lr=0.0006064837310300905, num_heads=8, num_layers=3; total time=   1.7s\n",
      "Epoch 10, Loss: 0.08620714396238327\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.28136855419336426, feed_forward_dim=128, head_dim=16, lr=0.0006064837310300905, num_heads=8, num_layers=3; total time=   1.6s\n",
      "Epoch 10, Loss: 0.13173890113830566\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.28136855419336426, feed_forward_dim=128, head_dim=16, lr=0.0006064837310300905, num_heads=8, num_layers=3; total time=   1.6s\n",
      "Epoch 9, Loss: 0.034052129834890366\n",
      "Epoch 10, Loss: 0.008562739938497543\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.28136855419336426, feed_forward_dim=128, head_dim=16, lr=0.0006064837310300905, num_heads=8, num_layers=3; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.16200177371501923\n",
      "Epoch 1, Loss: 0.159171462059021\n",
      "Epoch 2, Loss: 0.03454313799738884\n",
      "Epoch 1, Loss: 0.21978254616260529\n",
      "Epoch 1, Loss: 2.1257801055908203\n",
      "Epoch 1, Loss: 0.47499987483024597\n",
      "Epoch 2, Loss: 0.033123381435871124\n",
      "Epoch 1, Loss: 0.3172758221626282\n",
      "Epoch 3, Loss: 0.004478583578020334\n",
      "Epoch 1, Loss: 0.28086575865745544\n",
      "Epoch 1, Loss: 0.3364919424057007\n",
      "Epoch 4, Loss: 0.03366308659315109\n",
      "Epoch 3, Loss: 0.00802901666611433\n",
      "Epoch 2, Loss: 0.1097271516919136\n",
      "Epoch 1, Loss: 1.937461256980896\n",
      "Epoch 2, Loss: 0.23897282779216766\n",
      "Epoch 2, Loss: 1.5558432340621948\n",
      "Epoch 2, Loss: 0.13812318444252014\n",
      "Epoch 1, Loss: 0.5935187935829163\n",
      "Epoch 5, Loss: 0.057643551379442215\n",
      "Epoch 1, Loss: 0.4345631003379822\n",
      "Epoch 3, Loss: 0.09594926983118057\n",
      "Epoch 4, Loss: 0.03700389713048935\n",
      "Epoch 2, Loss: 0.12061218917369843\n",
      "Epoch 2, Loss: 0.17271652817726135\n",
      "Epoch 3, Loss: 0.07415111362934113\n",
      "Epoch 3, Loss: 1.078966498374939\n",
      "Epoch 3, Loss: 0.05765989050269127\n",
      "Epoch 1, Loss: 0.17746810615062714\n",
      "Epoch 6, Loss: 0.05615008994936943\n",
      "Epoch 2, Loss: 1.4115643501281738\n",
      "Epoch 4, Loss: 0.038961511105298996\n",
      "Epoch 5, Loss: 0.06071270629763603\n",
      "Epoch 2, Loss: 0.3402034640312195\n",
      "Epoch 2, Loss: 0.24253538250923157\n",
      "Epoch 4, Loss: 0.08080083131790161\n",
      "Epoch 3, Loss: 0.03944970294833183\n",
      "Epoch 4, Loss: 0.05401383340358734\n",
      "Epoch 4, Loss: 0.6995710730552673\n",
      "Epoch 7, Loss: 0.035034723579883575\n",
      "Epoch 3, Loss: 0.07908384501934052\n",
      "Epoch 6, Loss: 0.05408037453889847\n",
      "Epoch 3, Loss: 0.9699621200561523\n",
      "Epoch 5, Loss: 0.04951469227671623\n",
      "Epoch 5, Loss: 0.09495310485363007\n",
      "Epoch 3, Loss: 0.1723429262638092\n",
      "Epoch 8, Loss: 0.014334715902805328\n",
      "Epoch 3, Loss: 0.14137277007102966\n",
      "Epoch 2, Loss: 0.0985247939825058\n",
      "Epoch 4, Loss: 0.025408035144209862\n",
      "Epoch 7, Loss: 0.033967357128858566\n",
      "Epoch 4, Loss: 0.0559961199760437\n",
      "Epoch 5, Loss: 0.08196879923343658\n",
      "Epoch 5, Loss: 0.42285066843032837\n",
      "Epoch 6, Loss: 0.09234157204627991\n",
      "Epoch 4, Loss: 0.6097468137741089\n",
      "Epoch 9, Loss: 0.004015268292278051\n",
      "Epoch 6, Loss: 0.08619070798158646\n",
      "Epoch 8, Loss: 0.014645314775407314\n",
      "Epoch 5, Loss: 0.05036165192723274\n",
      "Epoch 4, Loss: 0.11160185933113098\n",
      "Epoch 4, Loss: 0.08429558575153351\n",
      "Epoch 6, Loss: 0.24094153940677643\n",
      "Epoch 6, Loss: 0.10176984965801239\n",
      "Epoch 3, Loss: 0.1081404834985733\n",
      "Epoch 10, Loss: 0.005049651488661766\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3497191424820648, feed_forward_dim=1024, head_dim=8, lr=0.000125689925133785, num_heads=4, num_layers=2; total time=   1.0s\n",
      "Epoch 5, Loss: 0.0734640583395958\n",
      "Epoch 7, Loss: 0.07764492183923721\n",
      "Epoch 7, Loss: 0.11539813131093979\n",
      "Epoch 9, Loss: 0.005220795050263405\n",
      "Epoch 5, Loss: 0.34044983983039856\n",
      "Epoch 6, Loss: 0.0771172046661377\n",
      "Epoch 7, Loss: 0.10366006195545197\n",
      "Epoch 7, Loss: 0.14467772841453552\n",
      "Epoch 5, Loss: 0.0598861463367939\n",
      "Epoch 8, Loss: 0.05722315236926079\n",
      "Epoch 5, Loss: 0.12685808539390564\n",
      "Epoch 8, Loss: 0.12666510045528412\n",
      "Epoch 6, Loss: 0.09779064357280731\n",
      "Epoch 4, Loss: 0.11115958541631699\n",
      "Epoch 10, Loss: 0.0075691803358495235\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3497191424820648, feed_forward_dim=1024, head_dim=8, lr=0.000125689925133785, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 8, Loss: 0.11767996102571487\n",
      "Epoch 9, Loss: 0.04056848958134651\n",
      "Epoch 6, Loss: 0.1555476039648056\n",
      "Epoch 8, Loss: 0.08107603341341019\n",
      "Epoch 6, Loss: 0.07567699253559113\n",
      "Epoch 7, Loss: 0.11066251248121262\n",
      "Epoch 9, Loss: 0.13626061379909515\n",
      "Epoch 7, Loss: 0.08628138899803162\n",
      "Epoch 6, Loss: 0.14671318233013153\n",
      "Epoch 10, Loss: 0.029348045587539673\n",
      "Epoch 9, Loss: 0.11438698321580887\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3497191424820648, feed_forward_dim=1024, head_dim=8, lr=0.000125689925133785, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 9, Loss: 0.056105099618434906\n",
      "Epoch 7, Loss: 0.05735041946172714\n",
      "Epoch 10, Loss: 0.1786321997642517\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3497191424820648, feed_forward_dim=1024, head_dim=8, lr=0.000125689925133785, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 8, Loss: 0.10325281322002411\n",
      "Epoch 5, Loss: 0.08809438347816467\n",
      "Epoch 7, Loss: 0.1510128229856491\n",
      "Epoch 10, Loss: 0.03386946767568588\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3497191424820648, feed_forward_dim=1024, head_dim=8, lr=0.000125689925133785, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 8, Loss: 0.07596415281295776\n",
      "Epoch 10, Loss: 0.08858443051576614\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3497191424820648, feed_forward_dim=1024, head_dim=8, lr=0.000125689925133785, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 7, Loss: 0.10539492964744568\n",
      "Epoch 8, Loss: 0.02831057645380497\n",
      "Epoch 6, Loss: 0.06173728033900261\n",
      "Epoch 9, Loss: 0.08603495359420776\n",
      "Epoch 8, Loss: 0.13885164260864258\n",
      "Epoch 9, Loss: 0.05625505372881889\n",
      "Epoch 9, Loss: 0.049798641353845596\n",
      "Epoch 8, Loss: 0.13041390478610992\n",
      "Epoch 10, Loss: 0.06293673813343048\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3497191424820648, feed_forward_dim=1024, head_dim=8, lr=0.000125689925133785, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.03512386977672577\n",
      "Epoch 7, Loss: 0.049824971705675125\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3497191424820648, feed_forward_dim=1024, head_dim=8, lr=0.000125689925133785, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 0.11305086314678192\n",
      "Epoch 10, Loss: 0.09951958060264587\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3497191424820648, feed_forward_dim=1024, head_dim=8, lr=0.000125689925133785, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 0.1401435136795044\n",
      "Epoch 8, Loss: 0.0479518286883831\n",
      "Epoch 10, Loss: 0.13422498106956482\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3497191424820648, feed_forward_dim=1024, head_dim=8, lr=0.000125689925133785, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.08526594191789627\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3497191424820648, feed_forward_dim=1024, head_dim=8, lr=0.000125689925133785, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 9, Loss: 0.04954635724425316\n",
      "Epoch 10, Loss: 0.044430118054151535\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3497191424820648, feed_forward_dim=1024, head_dim=8, lr=0.000125689925133785, num_heads=4, num_layers=2; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 1.4761518239974976\n",
      "Epoch 1, Loss: 3.1915078163146973\n",
      "Epoch 1, Loss: 0.3496595323085785\n",
      "Epoch 1, Loss: 0.08902915567159653\n",
      "Epoch 1, Loss: 0.26506495475769043\n",
      "Epoch 2, Loss: 0.9708700180053711\n",
      "Epoch 2, Loss: 0.07130678743124008\n",
      "Epoch 1, Loss: 0.4903090000152588\n",
      "Epoch 1, Loss: 0.27745261788368225\n",
      "Epoch 2, Loss: 2.140188694000244\n",
      "Epoch 1, Loss: 0.08221524953842163\n",
      "Epoch 2, Loss: 1.3000246286392212\n",
      "Epoch 1, Loss: 0.876092255115509\n",
      "Epoch 2, Loss: 3.0327842235565186\n",
      "Epoch 3, Loss: 0.867602527141571\n",
      "Epoch 3, Loss: 0.8341792225837708\n",
      "Epoch 1, Loss: 0.05519307404756546\n",
      "Epoch 1, Loss: 0.04751349613070488\n",
      "Epoch 2, Loss: 1.2546868324279785\n",
      "Epoch 4, Loss: 0.2337910681962967\n",
      "Epoch 3, Loss: 0.38747021555900574\n",
      "Epoch 1, Loss: 0.2927054464817047\n",
      "Epoch 3, Loss: 0.5838189125061035\n",
      "Epoch 2, Loss: 2.146580457687378\n",
      "Epoch 3, Loss: 0.3022100627422333\n",
      "Epoch 4, Loss: 0.7760200500488281\n",
      "Epoch 2, Loss: 2.7079126834869385\n",
      "Epoch 5, Loss: 0.05636206641793251\n",
      "Epoch 2, Loss: 0.6792448163032532\n",
      "Epoch 4, Loss: 0.025005411356687546\n",
      "Epoch 2, Loss: 2.7265284061431885\n",
      "Epoch 4, Loss: 0.020188460126519203\n",
      "Epoch 3, Loss: 0.590840756893158\n",
      "Epoch 6, Loss: 0.21902237832546234\n",
      "Epoch 4, Loss: 0.38326913118362427\n",
      "Epoch 2, Loss: 0.3517923951148987\n",
      "Epoch 5, Loss: 0.3750343918800354\n",
      "Epoch 2, Loss: 2.6315338611602783\n",
      "Epoch 3, Loss: 0.6034528613090515\n",
      "Epoch 3, Loss: 0.38495779037475586\n",
      "Epoch 5, Loss: 0.22503702342510223\n",
      "Epoch 3, Loss: 0.49667927622795105\n",
      "Epoch 7, Loss: 0.3175879418849945\n",
      "Epoch 6, Loss: 0.09014516323804855\n",
      "Epoch 3, Loss: 0.1133214607834816\n",
      "Epoch 5, Loss: 0.8123692274093628\n",
      "Epoch 4, Loss: 0.06165633350610733\n",
      "Epoch 4, Loss: 0.039566561579704285\n",
      "Epoch 5, Loss: 0.3467439115047455\n",
      "Epoch 4, Loss: 0.15388581156730652\n",
      "Epoch 8, Loss: 0.23481149971485138\n",
      "Epoch 3, Loss: 0.5584776401519775\n",
      "Epoch 3, Loss: 1.1441105604171753\n",
      "Epoch 7, Loss: 0.03979533538222313\n",
      "Epoch 6, Loss: 0.33188357949256897\n",
      "Epoch 6, Loss: 0.5498366951942444\n",
      "Epoch 4, Loss: 0.1107071116566658\n",
      "Epoch 4, Loss: 0.7298495769500732\n",
      "Epoch 6, Loss: 0.49122169613838196\n",
      "Epoch 9, Loss: 0.10675092041492462\n",
      "Epoch 5, Loss: 0.4564152956008911\n",
      "Epoch 5, Loss: 0.12893544137477875\n",
      "Epoch 7, Loss: 0.2320314198732376\n",
      "Epoch 5, Loss: 0.6633683443069458\n",
      "Epoch 8, Loss: 0.1331084817647934\n",
      "Epoch 7, Loss: 0.33377334475517273\n",
      "Epoch 4, Loss: 0.09527707099914551\n",
      "Epoch 7, Loss: 0.19660241901874542\n",
      "Epoch 10, Loss: 0.030302759259939194\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.12652207292420395, feed_forward_dim=256, head_dim=16, lr=0.0011746209545373519, num_heads=8, num_layers=2; total time=   1.0s\n",
      "Epoch 4, Loss: 0.28949445486068726\n",
      "Epoch 6, Loss: 0.5559940338134766\n",
      "Epoch 5, Loss: 0.042983025312423706\n",
      "Epoch 9, Loss: 0.22514241933822632\n",
      "Epoch 6, Loss: 0.6071716547012329\n",
      "Epoch 6, Loss: 0.3154507577419281\n",
      "Epoch 5, Loss: 0.9528616070747375\n",
      "Epoch 8, Loss: 0.12495534867048264\n",
      "Epoch 8, Loss: 0.03886793553829193\n",
      "Epoch 8, Loss: 0.09261884540319443\n",
      "Epoch 7, Loss: 0.3129538297653198\n",
      "Epoch 9, Loss: 0.027379853650927544\n",
      "Epoch 5, Loss: 0.03369567170739174\n",
      "Epoch 7, Loss: 0.29237955808639526\n",
      "Epoch 10, Loss: 0.24105732142925262\n",
      "Epoch 5, Loss: 0.5402494072914124\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.12652207292420395, feed_forward_dim=256, head_dim=16, lr=0.0011746209545373519, num_heads=8, num_layers=2; total time=   1.2s\n",
      "Epoch 9, Loss: 0.0766659751534462\n",
      "Epoch 9, Loss: 0.02607744373381138\n",
      "Epoch 6, Loss: 0.13689441978931427\n",
      "Epoch 6, Loss: 0.5187734961509705\n",
      "Epoch 7, Loss: 0.3033245801925659\n",
      "Epoch 8, Loss: 0.08951722085475922\n",
      "Epoch 10, Loss: 0.04584439471364021\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.12652207292420395, feed_forward_dim=256, head_dim=16, lr=0.0011746209545373519, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 10, Loss: 0.17743325233459473\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.12652207292420395, feed_forward_dim=256, head_dim=16, lr=0.0011746209545373519, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 8, Loss: 0.1504107564687729\n",
      "Epoch 10, Loss: 0.040866609662771225\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.12652207292420395, feed_forward_dim=256, head_dim=16, lr=0.0011746209545373519, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 8, Loss: 0.07625408470630646\n",
      "Epoch 7, Loss: 0.18905481696128845\n",
      "Epoch 6, Loss: 0.6239122152328491\n",
      "Epoch 7, Loss: 0.12980197370052338\n",
      "Epoch 9, Loss: 0.04310555011034012\n",
      "Epoch 9, Loss: 0.023639243096113205\n",
      "Epoch 6, Loss: 0.2792854905128479\n",
      "Epoch 9, Loss: 0.015413914807140827\n",
      "Epoch 8, Loss: 0.15123233199119568\n",
      "Epoch 8, Loss: 0.016155799850821495\n",
      "Epoch 10, Loss: 0.01897471398115158\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.12652207292420395, feed_forward_dim=256, head_dim=16, lr=0.0011746209545373519, num_heads=8, num_layers=2; total time=   1.5s\n",
      "Epoch 7, Loss: 0.3951587677001953\n",
      "Epoch 10, Loss: 0.08514013886451721\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.12652207292420395, feed_forward_dim=256, head_dim=16, lr=0.0011746209545373519, num_heads=8, num_layers=2; total time=   1.4s\n",
      "Epoch 7, Loss: 0.2784537672996521\n",
      "Epoch 10, Loss: 0.07643067836761475\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.12652207292420395, feed_forward_dim=256, head_dim=16, lr=0.0011746209545373519, num_heads=8, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 0.07819970697164536\n",
      "Epoch 9, Loss: 0.10390954464673996\n",
      "Epoch 8, Loss: 0.1466187685728073\n",
      "Epoch 8, Loss: 0.11770468950271606\n",
      "Epoch 10, Loss: 0.028894541785120964\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.12652207292420395, feed_forward_dim=256, head_dim=16, lr=0.0011746209545373519, num_heads=8, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.21931812167167664\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.12652207292420395, feed_forward_dim=256, head_dim=16, lr=0.0011746209545373519, num_heads=8, num_layers=2; total time=   1.6s\n",
      "Epoch 9, Loss: 0.03969183564186096\n",
      "Epoch 9, Loss: 0.020932797342538834\n",
      "Epoch 10, Loss: 0.06908316165208817\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.12652207292420395, feed_forward_dim=256, head_dim=16, lr=0.0011746209545373519, num_heads=8, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.041911687701940536\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.12652207292420395, feed_forward_dim=256, head_dim=16, lr=0.0011746209545373519, num_heads=8, num_layers=2; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.07121668756008148\n",
      "Epoch 1, Loss: 0.17688807845115662\n",
      "Epoch 1, Loss: 0.1810297966003418\n",
      "Epoch 1, Loss: 0.09427254647016525\n",
      "Epoch 2, Loss: 0.06208649277687073\n",
      "Epoch 1, Loss: 0.6539851427078247\n",
      "Epoch 1, Loss: 0.9782955050468445\n",
      "Epoch 1, Loss: 1.0265552997589111\n",
      "Epoch 2, Loss: 0.15983951091766357\n",
      "Epoch 2, Loss: 0.1480189710855484\n",
      "Epoch 3, Loss: 0.05763349309563637\n",
      "Epoch 1, Loss: 0.11797299236059189\n",
      "Epoch 2, Loss: 0.05001302435994148\n",
      "Epoch 2, Loss: 0.513947069644928\n",
      "Epoch 1, Loss: 0.7086336016654968\n",
      "Epoch 1, Loss: 1.6676288843154907\n",
      "Epoch 2, Loss: 0.8198987245559692\n",
      "Epoch 1, Loss: 2.060983896255493\n",
      "Epoch 4, Loss: 0.04928623139858246\n",
      "Epoch 3, Loss: 0.12229884415864944\n",
      "Epoch 3, Loss: 0.1356683373451233\n",
      "Epoch 2, Loss: 0.8566867113113403\n",
      "Epoch 3, Loss: 0.021083710715174675\n",
      "Epoch 1, Loss: 1.1437404155731201\n",
      "Epoch 4, Loss: 0.11566639691591263\n",
      "Epoch 3, Loss: 0.3836425840854645\n",
      "Epoch 2, Loss: 0.06332402676343918\n",
      "Epoch 2, Loss: 1.456462025642395\n",
      "Epoch 5, Loss: 0.04487798362970352\n",
      "Epoch 4, Loss: 0.10826055705547333\n",
      "Epoch 3, Loss: 0.6752774715423584\n",
      "Epoch 4, Loss: 0.007915140129625797\n",
      "Epoch 2, Loss: 0.5758143663406372\n",
      "Epoch 2, Loss: 1.811596393585205\n",
      "Epoch 5, Loss: 0.09990764409303665\n",
      "Epoch 3, Loss: 0.7010899186134338\n",
      "Epoch 6, Loss: 0.04038231074810028\n",
      "Epoch 4, Loss: 0.28336018323898315\n",
      "Epoch 2, Loss: 0.98103266954422\n",
      "Epoch 5, Loss: 0.10176604986190796\n",
      "Epoch 3, Loss: 1.2543045282363892\n",
      "Epoch 3, Loss: 0.03012826479971409\n",
      "Epoch 5, Loss: 0.006436839699745178\n",
      "Epoch 7, Loss: 0.03482413291931152\n",
      "Epoch 6, Loss: 0.08506166934967041\n",
      "Epoch 3, Loss: 1.5854768753051758\n",
      "Epoch 4, Loss: 0.5483543872833252\n",
      "Epoch 3, Loss: 0.4580189287662506\n",
      "Epoch 5, Loss: 0.20459504425525665\n",
      "Epoch 6, Loss: 0.09803418070077896\n",
      "Epoch 4, Loss: 0.5635022521018982\n",
      "Epoch 6, Loss: 0.013147268444299698\n",
      "Epoch 4, Loss: 0.011044127866625786\n",
      "Epoch 8, Loss: 0.029480740427970886\n",
      "Epoch 3, Loss: 0.8276416659355164\n",
      "Epoch 7, Loss: 0.07176722586154938\n",
      "Epoch 4, Loss: 1.0774755477905273\n",
      "Epoch 5, Loss: 0.4360229969024658\n",
      "Epoch 7, Loss: 0.09691623598337173\n",
      "Epoch 4, Loss: 1.370490550994873\n",
      "Epoch 5, Loss: 0.4490169882774353\n",
      "Epoch 6, Loss: 0.1393374353647232\n",
      "Epoch 9, Loss: 0.02536841668188572\n",
      "Epoch 4, Loss: 0.36162427067756653\n",
      "Epoch 7, Loss: 0.020829765126109123\n",
      "Epoch 8, Loss: 0.0577395036816597\n",
      "Epoch 5, Loss: 0.006723662838339806\n",
      "Epoch 8, Loss: 0.09406181424856186\n",
      "Epoch 4, Loss: 0.6915942430496216\n",
      "Epoch 10, Loss: 0.022258169949054718\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3702491575849971, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=8, num_layers=2; total time=   1.1s\n",
      "Epoch 6, Loss: 0.34375593066215515\n",
      "Epoch 5, Loss: 0.9075238108634949\n",
      "Epoch 9, Loss: 0.05129459127783775\n",
      "Epoch 8, Loss: 0.026721246540546417\n",
      "Epoch 7, Loss: 0.09261017292737961\n",
      "Epoch 5, Loss: 1.183232069015503\n",
      "Epoch 6, Loss: 0.3474917709827423\n",
      "Epoch 5, Loss: 0.27684155106544495\n",
      "Epoch 9, Loss: 0.09413212537765503\n",
      "Epoch 6, Loss: 0.011736735701560974\n",
      "Epoch 10, Loss: 0.04378756508231163\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3702491575849971, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=8, num_layers=2; total time=   1.2s\n",
      "Epoch 9, Loss: 0.026600440964102745\n",
      "Epoch 8, Loss: 0.06453630328178406\n",
      "Epoch 7, Loss: 0.26247918605804443\n",
      "Epoch 6, Loss: 0.7545501589775085\n",
      "Epoch 5, Loss: 0.5689087510108948\n",
      "Epoch 7, Loss: 0.26682040095329285\n",
      "Epoch 10, Loss: 0.08906006067991257\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3702491575849971, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 7, Loss: 0.0202321894466877\n",
      "Epoch 6, Loss: 0.21437899768352509\n",
      "Epoch 6, Loss: 0.9986411929130554\n",
      "Epoch 10, Loss: 0.023205995559692383\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3702491575849971, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 9, Loss: 0.05085400491952896\n",
      "Epoch 8, Loss: 0.19402317702770233\n",
      "Epoch 8, Loss: 0.20281608402729034\n",
      "Epoch 7, Loss: 0.6232690215110779\n",
      "Epoch 6, Loss: 0.45460808277130127\n",
      "Epoch 8, Loss: 0.028734393417835236\n",
      "Epoch 7, Loss: 0.1714394986629486\n",
      "Epoch 10, Loss: 0.04596823453903198\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3702491575849971, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=8, num_layers=2; total time=   1.5s\n",
      "Epoch 7, Loss: 0.8443191647529602\n",
      "Epoch 9, Loss: 0.14643369615077972\n",
      "Epoch 8, Loss: 0.5049242973327637\n",
      "Epoch 9, Loss: 0.15698769688606262\n",
      "Epoch 7, Loss: 0.3609711229801178\n",
      "Epoch 8, Loss: 0.14310136437416077\n",
      "Epoch 9, Loss: 0.03028237447142601\n",
      "Epoch 8, Loss: 0.7049332857131958\n",
      "Epoch 10, Loss: 0.10715971142053604\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3702491575849971, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=8, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.12473416328430176\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3702491575849971, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=8, num_layers=2; total time=   1.6s\n",
      "Epoch 9, Loss: 0.40078529715538025\n",
      "Epoch 10, Loss: 0.028258180245757103\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3702491575849971, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=8, num_layers=2; total time=   1.6s\n",
      "Epoch 8, Loss: 0.27853724360466003\n",
      "Epoch 9, Loss: 0.5777261853218079\n",
      "Epoch 9, Loss: 0.1307675987482071\n",
      "Epoch 10, Loss: 0.312238872051239\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3702491575849971, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=8, num_layers=2; total time=   1.7s\n",
      "Epoch 9, Loss: 0.20771969854831696\n",
      "Epoch 10, Loss: 0.4678627848625183\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3702491575849971, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=8, num_layers=2; total time=   1.7s\n",
      "Epoch 10, Loss: 0.12416975200176239\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3702491575849971, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=8, num_layers=2; total time=   1.7s\n",
      "Epoch 10, Loss: 0.15100574493408203\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3702491575849971, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=8, num_layers=2; total time=   1.8s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.06961888819932938\n",
      "Epoch 1, Loss: 0.483247846364975\n",
      "Epoch 1, Loss: 0.31646430492401123\n",
      "Epoch 1, Loss: 0.36946243047714233\n",
      "Epoch 1, Loss: 0.39384984970092773\n",
      "Epoch 1, Loss: 0.14313839375972748\n",
      "Epoch 2, Loss: 0.0275086909532547\n",
      "Epoch 1, Loss: 0.030228983610868454\n",
      "Epoch 2, Loss: 0.3734491467475891\n",
      "Epoch 2, Loss: 0.0838107243180275\n",
      "Epoch 1, Loss: 0.8143362402915955\n",
      "Epoch 2, Loss: 0.08823224902153015\n",
      "Epoch 3, Loss: 0.17667695879936218\n",
      "Epoch 1, Loss: 0.4676385521888733\n",
      "Epoch 2, Loss: 0.09816158562898636\n",
      "Epoch 2, Loss: 0.37452518939971924\n",
      "Epoch 3, Loss: 0.296883761882782\n",
      "Epoch 2, Loss: 0.6026046276092529\n",
      "Epoch 1, Loss: 1.015910267829895\n",
      "Epoch 3, Loss: 0.22296690940856934\n",
      "Epoch 1, Loss: 0.8776435256004333\n",
      "Epoch 3, Loss: 0.2495914250612259\n",
      "Epoch 2, Loss: 0.097569040954113\n",
      "Epoch 4, Loss: 0.010693003423511982\n",
      "Epoch 2, Loss: 0.08906091004610062\n",
      "Epoch 1, Loss: 1.9208695888519287\n",
      "Epoch 3, Loss: 0.26069197058677673\n",
      "Epoch 4, Loss: 0.20192013680934906\n",
      "Epoch 3, Loss: 0.0826760083436966\n",
      "Epoch 3, Loss: 0.037882450968027115\n",
      "Epoch 4, Loss: 0.06447902321815491\n",
      "Epoch 2, Loss: 0.1822994500398636\n",
      "Epoch 5, Loss: 0.11089824885129929\n",
      "Epoch 4, Loss: 0.13556720316410065\n",
      "Epoch 2, Loss: 0.09637473523616791\n",
      "Epoch 3, Loss: 0.2946341037750244\n",
      "Epoch 3, Loss: 0.33457764983177185\n",
      "Epoch 4, Loss: 0.1532142609357834\n",
      "Epoch 4, Loss: 0.1552799791097641\n",
      "Epoch 5, Loss: 0.05111001059412956\n",
      "Epoch 5, Loss: 0.09697935730218887\n",
      "Epoch 6, Loss: 0.07613250613212585\n",
      "Epoch 4, Loss: 0.09479409456253052\n",
      "Epoch 5, Loss: 0.0296234879642725\n",
      "Epoch 2, Loss: 0.20092710852622986\n",
      "Epoch 3, Loss: 0.3217911124229431\n",
      "Epoch 5, Loss: 0.03362810239195824\n",
      "Epoch 4, Loss: 0.1808958649635315\n",
      "Epoch 6, Loss: 0.01926412805914879\n",
      "Epoch 6, Loss: 0.03689608350396156\n",
      "Epoch 5, Loss: 0.29357361793518066\n",
      "Epoch 6, Loss: 0.13470713794231415\n",
      "Epoch 7, Loss: 0.011176817119121552\n",
      "Epoch 5, Loss: 0.16116616129875183\n",
      "Epoch 3, Loss: 0.4318683445453644\n",
      "Epoch 4, Loss: 0.37020784616470337\n",
      "Epoch 3, Loss: 0.21926969289779663\n",
      "Epoch 7, Loss: 0.0769401490688324\n",
      "Epoch 7, Loss: 0.08104041963815689\n",
      "Epoch 5, Loss: 0.035266339778900146\n",
      "Epoch 6, Loss: 0.031131746247410774\n",
      "Epoch 8, Loss: 0.03331146389245987\n",
      "Epoch 7, Loss: 0.08836042135953903\n",
      "Epoch 4, Loss: 0.4303181767463684\n",
      "Epoch 6, Loss: 0.19386212527751923\n",
      "Epoch 6, Loss: 0.106703020632267\n",
      "Epoch 8, Loss: 0.11560375243425369\n",
      "Epoch 4, Loss: 0.3938121497631073\n",
      "Epoch 9, Loss: 0.06260151416063309\n",
      "Epoch 5, Loss: 0.2230239361524582\n",
      "Epoch 8, Loss: 0.023967597633600235\n",
      "Epoch 8, Loss: 0.09803646802902222\n",
      "Epoch 4, Loss: 0.5886627435684204\n",
      "Epoch 6, Loss: 0.024369433522224426\n",
      "Epoch 7, Loss: 0.08329541981220245\n",
      "Epoch 7, Loss: 0.0542212575674057\n",
      "Epoch 10, Loss: 0.041748322546482086\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.22237889565638602, feed_forward_dim=128, head_dim=8, lr=0.0005081245296285903, num_heads=8, num_layers=2; total time=   1.0s\n",
      "Epoch 7, Loss: 0.029742969200015068\n",
      "Epoch 9, Loss: 0.09218219667673111\n",
      "Epoch 5, Loss: 0.17208506166934967\n",
      "Epoch 5, Loss: 0.30219826102256775\n",
      "Epoch 9, Loss: 0.02399219200015068\n",
      "Epoch 6, Loss: 0.0881093218922615\n",
      "Epoch 9, Loss: 0.060807548463344574\n",
      "Epoch 10, Loss: 0.04321853071451187\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.22237889565638602, feed_forward_dim=128, head_dim=8, lr=0.0005081245296285903, num_heads=8, num_layers=2; total time=   1.1s\n",
      "Epoch 8, Loss: 0.10089700669050217\n",
      "Epoch 8, Loss: 0.006910421419888735\n",
      "Epoch 5, Loss: 0.6076752543449402\n",
      "Epoch 7, Loss: 0.09321510046720505\n",
      "Epoch 8, Loss: 0.019462721422314644\n",
      "Epoch 10, Loss: 0.057785745710134506\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.22237889565638602, feed_forward_dim=128, head_dim=8, lr=0.0005081245296285903, num_heads=8, num_layers=2; total time=   1.2s\n",
      "Epoch 10, Loss: 0.0210911575704813\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.22237889565638602, feed_forward_dim=128, head_dim=8, lr=0.0005081245296285903, num_heads=8, num_layers=2; total time=   1.2s\n",
      "Epoch 7, Loss: 0.052909623831510544\n",
      "Epoch 6, Loss: 0.03649309277534485\n",
      "Epoch 6, Loss: 0.13759534060955048\n",
      "Epoch 9, Loss: 0.07067673653364182\n",
      "Epoch 9, Loss: 0.04690602794289589\n",
      "Epoch 9, Loss: 0.05890743434429169\n",
      "Epoch 8, Loss: 0.12064880132675171\n",
      "Epoch 8, Loss: 0.09156370162963867\n",
      "Epoch 10, Loss: 0.025833703577518463\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.22237889565638602, feed_forward_dim=128, head_dim=8, lr=0.0005081245296285903, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 7, Loss: 0.05340120941400528\n",
      "Epoch 6, Loss: 0.40837422013282776\n",
      "Epoch 10, Loss: 0.10221843421459198\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.22237889565638602, feed_forward_dim=128, head_dim=8, lr=0.0005081245296285903, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 7, Loss: 0.04790956899523735\n",
      "Epoch 10, Loss: 0.07197215408086777\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.22237889565638602, feed_forward_dim=128, head_dim=8, lr=0.0005081245296285903, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 9, Loss: 0.1388351172208786\n",
      "Epoch 9, Loss: 0.08355609327554703\n",
      "Epoch 8, Loss: 0.05933460220694542\n",
      "Epoch 7, Loss: 0.19322723150253296\n",
      "Epoch 8, Loss: 0.12040934711694717\n",
      "Epoch 10, Loss: 0.1465272307395935\n",
      "Epoch 10, Loss: 0.030398182570934296\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.22237889565638602, feed_forward_dim=128, head_dim=8, lr=0.0005081245296285903, num_heads=8, num_layers=2; total time=   1.4s\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.22237889565638602, feed_forward_dim=128, head_dim=8, lr=0.0005081245296285903, num_heads=8, num_layers=2; total time=   1.4s\n",
      "Epoch 9, Loss: 0.10423985123634338\n",
      "Epoch 8, Loss: 0.059033289551734924\n",
      "Epoch 9, Loss: 0.15754850208759308\n",
      "Epoch 10, Loss: 0.13020260632038116\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.22237889565638602, feed_forward_dim=128, head_dim=8, lr=0.0005081245296285903, num_heads=8, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 0.030995313078165054\n",
      "Epoch 10, Loss: 0.13005009293556213\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.22237889565638602, feed_forward_dim=128, head_dim=8, lr=0.0005081245296285903, num_heads=8, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.07802288979291916\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.22237889565638602, feed_forward_dim=128, head_dim=8, lr=0.0005081245296285903, num_heads=8, num_layers=2; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.5319476127624512\n",
      "Epoch 1, Loss: 4.368484973907471\n",
      "Epoch 1, Loss: 0.8335703611373901\n",
      "Epoch 2, Loss: 0.4048081636428833\n",
      "Epoch 1, Loss: 0.10582474619150162\n",
      "Epoch 2, Loss: 4.020515441894531\n",
      "Epoch 1, Loss: 0.16607922315597534\n",
      "Epoch 2, Loss: 0.6886460781097412\n",
      "Epoch 3, Loss: 0.2969125211238861\n",
      "Epoch 2, Loss: 0.06242907792329788\n",
      "Epoch 1, Loss: 0.1969907283782959\n",
      "Epoch 1, Loss: 0.21407529711723328\n",
      "Epoch 1, Loss: 0.3954145312309265\n",
      "Epoch 3, Loss: 3.67625093460083\n",
      "Epoch 3, Loss: 0.552299439907074\n",
      "Epoch 2, Loss: 0.1108269989490509\n",
      "Epoch 4, Loss: 0.20040880143642426\n",
      "Epoch 1, Loss: 0.6381449699401855\n",
      "Epoch 3, Loss: 0.03337758779525757\n",
      "Epoch 1, Loss: 1.1665314435958862\n",
      "Epoch 1, Loss: 0.3924303650856018\n",
      "Epoch 1, Loss: 0.028739307075738907\n",
      "Epoch 2, Loss: 0.14288540184497833\n",
      "Epoch 2, Loss: 0.15833424031734467\n",
      "Epoch 4, Loss: 3.3575401306152344\n",
      "Epoch 4, Loss: 0.4397619962692261\n",
      "Epoch 5, Loss: 0.1313369870185852\n",
      "Epoch 3, Loss: 0.07860112935304642\n",
      "Epoch 2, Loss: 0.306618869304657\n",
      "Epoch 4, Loss: 0.021342584863305092\n",
      "Epoch 2, Loss: 0.5078321099281311\n",
      "Epoch 2, Loss: 0.9917909502983093\n",
      "Epoch 3, Loss: 0.1066318228840828\n",
      "Epoch 5, Loss: 0.337091863155365\n",
      "Epoch 6, Loss: 0.08158097416162491\n",
      "Epoch 5, Loss: 3.0367507934570312\n",
      "Epoch 4, Loss: 0.06105908378958702\n",
      "Epoch 2, Loss: 0.010635243728756905\n",
      "Epoch 2, Loss: 0.2941536605358124\n",
      "Epoch 5, Loss: 0.021176068112254143\n",
      "Epoch 3, Loss: 0.23793676495552063\n",
      "Epoch 3, Loss: 0.11527670174837112\n",
      "Epoch 7, Loss: 0.046977896243333817\n",
      "Epoch 6, Loss: 2.751394748687744\n",
      "Epoch 6, Loss: 0.2581615447998047\n",
      "Epoch 4, Loss: 0.08396828919649124\n",
      "Epoch 3, Loss: 0.3939676880836487\n",
      "Epoch 5, Loss: 0.060446299612522125\n",
      "Epoch 3, Loss: 0.8395369052886963\n",
      "Epoch 3, Loss: 0.21806730329990387\n",
      "Epoch 4, Loss: 0.17911207675933838\n",
      "Epoch 7, Loss: 2.4488935470581055\n",
      "Epoch 4, Loss: 0.08530405163764954\n",
      "Epoch 6, Loss: 0.027602294459939003\n",
      "Epoch 3, Loss: 0.010852948762476444\n",
      "Epoch 8, Loss: 0.031192731112241745\n",
      "Epoch 7, Loss: 0.1873060017824173\n",
      "Epoch 6, Loss: 0.06562943011522293\n",
      "Epoch 5, Loss: 0.07458452135324478\n",
      "Epoch 8, Loss: 2.1867918968200684\n",
      "Epoch 9, Loss: 0.028541775420308113\n",
      "Epoch 7, Loss: 0.035898685455322266\n",
      "Epoch 5, Loss: 0.1340935081243515\n",
      "Epoch 5, Loss: 0.06553274393081665\n",
      "Epoch 4, Loss: 0.30412569642066956\n",
      "Epoch 4, Loss: 0.6925116777420044\n",
      "Epoch 4, Loss: 0.15867404639720917\n",
      "Epoch 10, Loss: 0.03428926318883896\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1778313953685856, feed_forward_dim=512, head_dim=16, lr=5.003748355466125e-05, num_heads=8, num_layers=2; total time=   0.9s\n",
      "Epoch 8, Loss: 0.13718043267726898\n",
      "Epoch 4, Loss: 0.01617174781858921\n",
      "Epoch 7, Loss: 0.07026142627000809\n",
      "Epoch 9, Loss: 1.9401748180389404\n",
      "Epoch 6, Loss: 0.05820919945836067\n",
      "Epoch 6, Loss: 0.10085805505514145\n",
      "Epoch 5, Loss: 0.23630529642105103\n",
      "Epoch 8, Loss: 0.036035578697919846\n",
      "Epoch 5, Loss: 0.5691604614257812\n",
      "Epoch 6, Loss: 0.07413873821496964\n",
      "Epoch 9, Loss: 0.09896775335073471\n",
      "Epoch 5, Loss: 0.11855337768793106\n",
      "Epoch 10, Loss: 1.6998642683029175\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1778313953685856, feed_forward_dim=512, head_dim=16, lr=5.003748355466125e-05, num_heads=8, num_layers=2; total time=   1.1s\n",
      "Epoch 8, Loss: 0.06839974224567413\n",
      "Epoch 7, Loss: 0.057862620800733566\n",
      "Epoch 9, Loss: 0.0344550795853138\n",
      "Epoch 7, Loss: 0.07763651013374329\n",
      "Epoch 6, Loss: 0.18330052495002747\n",
      "Epoch 5, Loss: 0.015843942761421204\n",
      "Epoch 10, Loss: 0.07132061570882797\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1778313953685856, feed_forward_dim=512, head_dim=16, lr=5.003748355466125e-05, num_heads=8, num_layers=2; total time=   1.1s\n",
      "Epoch 7, Loss: 0.08098288625478745\n",
      "Epoch 6, Loss: 0.4525104761123657\n",
      "Epoch 9, Loss: 0.0648294985294342\n",
      "Epoch 6, Loss: 0.09830831736326218\n",
      "Epoch 8, Loss: 0.06119878217577934\n",
      "Epoch 10, Loss: 0.028683295473456383\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1778313953685856, feed_forward_dim=512, head_dim=16, lr=5.003748355466125e-05, num_heads=8, num_layers=2; total time=   1.2s\n",
      "Epoch 8, Loss: 0.0797925665974617\n",
      "Epoch 7, Loss: 0.14992225170135498\n",
      "Epoch 8, Loss: 0.06823395192623138\n",
      "Epoch 6, Loss: 0.012678910046815872\n",
      "Epoch 10, Loss: 0.05702829733490944\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1778313953685856, feed_forward_dim=512, head_dim=16, lr=5.003748355466125e-05, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 9, Loss: 0.06625524908304214\n",
      "Epoch 7, Loss: 0.35773634910583496\n",
      "Epoch 9, Loss: 0.07975200563669205\n",
      "Epoch 7, Loss: 0.08858747035264969\n",
      "Epoch 9, Loss: 0.06468917429447174\n",
      "Epoch 8, Loss: 0.13374239206314087\n",
      "Epoch 7, Loss: 0.009887616150081158\n",
      "Epoch 10, Loss: 0.0681525245308876\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1778313953685856, feed_forward_dim=512, head_dim=16, lr=5.003748355466125e-05, num_heads=8, num_layers=2; total time=   1.4s\n",
      "Epoch 10, Loss: 0.07692492753267288\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1778313953685856, feed_forward_dim=512, head_dim=16, lr=5.003748355466125e-05, num_heads=8, num_layers=2; total time=   1.4s\n",
      "Epoch 8, Loss: 0.27500611543655396\n",
      "Epoch 10, Loss: 0.06645882874727249\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1778313953685856, feed_forward_dim=512, head_dim=16, lr=5.003748355466125e-05, num_heads=8, num_layers=2; total time=   1.4s\n",
      "Epoch 9, Loss: 0.1246168464422226\n",
      "Epoch 8, Loss: 0.08835314959287643\n",
      "Epoch 8, Loss: 0.008598641492426395\n",
      "Epoch 9, Loss: 0.20902520418167114\n",
      "Epoch 10, Loss: 0.127354696393013\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1778313953685856, feed_forward_dim=512, head_dim=16, lr=5.003748355466125e-05, num_heads=8, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 0.09393303841352463\n",
      "Epoch 9, Loss: 0.009202612563967705\n",
      "Epoch 10, Loss: 0.15297971665859222\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1778313953685856, feed_forward_dim=512, head_dim=16, lr=5.003748355466125e-05, num_heads=8, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.10348758846521378\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1778313953685856, feed_forward_dim=512, head_dim=16, lr=5.003748355466125e-05, num_heads=8, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.011034917086362839\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1778313953685856, feed_forward_dim=512, head_dim=16, lr=5.003748355466125e-05, num_heads=8, num_layers=2; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.7878642678260803\n",
      "Epoch 1, Loss: 1.6551636457443237\n",
      "Epoch 1, Loss: 0.9313726425170898\n",
      "Epoch 1, Loss: 1.582047700881958\n",
      "Epoch 1, Loss: 0.06806856393814087\n",
      "Epoch 2, Loss: 0.25510165095329285\n",
      "Epoch 1, Loss: 1.679577350616455\n",
      "Epoch 2, Loss: 0.7121803760528564\n",
      "Epoch 1, Loss: 0.1495257019996643\n",
      "Epoch 2, Loss: 0.636857271194458\n",
      "Epoch 2, Loss: 0.23906302452087402\n",
      "Epoch 3, Loss: 0.05176642909646034\n",
      "Epoch 1, Loss: 0.11463677883148193\n",
      "Epoch 2, Loss: 0.08999147266149521\n",
      "Epoch 1, Loss: 0.12630213797092438\n",
      "Epoch 1, Loss: 0.19500800967216492\n",
      "Epoch 3, Loss: 0.21290135383605957\n",
      "Epoch 4, Loss: 0.09997646510601044\n",
      "Epoch 3, Loss: 0.027890918776392937\n",
      "Epoch 2, Loss: 0.780167818069458\n",
      "Epoch 1, Loss: 0.9594960808753967\n",
      "Epoch 3, Loss: 0.13408562541007996\n",
      "Epoch 4, Loss: 0.09349125623703003\n",
      "Epoch 3, Loss: 0.051626984030008316\n",
      "Epoch 2, Loss: 0.11325250566005707\n",
      "Epoch 5, Loss: 0.20677657425403595\n",
      "Epoch 2, Loss: 0.09902995824813843\n",
      "Epoch 4, Loss: 0.12496142834424973\n",
      "Epoch 1, Loss: 0.06131783127784729\n",
      "Epoch 3, Loss: 0.27667516469955444\n",
      "Epoch 4, Loss: 0.03267127647995949\n",
      "Epoch 2, Loss: 0.03360242396593094\n",
      "Epoch 2, Loss: 0.140618234872818\n",
      "Epoch 5, Loss: 0.18331646919250488\n",
      "Epoch 6, Loss: 0.23529337346553802\n",
      "Epoch 4, Loss: 0.019688770174980164\n",
      "Epoch 2, Loss: 0.2391280084848404\n",
      "Epoch 3, Loss: 0.10641395300626755\n",
      "Epoch 5, Loss: 0.2549036741256714\n",
      "Epoch 4, Loss: 0.112847700715065\n",
      "Epoch 3, Loss: 0.08287619054317474\n",
      "Epoch 2, Loss: 0.14476005733013153\n",
      "Epoch 6, Loss: 0.31091728806495667\n",
      "Epoch 5, Loss: 0.17320719361305237\n",
      "Epoch 3, Loss: 0.1198589950799942\n",
      "Epoch 7, Loss: 0.19075548648834229\n",
      "Epoch 3, Loss: 0.08864519000053406\n",
      "Epoch 6, Loss: 0.2784126102924347\n",
      "Epoch 5, Loss: 0.03700746223330498\n",
      "Epoch 4, Loss: 0.0644458457827568\n",
      "Epoch 3, Loss: 0.012899317778646946\n",
      "Epoch 7, Loss: 0.37599295377731323\n",
      "Epoch 4, Loss: 0.04611688107252121\n",
      "Epoch 8, Loss: 0.11762148886919022\n",
      "Epoch 6, Loss: 0.32112857699394226\n",
      "Epoch 5, Loss: 0.1694110631942749\n",
      "Epoch 6, Loss: 0.04189694672822952\n",
      "Epoch 7, Loss: 0.22142602503299713\n",
      "Epoch 3, Loss: 0.0380699560046196\n",
      "Epoch 4, Loss: 0.06027736887335777\n",
      "Epoch 4, Loss: 0.05664173886179924\n",
      "Epoch 8, Loss: 0.3712100088596344\n",
      "Epoch 9, Loss: 0.051742296665906906\n",
      "Epoch 5, Loss: 0.04401532560586929\n",
      "Epoch 7, Loss: 0.3750106990337372\n",
      "Epoch 5, Loss: 0.03805641829967499\n",
      "Epoch 4, Loss: 0.10647062212228775\n",
      "Epoch 6, Loss: 0.294993132352829\n",
      "Epoch 7, Loss: 0.018861297518014908\n",
      "Epoch 9, Loss: 0.30650731921195984\n",
      "Epoch 8, Loss: 0.13146622478961945\n",
      "Epoch 5, Loss: 0.015288535505533218\n",
      "Epoch 10, Loss: 0.016281064599752426\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.2340688311812102, feed_forward_dim=128, head_dim=16, lr=0.0002509297538854363, num_heads=8, num_layers=2; total time=   1.0s\n",
      "Epoch 4, Loss: 0.049294959753751755\n",
      "Epoch 6, Loss: 0.04339361935853958\n",
      "Epoch 5, Loss: 0.03717564046382904\n",
      "Epoch 7, Loss: 0.3768518269062042\n",
      "Epoch 8, Loss: 0.3423427939414978\n",
      "Epoch 10, Loss: 0.21929655969142914\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.2340688311812102, feed_forward_dim=128, head_dim=16, lr=0.0002509297538854363, num_heads=8, num_layers=2; total time=   1.2s\n",
      "Epoch 5, Loss: 0.24040435254573822\n",
      "Epoch 6, Loss: 0.042681314051151276\n",
      "Epoch 8, Loss: 0.009845641441643238\n",
      "Epoch 9, Loss: 0.05284293368458748\n",
      "Epoch 6, Loss: 0.014742028899490833\n",
      "Epoch 7, Loss: 0.03720259293913841\n",
      "Epoch 6, Loss: 0.03968903794884682\n",
      "Epoch 9, Loss: 0.25422337651252747\n",
      "Epoch 7, Loss: 0.032275713980197906\n",
      "Epoch 10, Loss: 0.014115366153419018\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.2340688311812102, feed_forward_dim=128, head_dim=16, lr=0.0002509297538854363, num_heads=8, num_layers=2; total time=   1.4s\n",
      "Epoch 6, Loss: 0.27063190937042236\n",
      "Epoch 5, Loss: 0.07062118500471115\n",
      "Epoch 7, Loss: 0.03484338894486427\n",
      "Epoch 9, Loss: 0.02018682286143303\n",
      "Epoch 8, Loss: 0.384555459022522\n",
      "Epoch 10, Loss: 0.15578249096870422\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.2340688311812102, feed_forward_dim=128, head_dim=16, lr=0.0002509297538854363, num_heads=8, num_layers=2; total time=   1.4s\n",
      "Epoch 8, Loss: 0.02061118744313717\n",
      "Epoch 8, Loss: 0.017170729115605354\n",
      "Epoch 7, Loss: 0.033356212079524994\n",
      "Epoch 10, Loss: 0.026291247457265854\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.2340688311812102, feed_forward_dim=128, head_dim=16, lr=0.0002509297538854363, num_heads=8, num_layers=2; total time=   1.5s\n",
      "Epoch 8, Loss: 0.03970855474472046\n",
      "Epoch 7, Loss: 0.21872752904891968\n",
      "Epoch 6, Loss: 0.036510806530714035\n",
      "Epoch 9, Loss: 0.011066191829741001\n",
      "Epoch 9, Loss: 0.3391917645931244\n",
      "Epoch 8, Loss: 0.016177212819457054\n",
      "Epoch 9, Loss: 0.012217827141284943\n",
      "Epoch 10, Loss: 0.012324569746851921\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.2340688311812102, feed_forward_dim=128, head_dim=16, lr=0.0002509297538854363, num_heads=8, num_layers=2; total time=   1.6s\n",
      "Epoch 9, Loss: 0.02349775843322277\n",
      "Epoch 10, Loss: 0.2644113004207611\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.2340688311812102, feed_forward_dim=128, head_dim=16, lr=0.0002509297538854363, num_heads=8, num_layers=2; total time=   1.7s\n",
      "Epoch 8, Loss: 0.13775746524333954\n",
      "Epoch 10, Loss: 0.01664840616285801\n",
      "Epoch 7, Loss: 0.00985555537045002\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.2340688311812102, feed_forward_dim=128, head_dim=16, lr=0.0002509297538854363, num_heads=8, num_layers=2; total time=   1.7s\n",
      "Epoch 9, Loss: 0.007690744940191507\n",
      "Epoch 10, Loss: 0.008232221938669682\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.2340688311812102, feed_forward_dim=128, head_dim=16, lr=0.0002509297538854363, num_heads=8, num_layers=2; total time=   1.8s\n",
      "Epoch 9, Loss: 0.062199581414461136\n",
      "Epoch 8, Loss: 0.018531644716858864\n",
      "Epoch 10, Loss: 0.014711875468492508\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.2340688311812102, feed_forward_dim=128, head_dim=16, lr=0.0002509297538854363, num_heads=8, num_layers=2; total time=   1.8s\n",
      "Epoch 10, Loss: 0.018072517588734627\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.2340688311812102, feed_forward_dim=128, head_dim=16, lr=0.0002509297538854363, num_heads=8, num_layers=2; total time=   1.9s\n",
      "Epoch 9, Loss: 0.034953489899635315\n",
      "Epoch 10, Loss: 0.028478499501943588\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.2340688311812102, feed_forward_dim=128, head_dim=16, lr=0.0002509297538854363, num_heads=8, num_layers=2; total time=   2.0s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.19760672748088837\n",
      "Epoch 1, Loss: 0.2581084370613098\n",
      "Epoch 1, Loss: 2.5671122074127197\n",
      "Epoch 2, Loss: 0.2954503893852234\n",
      "Epoch 1, Loss: 1.5909991264343262\n",
      "Epoch 1, Loss: 0.22857095301151276\n",
      "Epoch 1, Loss: 0.12152029573917389\n",
      "Epoch 2, Loss: 0.9218558669090271\n",
      "Epoch 2, Loss: 0.062036313116550446\n",
      "Epoch 3, Loss: 0.09736093878746033\n",
      "Epoch 1, Loss: 0.25363636016845703\n",
      "Epoch 1, Loss: 0.4478161931037903\n",
      "Epoch 2, Loss: 0.4060516953468323\n",
      "Epoch 3, Loss: 0.14859409630298615\n",
      "Epoch 1, Loss: 1.6405529975891113\n",
      "Epoch 3, Loss: 0.18440937995910645\n",
      "Epoch 1, Loss: 0.33168211579322815\n",
      "Epoch 4, Loss: 0.1152980849146843\n",
      "Epoch 2, Loss: 0.2439275085926056\n",
      "Epoch 2, Loss: 0.2022216022014618\n",
      "Epoch 2, Loss: 0.05548488721251488\n",
      "Epoch 2, Loss: 0.03126930817961693\n",
      "Epoch 3, Loss: 0.06299462169408798\n",
      "Epoch 1, Loss: 0.7519396543502808\n",
      "Epoch 4, Loss: 0.09243515878915787\n",
      "Epoch 4, Loss: 0.10165803134441376\n",
      "Epoch 5, Loss: 0.12995317578315735\n",
      "Epoch 2, Loss: 0.13630114495754242\n",
      "Epoch 1, Loss: 0.6126703023910522\n",
      "Epoch 2, Loss: 0.27740657329559326\n",
      "Epoch 3, Loss: 0.07931995391845703\n",
      "Epoch 3, Loss: 0.16462752223014832\n",
      "Epoch 5, Loss: 0.020517298951745033\n",
      "Epoch 3, Loss: 0.16662219166755676\n",
      "Epoch 5, Loss: 0.3654239773750305\n",
      "Epoch 3, Loss: 0.24405212700366974\n",
      "Epoch 4, Loss: 0.23360750079154968\n",
      "Epoch 6, Loss: 0.06774348020553589\n",
      "Epoch 3, Loss: 0.21345756947994232\n",
      "Epoch 2, Loss: 0.05868984013795853\n",
      "Epoch 4, Loss: 0.0746518224477768\n",
      "Epoch 6, Loss: 0.030887266620993614\n",
      "Epoch 4, Loss: 0.07658636569976807\n",
      "Epoch 4, Loss: 0.11715078353881836\n",
      "Epoch 3, Loss: 0.05424314737319946\n",
      "Epoch 6, Loss: 0.5435304045677185\n",
      "Epoch 4, Loss: 0.22826778888702393\n",
      "Epoch 7, Loss: 0.024305419996380806\n",
      "Epoch 2, Loss: 0.12664246559143066\n",
      "Epoch 4, Loss: 0.08702414482831955\n",
      "Epoch 7, Loss: 0.07703886926174164\n",
      "Epoch 5, Loss: 0.4137091338634491\n",
      "Epoch 5, Loss: 0.09003140777349472\n",
      "Epoch 3, Loss: 0.14307723939418793\n",
      "Epoch 8, Loss: 0.035186972469091415\n",
      "Epoch 5, Loss: 0.09980615973472595\n",
      "Epoch 7, Loss: 0.5577438473701477\n",
      "Epoch 5, Loss: 0.027567580342292786\n",
      "Epoch 4, Loss: 0.3468472361564636\n",
      "Epoch 8, Loss: 0.07864611595869064\n",
      "Epoch 6, Loss: 0.4335384964942932\n",
      "Epoch 9, Loss: 0.053930748254060745\n",
      "Epoch 5, Loss: 0.019488461315631866\n",
      "Epoch 3, Loss: 0.09154912829399109\n",
      "Epoch 5, Loss: 0.1019366905093193\n",
      "Epoch 6, Loss: 0.10435802489519119\n",
      "Epoch 6, Loss: 0.06198836490511894\n",
      "Epoch 10, Loss: 0.042777612805366516\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.38093140379993384, feed_forward_dim=256, head_dim=16, lr=0.00037377432077170494, num_heads=8, num_layers=2; total time=   1.0s\n",
      "Epoch 6, Loss: 0.016711922362446785\n",
      "Epoch 7, Loss: 0.3368259370326996\n",
      "Epoch 8, Loss: 0.44869494438171387\n",
      "Epoch 4, Loss: 0.3022559881210327\n",
      "Epoch 5, Loss: 0.4943407475948334\n",
      "Epoch 9, Loss: 0.04119334742426872\n",
      "Epoch 7, Loss: 0.0740506649017334\n",
      "Epoch 6, Loss: 0.03169942647218704\n",
      "Epoch 6, Loss: 0.047162748873233795\n",
      "Epoch 7, Loss: 0.025752561166882515\n",
      "Epoch 9, Loss: 0.29553669691085815\n",
      "Epoch 4, Loss: 0.19868911802768707\n",
      "Epoch 8, Loss: 0.03604255989193916Epoch 8, Loss: 0.20565421879291534\n",
      "\n",
      "Epoch 6, Loss: 0.42376917600631714\n",
      "Epoch 5, Loss: 0.2677285075187683\n",
      "Epoch 10, Loss: 0.012257660739123821\n",
      "Epoch 7, Loss: 0.05509622395038605\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.38093140379993384, feed_forward_dim=256, head_dim=16, lr=0.00037377432077170494, num_heads=8, num_layers=2; total time=   1.1s\n",
      "Epoch 7, Loss: 0.051103897392749786\n",
      "Epoch 8, Loss: 0.02969631366431713\n",
      "Epoch 7, Loss: 0.07554134726524353\n",
      "Epoch 10, Loss: 0.1567917764186859\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.38093140379993384, feed_forward_dim=256, head_dim=16, lr=0.00037377432077170494, num_heads=8, num_layers=2; total time=   1.2s\n",
      "Epoch 9, Loss: 0.028658848255872726\n",
      "Epoch 7, Loss: 0.2524162530899048\n",
      "Epoch 8, Loss: 0.07429808378219604\n",
      "Epoch 9, Loss: 0.09844139963388443\n",
      "Epoch 6, Loss: 0.1434682011604309\n",
      "Epoch 8, Loss: 0.09709406644105911\n",
      "Epoch 5, Loss: 0.21600699424743652\n",
      "Epoch 9, Loss: 0.04607430845499039\n",
      "Epoch 8, Loss: 0.0560469888150692\n",
      "Epoch 10, Loss: 0.043239664286375046\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.38093140379993384, feed_forward_dim=256, head_dim=16, lr=0.00037377432077170494, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 8, Loss: 0.10179948061704636\n",
      "Epoch 10, Loss: 0.03751467913389206\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.38093140379993384, feed_forward_dim=256, head_dim=16, lr=0.00037377432077170494, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 9, Loss: 0.10859037935733795\n",
      "Epoch 9, Loss: 0.053126100450754166\n",
      "Epoch 10, Loss: 0.039307646453380585\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.38093140379993384, feed_forward_dim=256, head_dim=16, lr=0.00037377432077170494, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 6, Loss: 0.1535482555627823\n",
      "Epoch 7, Loss: 0.043649233877658844\n",
      "Epoch 9, Loss: 0.02048606611788273\n",
      "Epoch 9, Loss: 0.02084851823747158\n",
      "Epoch 10, Loss: 0.020820150151848793\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.38093140379993384, feed_forward_dim=256, head_dim=16, lr=0.00037377432077170494, num_heads=8, num_layers=2; total time=   1.4s\n",
      "Epoch 10, Loss: 0.07727810740470886\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.38093140379993384, feed_forward_dim=256, head_dim=16, lr=0.00037377432077170494, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 7, Loss: 0.07515709847211838\n",
      "Epoch 8, Loss: 0.01461493968963623\n",
      "Epoch 10, Loss: 0.016736535355448723\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.38093140379993384, feed_forward_dim=256, head_dim=16, lr=0.00037377432077170494, num_heads=8, num_layers=2; total time=   1.4s\n",
      "Epoch 10, Loss: 0.005948889534920454\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.38093140379993384, feed_forward_dim=256, head_dim=16, lr=0.00037377432077170494, num_heads=8, num_layers=2; total time=   1.4s\n",
      "Epoch 8, Loss: 0.026310468092560768\n",
      "Epoch 9, Loss: 0.043476130813360214\n",
      "Epoch 9, Loss: 0.019194472581148148\n",
      "Epoch 10, Loss: 0.08708225935697556\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.38093140379993384, feed_forward_dim=256, head_dim=16, lr=0.00037377432077170494, num_heads=8, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.04157182574272156\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.38093140379993384, feed_forward_dim=256, head_dim=16, lr=0.00037377432077170494, num_heads=8, num_layers=2; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.32773834466934204\n",
      "Epoch 1, Loss: 0.39656904339790344\n",
      "Epoch 1, Loss: 1.1058127880096436\n",
      "Epoch 1, Loss: 0.9870702028274536\n",
      "Epoch 1, Loss: 0.9184545278549194\n",
      "Epoch 2, Loss: 0.10279531031847\n",
      "Epoch 2, Loss: 0.22509369254112244\n",
      "Epoch 1, Loss: 0.8111921548843384\n",
      "Epoch 1, Loss: 0.06060410663485527\n",
      "Epoch 2, Loss: 0.5287145972251892\n",
      "Epoch 1, Loss: 0.7623997330665588\n",
      "Epoch 3, Loss: 0.015604491345584393\n",
      "Epoch 2, Loss: 0.44164586067199707\n",
      "Epoch 2, Loss: 0.47181183099746704\n",
      "Epoch 1, Loss: 0.10700000822544098\n",
      "Epoch 3, Loss: 0.19672223925590515\n",
      "Epoch 1, Loss: 0.1545620709657669\n",
      "Epoch 2, Loss: 0.3186779022216797\n",
      "Epoch 2, Loss: 0.08183193951845169\n",
      "Epoch 1, Loss: 1.166374683380127\n",
      "Epoch 4, Loss: 0.07036400586366653\n",
      "Epoch 2, Loss: 0.28188320994377136\n",
      "Epoch 3, Loss: 0.1629149317741394\n",
      "Epoch 3, Loss: 0.19139991700649261\n",
      "Epoch 1, Loss: 0.04605086147785187\n",
      "Epoch 3, Loss: 0.21740342676639557\n",
      "Epoch 4, Loss: 0.16087312996387482\n",
      "Epoch 4, Loss: 0.07230688631534576\n",
      "Epoch 2, Loss: 0.05621502548456192\n",
      "Epoch 5, Loss: 0.12645667791366577\n",
      "Epoch 3, Loss: 0.07595301419496536\n",
      "Epoch 3, Loss: 0.04503334313631058\n",
      "Epoch 2, Loss: 0.547325611114502\n",
      "Epoch 2, Loss: 0.1542981117963791\n",
      "Epoch 3, Loss: 0.06498681008815765\n",
      "Epoch 4, Loss: 0.15005406737327576\n",
      "Epoch 5, Loss: 0.12048070877790451\n",
      "Epoch 4, Loss: 0.09300293773412704\n",
      "Epoch 6, Loss: 0.12353722006082535\n",
      "Epoch 2, Loss: 0.07636716961860657\n",
      "Epoch 5, Loss: 0.1101255863904953\n",
      "Epoch 4, Loss: 0.044040415436029434\n",
      "Epoch 6, Loss: 0.0845409631729126\n",
      "Epoch 3, Loss: 0.07762804627418518\n",
      "Epoch 5, Loss: 0.19717660546302795\n",
      "Epoch 4, Loss: 0.02421683259308338\n",
      "Epoch 4, Loss: 0.05888191983103752\n",
      "Epoch 5, Loss: 0.15490950644016266\n",
      "Epoch 3, Loss: 0.19920919835567474\n",
      "Epoch 7, Loss: 0.08352085947990417\n",
      "Epoch 3, Loss: 0.1024642288684845\n",
      "Epoch 6, Loss: 0.2020929604768753\n",
      "Epoch 7, Loss: 0.06448156386613846\n",
      "Epoch 3, Loss: 0.03191458806395531\n",
      "Epoch 5, Loss: 0.12734761834144592\n",
      "Epoch 5, Loss: 0.03513293340802193\n",
      "Epoch 8, Loss: 0.03704095259308815\n",
      "Epoch 4, Loss: 0.039126548916101456\n",
      "Epoch 6, Loss: 0.23413871228694916\n",
      "Epoch 5, Loss: 0.1476922631263733\n",
      "Epoch 6, Loss: 0.26235926151275635\n",
      "Epoch 7, Loss: 0.26508575677871704\n",
      "Epoch 8, Loss: 0.0537654384970665\n",
      "Epoch 4, Loss: 0.10898050665855408\n",
      "Epoch 4, Loss: 0.08705142885446548\n",
      "Epoch 9, Loss: 0.009908957406878471\n",
      "Epoch 6, Loss: 0.2026345431804657\n",
      "Epoch 7, Loss: 0.26152503490448\n",
      "Epoch 4, Loss: 0.01835492253303528\n",
      "Epoch 5, Loss: 0.015575835481286049\n",
      "Epoch 6, Loss: 0.0313713438808918\n",
      "Epoch 9, Loss: 0.04440712556242943\n",
      "Epoch 6, Loss: 0.2137388437986374\n",
      "Epoch 7, Loss: 0.28665241599082947\n",
      "Epoch 8, Loss: 0.2706114649772644\n",
      "Epoch 10, Loss: 0.006984417326748371\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.11279880139235973, feed_forward_dim=128, head_dim=16, lr=0.00021008816592814846, num_heads=4, num_layers=3; total time=   1.1s\n",
      "Epoch 5, Loss: 0.1840786188840866\n",
      "Epoch 7, Loss: 0.2186182141304016\n",
      "Epoch 10, Loss: 0.03420155495405197\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.11279880139235973, feed_forward_dim=128, head_dim=16, lr=0.00021008816592814846, num_heads=4, num_layers=3; total time=   1.1s\n",
      "Epoch 7, Loss: 0.21695806086063385\n",
      "Epoch 6, Loss: 0.02539331093430519\n",
      "Epoch 9, Loss: 0.2351847141981125\n",
      "Epoch 8, Loss: 0.23240946233272552\n",
      "Epoch 8, Loss: 0.26279589533805847\n",
      "Epoch 5, Loss: 0.07882241904735565\n",
      "Epoch 7, Loss: 0.014946424402296543\n",
      "Epoch 5, Loss: 0.031072303652763367\n",
      "Epoch 8, Loss: 0.17680592834949493\n",
      "Epoch 10, Loss: 0.17785538733005524\n",
      "Epoch 6, Loss: 0.28369513154029846\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.11279880139235973, feed_forward_dim=128, head_dim=16, lr=0.00021008816592814846, num_heads=4, num_layers=3; total time=   1.2s\n",
      "Epoch 8, Loss: 0.17310504615306854\n",
      "Epoch 9, Loss: 0.21339960396289825\n",
      "Epoch 9, Loss: 0.17778010666370392\n",
      "Epoch 7, Loss: 0.03501829132437706\n",
      "Epoch 8, Loss: 0.010203396901488304\n",
      "Epoch 6, Loss: 0.025136886164546013\n",
      "Epoch 9, Loss: 0.11727748066186905\n",
      "Epoch 10, Loss: 0.15700910985469818\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.11279880139235973, feed_forward_dim=128, head_dim=16, lr=0.00021008816592814846, num_heads=4, num_layers=3; total time=   1.3s\n",
      "Epoch 10, Loss: 0.114068903028965\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.11279880139235973, feed_forward_dim=128, head_dim=16, lr=0.00021008816592814846, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.11207675188779831\n",
      "Epoch 6, Loss: 0.06068408861756325\n",
      "Epoch 8, Loss: 0.02246231585741043\n",
      "Epoch 7, Loss: 0.3212217688560486\n",
      "Epoch 10, Loss: 0.061777494847774506\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.11279880139235973, feed_forward_dim=128, head_dim=16, lr=0.00021008816592814846, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.017431024461984634\n",
      "Epoch 7, Loss: 0.010448222979903221\n",
      "Epoch 10, Loss: 0.05843178927898407\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.11279880139235973, feed_forward_dim=128, head_dim=16, lr=0.00021008816592814846, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Epoch 7, Loss: 0.04238615185022354\n",
      "Epoch 9, Loss: 0.008650382980704308\n",
      "Epoch 8, Loss: 0.28955352306365967\n",
      "Epoch 10, Loss: 0.019540317356586456\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.11279880139235973, feed_forward_dim=128, head_dim=16, lr=0.00021008816592814846, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 8, Loss: 0.009427178651094437\n",
      "Epoch 10, Loss: 0.009905249811708927\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.11279880139235973, feed_forward_dim=128, head_dim=16, lr=0.00021008816592814846, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 8, Loss: 0.036103490740060806\n",
      "Epoch 9, Loss: 0.2205151617527008\n",
      "Epoch 9, Loss: 0.01900932751595974\n",
      "Epoch 9, Loss: 0.03444104269146919\n",
      "Epoch 10, Loss: 0.1428767591714859\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.11279880139235973, feed_forward_dim=128, head_dim=16, lr=0.00021008816592814846, num_heads=4, num_layers=3; total time=   1.6s\n",
      "Epoch 10, Loss: 0.019877826794981956\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.11279880139235973, feed_forward_dim=128, head_dim=16, lr=0.00021008816592814846, num_heads=4, num_layers=3; total time=   1.6s\n",
      "Epoch 10, Loss: 0.025897573679685593\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.11279880139235973, feed_forward_dim=128, head_dim=16, lr=0.00021008816592814846, num_heads=4, num_layers=3; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.19156759977340698\n",
      "Epoch 2, Loss: 0.1623166799545288\n",
      "Epoch 1, Loss: 0.11539655923843384\n",
      "Epoch 1, Loss: 0.10328042507171631\n",
      "Epoch 3, Loss: 0.14667196571826935\n",
      "Epoch 1, Loss: 0.39695969223976135\n",
      "Epoch 1, Loss: 1.4725768566131592\n",
      "Epoch 2, Loss: 0.08070056885480881\n",
      "Epoch 1, Loss: 0.3275983929634094\n",
      "Epoch 2, Loss: 0.07073131203651428\n",
      "Epoch 1, Loss: 0.7519187331199646\n",
      "Epoch 4, Loss: 0.13111335039138794\n",
      "Epoch 1, Loss: 0.2034701704978943\n",
      "Epoch 2, Loss: 0.294030100107193\n",
      "Epoch 1, Loss: 0.4118150472640991\n",
      "Epoch 3, Loss: 0.05905342102050781\n",
      "Epoch 5, Loss: 0.12185156345367432\n",
      "Epoch 1, Loss: 0.7483376264572144\n",
      "Epoch 2, Loss: 1.2483524084091187\n",
      "Epoch 3, Loss: 0.05665789544582367\n",
      "Epoch 1, Loss: 1.1392117738723755\n",
      "Epoch 2, Loss: 0.22265860438346863\n",
      "Epoch 2, Loss: 0.6002750396728516\n",
      "Epoch 1, Loss: 0.7889255881309509\n",
      "Epoch 6, Loss: 0.11379191279411316\n",
      "Epoch 4, Loss: 0.049651097506284714\n",
      "Epoch 3, Loss: 0.21851599216461182\n",
      "Epoch 2, Loss: 0.18820054829120636\n",
      "Epoch 2, Loss: 0.3294967710971832\n",
      "Epoch 4, Loss: 0.05537232756614685\n",
      "Epoch 3, Loss: 1.035975456237793\n",
      "Epoch 2, Loss: 0.6211205720901489\n",
      "Epoch 7, Loss: 0.10214362293481827\n",
      "Epoch 5, Loss: 0.04807833582162857\n",
      "Epoch 3, Loss: 0.14520594477653503\n",
      "Epoch 4, Loss: 0.1484164595603943\n",
      "Epoch 3, Loss: 0.4519574046134949\n",
      "Epoch 2, Loss: 0.9516174793243408\n",
      "Epoch 3, Loss: 0.17376209795475006\n",
      "Epoch 2, Loss: 0.662736177444458\n",
      "Epoch 5, Loss: 0.05437775328755379\n",
      "Epoch 8, Loss: 0.09218159317970276\n",
      "Epoch 4, Loss: 0.8532560467720032\n",
      "Epoch 3, Loss: 0.25750207901000977\n",
      "Epoch 6, Loss: 0.05325566232204437\n",
      "Epoch 4, Loss: 0.0891963317990303\n",
      "Epoch 3, Loss: 0.507402241230011\n",
      "Epoch 5, Loss: 0.10073072463274002\n",
      "Epoch 4, Loss: 0.332324743270874\n",
      "Epoch 6, Loss: 0.05223655700683594\n",
      "Epoch 4, Loss: 0.1588830202817917\n",
      "Epoch 7, Loss: 0.05362726375460625\n",
      "Epoch 9, Loss: 0.08102869987487793\n",
      "Epoch 3, Loss: 0.5713308453559875\n",
      "Epoch 3, Loss: 0.7910676002502441\n",
      "Epoch 5, Loss: 0.6897456049919128\n",
      "Epoch 6, Loss: 0.06628051400184631\n",
      "Epoch 4, Loss: 0.20087283849716187\n",
      "Epoch 5, Loss: 0.05419668182730675\n",
      "Epoch 7, Loss: 0.04800575226545334\n",
      "Epoch 8, Loss: 0.05251717567443848\n",
      "Epoch 10, Loss: 0.07208514958620071\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.12747760741124464, feed_forward_dim=256, head_dim=16, lr=5e-05, num_heads=4, num_layers=1; total time=   1.2s\n",
      "Epoch 4, Loss: 0.40516528487205505\n",
      "Epoch 5, Loss: 0.2315012663602829\n",
      "Epoch 6, Loss: 0.5499018430709839\n",
      "Epoch 5, Loss: 0.14684206247329712\n",
      "Epoch 7, Loss: 0.047597236931324005\n",
      "Epoch 8, Loss: 0.04047655314207077\n",
      "Epoch 4, Loss: 0.4855632483959198\n",
      "Epoch 9, Loss: 0.04705122113227844\n",
      "Epoch 4, Loss: 0.636816680431366\n",
      "Epoch 6, Loss: 0.036759134382009506\n",
      "Epoch 5, Loss: 0.15233545005321503\n",
      "Epoch 6, Loss: 0.15040495991706848\n",
      "Epoch 7, Loss: 0.43269994854927063\n",
      "Epoch 5, Loss: 0.32173824310302734\n",
      "Epoch 10, Loss: 0.03885229304432869\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.12747760741124464, feed_forward_dim=256, head_dim=16, lr=5e-05, num_heads=4, num_layers=1; total time=   1.4s\n",
      "Epoch 8, Loss: 0.03961427882313728\n",
      "Epoch 9, Loss: 0.033283352851867676\n",
      "Epoch 6, Loss: 0.13589990139007568\n",
      "Epoch 5, Loss: 0.42167118191719055\n",
      "Epoch 8, Loss: 0.34182146191596985\n",
      "Epoch 7, Loss: 0.08915060013532639\n",
      "Epoch 7, Loss: 0.033868659287691116\n",
      "Epoch 5, Loss: 0.5068063139915466\n",
      "Epoch 6, Loss: 0.1208665519952774\n",
      "Epoch 9, Loss: 0.04135019704699516\n",
      "Epoch 10, Loss: 0.027958853170275688\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.12747760741124464, feed_forward_dim=256, head_dim=16, lr=5e-05, num_heads=4, num_layers=1; total time=   1.5s\n",
      "Epoch 6, Loss: 0.25636953115463257\n",
      "Epoch 9, Loss: 0.2710515260696411\n",
      "Epoch 6, Loss: 0.3781333863735199\n",
      "Epoch 7, Loss: 0.12632210552692413\n",
      "Epoch 10, Loss: 0.04758826270699501\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.12747760741124464, feed_forward_dim=256, head_dim=16, lr=5e-05, num_heads=4, num_layers=1; total time=   1.6s\n",
      "Epoch 8, Loss: 0.0507051907479763\n",
      "Epoch 8, Loss: 0.04191882535815239\n",
      "Epoch 6, Loss: 0.393392950296402\n",
      "Epoch 7, Loss: 0.19850392639636993\n",
      "Epoch 7, Loss: 0.09895429015159607\n",
      "Epoch 10, Loss: 0.21587541699409485\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.12747760741124464, feed_forward_dim=256, head_dim=16, lr=5e-05, num_heads=4, num_layers=1; total time=   1.6s\n",
      "Epoch 9, Loss: 0.05250054970383644\n",
      "Epoch 9, Loss: 0.02896885946393013\n",
      "Epoch 7, Loss: 0.34139424562454224\n",
      "Epoch 8, Loss: 0.1134600043296814\n",
      "Epoch 8, Loss: 0.08465622365474701\n",
      "Epoch 8, Loss: 0.15684588253498077\n",
      "Epoch 10, Loss: 0.06441742926836014\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.12747760741124464, feed_forward_dim=256, head_dim=16, lr=5e-05, num_heads=4, num_layers=1; total time=   1.7s\n",
      "Epoch 7, Loss: 0.29824164509773254\n",
      "Epoch 10, Loss: 0.020229032263159752\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.12747760741124464, feed_forward_dim=256, head_dim=16, lr=5e-05, num_heads=4, num_layers=1; total time=   1.8s\n",
      "Epoch 9, Loss: 0.10398858040571213\n",
      "Epoch 8, Loss: 0.3196769952774048\n",
      "Epoch 9, Loss: 0.12791003286838531\n",
      "Epoch 9, Loss: 0.0792931392788887\n",
      "Epoch 8, Loss: 0.2256624847650528\n",
      "Epoch 10, Loss: 0.09382141381502151\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.12747760741124464, feed_forward_dim=256, head_dim=16, lr=5e-05, num_heads=4, num_layers=1; total time=   1.9s\n",
      "Epoch 10, Loss: 0.10675735026597977\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.12747760741124464, feed_forward_dim=256, head_dim=16, lr=5e-05, num_heads=4, num_layers=1; total time=   1.8s\n",
      "Epoch 9, Loss: 0.3072262108325958\n",
      "Epoch 10, Loss: 0.07988439500331879\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.12747760741124464, feed_forward_dim=256, head_dim=16, lr=5e-05, num_heads=4, num_layers=1; total time=   1.9s\n",
      "Epoch 9, Loss: 0.16158302128314972\n",
      "Epoch 10, Loss: 0.3004976212978363\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.12747760741124464, feed_forward_dim=256, head_dim=16, lr=5e-05, num_heads=4, num_layers=1; total time=   1.9s\n",
      "Epoch 10, Loss: 0.12018561363220215\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.12747760741124464, feed_forward_dim=256, head_dim=16, lr=5e-05, num_heads=4, num_layers=1; total time=   2.0s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.15049102902412415\n",
      "Epoch 1, Loss: 0.5849459767341614\n",
      "Epoch 1, Loss: 0.5225155353546143\n",
      "Epoch 2, Loss: 0.1468302458524704\n",
      "Epoch 1, Loss: 0.11387208104133606\n",
      "Epoch 2, Loss: 0.31802627444267273\n",
      "Epoch 1, Loss: 0.15286678075790405\n",
      "Epoch 3, Loss: 0.15772777795791626\n",
      "Epoch 1, Loss: 0.15974518656730652\n",
      "Epoch 1, Loss: 0.26689112186431885\n",
      "Epoch 2, Loss: 0.18082985281944275\n",
      "Epoch 3, Loss: 0.3923620283603668\n",
      "Epoch 1, Loss: 0.44158920645713806\n",
      "Epoch 2, Loss: 0.34162437915802\n",
      "Epoch 4, Loss: 0.06719014048576355\n",
      "Epoch 1, Loss: 0.5016739368438721\n",
      "Epoch 2, Loss: 0.5896682143211365\n",
      "Epoch 1, Loss: 0.13091571629047394\n",
      "Epoch 2, Loss: 0.5112801194190979\n",
      "Epoch 2, Loss: 0.3025933504104614\n",
      "Epoch 1, Loss: 1.1804215908050537\n",
      "Epoch 5, Loss: 0.022774439305067062\n",
      "Epoch 3, Loss: 0.361544132232666\n",
      "Epoch 4, Loss: 0.162339985370636\n",
      "Epoch 2, Loss: 0.3443695604801178\n",
      "Epoch 3, Loss: 0.11158542335033417\n",
      "Epoch 3, Loss: 0.1248004287481308\n",
      "Epoch 1, Loss: 1.2460285425186157\n",
      "Epoch 2, Loss: 0.11378423124551773\n",
      "Epoch 2, Loss: 0.12308802455663681\n",
      "Epoch 3, Loss: 0.20342369377613068\n",
      "Epoch 4, Loss: 0.1878548115491867\n",
      "Epoch 3, Loss: 0.13149982690811157\n",
      "Epoch 5, Loss: 0.04247799515724182\n",
      "Epoch 6, Loss: 0.0774049237370491\n",
      "Epoch 2, Loss: 0.055150773376226425\n",
      "Epoch 4, Loss: 0.03988170251250267\n",
      "Epoch 7, Loss: 0.04664774611592293\n",
      "Epoch 3, Loss: 0.11501561105251312\n",
      "Epoch 4, Loss: 0.03159336373209953\n",
      "Epoch 3, Loss: 0.33101871609687805\n",
      "Epoch 6, Loss: 0.09123269468545914\n",
      "Epoch 4, Loss: 0.08705487102270126\n",
      "Epoch 5, Loss: 0.050838910043239594\n",
      "Epoch 4, Loss: 0.03658003732562065\n",
      "Epoch 3, Loss: 0.2813257873058319\n",
      "Epoch 2, Loss: 0.0782012864947319\n",
      "Epoch 5, Loss: 0.21137529611587524\n",
      "Epoch 8, Loss: 0.009642396122217178\n",
      "Epoch 7, Loss: 0.14290791749954224\n",
      "Epoch 6, Loss: 0.07279536873102188\n",
      "Epoch 3, Loss: 0.389687180519104\n",
      "Epoch 5, Loss: 0.21079814434051514\n",
      "Epoch 5, Loss: 0.0647905245423317\n",
      "Epoch 5, Loss: 0.11832091957330704\n",
      "Epoch 4, Loss: 0.05443967878818512\n",
      "Epoch 4, Loss: 0.19364780187606812\n",
      "Epoch 4, Loss: 0.10716807842254639\n",
      "Epoch 6, Loss: 0.19299861788749695\n",
      "Epoch 8, Loss: 0.10545194894075394\n",
      "Epoch 9, Loss: 0.03362664580345154\n",
      "Epoch 7, Loss: 0.13646849989891052\n",
      "Epoch 3, Loss: 0.4167821705341339\n",
      "Epoch 4, Loss: 0.5097349882125854\n",
      "Epoch 6, Loss: 0.16770538687705994\n",
      "Epoch 6, Loss: 0.126935213804245\n",
      "Epoch 9, Loss: 0.039669252932071686\n",
      "Epoch 7, Loss: 0.07857570052146912\n",
      "Epoch 10, Loss: 0.04749282822012901\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.20447189845764635, feed_forward_dim=256, head_dim=32, lr=0.0005574233535734502, num_heads=4, num_layers=2; total time=   0.9s\n",
      "Epoch 6, Loss: 0.12425380945205688\n",
      "Epoch 5, Loss: 0.060054171830415726\n",
      "Epoch 8, Loss: 0.14139579236507416\n",
      "Epoch 5, Loss: 0.022969424724578857\n",
      "Epoch 4, Loss: 0.5331087112426758\n",
      "Epoch 5, Loss: 0.043779563158750534\n",
      "Epoch 10, Loss: 0.00996773224323988\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.20447189845764635, feed_forward_dim=256, head_dim=32, lr=0.0005574233535734502, num_heads=4, num_layers=2; total time=   1.0s\n",
      "Epoch 7, Loss: 0.06456313282251358\n",
      "Epoch 9, Loss: 0.08372682332992554\n",
      "Epoch 5, Loss: 0.3010445535182953\n",
      "Epoch 8, Loss: 0.009337184950709343\n",
      "Epoch 7, Loss: 0.08633116632699966\n",
      "Epoch 6, Loss: 0.018711689859628677\n",
      "Epoch 7, Loss: 0.05399635061621666\n",
      "Epoch 6, Loss: 0.06096461042761803\n",
      "Epoch 5, Loss: 0.3337869942188263\n",
      "Epoch 8, Loss: 0.02488666959106922\n",
      "Epoch 10, Loss: 0.03154616057872772\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.20447189845764635, feed_forward_dim=256, head_dim=32, lr=0.0005574233535734502, num_heads=4, num_layers=2; total time=   1.1s\n",
      "Epoch 6, Loss: 0.11458298563957214\n",
      "Epoch 8, Loss: 0.01108634378761053\n",
      "Epoch 9, Loss: 0.026189260184764862\n",
      "Epoch 6, Loss: 0.08926641941070557\n",
      "Epoch 8, Loss: 0.02217741310596466\n",
      "Epoch 7, Loss: 0.055716145783662796\n",
      "Epoch 7, Loss: 0.032370924949645996\n",
      "Epoch 9, Loss: 0.029141392558813095\n",
      "Epoch 7, Loss: 0.14042127132415771\n",
      "Epoch 10, Loss: 0.07833443582057953\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.20447189845764635, feed_forward_dim=256, head_dim=32, lr=0.0005574233535734502, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 9, Loss: 0.05598355457186699\n",
      "Epoch 7, Loss: 0.01798923686146736\n",
      "Epoch 9, Loss: 0.008437410928308964\n",
      "Epoch 6, Loss: 0.12047366052865982\n",
      "Epoch 8, Loss: 0.0127711808308959\n",
      "Epoch 10, Loss: 0.06161646917462349\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.20447189845764635, feed_forward_dim=256, head_dim=32, lr=0.0005574233535734502, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 8, Loss: 0.09112929552793503\n",
      "Epoch 10, Loss: 0.08926070481538773\n",
      "Epoch 8, Loss: 0.09090561419725418\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.20447189845764635, feed_forward_dim=256, head_dim=32, lr=0.0005574233535734502, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 10, Loss: 0.039296481758356094\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.20447189845764635, feed_forward_dim=256, head_dim=32, lr=0.0005574233535734502, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 7, Loss: 0.03374407812952995\n",
      "Epoch 9, Loss: 0.034815527498722076\n",
      "Epoch 8, Loss: 0.06423436105251312\n",
      "Epoch 9, Loss: 0.07926304638385773\n",
      "Epoch 9, Loss: 0.029495801776647568\n",
      "Epoch 8, Loss: 0.0669996589422226\n",
      "Epoch 10, Loss: 0.0413021445274353\n",
      "Epoch 10, Loss: 0.03676828369498253\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.20447189845764635, feed_forward_dim=256, head_dim=32, lr=0.0005574233535734502, num_heads=4, num_layers=2; total time=   1.4s\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.20447189845764635, feed_forward_dim=256, head_dim=32, lr=0.0005574233535734502, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 10, Loss: 0.010134135372936726\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.20447189845764635, feed_forward_dim=256, head_dim=32, lr=0.0005574233535734502, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 9, Loss: 0.14029739797115326\n",
      "Epoch 9, Loss: 0.1426004022359848\n",
      "Epoch 10, Loss: 0.17234236001968384\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.20447189845764635, feed_forward_dim=256, head_dim=32, lr=0.0005574233535734502, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.1814490407705307\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.20447189845764635, feed_forward_dim=256, head_dim=32, lr=0.0005574233535734502, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 2.197033405303955\n",
      "Epoch 1, Loss: 0.4367426633834839\n",
      "Epoch 1, Loss: 0.35818442702293396\n",
      "Epoch 2, Loss: 1.6119275093078613\n",
      "Epoch 1, Loss: 0.21804086863994598\n",
      "Epoch 1, Loss: 0.5418844819068909\n",
      "Epoch 2, Loss: 0.2486944943666458\n",
      "Epoch 2, Loss: 0.2126730978488922\n",
      "Epoch 1, Loss: 2.2559428215026855\n",
      "Epoch 3, Loss: 1.107533574104309\n",
      "Epoch 1, Loss: 0.41795143485069275\n",
      "Epoch 2, Loss: 0.10576755553483963\n",
      "Epoch 1, Loss: 0.08130574226379395\n",
      "Epoch 3, Loss: 0.15213291347026825\n",
      "Epoch 4, Loss: 0.7126864790916443\n",
      "Epoch 2, Loss: 0.38323044776916504\n",
      "Epoch 1, Loss: 0.018969731405377388\n",
      "Epoch 2, Loss: 1.7462049722671509\n",
      "Epoch 1, Loss: 1.263038992881775\n",
      "Epoch 3, Loss: 0.06354688853025436\n",
      "Epoch 3, Loss: 0.1482730656862259\n",
      "Epoch 1, Loss: 0.1391667127609253\n",
      "Epoch 4, Loss: 0.1287328004837036\n",
      "Epoch 1, Loss: 2.490633726119995\n",
      "Epoch 5, Loss: 0.40898844599723816\n",
      "Epoch 2, Loss: 0.21545743942260742\n",
      "Epoch 2, Loss: 0.06890805810689926\n",
      "Epoch 4, Loss: 0.14296290278434753\n",
      "Epoch 3, Loss: 0.2817266583442688\n",
      "Epoch 3, Loss: 1.3145949840545654\n",
      "Epoch 4, Loss: 0.06721534579992294\n",
      "Epoch 5, Loss: 0.14370635151863098\n",
      "Epoch 6, Loss: 0.21494589745998383\n",
      "Epoch 2, Loss: 0.894522488117218\n",
      "Epoch 2, Loss: 0.11112656444311142\n",
      "Epoch 2, Loss: 0.050417929887771606\n",
      "Epoch 3, Loss: 0.05596295744180679\n",
      "Epoch 3, Loss: 0.11609546095132828\n",
      "Epoch 5, Loss: 0.15547892451286316\n",
      "Epoch 2, Loss: 1.8926066160202026\n",
      "Epoch 4, Loss: 0.22525353729724884\n",
      "Epoch 6, Loss: 0.15558050572872162\n",
      "Epoch 4, Loss: 0.9407654404640198\n",
      "Epoch 5, Loss: 0.08486993610858917\n",
      "Epoch 7, Loss: 0.10600545257329941\n",
      "Epoch 3, Loss: 0.5970780849456787\n",
      "Epoch 6, Loss: 0.16049359738826752\n",
      "Epoch 5, Loss: 0.20677970349788666\n",
      "Epoch 3, Loss: 0.016297267749905586\n",
      "Epoch 3, Loss: 0.0974746122956276\n",
      "Epoch 3, Loss: 1.396604299545288\n",
      "Epoch 4, Loss: 0.03995209559798241\n",
      "Epoch 6, Loss: 0.08759714663028717\n",
      "Epoch 7, Loss: 0.1551649570465088\n",
      "Epoch 4, Loss: 0.09756600856781006\n",
      "Epoch 8, Loss: 0.06559959799051285\n",
      "Epoch 5, Loss: 0.6488413214683533\n",
      "Epoch 7, Loss: 0.14310412108898163\n",
      "Epoch 9, Loss: 0.0827854722738266\n",
      "Epoch 4, Loss: 0.36867496371269226\n",
      "Epoch 6, Loss: 0.20683249831199646\n",
      "Epoch 8, Loss: 0.12925809621810913\n",
      "Epoch 7, Loss: 0.07698327302932739\n",
      "Epoch 4, Loss: 0.02530352585017681\n",
      "Epoch 4, Loss: 0.07677502185106277\n",
      "Epoch 5, Loss: 0.11723797023296356\n",
      "Epoch 4, Loss: 0.9900368452072144\n",
      "Epoch 5, Loss: 0.03011980652809143\n",
      "Epoch 8, Loss: 0.11583485454320908\n",
      "Epoch 10, Loss: 0.13447800278663635\n",
      "Epoch 6, Loss: 0.4202764332294464\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=1024, head_dim=32, lr=0.00011696819119213024, num_heads=2, num_layers=1; total time=   0.9s\n",
      "Epoch 9, Loss: 0.10183519870042801\n",
      "Epoch 7, Loss: 0.20801788568496704\n",
      "Epoch 6, Loss: 0.14318308234214783\n",
      "Epoch 9, Loss: 0.08931877464056015\n",
      "Epoch 8, Loss: 0.057277899235486984\n",
      "Epoch 5, Loss: 0.0339701846241951\n",
      "Epoch 5, Loss: 0.2167169749736786\n",
      "Epoch 7, Loss: 0.2656158208847046\n",
      "Epoch 10, Loss: 0.07406967878341675\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=1024, head_dim=32, lr=0.00011696819119213024, num_heads=2, num_layers=1; total time=   1.0s\n",
      "Epoch 6, Loss: 0.026887118816375732\n",
      "Epoch 5, Loss: 0.6748355627059937\n",
      "Epoch 5, Loss: 0.05689798668026924\n",
      "Epoch 10, Loss: 0.06835205852985382\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=1024, head_dim=32, lr=0.00011696819119213024, num_heads=2, num_layers=1; total time=   1.1s\n",
      "Epoch 8, Loss: 0.2061312049627304\n",
      "Epoch 9, Loss: 0.03889273852109909\n",
      "Epoch 7, Loss: 0.14881248772144318\n",
      "Epoch 6, Loss: 0.02277751825749874\n",
      "Epoch 8, Loss: 0.1689094752073288\n",
      "Epoch 7, Loss: 0.019803589209914207\n",
      "Epoch 6, Loss: 0.45944029092788696\n",
      "Epoch 6, Loss: 0.1335698664188385\n",
      "Epoch 8, Loss: 0.13012641668319702\n",
      "Epoch 10, Loss: 0.02574758231639862\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=1024, head_dim=32, lr=0.00011696819119213024, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 9, Loss: 0.19153377413749695\n",
      "Epoch 6, Loss: 0.0479208268225193\n",
      "Epoch 7, Loss: 0.013383596204221249\n",
      "Epoch 9, Loss: 0.11899573355913162\n",
      "Epoch 8, Loss: 0.012547890655696392\n",
      "Epoch 7, Loss: 0.320020467042923\n",
      "Epoch 10, Loss: 0.17203891277313232\n",
      "Epoch 7, Loss: 0.1064060851931572\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=1024, head_dim=32, lr=0.00011696819119213024, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 9, Loss: 0.09823902696371078\n",
      "Epoch 8, Loss: 0.016164593398571014\n",
      "Epoch 10, Loss: 0.11565486341714859\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=1024, head_dim=32, lr=0.00011696819119213024, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 9, Loss: 0.009109829552471638\n",
      "Epoch 7, Loss: 0.03982457146048546\n",
      "Epoch 10, Loss: 0.06860382109880447\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=1024, head_dim=32, lr=0.00011696819119213024, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 8, Loss: 0.25158384442329407\n",
      "Epoch 8, Loss: 0.12052988260984421\n",
      "Epoch 10, Loss: 0.009425931610167027\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=1024, head_dim=32, lr=0.00011696819119213024, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 9, Loss: 0.021803874522447586\n",
      "Epoch 8, Loss: 0.03202679380774498\n",
      "Epoch 9, Loss: 0.23472851514816284\n",
      "Epoch 9, Loss: 0.15204738080501556\n",
      "Epoch 10, Loss: 0.021928684785962105\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=1024, head_dim=32, lr=0.00011696819119213024, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 9, Loss: 0.022919774055480957\n",
      "Epoch 10, Loss: 0.24620334804058075\n",
      "Epoch 10, Loss: 0.18572290241718292\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=1024, head_dim=32, lr=0.00011696819119213024, num_heads=2, num_layers=1; total time=   1.4s\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=1024, head_dim=32, lr=0.00011696819119213024, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.01725027710199356\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=1024, head_dim=32, lr=0.00011696819119213024, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.178496852517128\n",
      "Epoch 1, Loss: 0.14519982039928436\n",
      "Epoch 1, Loss: 0.14299409091472626\n",
      "Epoch 1, Loss: 0.07773541659116745\n",
      "Epoch 1, Loss: 0.8470467329025269\n",
      "Epoch 1, Loss: 2.904045343399048\n",
      "Epoch 2, Loss: 0.32463812828063965\n",
      "Epoch 2, Loss: 0.21179799735546112\n",
      "Epoch 1, Loss: 0.3155929744243622\n",
      "Epoch 2, Loss: 0.2999434173107147\n",
      "Epoch 1, Loss: 0.08521874248981476\n",
      "Epoch 1, Loss: 0.40880146622657776\n",
      "Epoch 3, Loss: 0.14322766661643982\n",
      "Epoch 2, Loss: 0.2882276475429535\n",
      "Epoch 2, Loss: 0.10072962194681168\n",
      "Epoch 1, Loss: 0.09831949323415756\n",
      "Epoch 3, Loss: 0.1151098981499672\n",
      "Epoch 2, Loss: 1.0747357606887817\n",
      "Epoch 2, Loss: 0.15563631057739258\n",
      "Epoch 1, Loss: 0.21206240355968475\n",
      "Epoch 4, Loss: 0.03481835871934891\n",
      "Epoch 3, Loss: 0.114443838596344\n",
      "Epoch 1, Loss: 0.0673326700925827\n",
      "Epoch 3, Loss: 0.14067022502422333\n",
      "Epoch 2, Loss: 0.02897653728723526\n",
      "Epoch 4, Loss: 0.00826675072312355\n",
      "Epoch 2, Loss: 0.21061767637729645\n",
      "Epoch 3, Loss: 0.188112273812294\n",
      "Epoch 3, Loss: 0.048041246831417084\n",
      "Epoch 5, Loss: 0.1116325855255127\n",
      "Epoch 2, Loss: 0.3053295612335205\n",
      "Epoch 4, Loss: 0.019102739170193672\n",
      "Epoch 3, Loss: 0.22672271728515625\n",
      "Epoch 4, Loss: 0.309659481048584\n",
      "Epoch 5, Loss: 0.05933786556124687\n",
      "Epoch 6, Loss: 0.12117699533700943\n",
      "Epoch 2, Loss: 0.01459318958222866\n",
      "Epoch 3, Loss: 0.1882321536540985\n",
      "Epoch 2, Loss: 0.10630772262811661\n",
      "Epoch 4, Loss: 0.11113455146551132\n",
      "Epoch 5, Loss: 0.10322365909814835\n",
      "Epoch 4, Loss: 0.12545904517173767\n",
      "Epoch 3, Loss: 0.07210494577884674\n",
      "Epoch 7, Loss: 0.048966094851493835\n",
      "Epoch 4, Loss: 0.11456569284200668\n",
      "Epoch 5, Loss: 0.2865811884403229\n",
      "Epoch 3, Loss: 0.0766124352812767\n",
      "Epoch 6, Loss: 0.09391988068819046\n",
      "Epoch 3, Loss: 0.03616926819086075\n",
      "Epoch 6, Loss: 0.11555077880620956\n",
      "Epoch 6, Loss: 0.16474367678165436\n",
      "Epoch 5, Loss: 0.41437384486198425\n",
      "Epoch 4, Loss: 0.20208823680877686\n",
      "Epoch 4, Loss: 0.01918703317642212\n",
      "Epoch 5, Loss: 0.04333651438355446\n",
      "Epoch 5, Loss: 0.15187782049179077\n",
      "Epoch 4, Loss: 0.05766848102211952\n",
      "Epoch 8, Loss: 0.010658185929059982\n",
      "Epoch 7, Loss: 0.04867272824048996\n",
      "Epoch 3, Loss: 0.15229792892932892\n",
      "Epoch 7, Loss: 0.04722686484456062\n",
      "Epoch 7, Loss: 0.06511135399341583\n",
      "Epoch 4, Loss: 0.1158197894692421\n",
      "Epoch 6, Loss: 0.5959009528160095\n",
      "Epoch 8, Loss: 0.007430599071085453\n",
      "Epoch 6, Loss: 0.08155874907970428\n",
      "Epoch 9, Loss: 0.03225543349981308\n",
      "Epoch 5, Loss: 0.07654568552970886\n",
      "Epoch 5, Loss: 0.10289173573255539\n",
      "Epoch 6, Loss: 0.0709482729434967\n",
      "Epoch 5, Loss: 0.13355696201324463\n",
      "Epoch 7, Loss: 0.5797742605209351\n",
      "Epoch 9, Loss: 0.013252553530037403\n",
      "Epoch 8, Loss: 0.007991647347807884\n",
      "Epoch 4, Loss: 0.05419332906603813\n",
      "Epoch 7, Loss: 0.022183895111083984\n",
      "Epoch 10, Loss: 0.06241334602236748\n",
      "Epoch 5, Loss: 0.02152714692056179\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13534428490382086, feed_forward_dim=1024, head_dim=16, lr=0.000436210534226456, num_heads=4, num_layers=2; total time=   1.0s\n",
      "Epoch 8, Loss: 0.023964738473296165\n",
      "Epoch 6, Loss: 0.028486115857958794\n",
      "Epoch 10, Loss: 0.04136750474572182\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13534428490382086, feed_forward_dim=1024, head_dim=16, lr=0.000436210534226456, num_heads=4, num_layers=2; total time=   1.0s\n",
      "Epoch 6, Loss: 0.0984189584851265\n",
      "Epoch 6, Loss: 0.07572486251592636\n",
      "Epoch 9, Loss: 0.032510288059711456\n",
      "Epoch 8, Loss: 0.4509066641330719\n",
      "Epoch 8, Loss: 0.03201599791646004\n",
      "Epoch 9, Loss: 0.03874105587601662\n",
      "Epoch 7, Loss: 0.09464038163423538\n",
      "Epoch 5, Loss: 0.0230531208217144\n",
      "Epoch 9, Loss: 0.29213377833366394\n",
      "Epoch 6, Loss: 0.04599623382091522\n",
      "Epoch 7, Loss: 0.0280647911131382\n",
      "Epoch 7, Loss: 0.02528722584247589\n",
      "Epoch 10, Loss: 0.06428257375955582\n",
      "Epoch 7, Loss: 0.029049940407276154\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13534428490382086, feed_forward_dim=1024, head_dim=16, lr=0.000436210534226456, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 10, Loss: 0.07563355565071106\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13534428490382086, feed_forward_dim=1024, head_dim=16, lr=0.000436210534226456, num_heads=4, num_layers=2; total time=   1.1s\n",
      "Epoch 9, Loss: 0.06960510462522507\n",
      "Epoch 8, Loss: 0.06640666723251343\n",
      "Epoch 6, Loss: 0.06018855422735214\n",
      "Epoch 10, Loss: 0.15838965773582458\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13534428490382086, feed_forward_dim=1024, head_dim=16, lr=0.000436210534226456, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 8, Loss: 0.06088223308324814\n",
      "Epoch 8, Loss: 0.005032048560678959\n",
      "Epoch 7, Loss: 0.06000581011176109\n",
      "Epoch 8, Loss: 0.01619887538254261\n",
      "Epoch 9, Loss: 0.0270608551800251\n",
      "Epoch 10, Loss: 0.07033410668373108\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13534428490382086, feed_forward_dim=1024, head_dim=16, lr=0.000436210534226456, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 7, Loss: 0.0710449367761612\n",
      "Epoch 9, Loss: 0.08690439164638519\n",
      "Epoch 9, Loss: 0.021380087360739708\n",
      "Epoch 8, Loss: 0.013989335857331753\n",
      "Epoch 9, Loss: 0.047298457473516464\n",
      "Epoch 10, Loss: 0.016014037653803825\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13534428490382086, feed_forward_dim=1024, head_dim=16, lr=0.000436210534226456, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 10, Loss: 0.0790352076292038\n",
      "Epoch 8, Loss: 0.039629653096199036\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13534428490382086, feed_forward_dim=1024, head_dim=16, lr=0.000436210534226456, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 10, Loss: 0.04064543917775154\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13534428490382086, feed_forward_dim=1024, head_dim=16, lr=0.000436210534226456, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 10, Loss: 0.0636783167719841\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13534428490382086, feed_forward_dim=1024, head_dim=16, lr=0.000436210534226456, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 9, Loss: 0.013212059624493122\n",
      "Epoch 9, Loss: 0.011461891233921051\n",
      "Epoch 10, Loss: 0.03641178458929062\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13534428490382086, feed_forward_dim=1024, head_dim=16, lr=0.000436210534226456, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 10, Loss: 0.013511702418327332\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13534428490382086, feed_forward_dim=1024, head_dim=16, lr=0.000436210534226456, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.08642657846212387\n",
      "Epoch 1, Loss: 0.09737709909677505\n",
      "Epoch 1, Loss: 1.5945993661880493\n",
      "Epoch 1, Loss: 0.7073423266410828\n",
      "Epoch 1, Loss: 0.9828117489814758\n",
      "Epoch 2, Loss: 0.07485535740852356\n",
      "Epoch 2, Loss: 0.030301135033369064\n",
      "Epoch 1, Loss: 2.3104753494262695\n",
      "Epoch 1, Loss: 0.9800348877906799\n",
      "Epoch 2, Loss: 1.0424071550369263\n",
      "Epoch 1, Loss: 0.057477664202451706\n",
      "Epoch 2, Loss: 0.2868120074272156\n",
      "Epoch 3, Loss: 0.06582753360271454\n",
      "Epoch 3, Loss: 0.0563906766474247\n",
      "Epoch 2, Loss: 0.5956284403800964\n",
      "Epoch 1, Loss: 1.6201332807540894\n",
      "Epoch 2, Loss: 1.618188738822937\n",
      "Epoch 1, Loss: 0.9610586762428284\n",
      "Epoch 2, Loss: 0.6047313809394836\n",
      "Epoch 3, Loss: 0.6209078431129456\n",
      "Epoch 4, Loss: 0.04571443796157837\n",
      "Epoch 1, Loss: 0.025400398299098015\n",
      "Epoch 4, Loss: 0.055768486112356186\n",
      "Epoch 1, Loss: 0.1283600926399231\n",
      "Epoch 2, Loss: 0.04034201800823212\n",
      "Epoch 3, Loss: 0.06611553579568863\n",
      "Epoch 3, Loss: 0.309841126203537\n",
      "Epoch 5, Loss: 0.03755312040448189\n",
      "Epoch 3, Loss: 1.0647605657577515\n",
      "Epoch 2, Loss: 1.019508957862854\n",
      "Epoch 4, Loss: 0.31947124004364014\n",
      "Epoch 3, Loss: 0.334584504365921\n",
      "Epoch 2, Loss: 0.48355501890182495\n",
      "Epoch 5, Loss: 0.032826099544763565\n",
      "Epoch 2, Loss: 0.047889821231365204\n",
      "Epoch 4, Loss: 0.029653172940015793\n",
      "Epoch 3, Loss: 0.04426870867609978\n",
      "Epoch 6, Loss: 0.034710951149463654\n",
      "Epoch 2, Loss: 0.10222485661506653\n",
      "Epoch 4, Loss: 0.14119988679885864\n",
      "Epoch 5, Loss: 0.15554241836071014\n",
      "Epoch 4, Loss: 0.6446229219436646\n",
      "Epoch 6, Loss: 0.01679696887731552\n",
      "Epoch 3, Loss: 0.565350353717804\n",
      "Epoch 4, Loss: 0.16627629101276398\n",
      "Epoch 7, Loss: 0.0286257304251194\n",
      "Epoch 5, Loss: 0.09905508160591125\n",
      "Epoch 3, Loss: 0.18638187646865845\n",
      "Epoch 6, Loss: 0.10178471356630325\n",
      "Epoch 3, Loss: 0.01590161956846714\n",
      "Epoch 5, Loss: 0.06803019344806671\n",
      "Epoch 4, Loss: 0.023535076528787613\n",
      "Epoch 7, Loss: 0.019509458914399147\n",
      "Epoch 8, Loss: 0.019581835716962814\n",
      "Epoch 3, Loss: 0.09116856753826141\n",
      "Epoch 5, Loss: 0.3441918194293976\n",
      "Epoch 5, Loss: 0.09144443273544312\n",
      "Epoch 7, Loss: 0.12499244511127472\n",
      "Epoch 4, Loss: 0.2557074725627899\n",
      "Epoch 6, Loss: 0.16789419949054718\n",
      "Epoch 4, Loss: 0.038069237023591995\n",
      "Epoch 9, Loss: 0.013758386485278606\n",
      "Epoch 8, Loss: 0.027810823172330856\n",
      "Epoch 6, Loss: 0.06949902325868607\n",
      "Epoch 6, Loss: 0.16407568752765656\n",
      "Epoch 4, Loss: 0.01955864019691944\n",
      "Epoch 5, Loss: 0.015627926215529442\n",
      "Epoch 8, Loss: 0.1843065321445465\n",
      "Epoch 10, Loss: 0.014062895439565182\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=0.00014406984355848848, num_heads=2, num_layers=1; total time=   1.1s\n",
      "Epoch 7, Loss: 0.18980209529399872\n",
      "Epoch 4, Loss: 0.06597312539815903\n",
      "Epoch 6, Loss: 0.08520907163619995\n",
      "Epoch 5, Loss: 0.07767356187105179\n",
      "Epoch 9, Loss: 0.028322730213403702\n",
      "Epoch 5, Loss: 0.015390152111649513\n",
      "Epoch 7, Loss: 0.11138097196817398\n",
      "Epoch 9, Loss: 0.2404271960258484\n",
      "Epoch 8, Loss: 0.16490963101387024\n",
      "Epoch 6, Loss: 0.019778411835432053\n",
      "Epoch 7, Loss: 0.07974808663129807\n",
      "Epoch 5, Loss: 0.025298213586211205\n",
      "Epoch 10, Loss: 0.020246854051947594\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=0.00014406984355848848, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 7, Loss: 0.11953362822532654\n",
      "Epoch 8, Loss: 0.158199280500412\n",
      "Epoch 6, Loss: 0.01506691426038742\n",
      "Epoch 5, Loss: 0.050222836434841156\n",
      "Epoch 10, Loss: 0.27762067317962646\n",
      "Epoch 6, Loss: 0.0651741698384285\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=0.00014406984355848848, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 9, Loss: 0.11319015920162201\n",
      "Epoch 7, Loss: 0.018550468608736992\n",
      "Epoch 8, Loss: 0.06783466786146164\n",
      "Epoch 8, Loss: 0.16392403841018677\n",
      "Epoch 6, Loss: 0.013883741572499275\n",
      "Epoch 9, Loss: 0.1892242580652237\n",
      "Epoch 7, Loss: 0.13155467808246613\n",
      "Epoch 10, Loss: 0.06041479483246803\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=0.00014406984355848848, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 6, Loss: 0.043678753077983856\n",
      "Epoch 9, Loss: 0.10609354078769684\n",
      "Epoch 8, Loss: 0.011692692525684834\n",
      "Epoch 7, Loss: 0.031907085329294205\n",
      "Epoch 9, Loss: 0.19795407354831696\n",
      "Epoch 7, Loss: 0.006933667231351137\n",
      "Epoch 10, Loss: 0.16238456964492798\n",
      "Epoch 10, Loss: 0.1981128603219986\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=0.00014406984355848848, num_heads=2, num_layers=1; total time=   1.6s\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=0.00014406984355848848, num_heads=2, num_layers=1; total time=   1.6s\n",
      "Epoch 9, Loss: 0.007630783133208752\n",
      "Epoch 7, Loss: 0.03512642905116081\n",
      "Epoch 10, Loss: 0.20953083038330078\n",
      "Epoch 8, Loss: 0.1769883781671524\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=0.00014406984355848848, num_heads=2, num_layers=1; total time=   1.6s\n",
      "Epoch 8, Loss: 0.09257619082927704\n",
      "Epoch 8, Loss: 0.011510910466313362\n",
      "Epoch 10, Loss: 0.010168406181037426\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=0.00014406984355848848, num_heads=2, num_layers=1; total time=   1.7s\n",
      "Epoch 8, Loss: 0.02376982755959034\n",
      "Epoch 9, Loss: 0.19311301410198212\n",
      "Epoch 9, Loss: 0.15983794629573822\n",
      "Epoch 9, Loss: 0.017084963619709015\n",
      "Epoch 9, Loss: 0.015873417258262634\n",
      "Epoch 10, Loss: 0.1750103384256363\n",
      "Epoch 10, Loss: 0.20955608785152435\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=0.00014406984355848848, num_heads=2, num_layers=1; total time=   1.8s\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=0.00014406984355848848, num_heads=2, num_layers=1; total time=   1.8s\n",
      "Epoch 10, Loss: 0.013480094261467457\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=0.00014406984355848848, num_heads=2, num_layers=1; total time=   1.7s\n",
      "Epoch 10, Loss: 0.013720678165555\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=0.00014406984355848848, num_heads=2, num_layers=1; total time=   1.8s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.4786469042301178\n",
      "Epoch 1, Loss: 0.4619669020175934\n",
      "Epoch 2, Loss: 0.3839350938796997\n",
      "Epoch 1, Loss: 0.5852580666542053\n",
      "Epoch 1, Loss: 1.9952082633972168\n",
      "Epoch 2, Loss: 0.3755147159099579\n",
      "Epoch 1, Loss: 0.17990149557590485\n",
      "Epoch 1, Loss: 0.639656662940979\n",
      "Epoch 2, Loss: 0.4685971140861511\n",
      "Epoch 3, Loss: 0.30229753255844116\n",
      "Epoch 1, Loss: 0.17280976474285126\n",
      "Epoch 2, Loss: 1.7701793909072876\n",
      "Epoch 2, Loss: 0.12788338959217072\n",
      "Epoch 1, Loss: 0.25000062584877014\n",
      "Epoch 3, Loss: 0.2980254888534546\n",
      "Epoch 2, Loss: 0.493665486574173\n",
      "Epoch 1, Loss: 0.01499580591917038\n",
      "Epoch 3, Loss: 0.3593708276748657\n",
      "Epoch 4, Loss: 0.23173834383487701\n",
      "Epoch 2, Loss: 0.18178938329219818\n",
      "Epoch 3, Loss: 1.5637768507003784\n",
      "Epoch 3, Loss: 0.09255050122737885\n",
      "Epoch 4, Loss: 0.2415328323841095\n",
      "Epoch 5, Loss: 0.17780637741088867\n",
      "Epoch 2, Loss: 0.14976392686367035\n",
      "Epoch 4, Loss: 0.269433856010437\n",
      "Epoch 2, Loss: 0.014255452901124954\n",
      "Epoch 3, Loss: 0.36714524030685425\n",
      "Epoch 5, Loss: 0.20491425693035126\n",
      "Epoch 4, Loss: 1.3770654201507568\n",
      "Epoch 3, Loss: 0.12877961993217468\n",
      "Epoch 6, Loss: 0.13638578355312347\n",
      "Epoch 5, Loss: 0.19449353218078613\n",
      "Epoch 4, Loss: 0.07358065992593765\n",
      "Epoch 3, Loss: 0.1322106420993805\n",
      "Epoch 4, Loss: 0.2621472477912903\n",
      "Epoch 3, Loss: 0.011580193415284157\n",
      "Epoch 6, Loss: 0.17682234942913055\n",
      "Epoch 7, Loss: 0.10433556884527206\n",
      "Epoch 6, Loss: 0.13269884884357452\n",
      "Epoch 5, Loss: 0.06490860134363174\n",
      "Epoch 4, Loss: 0.08400510251522064\n",
      "Epoch 4, Loss: 0.12922856211662292\n",
      "Epoch 1, Loss: 0.3338128328323364\n",
      "Epoch 5, Loss: 1.191941499710083\n",
      "Epoch 7, Loss: 0.1617533415555954\n",
      "Epoch 5, Loss: 0.18004459142684937\n",
      "Epoch 8, Loss: 0.0865975171327591\n",
      "Epoch 1, Loss: 0.24014891684055328\n",
      "Epoch 4, Loss: 0.01101834885776043\n",
      "Epoch 7, Loss: 0.08622569590806961\n",
      "Epoch 8, Loss: 0.15723544359207153\n",
      "Epoch 5, Loss: 0.11866980791091919\n",
      "Epoch 6, Loss: 1.0298433303833008\n",
      "Epoch 5, Loss: 0.05165305733680725\n",
      "Epoch 9, Loss: 0.07579712569713593\n",
      "Epoch 1, Loss: 0.03438378870487213\n",
      "Epoch 2, Loss: 0.23488564789295197\n",
      "Epoch 6, Loss: 0.067009836435318\n",
      "Epoch 9, Loss: 0.15445102751255035\n",
      "Epoch 6, Loss: 0.11348629742860794\n",
      "Epoch 2, Loss: 0.17729933559894562\n",
      "Epoch 8, Loss: 0.05129432678222656\n",
      "Epoch 5, Loss: 0.010074729099869728\n",
      "Epoch 10, Loss: 0.07440625876188278\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3419492351624905, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=4, num_layers=4; total time=   1.1s\n",
      "Epoch 7, Loss: 0.8767277598381042\n",
      "Epoch 6, Loss: 0.11142497509717941\n",
      "Epoch 7, Loss: 0.07341332733631134\n",
      "Epoch 10, Loss: 0.15192393958568573\n",
      "Epoch 6, Loss: 0.03376379609107971\n",
      "Epoch 2, Loss: 0.02958342805504799\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3419492351624905, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=4, num_layers=4; total time=   1.1s\n",
      "Epoch 7, Loss: 0.0732138380408287Epoch 3, Loss: 0.15970292687416077\n",
      "\n",
      "Epoch 9, Loss: 0.02872188203036785\n",
      "Epoch 3, Loss: 0.13559770584106445\n",
      "Epoch 8, Loss: 0.7321335673332214\n",
      "Epoch 6, Loss: 0.009029664099216461\n",
      "Epoch 8, Loss: 0.07656652480363846\n",
      "Epoch 7, Loss: 0.10141302645206451\n",
      "Epoch 7, Loss: 0.027006782591342926\n",
      "Epoch 8, Loss: 0.04405146837234497\n",
      "Epoch 4, Loss: 0.099789097905159\n",
      "Epoch 9, Loss: 0.6171668171882629\n",
      "Epoch 10, Loss: 0.016578303650021553\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3419492351624905, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 3, Loss: 0.026822226122021675\n",
      "Epoch 7, Loss: 0.009279088117182255\n",
      "Epoch 9, Loss: 0.07593889534473419\n",
      "Epoch 4, Loss: 0.10397672653198242\n",
      "Epoch 8, Loss: 0.09269294887781143\n",
      "Epoch 8, Loss: 0.025364603847265244\n",
      "Epoch 9, Loss: 0.031193256378173828\n",
      "Epoch 10, Loss: 0.4987260401248932\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3419492351624905, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 5, Loss: 0.056359726935625076\n",
      "Epoch 10, Loss: 0.07086662203073502\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3419492351624905, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 8, Loss: 0.009219061583280563\n",
      "Epoch 5, Loss: 0.08402951806783676\n",
      "Epoch 4, Loss: 0.02239452302455902\n",
      "Epoch 9, Loss: 0.03196538984775543\n",
      "Epoch 9, Loss: 0.08244722336530685\n",
      "Epoch 10, Loss: 0.032790880650281906\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3419492351624905, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Epoch 6, Loss: 0.029159534722566605\n",
      "Epoch 9, Loss: 0.008519654162228107\n",
      "Epoch 10, Loss: 0.03962421417236328\n",
      "Epoch 6, Loss: 0.0761103704571724\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3419492351624905, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Epoch 5, Loss: 0.018465453758835793\n",
      "Epoch 10, Loss: 0.07453692704439163\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3419492351624905, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.00801168940961361\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3419492351624905, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Epoch 7, Loss: 0.017151108011603355\n",
      "Epoch 6, Loss: 0.01621231436729431\n",
      "Epoch 7, Loss: 0.07818048447370529\n",
      "Epoch 8, Loss: 0.016306698322296143\n",
      "Epoch 7, Loss: 0.01419016346335411\n",
      "Epoch 8, Loss: 0.08296394348144531\n",
      "Epoch 9, Loss: 0.022422654554247856\n",
      "Epoch 9, Loss: 0.08692101389169693\n",
      "Epoch 8, Loss: 0.012507808394730091\n",
      "Epoch 10, Loss: 0.03369758278131485\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3419492351624905, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 10, Loss: 0.088443323969841\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3419492351624905, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 9, Loss: 0.011135791428387165\n",
      "Epoch 10, Loss: 0.01045715156942606\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3419492351624905, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.13030487298965454\n",
      "Epoch 1, Loss: 0.035689450800418854\n",
      "Epoch 2, Loss: 0.09415935724973679\n",
      "Epoch 1, Loss: 0.39455267786979675\n",
      "Epoch 1, Loss: 1.2109228372573853\n",
      "Epoch 1, Loss: 1.6432651281356812\n",
      "Epoch 3, Loss: 0.05970398336648941\n",
      "Epoch 1, Loss: 0.20827044546604156\n",
      "Epoch 2, Loss: 0.3429122567176819\n",
      "Epoch 1, Loss: 0.3879331350326538\n",
      "Epoch 1, Loss: 0.6410828828811646\n",
      "Epoch 2, Loss: 0.15040914714336395\n",
      "Epoch 1, Loss: 0.044418856501579285\n",
      "Epoch 2, Loss: 0.25513654947280884\n",
      "Epoch 2, Loss: 0.532597005367279\n",
      "Epoch 4, Loss: 0.038262736052274704\n",
      "Epoch 3, Loss: 0.04575624316930771\n",
      "Epoch 1, Loss: 0.788191556930542\n",
      "Epoch 1, Loss: 0.23941804468631744\n",
      "Epoch 2, Loss: 0.2830837666988373\n",
      "Epoch 3, Loss: 0.22822991013526917\n",
      "Epoch 3, Loss: 0.06648674607276917\n",
      "Epoch 2, Loss: 0.24682308733463287\n",
      "Epoch 1, Loss: 0.4034673273563385\n",
      "Epoch 5, Loss: 0.01932458207011223\n",
      "Epoch 2, Loss: 0.08411303907632828\n",
      "Epoch 3, Loss: 0.10114574432373047\n",
      "Epoch 4, Loss: 0.08207792788743973\n",
      "Epoch 3, Loss: 0.152083620429039\n",
      "Epoch 2, Loss: 0.12841373682022095\n",
      "Epoch 2, Loss: 0.14466451108455658\n",
      "Epoch 6, Loss: 0.02344326488673687\n",
      "Epoch 4, Loss: 0.25890758633613586\n",
      "Epoch 3, Loss: 0.041669588536024094\n",
      "Epoch 4, Loss: 0.18551434576511383\n",
      "Epoch 2, Loss: 0.08296146243810654\n",
      "Epoch 5, Loss: 0.1717483252286911\n",
      "Epoch 4, Loss: 0.1664249449968338\n",
      "Epoch 4, Loss: 0.0645264983177185\n",
      "Epoch 2, Loss: 0.07305551320314407\n",
      "Epoch 7, Loss: 0.012602315284311771\n",
      "Epoch 3, Loss: 0.1628996729850769\n",
      "Epoch 3, Loss: 0.2352275848388672\n",
      "Epoch 6, Loss: 0.11870696395635605\n",
      "Epoch 5, Loss: 0.37522339820861816\n",
      "Epoch 5, Loss: 0.09171943366527557\n",
      "Epoch 5, Loss: 0.3550501763820648\n",
      "Epoch 3, Loss: 0.20429806411266327\n",
      "Epoch 4, Loss: 0.06194482743740082\n",
      "Epoch 8, Loss: 0.013166208751499653\n",
      "Epoch 3, Loss: 0.17101356387138367\n",
      "Epoch 5, Loss: 0.10565177351236343\n",
      "Epoch 6, Loss: 0.3377055823802948\n",
      "Epoch 7, Loss: 0.03575843200087547\n",
      "Epoch 4, Loss: 0.27899542450904846\n",
      "Epoch 6, Loss: 0.05129948630928993\n",
      "Epoch 4, Loss: 0.199640154838562\n",
      "Epoch 3, Loss: 0.24639491736888885\n",
      "Epoch 6, Loss: 0.4273666441440582\n",
      "Epoch 9, Loss: 0.020222224295139313\n",
      "Epoch 5, Loss: 0.12532943487167358\n",
      "Epoch 4, Loss: 0.34262850880622864\n",
      "Epoch 8, Loss: 0.015220976434648037\n",
      "Epoch 7, Loss: 0.22691643238067627\n",
      "Epoch 6, Loss: 0.10736952722072601\n",
      "Epoch 7, Loss: 0.06609246879816055\n",
      "Epoch 4, Loss: 0.07122894376516342\n",
      "Epoch 10, Loss: 0.0156644769012928\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.0003710098026308474, num_heads=4, num_layers=4; total time=   1.0s\n",
      "Epoch 5, Loss: 0.22928591072559357\n",
      "Epoch 7, Loss: 0.3774935007095337\n",
      "Epoch 5, Loss: 0.10852834582328796\n",
      "Epoch 9, Loss: 0.05202509090304375\n",
      "Epoch 6, Loss: 0.08375810831785202\n",
      "Epoch 8, Loss: 0.11503283679485321\n",
      "Epoch 4, Loss: 0.18260368704795837\n",
      "Epoch 8, Loss: 0.07949841022491455\n",
      "Epoch 7, Loss: 0.054234493523836136\n",
      "Epoch 5, Loss: 0.2954849600791931\n",
      "Epoch 8, Loss: 0.26696348190307617\n",
      "Epoch 6, Loss: 0.06089963763952255\n",
      "Epoch 10, Loss: 0.08220495283603668\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.0003710098026308474, num_heads=4, num_layers=4; total time=   1.1s\n",
      "Epoch 9, Loss: 0.06743419915437698\n",
      "Epoch 6, Loss: 0.11757689714431763\n",
      "Epoch 5, Loss: 0.010477828793227673\n",
      "Epoch 9, Loss: 0.05147852748632431\n",
      "Epoch 7, Loss: 0.026024671271443367\n",
      "Epoch 5, Loss: 0.055238332599401474\n",
      "Epoch 8, Loss: 0.019725268706679344\n",
      "Epoch 10, Loss: 0.03640640527009964\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.0003710098026308474, num_heads=4, num_layers=4; total time=   1.2s\n",
      "Epoch 6, Loss: 0.16894890367984772\n",
      "Epoch 9, Loss: 0.1527375429868698\n",
      "Epoch 10, Loss: 0.03869996219873428\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.0003710098026308474, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 6, Loss: 0.04441644996404648\n",
      "Epoch 7, Loss: 0.07219771295785904\n",
      "Epoch 7, Loss: 0.03981148451566696\n",
      "Epoch 8, Loss: 0.017154186964035034\n",
      "Epoch 9, Loss: 0.03534150496125221\n",
      "Epoch 10, Loss: 0.06926870346069336\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.0003710098026308474, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 6, Loss: 0.01703985221683979\n",
      "Epoch 7, Loss: 0.07673384994268417\n",
      "Epoch 8, Loss: 0.028348010033369064\n",
      "Epoch 8, Loss: 0.09420251101255417\n",
      "Epoch 10, Loss: 0.05409124121069908\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.0003710098026308474, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 9, Loss: 0.04507925733923912\n",
      "Epoch 7, Loss: 0.07043638080358505\n",
      "Epoch 7, Loss: 0.06020684912800789\n",
      "Epoch 8, Loss: 0.05821770802140236\n",
      "Epoch 9, Loss: 0.06195468828082085\n",
      "Epoch 9, Loss: 0.08759519457817078\n",
      "Epoch 10, Loss: 0.06043847277760506\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.0003710098026308474, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Epoch 9, Loss: 0.020318124443292618\n",
      "Epoch 8, Loss: 0.04623456671833992\n",
      "Epoch 10, Loss: 0.09383106976747513\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.0003710098026308474, num_heads=4, num_layers=4; total time=   1.6s\n",
      "Epoch 8, Loss: 0.09794320166110992\n",
      "Epoch 10, Loss: 0.06072883680462837\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.0003710098026308474, num_heads=4, num_layers=4; total time=   1.6s\n",
      "Epoch 10, Loss: 0.006884866859763861\n",
      "Epoch 9, Loss: 0.07316175848245621\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.0003710098026308474, num_heads=4, num_layers=4; total time=   1.6s\n",
      "Epoch 9, Loss: 0.08736350387334824\n",
      "Epoch 10, Loss: 0.11064479500055313\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.0003710098026308474, num_heads=4, num_layers=4; total time=   1.7s\n",
      "Epoch 10, Loss: 0.04708201810717583\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.0003710098026308474, num_heads=4, num_layers=4; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.2766052186489105\n",
      "Epoch 1, Loss: 1.2441707849502563\n",
      "Epoch 2, Loss: 0.06876746565103531\n",
      "Epoch 1, Loss: 0.894135057926178\n",
      "Epoch 2, Loss: 0.22904916107654572\n",
      "Epoch 1, Loss: 0.9867153763771057\n",
      "Epoch 1, Loss: 0.21747589111328125\n",
      "Epoch 1, Loss: 1.6187795400619507\n",
      "Epoch 3, Loss: 0.18190144002437592\n",
      "Epoch 2, Loss: 0.1132158488035202\n",
      "Epoch 3, Loss: 0.2428535521030426\n",
      "Epoch 1, Loss: 1.662079930305481\n",
      "Epoch 2, Loss: 0.08598051965236664\n",
      "Epoch 1, Loss: 0.06185473874211311\n",
      "Epoch 4, Loss: 0.43458953499794006\n",
      "Epoch 1, Loss: 0.4781913757324219\n",
      "Epoch 4, Loss: 0.08987359702587128\n",
      "Epoch 2, Loss: 0.18742243945598602\n",
      "Epoch 1, Loss: 0.2895665168762207\n",
      "Epoch 2, Loss: 0.32547175884246826\n",
      "Epoch 3, Loss: 0.3469527065753937\n",
      "Epoch 1, Loss: 0.22716185450553894\n",
      "Epoch 5, Loss: 0.4182012379169464\n",
      "Epoch 3, Loss: 0.3422700762748718\n",
      "Epoch 2, Loss: 0.120367132127285\n",
      "Epoch 1, Loss: 0.8935447931289673\n",
      "Epoch 5, Loss: 0.016449911519885063\n",
      "Epoch 2, Loss: 0.4572908580303192\n",
      "Epoch 3, Loss: 0.18011340498924255\n",
      "Epoch 2, Loss: 0.11430880427360535\n",
      "Epoch 6, Loss: 0.2789287865161896\n",
      "Epoch 3, Loss: 0.10630571842193604\n",
      "Epoch 2, Loss: 0.040759455412626266\n",
      "Epoch 4, Loss: 0.40233680605888367\n",
      "Epoch 6, Loss: 0.03138209506869316\n",
      "Epoch 4, Loss: 0.4534473121166229\n",
      "Epoch 2, Loss: 0.1349649429321289\n",
      "Epoch 7, Loss: 0.1353016346693039\n",
      "Epoch 3, Loss: 0.3656642735004425\n",
      "Epoch 3, Loss: 0.06764969229698181\n",
      "Epoch 2, Loss: 0.09727605432271957\n",
      "Epoch 4, Loss: 0.02944129891693592\n",
      "Epoch 3, Loss: 0.21350648999214172\n",
      "Epoch 4, Loss: 0.3714965879917145\n",
      "Epoch 7, Loss: 0.07142385095357895\n",
      "Epoch 3, Loss: 0.25708603858947754\n",
      "Epoch 8, Loss: 0.059370726346969604\n",
      "Epoch 5, Loss: 0.29384103417396545\n",
      "Epoch 5, Loss: 0.25182807445526123\n",
      "Epoch 3, Loss: 0.17260967195034027\n",
      "Epoch 4, Loss: 0.6657360792160034\n",
      "Epoch 4, Loss: 0.05883673578500748\n",
      "Epoch 5, Loss: 0.019047105684876442\n",
      "Epoch 8, Loss: 0.06868864595890045\n",
      "Epoch 4, Loss: 0.08281141519546509\n",
      "Epoch 6, Loss: 0.11517377942800522\n",
      "Epoch 3, Loss: 0.18946881592273712\n",
      "Epoch 5, Loss: 0.46660295128822327\n",
      "Epoch 6, Loss: 0.09664950519800186\n",
      "Epoch 9, Loss: 0.05327780172228813\n",
      "Epoch 4, Loss: 0.22554358839988708\n",
      "Epoch 5, Loss: 0.19342826306819916\n",
      "Epoch 5, Loss: 0.5013561248779297\n",
      "Epoch 4, Loss: 0.059348396956920624\n",
      "Epoch 6, Loss: 0.086484394967556\n",
      "Epoch 9, Loss: 0.035841744393110275\n",
      "Epoch 7, Loss: 0.03580906614661217\n",
      "Epoch 5, Loss: 0.009853607043623924\n",
      "Epoch 6, Loss: 0.36843231320381165\n",
      "Epoch 7, Loss: 0.04209868237376213\n",
      "Epoch 4, Loss: 0.3400178849697113\n",
      "Epoch 10, Loss: 0.08977054804563522\n",
      "Epoch 10, Loss: 0.009329401887953281\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1907537310037932, feed_forward_dim=1024, head_dim=16, lr=0.0004748986772470451, num_heads=4, num_layers=4; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1907537310037932, feed_forward_dim=1024, head_dim=16, lr=0.0004748986772470451, num_heads=4, num_layers=4; total time=   1.0s\n",
      "Epoch 6, Loss: 0.22469885647296906\n",
      "Epoch 7, Loss: 0.09489630907773972\n",
      "Epoch 6, Loss: 0.15305908024311066\n",
      "Epoch 5, Loss: 0.08767753839492798\n",
      "Epoch 5, Loss: 0.021231012418866158\n",
      "Epoch 7, Loss: 0.21774770319461823\n",
      "Epoch 6, Loss: 0.051764633506536484\n",
      "Epoch 8, Loss: 0.05755235627293587\n",
      "Epoch 8, Loss: 0.07503572106361389\n",
      "Epoch 7, Loss: 0.05143573507666588\n",
      "Epoch 8, Loss: 0.04707447439432144\n",
      "Epoch 8, Loss: 0.09741899371147156\n",
      "Epoch 5, Loss: 0.2867605686187744\n",
      "Epoch 7, Loss: 0.048794519156217575\n",
      "Epoch 6, Loss: 0.060699302703142166\n",
      "Epoch 9, Loss: 0.1267423927783966\n",
      "Epoch 6, Loss: 0.016067979857325554\n",
      "Epoch 8, Loss: 0.039742182940244675\n",
      "Epoch 9, Loss: 0.11771436780691147\n",
      "Epoch 7, Loss: 0.09502299129962921\n",
      "Epoch 9, Loss: 0.008808421902358532\n",
      "Epoch 10, Loss: 0.14100857079029083\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1907537310037932, feed_forward_dim=1024, head_dim=16, lr=0.0004748986772470451, num_heads=4, num_layers=4; total time=   1.2s\n",
      "Epoch 9, Loss: 0.039207931607961655\n",
      "Epoch 7, Loss: 0.07860661298036575\n",
      "Epoch 10, Loss: 0.14916451275348663\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1907537310037932, feed_forward_dim=1024, head_dim=16, lr=0.0004748986772470451, num_heads=4, num_layers=4; total time=   1.2s\n",
      "Epoch 7, Loss: 0.039522554725408554\n",
      "Epoch 9, Loss: 0.12278576195240021\n",
      "Epoch 10, Loss: 0.009870636276900768\n",
      "Epoch 8, Loss: 0.008839473128318787\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1907537310037932, feed_forward_dim=1024, head_dim=16, lr=0.0004748986772470451, num_heads=4, num_layers=4; total time=   1.2s\n",
      "Epoch 8, Loss: 0.07142823934555054\n",
      "Epoch 6, Loss: 0.15231755375862122\n",
      "Epoch 10, Loss: 0.03666463866829872\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1907537310037932, feed_forward_dim=1024, head_dim=16, lr=0.0004748986772470451, num_heads=4, num_layers=4; total time=   1.2s\n",
      "Epoch 8, Loss: 0.08823338150978088\n",
      "Epoch 8, Loss: 0.04840308055281639\n",
      "Epoch 10, Loss: 0.19674618542194366\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1907537310037932, feed_forward_dim=1024, head_dim=16, lr=0.0004748986772470451, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 9, Loss: 0.02384597808122635\n",
      "Epoch 7, Loss: 0.04984186217188835\n",
      "Epoch 9, Loss: 0.04467197135090828\n",
      "Epoch 9, Loss: 0.10028871148824692\n",
      "Epoch 9, Loss: 0.015018163248896599\n",
      "Epoch 10, Loss: 0.004731203429400921\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1907537310037932, feed_forward_dim=1024, head_dim=16, lr=0.0004748986772470451, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 10, Loss: 0.08645857870578766\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1907537310037932, feed_forward_dim=1024, head_dim=16, lr=0.0004748986772470451, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 8, Loss: 0.022787049412727356\n",
      "Epoch 10, Loss: 0.0728263407945633\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1907537310037932, feed_forward_dim=1024, head_dim=16, lr=0.0004748986772470451, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.009566297754645348\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1907537310037932, feed_forward_dim=1024, head_dim=16, lr=0.0004748986772470451, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 9, Loss: 0.055443283170461655\n",
      "Epoch 10, Loss: 0.10025086998939514\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1907537310037932, feed_forward_dim=1024, head_dim=16, lr=0.0004748986772470451, num_heads=4, num_layers=4; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 1.258283019065857\n",
      "Epoch 1, Loss: 0.9120833873748779\n",
      "Epoch 1, Loss: 0.09952376782894135\n",
      "Epoch 2, Loss: 0.5442965030670166\n",
      "Epoch 1, Loss: 0.44650065898895264\n",
      "Epoch 1, Loss: 1.0395662784576416\n",
      "Epoch 2, Loss: 0.2705356776714325\n",
      "Epoch 2, Loss: 0.09863955527544022\n",
      "Epoch 1, Loss: 0.3338964283466339\n",
      "Epoch 1, Loss: 0.40944838523864746\n",
      "Epoch 1, Loss: 0.3177608847618103\n",
      "Epoch 2, Loss: 0.08533431589603424\n",
      "Epoch 3, Loss: 0.21771220862865448\n",
      "Epoch 1, Loss: 0.3679872155189514\n",
      "Epoch 2, Loss: 0.378754198551178\n",
      "Epoch 2, Loss: 0.052722442895174026\n",
      "Epoch 3, Loss: 0.0806417465209961\n",
      "Epoch 3, Loss: 0.04677746444940567\n",
      "Epoch 1, Loss: 2.255303144454956\n",
      "Epoch 1, Loss: 0.056450255215168\n",
      "Epoch 4, Loss: 0.21496860682964325\n",
      "Epoch 2, Loss: 0.050986677408218384\n",
      "Epoch 2, Loss: 0.08356620371341705\n",
      "Epoch 1, Loss: 0.14958377182483673\n",
      "Epoch 3, Loss: 0.1251811534166336\n",
      "Epoch 2, Loss: 0.025439705699682236\n",
      "Epoch 3, Loss: 0.08121459931135178\n",
      "Epoch 4, Loss: 0.0557185523211956\n",
      "Epoch 4, Loss: 0.1829359084367752\n",
      "Epoch 3, Loss: 0.11424101144075394\n",
      "Epoch 2, Loss: 1.169861078262329\n",
      "Epoch 5, Loss: 0.32796162366867065\n",
      "Epoch 4, Loss: 0.17643529176712036\n",
      "Epoch 3, Loss: 0.17468269169330597\n",
      "Epoch 2, Loss: 0.09575505554676056\n",
      "Epoch 5, Loss: 0.03282899409532547\n",
      "Epoch 3, Loss: 0.07729089260101318\n",
      "Epoch 6, Loss: 0.3802408277988434\n",
      "Epoch 5, Loss: 0.2962551414966583\n",
      "Epoch 4, Loss: 0.1490418165922165\n",
      "Epoch 4, Loss: 0.17847278714179993\n",
      "Epoch 3, Loss: 0.08930549770593643\n",
      "Epoch 3, Loss: 0.4552440047264099\n",
      "Epoch 5, Loss: 0.1821705847978592\n",
      "Epoch 2, Loss: 0.08596742898225784\n",
      "Epoch 6, Loss: 0.018838079646229744\n",
      "Epoch 7, Loss: 0.34813347458839417\n",
      "Epoch 6, Loss: 0.2859248220920563\n",
      "Epoch 4, Loss: 0.17143061757087708\n",
      "Epoch 4, Loss: 0.16523513197898865\n",
      "Epoch 4, Loss: 0.16542375087738037\n",
      "Epoch 5, Loss: 0.12852181494235992\n",
      "Epoch 3, Loss: 0.04228799417614937\n",
      "Epoch 5, Loss: 0.26451507210731506\n",
      "Epoch 6, Loss: 0.12303005903959274\n",
      "Epoch 7, Loss: 0.026987848803400993\n",
      "Epoch 8, Loss: 0.2634182572364807\n",
      "Epoch 4, Loss: 0.10527271777391434\n",
      "Epoch 7, Loss: 0.20882859826087952\n",
      "Epoch 5, Loss: 0.15883611142635345\n",
      "Epoch 3, Loss: 0.10037263482809067\n",
      "Epoch 8, Loss: 0.024778077378869057\n",
      "Epoch 6, Loss: 0.3113926351070404\n",
      "Epoch 9, Loss: 0.17104527354240417\n",
      "Epoch 5, Loss: 0.13033083081245422\n",
      "Epoch 6, Loss: 0.05609656870365143\n",
      "Epoch 5, Loss: 0.08500140905380249\n",
      "Epoch 7, Loss: 0.05563206970691681\n",
      "Epoch 8, Loss: 0.11429288983345032\n",
      "Epoch 4, Loss: 0.014912321232259274\n",
      "Epoch 6, Loss: 0.08865700662136078\n",
      "Epoch 5, Loss: 0.046409495174884796\n",
      "Epoch 10, Loss: 0.0975119099020958\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.34729199745712047, feed_forward_dim=512, head_dim=32, lr=0.0002500008271847295, num_heads=2, num_layers=4; total time=   1.1s\n",
      "Epoch 9, Loss: 0.015878111124038696\n",
      "Epoch 9, Loss: 0.043362267315387726\n",
      "Epoch 7, Loss: 0.026539836078882217\n",
      "Epoch 7, Loss: 0.27803635597229004\n",
      "Epoch 4, Loss: 0.053648967295885086\n",
      "Epoch 6, Loss: 0.03240927308797836\n",
      "Epoch 6, Loss: 0.05464101582765579\n",
      "Epoch 8, Loss: 0.023946741595864296\n",
      "Epoch 10, Loss: 0.019462333992123604\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.34729199745712047, feed_forward_dim=512, head_dim=32, lr=0.0002500008271847295, num_heads=2, num_layers=4; total time=   1.1s\n",
      "Epoch 5, Loss: 0.03738212212920189\n",
      "Epoch 7, Loss: 0.03159187361598015\n",
      "Epoch 10, Loss: 0.02367774024605751\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.34729199745712047, feed_forward_dim=512, head_dim=32, lr=0.0002500008271847295, num_heads=2, num_layers=4; total time=   1.2s\n",
      "Epoch 8, Loss: 0.042679108679294586\n",
      "Epoch 6, Loss: 0.15704010426998138\n",
      "Epoch 8, Loss: 0.19941388070583344\n",
      "Epoch 9, Loss: 0.029504774138331413\n",
      "Epoch 7, Loss: 0.03558754175901413\n",
      "Epoch 7, Loss: 0.008066046051681042\n",
      "Epoch 6, Loss: 0.03724323585629463\n",
      "Epoch 5, Loss: 0.023265909403562546\n",
      "Epoch 8, Loss: 0.01581188105046749\n",
      "Epoch 9, Loss: 0.06952008605003357\n",
      "Epoch 9, Loss: 0.11660917848348618\n",
      "Epoch 7, Loss: 0.29788950085639954\n",
      "Epoch 10, Loss: 0.05667132884263992\n",
      "Epoch 8, Loss: 0.06056777387857437\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.34729199745712047, feed_forward_dim=512, head_dim=32, lr=0.0002500008271847295, num_heads=2, num_layers=4; total time=   1.3s\n",
      "Epoch 10, Loss: 0.07698187232017517\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.34729199745712047, feed_forward_dim=512, head_dim=32, lr=0.0002500008271847295, num_heads=2, num_layers=4; total time=   1.3s\n",
      "Epoch 6, Loss: 0.03016657382249832\n",
      "Epoch 10, Loss: 0.058788277208805084\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.34729199745712047, feed_forward_dim=512, head_dim=32, lr=0.0002500008271847295, num_heads=2, num_layers=4; total time=   1.4s\n",
      "Epoch 7, Loss: 0.014438378624618053\n",
      "Epoch 9, Loss: 0.03496366739273071\n",
      "Epoch 8, Loss: 0.01136623416095972\n",
      "Epoch 8, Loss: 0.3815363049507141\n",
      "Epoch 9, Loss: 0.06551264226436615\n",
      "Epoch 10, Loss: 0.060580067336559296\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.34729199745712047, feed_forward_dim=512, head_dim=32, lr=0.0002500008271847295, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Epoch 7, Loss: 0.03625619038939476\n",
      "Epoch 8, Loss: 0.006681252736598253\n",
      "Epoch 9, Loss: 0.042527586221694946\n",
      "Epoch 9, Loss: 0.394694447517395\n",
      "Epoch 10, Loss: 0.04421878233551979\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.34729199745712047, feed_forward_dim=512, head_dim=32, lr=0.0002500008271847295, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Epoch 8, Loss: 0.022123847156763077\n",
      "Epoch 9, Loss: 0.0191819928586483\n",
      "Epoch 10, Loss: 0.3493877947330475\n",
      "Epoch 10, Loss: 0.06496697664260864\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.34729199745712047, feed_forward_dim=512, head_dim=32, lr=0.0002500008271847295, num_heads=2, num_layers=4; total time=   1.6s\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.34729199745712047, feed_forward_dim=512, head_dim=32, lr=0.0002500008271847295, num_heads=2, num_layers=4; total time=   1.6s\n",
      "Epoch 10, Loss: 0.02443820796906948\n",
      "Epoch 9, Loss: 0.008293306455016136\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.34729199745712047, feed_forward_dim=512, head_dim=32, lr=0.0002500008271847295, num_heads=2, num_layers=4; total time=   1.6s\n",
      "Epoch 10, Loss: 0.008358577266335487\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.34729199745712047, feed_forward_dim=512, head_dim=32, lr=0.0002500008271847295, num_heads=2, num_layers=4; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.08189582079648972\n",
      "Epoch 1, Loss: 0.38607057929039\n",
      "Epoch 2, Loss: 0.1202242374420166\n",
      "Epoch 1, Loss: 1.4664344787597656\n",
      "Epoch 1, Loss: 0.2107226848602295\n",
      "Epoch 1, Loss: 0.23758165538311005\n",
      "Epoch 3, Loss: 0.06422682851552963\n",
      "Epoch 1, Loss: 0.9878072738647461\n",
      "Epoch 1, Loss: 0.041686221957206726\n",
      "Epoch 2, Loss: 0.05621827021241188\n",
      "Epoch 2, Loss: 0.4872171878814697\n",
      "Epoch 2, Loss: 0.09207755327224731\n",
      "Epoch 1, Loss: 0.01982766203582287\n",
      "Epoch 4, Loss: 0.0039467778988182545\n",
      "Epoch 2, Loss: 0.24128615856170654\n",
      "Epoch 1, Loss: 0.7055397629737854\n",
      "Epoch 3, Loss: 0.20073626935482025\n",
      "Epoch 2, Loss: 0.04575323686003685\n",
      "Epoch 3, Loss: 0.05262182652950287\n",
      "Epoch 1, Loss: 0.3231256306171417\n",
      "Epoch 2, Loss: 0.2631245255470276\n",
      "Epoch 5, Loss: 0.03747939318418503\n",
      "Epoch 1, Loss: 0.2942125201225281\n",
      "Epoch 3, Loss: 0.159720316529274\n",
      "Epoch 4, Loss: 0.1897561252117157\n",
      "Epoch 1, Loss: 0.1791558861732483\n",
      "Epoch 2, Loss: 0.2404615730047226\n",
      "Epoch 3, Loss: 0.024743370711803436\n",
      "Epoch 3, Loss: 0.1671694815158844\n",
      "Epoch 4, Loss: 0.08303119987249374\n",
      "Epoch 2, Loss: 0.09042808413505554\n",
      "Epoch 6, Loss: 0.05707667022943497\n",
      "Epoch 2, Loss: 0.08340921252965927\n",
      "Epoch 3, Loss: 0.03556549921631813\n",
      "Epoch 4, Loss: 0.05419294908642769\n",
      "Epoch 5, Loss: 0.08096928894519806\n",
      "Epoch 5, Loss: 0.2705688774585724\n",
      "Epoch 7, Loss: 0.029264695942401886\n",
      "Epoch 2, Loss: 0.058212507516145706\n",
      "Epoch 4, Loss: 0.09563945978879929\n",
      "Epoch 4, Loss: 0.15416014194488525\n",
      "Epoch 3, Loss: 0.029109787195920944\n",
      "Epoch 2, Loss: 0.1517278403043747\n",
      "Epoch 3, Loss: 0.10224449634552002\n",
      "Epoch 5, Loss: 0.013486625626683235\n",
      "Epoch 4, Loss: 0.07618864625692368\n",
      "Epoch 6, Loss: 0.022825069725513458\n",
      "Epoch 8, Loss: 0.006157476920634508\n",
      "Epoch 6, Loss: 0.35720157623291016\n",
      "Epoch 3, Loss: 0.16769658029079437\n",
      "Epoch 5, Loss: 0.016212182119488716\n",
      "Epoch 3, Loss: 0.1175728440284729\n",
      "Epoch 4, Loss: 0.050223272293806076\n",
      "Epoch 6, Loss: 0.057576585561037064\n",
      "Epoch 5, Loss: 0.2839067578315735\n",
      "Epoch 7, Loss: 0.03872630372643471\n",
      "Epoch 4, Loss: 0.26741597056388855\n",
      "Epoch 9, Loss: 0.010983987711369991\n",
      "Epoch 3, Loss: 0.16986533999443054\n",
      "Epoch 5, Loss: 0.13775204122066498\n",
      "Epoch 7, Loss: 0.315000981092453\n",
      "Epoch 4, Loss: 0.15478947758674622\n",
      "Epoch 6, Loss: 0.02281479723751545\n",
      "Epoch 8, Loss: 0.07414007931947708Epoch 10, Loss: 0.02762961946427822\n",
      "\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2103992492595283, feed_forward_dim=256, head_dim=16, lr=0.0003572156050926921, num_heads=4, num_layers=1; total time=   1.0s\n",
      "Epoch 7, Loss: 0.07734250277280807\n",
      "Epoch 6, Loss: 0.2818402051925659\n",
      "Epoch 5, Loss: 0.12057708948850632\n",
      "Epoch 4, Loss: 0.03648858889937401\n",
      "Epoch 5, Loss: 0.260856032371521\n",
      "Epoch 8, Loss: 0.21023307740688324\n",
      "Epoch 4, Loss: 0.1241152212023735\n",
      "Epoch 6, Loss: 0.08399198204278946\n",
      "Epoch 7, Loss: 0.0654478594660759\n",
      "Epoch 9, Loss: 0.08161813765764236\n",
      "Epoch 8, Loss: 0.04704413190484047\n",
      "Epoch 5, Loss: 0.07696695625782013\n",
      "Epoch 7, Loss: 0.20420841872692108\n",
      "Epoch 9, Loss: 0.10697118192911148\n",
      "Epoch 6, Loss: 0.08377399295568466\n",
      "Epoch 6, Loss: 0.15629692375659943\n",
      "Epoch 10, Loss: 0.05249147489666939\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2103992492595283, feed_forward_dim=256, head_dim=16, lr=0.0003572156050926921, num_heads=4, num_layers=1; total time=   1.2s\n",
      "Epoch 5, Loss: 0.035614147782325745\n",
      "Epoch 9, Loss: 0.013284968212246895\n",
      "Epoch 8, Loss: 0.0714055672287941\n",
      "Epoch 5, Loss: 0.037010084837675095\n",
      "Epoch 7, Loss: 0.020079828798770905\n",
      "Epoch 6, Loss: 0.02778903767466545\n",
      "Epoch 8, Loss: 0.1088113859295845\n",
      "Epoch 10, Loss: 0.03772611543536186\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2103992492595283, feed_forward_dim=256, head_dim=16, lr=0.0003572156050926921, num_heads=4, num_layers=1; total time=   1.3s\n",
      "Epoch 7, Loss: 0.024838628247380257\n",
      "Epoch 7, Loss: 0.05846536159515381\n",
      "Epoch 10, Loss: 0.010316451080143452\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2103992492595283, feed_forward_dim=256, head_dim=16, lr=0.0003572156050926921, num_heads=4, num_layers=1; total time=   1.3s\n",
      "Epoch 9, Loss: 0.04217328131198883\n",
      "Epoch 8, Loss: 0.016202377155423164\n",
      "Epoch 6, Loss: 0.0559706948697567\n",
      "Epoch 9, Loss: 0.04052302986383438\n",
      "Epoch 8, Loss: 0.008877621963620186\n",
      "Epoch 6, Loss: 0.011759772896766663\n",
      "Epoch 7, Loss: 0.036623939871788025\n",
      "Epoch 8, Loss: 0.020408235490322113\n",
      "Epoch 10, Loss: 0.012855948880314827\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2103992492595283, feed_forward_dim=256, head_dim=16, lr=0.0003572156050926921, num_heads=4, num_layers=1; total time=   1.4s\n",
      "Epoch 9, Loss: 0.049333009868860245\n",
      "Epoch 7, Loss: 0.037976544350385666\n",
      "Epoch 9, Loss: 0.0358116514980793\n",
      "Epoch 10, Loss: 0.01681506633758545\n",
      "Epoch 9, Loss: 0.038262367248535156\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2103992492595283, feed_forward_dim=256, head_dim=16, lr=0.0003572156050926921, num_heads=4, num_layers=1; total time=   1.5s\n",
      "Epoch 7, Loss: 0.03940381854772568\n",
      "Epoch 8, Loss: 0.0648200735449791\n",
      "Epoch 10, Loss: 0.0622909776866436\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2103992492595283, feed_forward_dim=256, head_dim=16, lr=0.0003572156050926921, num_heads=4, num_layers=1; total time=   1.6s\n",
      "Epoch 8, Loss: 0.011715536937117577\n",
      "Epoch 10, Loss: 0.057351235300302505\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2103992492595283, feed_forward_dim=256, head_dim=16, lr=0.0003572156050926921, num_heads=4, num_layers=1; total time=   1.6s\n",
      "Epoch 10, Loss: 0.07726141065359116\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2103992492595283, feed_forward_dim=256, head_dim=16, lr=0.0003572156050926921, num_heads=4, num_layers=1; total time=   1.6s\n",
      "Epoch 8, Loss: 0.059145648032426834\n",
      "Epoch 9, Loss: 0.06730130314826965\n",
      "Epoch 9, Loss: 0.01456860825419426\n",
      "Epoch 10, Loss: 0.04098466783761978\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2103992492595283, feed_forward_dim=256, head_dim=16, lr=0.0003572156050926921, num_heads=4, num_layers=1; total time=   1.7s\n",
      "Epoch 9, Loss: 0.04757843539118767\n",
      "Epoch 10, Loss: 0.03244666010141373\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2103992492595283, feed_forward_dim=256, head_dim=16, lr=0.0003572156050926921, num_heads=4, num_layers=1; total time=   1.7s\n",
      "Epoch 10, Loss: 0.02014261670410633\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2103992492595283, feed_forward_dim=256, head_dim=16, lr=0.0003572156050926921, num_heads=4, num_layers=1; total time=   1.8s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 3.3489677906036377\n",
      "Epoch 1, Loss: 0.37012410163879395\n",
      "Epoch 1, Loss: 0.13924972712993622\n",
      "Epoch 1, Loss: 0.1758834719657898\n",
      "Epoch 2, Loss: 1.0698456764221191\n",
      "Epoch 1, Loss: 0.17290589213371277\n",
      "Epoch 2, Loss: 0.21044360101222992\n",
      "Epoch 1, Loss: 0.9167481064796448\n",
      "Epoch 2, Loss: 0.4887813925743103\n",
      "Epoch 3, Loss: 0.10275848954916\n",
      "Epoch 1, Loss: 0.3076029419898987\n",
      "Epoch 2, Loss: 0.2580562233924866\n",
      "Epoch 2, Loss: 0.3606008291244507\n",
      "Epoch 3, Loss: 0.12336333841085434\n",
      "Epoch 3, Loss: 0.2391538769006729\n",
      "Epoch 1, Loss: 0.5332263112068176\n",
      "Epoch 2, Loss: 0.09756805747747421\n",
      "Epoch 4, Loss: 0.09805771708488464\n",
      "Epoch 3, Loss: 0.15634627640247345\n",
      "Epoch 3, Loss: 0.1344231218099594\n",
      "Epoch 1, Loss: 0.6846948266029358\n",
      "Epoch 1, Loss: 0.05503873899579048\n",
      "Epoch 4, Loss: 0.08737966418266296\n",
      "Epoch 1, Loss: 1.179897427558899\n",
      "Epoch 2, Loss: 0.0481099858880043\n",
      "Epoch 4, Loss: 0.06423235684633255\n",
      "Epoch 1, Loss: 0.214413121342659\n",
      "Epoch 2, Loss: 0.07930053025484085\n",
      "Epoch 5, Loss: 0.4058705270290375\n",
      "Epoch 5, Loss: 0.044478639960289\n",
      "Epoch 4, Loss: 0.01525458600372076\n",
      "Epoch 2, Loss: 0.09339801222085953\n",
      "Epoch 3, Loss: 0.3275746703147888\n",
      "Epoch 4, Loss: 0.03960033878684044\n",
      "Epoch 6, Loss: 0.09752476215362549\n",
      "Epoch 6, Loss: 0.5681033134460449\n",
      "Epoch 2, Loss: 0.10658908635377884\n",
      "Epoch 2, Loss: 0.13929471373558044\n",
      "Epoch 5, Loss: 0.20265048742294312\n",
      "Epoch 3, Loss: 0.18999777734279633\n",
      "Epoch 3, Loss: 0.33229103684425354\n",
      "Epoch 5, Loss: 0.05272224172949791\n",
      "Epoch 5, Loss: 0.12478909641504288\n",
      "Epoch 4, Loss: 0.39681610465049744\n",
      "Epoch 2, Loss: 0.29883885383605957\n",
      "Epoch 3, Loss: 0.09595230221748352\n",
      "Epoch 7, Loss: 0.5511060357093811\n",
      "Epoch 7, Loss: 0.1064688190817833\n",
      "Epoch 4, Loss: 0.1365610808134079\n",
      "Epoch 3, Loss: 0.33394506573677063\n",
      "Epoch 3, Loss: 0.40238896012306213\n",
      "Epoch 6, Loss: 0.1069096028804779\n",
      "Epoch 8, Loss: 0.426578551530838\n",
      "Epoch 4, Loss: 0.17673203349113464\n",
      "Epoch 6, Loss: 0.13031068444252014\n",
      "Epoch 6, Loss: 0.1528371274471283\n",
      "Epoch 8, Loss: 0.0565955825150013\n",
      "Epoch 5, Loss: 0.2560398280620575\n",
      "Epoch 9, Loss: 0.27951207756996155\n",
      "Epoch 4, Loss: 0.06992194801568985\n",
      "Epoch 9, Loss: 0.016037916764616966\n",
      "Epoch 3, Loss: 0.16862793266773224\n",
      "Epoch 7, Loss: 0.07341908663511276\n",
      "Epoch 4, Loss: 0.29081490635871887\n",
      "Epoch 7, Loss: 0.038607172667980194\n",
      "Epoch 5, Loss: 0.04343676194548607\n",
      "Epoch 5, Loss: 0.019289568066596985\n",
      "Epoch 4, Loss: 0.5000337362289429\n",
      "Epoch 6, Loss: 0.10027860850095749\n",
      "Epoch 7, Loss: 0.05484527722001076\n",
      "Epoch 10, Loss: 0.1525782346725464\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.17094985786090858, feed_forward_dim=128, head_dim=8, lr=0.0005160642393330307, num_heads=8, num_layers=4; total time=   0.9s\n",
      "Epoch 10, Loss: 0.0199951883405447\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.17094985786090858, feed_forward_dim=128, head_dim=8, lr=0.0005160642393330307, num_heads=8, num_layers=4; total time=   0.9s\n",
      "Epoch 5, Loss: 0.013857212848961353\n",
      "Epoch 8, Loss: 0.018572958186268806\n",
      "Epoch 8, Loss: 0.013382814824581146\n",
      "Epoch 4, Loss: 0.026922572404146194\n",
      "Epoch 5, Loss: 0.12776069343090057\n",
      "Epoch 7, Loss: 0.03821234777569771\n",
      "Epoch 6, Loss: 0.032439131289720535\n",
      "Epoch 6, Loss: 0.023363394662737846\n",
      "Epoch 8, Loss: 0.012234196998178959\n",
      "Epoch 9, Loss: 0.0071084327064454556\n",
      "Epoch 9, Loss: 0.060137245804071426\n",
      "Epoch 6, Loss: 0.05454795062541962\n",
      "Epoch 5, Loss: 0.3249187469482422\n",
      "Epoch 7, Loss: 0.059791430830955505\n",
      "Epoch 9, Loss: 0.03601078689098358\n",
      "Epoch 8, Loss: 0.060735028237104416\n",
      "Epoch 10, Loss: 0.03174969181418419\n",
      "Epoch 5, Loss: 0.07568243145942688\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.17094985786090858, feed_forward_dim=128, head_dim=8, lr=0.0005160642393330307, num_heads=8, num_layers=4; total time=   1.1s\n",
      "Epoch 10, Loss: 0.09077126532793045\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.17094985786090858, feed_forward_dim=128, head_dim=8, lr=0.0005160642393330307, num_heads=8, num_layers=4; total time=   1.1s\n",
      "Epoch 7, Loss: 0.11000972241163254\n",
      "Epoch 6, Loss: 0.04017100855708122\n",
      "Epoch 7, Loss: 0.046436749398708344\n",
      "Epoch 10, Loss: 0.06956973671913147\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.17094985786090858, feed_forward_dim=128, head_dim=8, lr=0.0005160642393330307, num_heads=8, num_layers=4; total time=   1.2s\n",
      "Epoch 9, Loss: 0.1088290587067604\n",
      "Epoch 8, Loss: 0.08386275917291641\n",
      "Epoch 6, Loss: 0.1315852403640747\n",
      "Epoch 6, Loss: 0.11964564770460129\n",
      "Epoch 7, Loss: 0.05234558507800102\n",
      "Epoch 10, Loss: 0.1339070200920105\n",
      "Epoch 8, Loss: 0.010328463278710842\n",
      "Epoch 8, Loss: 0.12878292798995972\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.17094985786090858, feed_forward_dim=128, head_dim=8, lr=0.0005160642393330307, num_heads=8, num_layers=4; total time=   1.2s\n",
      "Epoch 9, Loss: 0.06697893142700195\n",
      "Epoch 7, Loss: 0.05398652330040932\n",
      "Epoch 8, Loss: 0.0996253713965416\n",
      "Epoch 7, Loss: 0.072588250041008\n",
      "Epoch 10, Loss: 0.03314819186925888\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.17094985786090858, feed_forward_dim=128, head_dim=8, lr=0.0005160642393330307, num_heads=8, num_layers=4; total time=   1.3s\n",
      "Epoch 9, Loss: 0.01363344956189394\n",
      "Epoch 9, Loss: 0.08544410765171051\n",
      "Epoch 8, Loss: 0.0834982767701149\n",
      "Epoch 9, Loss: 0.11855460703372955\n",
      "Epoch 10, Loss: 0.028243526816368103\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.17094985786090858, feed_forward_dim=128, head_dim=8, lr=0.0005160642393330307, num_heads=8, num_layers=4; total time=   1.4s\n",
      "Epoch 8, Loss: 0.015338819473981857\n",
      "Epoch 10, Loss: 0.0327845960855484\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.17094985786090858, feed_forward_dim=128, head_dim=8, lr=0.0005160642393330307, num_heads=8, num_layers=4; total time=   1.4s\n",
      "Epoch 9, Loss: 0.14329613745212555\n",
      "Epoch 10, Loss: 0.0901949480175972\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.17094985786090858, feed_forward_dim=128, head_dim=8, lr=0.0005160642393330307, num_heads=8, num_layers=4; total time=   1.4s\n",
      "Epoch 9, Loss: 0.013245152309536934\n",
      "Epoch 10, Loss: 0.17050087451934814\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.17094985786090858, feed_forward_dim=128, head_dim=8, lr=0.0005160642393330307, num_heads=8, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.043766893446445465\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.17094985786090858, feed_forward_dim=128, head_dim=8, lr=0.0005160642393330307, num_heads=8, num_layers=4; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.7677095532417297\n",
      "Epoch 1, Loss: 0.032506346702575684\n",
      "Epoch 1, Loss: 2.194018840789795\n",
      "Epoch 1, Loss: 2.2329466342926025\n",
      "Epoch 2, Loss: 0.04315992072224617\n",
      "Epoch 1, Loss: 1.56867253780365\n",
      "Epoch 1, Loss: 0.5933042764663696\n",
      "Epoch 2, Loss: 0.19494131207466125\n",
      "Epoch 2, Loss: 0.47456327080726624\n",
      "Epoch 3, Loss: 0.3200591504573822\n",
      "Epoch 2, Loss: 0.3496257960796356\n",
      "Epoch 1, Loss: 0.12714996933937073\n",
      "Epoch 2, Loss: 0.07142243534326553\n",
      "Epoch 1, Loss: 0.2990274429321289\n",
      "Epoch 1, Loss: 0.37018412351608276\n",
      "Epoch 1, Loss: 1.2860395908355713\n",
      "Epoch 3, Loss: 0.061422090977430344\n",
      "Epoch 4, Loss: 0.366897314786911\n",
      "Epoch 2, Loss: 0.2347494661808014\n",
      "Epoch 3, Loss: 0.11950279027223587\n",
      "Epoch 2, Loss: 0.6134198904037476\n",
      "Epoch 3, Loss: 0.08289526402950287\n",
      "Epoch 1, Loss: 2.9180142879486084\n",
      "Epoch 4, Loss: 0.15085317194461823\n",
      "Epoch 1, Loss: 0.09369191527366638\n",
      "Epoch 3, Loss: 0.3237540125846863\n",
      "Epoch 5, Loss: 0.1996604949235916\n",
      "Epoch 2, Loss: 0.4619916081428528\n",
      "Epoch 2, Loss: 0.12273743003606796\n",
      "Epoch 2, Loss: 0.1868886798620224\n",
      "Epoch 4, Loss: 0.41363266110420227\n",
      "Epoch 3, Loss: 0.3828037977218628\n",
      "Epoch 4, Loss: 0.5151609182357788\n",
      "Epoch 3, Loss: 0.14327524602413177\n",
      "Epoch 5, Loss: 0.036584168672561646\n",
      "Epoch 6, Loss: 0.058366697281599045\n",
      "Epoch 2, Loss: 0.6649451851844788\n",
      "Epoch 4, Loss: 0.6030083298683167\n",
      "Epoch 2, Loss: 0.3797667622566223\n",
      "Epoch 5, Loss: 0.5581420660018921\n",
      "Epoch 3, Loss: 0.2766985595226288\n",
      "Epoch 4, Loss: 0.19455952942371368\n",
      "Epoch 6, Loss: 0.019112471491098404\n",
      "Epoch 7, Loss: 0.03315098211169243\n",
      "Epoch 3, Loss: 0.26731184124946594\n",
      "Epoch 5, Loss: 0.6216810345649719\n",
      "Epoch 3, Loss: 0.19726736843585968\n",
      "Epoch 4, Loss: 0.07355841249227524\n",
      "Epoch 3, Loss: 0.026303891092538834\n",
      "Epoch 5, Loss: 0.48669204115867615\n",
      "Epoch 8, Loss: 0.08758024126291275\n",
      "Epoch 6, Loss: 0.47560352087020874\n",
      "Epoch 6, Loss: 0.4573018550872803\n",
      "Epoch 7, Loss: 0.06962459534406662\n",
      "Epoch 5, Loss: 0.053034547716379166\n",
      "Epoch 3, Loss: 0.10055092722177505\n",
      "Epoch 4, Loss: 0.02520553208887577\n",
      "Epoch 4, Loss: 0.10380835831165314\n",
      "Epoch 4, Loss: 0.43322432041168213\n",
      "Epoch 6, Loss: 0.23534612357616425\n",
      "Epoch 9, Loss: 0.1411549597978592\n",
      "Epoch 7, Loss: 0.29881563782691956\n",
      "Epoch 5, Loss: 0.2477046251296997\n",
      "Epoch 8, Loss: 0.06500206142663956\n",
      "Epoch 4, Loss: 0.3956337571144104\n",
      "Epoch 7, Loss: 0.23615767061710358\n",
      "Epoch 6, Loss: 0.06940878182649612\n",
      "Epoch 10, Loss: 0.14527224004268646\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.25603106093122946, feed_forward_dim=512, head_dim=8, lr=0.0005113954450751927, num_heads=8, num_layers=4; total time=   1.1s\n",
      "Epoch 5, Loss: 0.027277464047074318\n",
      "Epoch 5, Loss: 0.09458798915147781\n",
      "Epoch 7, Loss: 0.05639589577913284\n",
      "Epoch 8, Loss: 0.13879217207431793\n",
      "Epoch 9, Loss: 0.024392180144786835\n",
      "Epoch 4, Loss: 0.019067512825131416\n",
      "Epoch 6, Loss: 0.20470452308654785\n",
      "Epoch 5, Loss: 0.381697416305542\n",
      "Epoch 8, Loss: 0.07493124902248383\n",
      "Epoch 5, Loss: 0.6792721748352051\n",
      "Epoch 10, Loss: 0.008724351413547993\n",
      "Epoch 8, Loss: 0.012036379426717758\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.25603106093122946, feed_forward_dim=512, head_dim=8, lr=0.0005113954450751927, num_heads=8, num_layers=4; total time=   1.2s\n",
      "Epoch 7, Loss: 0.12517602741718292\n",
      "Epoch 9, Loss: 0.04292818903923035\n",
      "Epoch 6, Loss: 0.07790729403495789\n",
      "Epoch 6, Loss: 0.18643413484096527\n",
      "Epoch 7, Loss: 0.0727866142988205\n",
      "Epoch 9, Loss: 0.018289310857653618\n",
      "Epoch 5, Loss: 0.13558347523212433\n",
      "Epoch 6, Loss: 0.21339917182922363\n",
      "Epoch 6, Loss: 0.6405559182167053\n",
      "Epoch 9, Loss: 0.06850685179233551\n",
      "Epoch 10, Loss: 0.018897196277976036\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.25603106093122946, feed_forward_dim=512, head_dim=8, lr=0.0005113954450751927, num_heads=8, num_layers=4; total time=   1.4s\n",
      "Epoch 8, Loss: 0.12056320160627365\n",
      "Epoch 7, Loss: 0.1317981779575348\n",
      "Epoch 7, Loss: 0.12190914154052734\n",
      "Epoch 10, Loss: 0.040843453258275986\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.25603106093122946, feed_forward_dim=512, head_dim=8, lr=0.0005113954450751927, num_heads=8, num_layers=4; total time=   1.4s\n",
      "Epoch 8, Loss: 0.02023870311677456\n",
      "Epoch 7, Loss: 0.07136361300945282\n",
      "Epoch 10, Loss: 0.14567963778972626\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.25603106093122946, feed_forward_dim=512, head_dim=8, lr=0.0005113954450751927, num_heads=8, num_layers=4; total time=   1.5s\n",
      "Epoch 9, Loss: 0.06346315890550613\n",
      "Epoch 6, Loss: 0.12811379134655\n",
      "Epoch 8, Loss: 0.09288089722394943\n",
      "Epoch 8, Loss: 0.04165655001997948\n",
      "Epoch 7, Loss: 0.4359659254550934\n",
      "Epoch 10, Loss: 0.018599463626742363\n",
      "Epoch 9, Loss: 0.05649001896381378\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.25603106093122946, feed_forward_dim=512, head_dim=8, lr=0.0005113954450751927, num_heads=8, num_layers=4; total time=   1.5s\n",
      "Epoch 8, Loss: 0.019434046000242233\n",
      "Epoch 9, Loss: 0.01023087464272976\n",
      "Epoch 7, Loss: 0.044773925095796585\n",
      "Epoch 9, Loss: 0.038484785705804825\n",
      "Epoch 8, Loss: 0.22186064720153809\n",
      "Epoch 10, Loss: 0.10368344932794571\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.25603106093122946, feed_forward_dim=512, head_dim=8, lr=0.0005113954450751927, num_heads=8, num_layers=4; total time=   1.6s\n",
      "Epoch 9, Loss: 0.048378776758909225\n",
      "Epoch 10, Loss: 0.04195244237780571\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.25603106093122946, feed_forward_dim=512, head_dim=8, lr=0.0005113954450751927, num_heads=8, num_layers=4; total time=   1.6s\n",
      "Epoch 10, Loss: 0.013221020810306072\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.25603106093122946, feed_forward_dim=512, head_dim=8, lr=0.0005113954450751927, num_heads=8, num_layers=4; total time=   1.6s\n",
      "Epoch 8, Loss: 0.0034556263126432896\n",
      "Epoch 9, Loss: 0.07374358177185059\n",
      "Epoch 10, Loss: 0.10483215004205704\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.25603106093122946, feed_forward_dim=512, head_dim=8, lr=0.0005113954450751927, num_heads=8, num_layers=4; total time=   1.7s\n",
      "Epoch 9, Loss: 0.027618883177638054\n",
      "Epoch 10, Loss: 0.01851760409772396\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.25603106093122946, feed_forward_dim=512, head_dim=8, lr=0.0005113954450751927, num_heads=8, num_layers=4; total time=   1.7s\n",
      "Epoch 10, Loss: 0.061225924640893936\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.25603106093122946, feed_forward_dim=512, head_dim=8, lr=0.0005113954450751927, num_heads=8, num_layers=4; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.2573157250881195\n",
      "Epoch 1, Loss: 0.0724547803401947\n",
      "Epoch 1, Loss: 0.7562874555587769\n",
      "Epoch 2, Loss: 0.7027886509895325\n",
      "Epoch 1, Loss: 0.37011897563934326\n",
      "Epoch 1, Loss: 0.13641206920146942\n",
      "Epoch 2, Loss: 0.7427446246147156\n",
      "Epoch 1, Loss: 1.0442553758621216\n",
      "Epoch 3, Loss: 0.23920965194702148\n",
      "Epoch 1, Loss: 0.1599511355161667\n",
      "Epoch 2, Loss: 0.22724123299121857\n",
      "Epoch 1, Loss: 1.7411537170410156\n",
      "Epoch 2, Loss: 0.7248286008834839\n",
      "Epoch 2, Loss: 0.8293476104736328\n",
      "Epoch 1, Loss: 0.7100259065628052\n",
      "Epoch 4, Loss: 0.03606182709336281\n",
      "Epoch 2, Loss: 0.04030558466911316\n",
      "Epoch 1, Loss: 0.49501898884773254\n",
      "Epoch 3, Loss: 0.11278507858514786\n",
      "Epoch 1, Loss: 0.3464317321777344\n",
      "Epoch 2, Loss: 0.6067033410072327Epoch 3, Loss: 0.42029669880867004\n",
      "\n",
      "Epoch 2, Loss: 0.0825628936290741\n",
      "Epoch 3, Loss: 0.07170247286558151\n",
      "Epoch 1, Loss: 0.06047910824418068\n",
      "Epoch 3, Loss: 0.25771257281303406\n",
      "Epoch 5, Loss: 0.18083029985427856\n",
      "Epoch 3, Loss: 0.38328662514686584\n",
      "Epoch 4, Loss: 0.24170003831386566\n",
      "Epoch 4, Loss: 0.08636791259050369\n",
      "Epoch 2, Loss: 0.2061825692653656\n",
      "Epoch 2, Loss: 0.271390825510025\n",
      "Epoch 4, Loss: 0.2588248550891876\n",
      "Epoch 6, Loss: 0.21869273483753204\n",
      "Epoch 4, Loss: 0.05181260034441948\n",
      "Epoch 3, Loss: 0.16887764632701874\n",
      "Epoch 2, Loss: 0.39490219950675964\n",
      "Epoch 5, Loss: 0.0689658522605896\n",
      "Epoch 3, Loss: 0.2745805084705353\n",
      "Epoch 5, Loss: 0.29243966937065125\n",
      "Epoch 4, Loss: 0.442621648311615\n",
      "Epoch 7, Loss: 0.11325716227293015\n",
      "Epoch 3, Loss: 0.4309324026107788\n",
      "Epoch 2, Loss: 0.6198744773864746\n",
      "Epoch 5, Loss: 0.18430303037166595\n",
      "Epoch 4, Loss: 0.042148198932409286\n",
      "Epoch 6, Loss: 0.04513012617826462\n",
      "Epoch 4, Loss: 0.5569357872009277\n",
      "Epoch 3, Loss: 0.3291039764881134\n",
      "Epoch 5, Loss: 0.3819997012615204\n",
      "Epoch 6, Loss: 0.21925203502178192\n",
      "Epoch 5, Loss: 0.2576477527618408\n",
      "Epoch 8, Loss: 0.023074431344866753\n",
      "Epoch 7, Loss: 0.10847639292478561\n",
      "Epoch 3, Loss: 0.24290381371974945\n",
      "Epoch 4, Loss: 0.2762247920036316\n",
      "Epoch 5, Loss: 0.22594009339809418\n",
      "Epoch 6, Loss: 0.22686335444450378\n",
      "Epoch 7, Loss: 0.06607327610254288\n",
      "Epoch 3, Loss: 0.08555052429437637\n",
      "Epoch 5, Loss: 0.4800783097743988\n",
      "Epoch 6, Loss: 0.1825362741947174\n",
      "Epoch 9, Loss: 0.025490541011095047\n",
      "Epoch 6, Loss: 0.08680181950330734\n",
      "Epoch 8, Loss: 0.13983406126499176\n",
      "Epoch 4, Loss: 0.11586446315050125\n",
      "Epoch 8, Loss: 0.009674928151071072\n",
      "Epoch 4, Loss: 0.06676460057497025\n",
      "Epoch 6, Loss: 0.17998875677585602\n",
      "Epoch 7, Loss: 0.1348741203546524\n",
      "Epoch 10, Loss: 0.076419897377491\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2396164406597242, feed_forward_dim=1024, head_dim=8, lr=0.0006501963049300996, num_heads=4, num_layers=4; total time=   0.9s\n",
      "Epoch 7, Loss: 0.03192562237381935\n",
      "Epoch 5, Loss: 0.08912841230630875\n",
      "Epoch 7, Loss: 0.024298466742038727\n",
      "Epoch 6, Loss: 0.267974853515625\n",
      "Epoch 9, Loss: 0.054599206894636154\n",
      "Epoch 8, Loss: 0.037490446120500565\n",
      "Epoch 9, Loss: 0.11209898442029953\n",
      "Epoch 4, Loss: 0.08752274513244629\n",
      "Epoch 5, Loss: 0.10409598797559738\n",
      "Epoch 8, Loss: 0.036065492779016495\n",
      "Epoch 7, Loss: 0.04918995127081871\n",
      "Epoch 8, Loss: 0.05634136497974396\n",
      "Epoch 5, Loss: 0.022355299443006516\n",
      "Epoch 9, Loss: 0.023154396563768387\n",
      "Epoch 10, Loss: 0.057623669505119324\n",
      "Epoch 6, Loss: 0.033486075699329376\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2396164406597242, feed_forward_dim=1024, head_dim=8, lr=0.0006501963049300996, num_heads=4, num_layers=4; total time=   1.1s\n",
      "Epoch 10, Loss: 0.1115536317229271\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2396164406597242, feed_forward_dim=1024, head_dim=8, lr=0.0006501963049300996, num_heads=4, num_layers=4; total time=   1.1s\n",
      "Epoch 7, Loss: 0.09506330639123917\n",
      "Epoch 9, Loss: 0.1104188933968544\n",
      "Epoch 6, Loss: 0.15184402465820312\n",
      "Epoch 8, Loss: 0.008741755969822407\n",
      "Epoch 9, Loss: 0.11718498915433884\n",
      "Epoch 10, Loss: 0.0680350586771965\n",
      "Epoch 5, Loss: 0.25235792994499207\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2396164406597242, feed_forward_dim=1024, head_dim=8, lr=0.0006501963049300996, num_heads=4, num_layers=4; total time=   1.1s\n",
      "Epoch 10, Loss: 0.14709258079528809\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2396164406597242, feed_forward_dim=1024, head_dim=8, lr=0.0006501963049300996, num_heads=4, num_layers=4; total time=   1.2s\n",
      "Epoch 6, Loss: 0.07383523881435394\n",
      "Epoch 8, Loss: 0.022415846586227417\n",
      "Epoch 9, Loss: 0.05408994480967522\n",
      "Epoch 7, Loss: 0.10338321328163147\n",
      "Epoch 7, Loss: 0.08358503878116608\n",
      "Epoch 6, Loss: 0.18048347532749176\n",
      "Epoch 10, Loss: 0.14433011412620544\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2396164406597242, feed_forward_dim=1024, head_dim=8, lr=0.0006501963049300996, num_heads=4, num_layers=4; total time=   1.2s\n",
      "Epoch 9, Loss: 0.0393274649977684\n",
      "Epoch 7, Loss: 0.12311289459466934\n",
      "Epoch 10, Loss: 0.09484367817640305\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2396164406597242, feed_forward_dim=1024, head_dim=8, lr=0.0006501963049300996, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 8, Loss: 0.03538399189710617\n",
      "Epoch 8, Loss: 0.1349405199289322\n",
      "Epoch 10, Loss: 0.0973971039056778\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2396164406597242, feed_forward_dim=1024, head_dim=8, lr=0.0006501963049300996, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 7, Loss: 0.05164631828665733\n",
      "Epoch 8, Loss: 0.09925204515457153\n",
      "Epoch 9, Loss: 0.022536149248480797\n",
      "Epoch 9, Loss: 0.12931834161281586\n",
      "Epoch 9, Loss: 0.04223312437534332\n",
      "Epoch 8, Loss: 0.009032689966261387\n",
      "Epoch 10, Loss: 0.0546448640525341\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2396164406597242, feed_forward_dim=1024, head_dim=8, lr=0.0006501963049300996, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 10, Loss: 0.08043266832828522\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2396164406597242, feed_forward_dim=1024, head_dim=8, lr=0.0006501963049300996, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.008396158926188946\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2396164406597242, feed_forward_dim=1024, head_dim=8, lr=0.0006501963049300996, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Epoch 9, Loss: 0.045547448098659515\n",
      "Epoch 10, Loss: 0.09055323153734207\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2396164406597242, feed_forward_dim=1024, head_dim=8, lr=0.0006501963049300996, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.2712189555168152\n",
      "Epoch 1, Loss: 0.7958686947822571\n",
      "Epoch 2, Loss: 0.12739615142345428\n",
      "Epoch 1, Loss: 0.553238034248352\n",
      "Epoch 1, Loss: 0.7604004740715027\n",
      "Epoch 2, Loss: 0.47478151321411133\n",
      "Epoch 3, Loss: 0.04738340154290199\n",
      "Epoch 1, Loss: 1.2721108198165894\n",
      "Epoch 2, Loss: 0.32247424125671387\n",
      "Epoch 1, Loss: 0.460609495639801\n",
      "Epoch 3, Loss: 0.2391423135995865\n",
      "Epoch 1, Loss: 0.40662822127342224\n",
      "Epoch 2, Loss: 0.4452213644981384\n",
      "Epoch 1, Loss: 0.4228167235851288\n",
      "Epoch 4, Loss: 0.027247514575719833\n",
      "Epoch 1, Loss: 0.13037991523742676\n",
      "Epoch 1, Loss: 0.18386372923851013\n",
      "Epoch 3, Loss: 0.14820106327533722\n",
      "Epoch 4, Loss: 0.09905365854501724\n",
      "Epoch 2, Loss: 0.23700831830501556\n",
      "Epoch 1, Loss: 0.13987116515636444\n",
      "Epoch 2, Loss: 0.8928731679916382\n",
      "Epoch 5, Loss: 0.0427575558423996\n",
      "Epoch 2, Loss: 0.26029664278030396\n",
      "Epoch 1, Loss: 0.047800347208976746\n",
      "Epoch 3, Loss: 0.21686339378356934\n",
      "Epoch 2, Loss: 0.2727828323841095\n",
      "Epoch 5, Loss: 0.03312433511018753\n",
      "Epoch 4, Loss: 0.04996377229690552\n",
      "Epoch 2, Loss: 0.0779227539896965\n",
      "Epoch 6, Loss: 0.06673389673233032\n",
      "Epoch 3, Loss: 0.12827514111995697\n",
      "Epoch 3, Loss: 0.12610110640525818\n",
      "Epoch 2, Loss: 0.10787390917539597\n",
      "Epoch 2, Loss: 0.10461696982383728\n",
      "Epoch 3, Loss: 0.5895866751670837\n",
      "Epoch 5, Loss: 0.01197990495711565\n",
      "Epoch 4, Loss: 0.07799080014228821\n",
      "Epoch 7, Loss: 0.07802419364452362\n",
      "Epoch 2, Loss: 0.04008544608950615\n",
      "Epoch 3, Loss: 0.16360405087471008\n",
      "Epoch 3, Loss: 0.07817384600639343\n",
      "Epoch 6, Loss: 0.03133036196231842\n",
      "Epoch 4, Loss: 0.05413892865180969\n",
      "Epoch 4, Loss: 0.08094526082277298\n",
      "Epoch 5, Loss: 0.0226154625415802\n",
      "Epoch 6, Loss: 0.023211343213915825\n",
      "Epoch 7, Loss: 0.06983686983585358\n",
      "Epoch 8, Loss: 0.06984105706214905\n",
      "Epoch 3, Loss: 0.09073453396558762\n",
      "Epoch 4, Loss: 0.37605994939804077\n",
      "Epoch 3, Loss: 0.09471050649881363\n",
      "Epoch 7, Loss: 0.06025024503469467\n",
      "Epoch 4, Loss: 0.10017216950654984\n",
      "Epoch 4, Loss: 0.07873068004846573\n",
      "Epoch 5, Loss: 0.07685703784227371\n",
      "Epoch 8, Loss: 0.11380607634782791\n",
      "Epoch 6, Loss: 0.02717239037156105\n",
      "Epoch 3, Loss: 0.03560597077012062\n",
      "Epoch 5, Loss: 0.03367776423692703\n",
      "Epoch 4, Loss: 0.0978458896279335\n",
      "Epoch 9, Loss: 0.0547906868159771\n",
      "Epoch 8, Loss: 0.09382254630327225\n",
      "Epoch 5, Loss: 0.07251627743244171\n",
      "Epoch 5, Loss: 0.2289237082004547\n",
      "Epoch 10, Loss: 0.03713512048125267\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0001026846221947124, num_heads=2, num_layers=4; total time=   0.9s\n",
      "Epoch 4, Loss: 0.08979672938585281\n",
      "Epoch 6, Loss: 0.09801565855741501\n",
      "Epoch 7, Loss: 0.06655103713274002\n",
      "Epoch 6, Loss: 0.048891909420490265\n",
      "Epoch 5, Loss: 0.06539697200059891\n",
      "Epoch 9, Loss: 0.14412836730480194\n",
      "Epoch 4, Loss: 0.025320865213871002\n",
      "Epoch 5, Loss: 0.09393686801195145\n",
      "Epoch 9, Loss: 0.11543378233909607\n",
      "Epoch 10, Loss: 0.1547129601240158\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0001026846221947124, num_heads=2, num_layers=4; total time=   1.0s\n",
      "Epoch 8, Loss: 0.11108947545289993\n",
      "Epoch 7, Loss: 0.07795091718435287\n",
      "Epoch 7, Loss: 0.1189524307847023\n",
      "Epoch 5, Loss: 0.082014299929142\n",
      "Epoch 6, Loss: 0.14903469383716583\n",
      "Epoch 6, Loss: 0.07203511893749237\n",
      "Epoch 10, Loss: 0.11109576374292374\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0001026846221947124, num_heads=2, num_layers=4; total time=   1.1s\n",
      "Epoch 5, Loss: 0.019984234124422073\n",
      "Epoch 6, Loss: 0.048199500888586044\n",
      "Epoch 9, Loss: 0.14171935617923737\n",
      "Epoch 8, Loss: 0.10118333995342255\n",
      "Epoch 8, Loss: 0.124870665371418\n",
      "Epoch 7, Loss: 0.0843571126461029\n",
      "Epoch 6, Loss: 0.08162382245063782\n",
      "Epoch 7, Loss: 0.11926338821649551\n",
      "Epoch 6, Loss: 0.069021075963974\n",
      "Epoch 10, Loss: 0.15283402800559998\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0001026846221947124, num_heads=2, num_layers=4; total time=   1.2s\n",
      "Epoch 9, Loss: 0.11157257854938507\n",
      "Epoch 8, Loss: 0.12684915959835052\n",
      "Epoch 6, Loss: 0.018241051584482193\n",
      "Epoch 9, Loss: 0.11843742430210114\n",
      "Epoch 8, Loss: 0.1001117005944252\n",
      "Epoch 7, Loss: 0.0371086560189724\n",
      "Epoch 7, Loss: 0.06093454360961914\n",
      "Epoch 7, Loss: 0.05702187493443489\n",
      "Epoch 10, Loss: 0.10506749898195267\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0001026846221947124, num_heads=2, num_layers=4; total time=   1.3s\n",
      "Epoch 9, Loss: 0.1508246660232544\n",
      "Epoch 10, Loss: 0.10219845920801163\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0001026846221947124, num_heads=2, num_layers=4; total time=   1.3s\n",
      "Epoch 9, Loss: 0.10874047875404358\n",
      "Epoch 7, Loss: 0.015420448035001755\n",
      "Epoch 8, Loss: 0.03370247781276703\n",
      "Epoch 8, Loss: 0.0464336983859539\n",
      "Epoch 10, Loss: 0.18092739582061768\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0001026846221947124, num_heads=2, num_layers=4; total time=   1.4s\n",
      "Epoch 10, Loss: 0.10820024460554123\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0001026846221947124, num_heads=2, num_layers=4; total time=   1.4s\n",
      "Epoch 8, Loss: 0.04801621288061142\n",
      "Epoch 8, Loss: 0.011252895928919315\n",
      "Epoch 9, Loss: 0.038249723613262177\n",
      "Epoch 9, Loss: 0.03458359092473984\n",
      "Epoch 9, Loss: 0.04146120324730873\n",
      "Epoch 9, Loss: 0.008521245792508125\n",
      "Epoch 10, Loss: 0.0359206423163414\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0001026846221947124, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.03198724985122681\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0001026846221947124, num_heads=2, num_layers=4; total time=   1.6s\n",
      "Epoch 10, Loss: 0.03732896223664284\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0001026846221947124, num_heads=2, num_layers=4; total time=   1.6s\n",
      "Epoch 10, Loss: 0.0087649030610919\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0001026846221947124, num_heads=2, num_layers=4; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.8072464466094971\n",
      "Epoch 1, Loss: 0.07293995469808578\n",
      "Epoch 1, Loss: 2.956042528152466\n",
      "Epoch 1, Loss: 0.05558443441987038\n",
      "Epoch 1, Loss: 0.2160179316997528\n",
      "Epoch 2, Loss: 0.1243797242641449\n",
      "Epoch 1, Loss: 1.287025809288025\n",
      "Epoch 2, Loss: 0.20881757140159607\n",
      "Epoch 2, Loss: 0.9455832242965698\n",
      "Epoch 2, Loss: 0.5339094996452332\n",
      "Epoch 1, Loss: 0.03912639245390892\n",
      "Epoch 1, Loss: 0.27007871866226196\n",
      "Epoch 3, Loss: 0.25729888677597046\n",
      "Epoch 3, Loss: 0.06260516494512558\n",
      "Epoch 1, Loss: 0.04326546564698219\n",
      "Epoch 2, Loss: 0.2709429860115051\n",
      "Epoch 2, Loss: 0.08385640382766724\n",
      "Epoch 1, Loss: 0.8467187285423279\n",
      "Epoch 1, Loss: 0.30890557169914246\n",
      "Epoch 3, Loss: 0.04260890930891037\n",
      "Epoch 3, Loss: 0.19244322180747986\n",
      "Epoch 4, Loss: 0.34248316287994385\n",
      "Epoch 4, Loss: 0.016151849180459976\n",
      "Epoch 2, Loss: 0.1636313945055008\n",
      "Epoch 2, Loss: 0.5200379490852356\n",
      "Epoch 1, Loss: 0.4462316632270813\n",
      "Epoch 3, Loss: 0.2001877874135971\n",
      "Epoch 3, Loss: 0.14171983301639557\n",
      "Epoch 2, Loss: 0.3018817901611328\n",
      "Epoch 4, Loss: 0.15696094930171967\n",
      "Epoch 5, Loss: 0.2452847957611084\n",
      "Epoch 4, Loss: 0.32303524017333984\n",
      "Epoch 2, Loss: 0.04324719309806824\n",
      "Epoch 5, Loss: 0.08066172897815704\n",
      "Epoch 2, Loss: 0.3556699752807617\n",
      "Epoch 3, Loss: 0.0544603131711483\n",
      "Epoch 3, Loss: 0.19145570695400238\n",
      "Epoch 2, Loss: 0.16691839694976807\n",
      "Epoch 4, Loss: 0.05101818963885307\n",
      "Epoch 4, Loss: 0.41922399401664734\n",
      "Epoch 6, Loss: 0.10247098654508591\n",
      "Epoch 5, Loss: 0.2702972888946533\n",
      "Epoch 5, Loss: 0.5934985280036926\n",
      "Epoch 3, Loss: 0.04778004065155983\n",
      "Epoch 6, Loss: 0.07563332468271255\n",
      "Epoch 7, Loss: 0.023993829265236855\n",
      "Epoch 4, Loss: 0.10382945835590363\n",
      "Epoch 3, Loss: 0.25801998376846313\n",
      "Epoch 6, Loss: 0.135172501206398\n",
      "Epoch 4, Loss: 0.04601389914751053\n",
      "Epoch 3, Loss: 0.24924321472644806\n",
      "Epoch 3, Loss: 0.28592410683631897\n",
      "Epoch 5, Loss: 0.014687546528875828\n",
      "Epoch 6, Loss: 0.6542306542396545\n",
      "Epoch 5, Loss: 0.43738022446632385\n",
      "Epoch 8, Loss: 0.034470394253730774\n",
      "Epoch 7, Loss: 0.02214518003165722\n",
      "Epoch 7, Loss: 0.025543132796883583\n",
      "Epoch 4, Loss: 0.0692186951637268\n",
      "Epoch 6, Loss: 0.042759209871292114\n",
      "Epoch 9, Loss: 0.08649523556232452\n",
      "Epoch 5, Loss: 0.02068639174103737\n",
      "Epoch 7, Loss: 0.5462788939476013\n",
      "Epoch 6, Loss: 0.30365651845932007\n",
      "Epoch 4, Loss: 0.37417086958885193\n",
      "Epoch 4, Loss: 0.08977009356021881\n",
      "Epoch 5, Loss: 0.24227595329284668\n",
      "Epoch 4, Loss: 0.1738193780183792\n",
      "Epoch 8, Loss: 0.028936738148331642\n",
      "Epoch 10, Loss: 0.11149688810110092\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.394915590313483, feed_forward_dim=256, head_dim=16, lr=0.0004463007507384481, num_heads=2, num_layers=3; total time=   1.1s\n",
      "Epoch 6, Loss: 0.079057976603508\n",
      "Epoch 7, Loss: 0.05877986550331116\n",
      "Epoch 8, Loss: 0.0056640938855707645\n",
      "Epoch 5, Loss: 0.14862076938152313\n",
      "Epoch 8, Loss: 0.3663714528083801\n",
      "Epoch 7, Loss: 0.15067888796329498\n",
      "Epoch 9, Loss: 0.09214113652706146\n",
      "Epoch 5, Loss: 0.10745557397603989\n",
      "Epoch 5, Loss: 0.06231627240777016\n",
      "Epoch 6, Loss: 0.17460064589977264\n",
      "Epoch 8, Loss: 0.037354808300733566\n",
      "Epoch 5, Loss: 0.23525018990039825\n",
      "Epoch 9, Loss: 0.025928903371095657\n",
      "Epoch 7, Loss: 0.08670275658369064\n",
      "Epoch 9, Loss: 0.1987886130809784\n",
      "Epoch 6, Loss: 0.08743271231651306\n",
      "Epoch 10, Loss: 0.11622712016105652\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.394915590313483, feed_forward_dim=256, head_dim=16, lr=0.0004463007507384481, num_heads=2, num_layers=3; total time=   1.3s\n",
      "Epoch 10, Loss: 0.04448569566011429\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.394915590313483, feed_forward_dim=256, head_dim=16, lr=0.0004463007507384481, num_heads=2, num_layers=3; total time=   1.3s\n",
      "Epoch 9, Loss: 0.010719915851950645\n",
      "Epoch 8, Loss: 0.05857791751623154\n",
      "Epoch 6, Loss: 0.1521563082933426\n",
      "Epoch 7, Loss: 0.05427011847496033\n",
      "Epoch 8, Loss: 0.04373941570520401\n",
      "Epoch 6, Loss: 0.05586394667625427\n",
      "Epoch 10, Loss: 0.08797316998243332\n",
      "Epoch 6, Loss: 0.08071617037057877\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.394915590313483, feed_forward_dim=256, head_dim=16, lr=0.0004463007507384481, num_heads=2, num_layers=3; total time=   1.4s\n",
      "Epoch 7, Loss: 0.020937496796250343\n",
      "Epoch 10, Loss: 0.008673850446939468\n",
      "Epoch 9, Loss: 0.04500435292720795\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.394915590313483, feed_forward_dim=256, head_dim=16, lr=0.0004463007507384481, num_heads=2, num_layers=3; total time=   1.4s\n",
      "Epoch 8, Loss: 0.007570653222501278\n",
      "Epoch 9, Loss: 0.007795495446771383\n",
      "Epoch 7, Loss: 0.10381539911031723\n",
      "Epoch 7, Loss: 0.02119128778576851\n",
      "Epoch 8, Loss: 0.018719883635640144\n",
      "Epoch 10, Loss: 0.07988716661930084\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.394915590313483, feed_forward_dim=256, head_dim=16, lr=0.0004463007507384481, num_heads=2, num_layers=3; total time=   1.5s\n",
      "Epoch 7, Loss: 0.09231594204902649\n",
      "Epoch 10, Loss: 0.012514404952526093\n",
      "Epoch 9, Loss: 0.041477784514427185\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.394915590313483, feed_forward_dim=256, head_dim=16, lr=0.0004463007507384481, num_heads=2, num_layers=3; total time=   1.5s\n",
      "Epoch 8, Loss: 0.046521250158548355\n",
      "Epoch 8, Loss: 0.04119859263300896\n",
      "Epoch 10, Loss: 0.09181633591651917\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.394915590313483, feed_forward_dim=256, head_dim=16, lr=0.0004463007507384481, num_heads=2, num_layers=3; total time=   1.6s\n",
      "Epoch 8, Loss: 0.09353630244731903\n",
      "Epoch 9, Loss: 0.05151687562465668\n",
      "Epoch 9, Loss: 0.03168853372335434\n",
      "Epoch 10, Loss: 0.0676315426826477\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.394915590313483, feed_forward_dim=256, head_dim=16, lr=0.0004463007507384481, num_heads=2, num_layers=3; total time=   1.7s\n",
      "Epoch 9, Loss: 0.0976489782333374\n",
      "Epoch 9, Loss: 0.05776253715157509\n",
      "Epoch 10, Loss: 0.05840836092829704\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.394915590313483, feed_forward_dim=256, head_dim=16, lr=0.0004463007507384481, num_heads=2, num_layers=3; total time=   1.7s\n",
      "Epoch 10, Loss: 0.124513179063797\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.394915590313483, feed_forward_dim=256, head_dim=16, lr=0.0004463007507384481, num_heads=2, num_layers=3; total time=   1.8s\n",
      "Epoch 10, Loss: 0.02054428681731224\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.394915590313483, feed_forward_dim=256, head_dim=16, lr=0.0004463007507384481, num_heads=2, num_layers=3; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.062300410121679306\n",
      "Epoch 1, Loss: 0.4390316903591156\n",
      "Epoch 1, Loss: 0.2130511850118637\n",
      "Epoch 2, Loss: 0.31083109974861145\n",
      "Epoch 1, Loss: 0.5011797547340393\n",
      "Epoch 2, Loss: 0.13067039847373962\n",
      "Epoch 1, Loss: 0.49466121196746826\n",
      "Epoch 1, Loss: 0.611763596534729\n",
      "Epoch 1, Loss: 0.12158990651369095\n",
      "Epoch 3, Loss: 0.038938261568546295\n",
      "Epoch 2, Loss: 0.062410734593868256\n",
      "Epoch 1, Loss: 0.8854934573173523\n",
      "Epoch 3, Loss: 0.21000154316425323\n",
      "Epoch 1, Loss: 0.8607696294784546\n",
      "Epoch 1, Loss: 0.14785656332969666\n",
      "Epoch 2, Loss: 0.24004340171813965\n",
      "Epoch 2, Loss: 0.03887106850743294\n",
      "Epoch 4, Loss: 0.10359680652618408\n",
      "Epoch 1, Loss: 0.36760345101356506\n",
      "Epoch 2, Loss: 0.09120616316795349\n",
      "Epoch 2, Loss: 0.17794454097747803\n",
      "Epoch 3, Loss: 0.15772706270217896\n",
      "Epoch 1, Loss: 1.5104280710220337\n",
      "Epoch 4, Loss: 0.2175905704498291\n",
      "Epoch 2, Loss: 0.08362599462270737\n",
      "Epoch 3, Loss: 0.30279093980789185\n",
      "Epoch 5, Loss: 0.16229087114334106\n",
      "Epoch 3, Loss: 0.16243138909339905\n",
      "Epoch 2, Loss: 0.12210755795240402\n",
      "Epoch 4, Loss: 0.07160540670156479\n",
      "Epoch 2, Loss: 0.14141039550304413\n",
      "Epoch 2, Loss: 0.016358250752091408\n",
      "Epoch 3, Loss: 0.08254127949476242\n",
      "Epoch 3, Loss: 0.14788410067558289\n",
      "Epoch 5, Loss: 0.13502877950668335\n",
      "Epoch 2, Loss: 0.404598593711853\n",
      "Epoch 6, Loss: 0.07533248513936996\n",
      "Epoch 4, Loss: 0.20210613310337067\n",
      "Epoch 5, Loss: 0.009308823384344578\n",
      "Epoch 3, Loss: 0.10555597394704819\n",
      "Epoch 3, Loss: 0.07450944185256958\n",
      "Epoch 4, Loss: 0.24475254118442535\n",
      "Epoch 7, Loss: 0.016157856211066246\n",
      "Epoch 3, Loss: 0.06719326972961426\n",
      "Epoch 4, Loss: 0.270988792181015\n",
      "Epoch 6, Loss: 0.05947965011000633\n",
      "Epoch 5, Loss: 0.09376818686723709\n",
      "Epoch 3, Loss: 0.1530485898256302\n",
      "Epoch 4, Loss: 0.030253816395998\n",
      "Epoch 6, Loss: 0.03349873423576355\n",
      "Epoch 4, Loss: 0.03267718479037285\n",
      "Epoch 5, Loss: 0.16109861433506012\n",
      "Epoch 3, Loss: 0.07543909549713135\n",
      "Epoch 8, Loss: 0.03779630735516548\n",
      "Epoch 7, Loss: 0.04212677478790283\n",
      "Epoch 4, Loss: 0.2755635678768158\n",
      "Epoch 5, Loss: 0.23188605904579163\n",
      "Epoch 6, Loss: 0.06683586537837982\n",
      "Epoch 4, Loss: 0.1871499866247177\n",
      "Epoch 6, Loss: 0.06007927283644676\n",
      "Epoch 7, Loss: 0.0684068575501442\n",
      "Epoch 4, Loss: 0.260351300239563\n",
      "Epoch 8, Loss: 0.06502093374729156\n",
      "Epoch 9, Loss: 0.07794956117868423\n",
      "Epoch 5, Loss: 0.06590576469898224\n",
      "Epoch 5, Loss: 0.03399832546710968\n",
      "Epoch 6, Loss: 0.1281568855047226\n",
      "Epoch 5, Loss: 0.2967822551727295\n",
      "Epoch 4, Loss: 0.22720752656459808\n",
      "Epoch 7, Loss: 0.09553185850381851\n",
      "Epoch 8, Loss: 0.06004450097680092\n",
      "Epoch 9, Loss: 0.08334312587976456\n",
      "Epoch 7, Loss: 0.02353467419743538\n",
      "Epoch 10, Loss: 0.076038658618927\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2102921464513309, feed_forward_dim=512, head_dim=32, lr=0.00035983319662870913, num_heads=2, num_layers=4; total time=   1.1s\n",
      "Epoch 5, Loss: 0.10086986422538757\n",
      "Epoch 6, Loss: 0.06319204717874527\n",
      "Epoch 5, Loss: 0.30715978145599365\n",
      "Epoch 7, Loss: 0.049588631838560104\n",
      "Epoch 6, Loss: 0.19073861837387085\n",
      "Epoch 8, Loss: 0.09466076642274857\n",
      "Epoch 10, Loss: 0.0716710090637207\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2102921464513309, feed_forward_dim=512, head_dim=32, lr=0.00035983319662870913, num_heads=2, num_layers=4; total time=   1.2s\n",
      "Epoch 9, Loss: 0.026361891999840736\n",
      "Epoch 6, Loss: 0.057748887687921524\n",
      "Epoch 8, Loss: 0.04682493582367897\n",
      "Epoch 5, Loss: 0.40466076135635376\n",
      "Epoch 7, Loss: 0.024492502212524414\n",
      "Epoch 8, Loss: 0.035699374973773956\n",
      "Epoch 6, Loss: 0.2191006988286972\n",
      "Epoch 10, Loss: 0.006304895505309105\n",
      "Epoch 6, Loss: 0.02503548189997673\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2102921464513309, feed_forward_dim=512, head_dim=32, lr=0.00035983319662870913, num_heads=2, num_layers=4; total time=   1.2s\n",
      "Epoch 9, Loss: 0.057811979204416275\n",
      "Epoch 7, Loss: 0.07614295929670334\n",
      "Epoch 9, Loss: 0.08470558375120163\n",
      "Epoch 8, Loss: 0.00863682385534048\n",
      "Epoch 9, Loss: 0.06424406915903091\n",
      "Epoch 6, Loss: 0.43338271975517273\n",
      "Epoch 10, Loss: 0.022904256358742714\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2102921464513309, feed_forward_dim=512, head_dim=32, lr=0.00035983319662870913, num_heads=2, num_layers=4; total time=   1.3s\n",
      "Epoch 7, Loss: 0.0427544042468071\n",
      "Epoch 7, Loss: 0.012521523982286453\n",
      "Epoch 7, Loss: 0.10054660588502884\n",
      "Epoch 8, Loss: 0.012802833691239357\n",
      "Epoch 10, Loss: 0.09640351682901382\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2102921464513309, feed_forward_dim=512, head_dim=32, lr=0.00035983319662870913, num_heads=2, num_layers=4; total time=   1.4s\n",
      "Epoch 10, Loss: 0.09330068528652191\n",
      "Epoch 9, Loss: 0.027228571474552155\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2102921464513309, feed_forward_dim=512, head_dim=32, lr=0.00035983319662870913, num_heads=2, num_layers=4; total time=   1.4s\n",
      "Epoch 7, Loss: 0.346684068441391\n",
      "Epoch 9, Loss: 0.011925465427339077\n",
      "Epoch 8, Loss: 0.025545567274093628\n",
      "Epoch 8, Loss: 0.013924578204751015\n",
      "Epoch 8, Loss: 0.04704148322343826\n",
      "Epoch 10, Loss: 0.0370146669447422\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2102921464513309, feed_forward_dim=512, head_dim=32, lr=0.00035983319662870913, num_heads=2, num_layers=4; total time=   1.4s\n",
      "Epoch 10, Loss: 0.05029070004820824\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2102921464513309, feed_forward_dim=512, head_dim=32, lr=0.00035983319662870913, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Epoch 8, Loss: 0.22110062837600708\n",
      "Epoch 9, Loss: 0.011494357138872147\n",
      "Epoch 9, Loss: 0.013521727174520493\n",
      "Epoch 9, Loss: 0.07398438453674316\n",
      "Epoch 10, Loss: 0.028164274990558624\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2102921464513309, feed_forward_dim=512, head_dim=32, lr=0.00035983319662870913, num_heads=2, num_layers=4; total time=   1.6s\n",
      "Epoch 10, Loss: 0.043879520148038864\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2102921464513309, feed_forward_dim=512, head_dim=32, lr=0.00035983319662870913, num_heads=2, num_layers=4; total time=   1.6s\n",
      "Epoch 10, Loss: 0.07044673711061478\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2102921464513309, feed_forward_dim=512, head_dim=32, lr=0.00035983319662870913, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Epoch 9, Loss: 0.10986760258674622\n",
      "Epoch 10, Loss: 0.046539753675460815\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.2102921464513309, feed_forward_dim=512, head_dim=32, lr=0.00035983319662870913, num_heads=2, num_layers=4; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 1.083289623260498\n",
      "Epoch 1, Loss: 0.1273225098848343\n",
      "Epoch 1, Loss: 0.4792488217353821\n",
      "Epoch 2, Loss: 0.06907463073730469\n",
      "Epoch 1, Loss: 0.870222270488739\n",
      "Epoch 1, Loss: 0.10134367644786835\n",
      "Epoch 2, Loss: 0.444368451833725\n",
      "Epoch 3, Loss: 0.21072199940681458\n",
      "Epoch 1, Loss: 0.11577530950307846\n",
      "Epoch 1, Loss: 0.26986804604530334\n",
      "Epoch 2, Loss: 0.10861906409263611\n",
      "Epoch 4, Loss: 0.40186527371406555\n",
      "Epoch 2, Loss: 0.16850638389587402\n",
      "Epoch 3, Loss: 0.1351187378168106\n",
      "Epoch 1, Loss: 0.2616945803165436\n",
      "Epoch 2, Loss: 0.43726080656051636\n",
      "Epoch 1, Loss: 0.2726946175098419\n",
      "Epoch 1, Loss: 0.23290923237800598\n",
      "Epoch 2, Loss: 0.1661445051431656\n",
      "Epoch 5, Loss: 0.328116774559021\n",
      "Epoch 3, Loss: 0.3111625909805298\n",
      "Epoch 1, Loss: 0.587210476398468\n",
      "Epoch 2, Loss: 0.3474988639354706\n",
      "Epoch 4, Loss: 0.01803070493042469\n",
      "Epoch 1, Loss: 1.6981035470962524\n",
      "Epoch 6, Loss: 0.16158877313137054\n",
      "Epoch 3, Loss: 0.21373829245567322\n",
      "Epoch 2, Loss: 0.14130112528800964\n",
      "Epoch 3, Loss: 0.2594369351863861\n",
      "Epoch 2, Loss: 0.0867658406496048\n",
      "Epoch 4, Loss: 0.20245960354804993\n",
      "Epoch 3, Loss: 0.09456782042980194\n",
      "Epoch 7, Loss: 0.04525044932961464\n",
      "Epoch 5, Loss: 0.15589721500873566\n",
      "Epoch 2, Loss: 0.2253725528717041\n",
      "Epoch 2, Loss: 0.3671514093875885\n",
      "Epoch 3, Loss: 0.0773034542798996\n",
      "Epoch 4, Loss: 0.07504832744598389\n",
      "Epoch 4, Loss: 0.36258581280708313\n",
      "Epoch 5, Loss: 0.05838555470108986\n",
      "Epoch 8, Loss: 0.01686657778918743\n",
      "Epoch 2, Loss: 0.32495707273483276\n",
      "Epoch 4, Loss: 0.05212240666151047\n",
      "Epoch 3, Loss: 0.17110230028629303\n",
      "Epoch 6, Loss: 0.16060104966163635\n",
      "Epoch 3, Loss: 0.19600743055343628\n",
      "Epoch 4, Loss: 0.09064988791942596\n",
      "Epoch 3, Loss: 0.1785530149936676\n",
      "Epoch 6, Loss: 0.04033251479268074\n",
      "Epoch 3, Loss: 0.3728364408016205\n",
      "Epoch 9, Loss: 0.05311309173703194\n",
      "Epoch 5, Loss: 0.2930434048175812\n",
      "Epoch 7, Loss: 0.0593307800590992\n",
      "Epoch 5, Loss: 0.020863573998212814\n",
      "Epoch 5, Loss: 0.17754749953746796\n",
      "Epoch 5, Loss: 0.1571323573589325\n",
      "Epoch 7, Loss: 0.09866141527891159\n",
      "Epoch 4, Loss: 0.051850076764822006\n",
      "Epoch 10, Loss: 0.10077375173568726\n",
      "Epoch 3, Loss: 0.014029616490006447\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.306145155989233, feed_forward_dim=1024, head_dim=16, lr=0.0004906530334092168, num_heads=4, num_layers=2; total time=   1.1s\n",
      "Epoch 4, Loss: 0.07548897713422775\n",
      "Epoch 8, Loss: 0.006379138212651014\n",
      "Epoch 6, Loss: 0.167774960398674\n",
      "Epoch 4, Loss: 0.2557075321674347\n",
      "Epoch 6, Loss: 0.0687038004398346\n",
      "Epoch 4, Loss: 0.04377800226211548\n",
      "Epoch 6, Loss: 0.14958830177783966\n",
      "Epoch 6, Loss: 0.10637189447879791\n",
      "Epoch 8, Loss: 0.12836472690105438\n",
      "Epoch 9, Loss: 0.03506627306342125\n",
      "Epoch 5, Loss: 0.038316283375024796\n",
      "Epoch 7, Loss: 0.07561681419610977\n",
      "Epoch 5, Loss: 0.005473101511597633\n",
      "Epoch 7, Loss: 0.09946730732917786\n",
      "Epoch 7, Loss: 0.051683101803064346\n",
      "Epoch 7, Loss: 0.034642331302165985\n",
      "Epoch 10, Loss: 0.07864367961883545\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.306145155989233, feed_forward_dim=1024, head_dim=16, lr=0.0004906530334092168, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 4, Loss: 0.29740792512893677\n",
      "Epoch 5, Loss: 0.1104402020573616\n",
      "Epoch 9, Loss: 0.10118658095598221\n",
      "Epoch 5, Loss: 0.10736488550901413\n",
      "Epoch 8, Loss: 0.050978440791368484\n",
      "Epoch 6, Loss: 0.08474252372980118\n",
      "Epoch 8, Loss: 0.018000859767198563\n",
      "Epoch 10, Loss: 0.04887950047850609\n",
      "Epoch 6, Loss: 0.04301263764500618\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.306145155989233, feed_forward_dim=1024, head_dim=16, lr=0.0004906530334092168, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 8, Loss: 0.012690626084804535\n",
      "Epoch 9, Loss: 0.07359833270311356\n",
      "Epoch 6, Loss: 0.1343936175107956\n",
      "Epoch 8, Loss: 0.0706421360373497\n",
      "Epoch 6, Loss: 0.06874903291463852\n",
      "Epoch 9, Loss: 0.04793405905365944\n",
      "Epoch 5, Loss: 0.4578512907028198\n",
      "Epoch 7, Loss: 0.08187298476696014\n",
      "Epoch 10, Loss: 0.10662124305963516\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.306145155989233, feed_forward_dim=1024, head_dim=16, lr=0.0004906530334092168, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 7, Loss: 0.08499222993850708\n",
      "Epoch 9, Loss: 0.02743484452366829\n",
      "Epoch 7, Loss: 0.06558793783187866\n",
      "Epoch 9, Loss: 0.04650851711630821\n",
      "Epoch 10, Loss: 0.06816395372152328\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.306145155989233, feed_forward_dim=1024, head_dim=16, lr=0.0004906530334092168, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 7, Loss: 0.11178411543369293\n",
      "Epoch 8, Loss: 0.038656316697597504\n",
      "Epoch 8, Loss: 0.07057496905326843\n",
      "Epoch 10, Loss: 0.011449741199612617\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.306145155989233, feed_forward_dim=1024, head_dim=16, lr=0.0004906530334092168, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 6, Loss: 0.39112991094589233\n",
      "Epoch 10, Loss: 0.08582375943660736\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.306145155989233, feed_forward_dim=1024, head_dim=16, lr=0.0004906530334092168, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 8, Loss: 0.013825329951941967\n",
      "Epoch 8, Loss: 0.13327452540397644\n",
      "Epoch 9, Loss: 0.013824228197336197\n",
      "Epoch 9, Loss: 0.028355207294225693\n",
      "Epoch 7, Loss: 0.23164844512939453\n",
      "Epoch 9, Loss: 0.029026072472333908\n",
      "Epoch 9, Loss: 0.0942755788564682\n",
      "Epoch 10, Loss: 0.030345121398568153\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.306145155989233, feed_forward_dim=1024, head_dim=16, lr=0.0004906530334092168, num_heads=4, num_layers=2; total time=   1.7s\n",
      "Epoch 10, Loss: 0.004651697352528572\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.306145155989233, feed_forward_dim=1024, head_dim=16, lr=0.0004906530334092168, num_heads=4, num_layers=2; total time=   1.7s\n",
      "Epoch 10, Loss: 0.06211523711681366\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.306145155989233, feed_forward_dim=1024, head_dim=16, lr=0.0004906530334092168, num_heads=4, num_layers=2; total time=   1.7s\n",
      "Epoch 8, Loss: 0.09051872789859772\n",
      "Epoch 10, Loss: 0.040864598006010056\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.306145155989233, feed_forward_dim=1024, head_dim=16, lr=0.0004906530334092168, num_heads=4, num_layers=2; total time=   1.7s\n",
      "Epoch 9, Loss: 0.01662406697869301\n",
      "Epoch 10, Loss: 0.010481145232915878\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.306145155989233, feed_forward_dim=1024, head_dim=16, lr=0.0004906530334092168, num_heads=4, num_layers=2; total time=   1.9s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.2425578087568283\n",
      "Epoch 1, Loss: 0.3464432656764984\n",
      "Epoch 1, Loss: 0.1900511085987091\n",
      "Epoch 2, Loss: 0.27040809392929077\n",
      "Epoch 1, Loss: 1.908717393875122\n",
      "Epoch 2, Loss: 0.14484837651252747\n",
      "Epoch 1, Loss: 1.7067707777023315\n",
      "Epoch 3, Loss: 0.20942319929599762\n",
      "Epoch 1, Loss: 0.5477079749107361\n",
      "Epoch 3, Loss: 0.07637294381856918\n",
      "Epoch 1, Loss: 0.7090076208114624\n",
      "Epoch 2, Loss: 0.11569156497716904\n",
      "Epoch 1, Loss: 4.691311836242676\n",
      "Epoch 2, Loss: 1.6528533697128296\n",
      "Epoch 2, Loss: 1.4254786968231201\n",
      "Epoch 1, Loss: 0.9024220108985901\n",
      "Epoch 4, Loss: 0.15894664824008942\n",
      "Epoch 1, Loss: 0.5537989139556885\n",
      "Epoch 1, Loss: 0.3803170919418335\n",
      "Epoch 3, Loss: 1.1707221269607544\n",
      "Epoch 4, Loss: 0.039714422076940536\n",
      "Epoch 3, Loss: 0.0676283985376358\n",
      "Epoch 2, Loss: 0.4068771004676819\n",
      "Epoch 3, Loss: 1.413417935371399\n",
      "Epoch 2, Loss: 4.235054969787598\n",
      "Epoch 1, Loss: 0.06195016950368881\n",
      "Epoch 2, Loss: 0.5637723207473755\n",
      "Epoch 5, Loss: 0.12549513578414917\n",
      "Epoch 5, Loss: 0.02316299080848694\n",
      "Epoch 4, Loss: 0.9406991600990295\n",
      "Epoch 2, Loss: 0.7213918566703796\n",
      "Epoch 4, Loss: 0.04600289463996887\n",
      "Epoch 3, Loss: 3.8111162185668945\n",
      "Epoch 4, Loss: 1.1879383325576782\n",
      "Epoch 3, Loss: 0.28799495100975037\n",
      "Epoch 6, Loss: 0.02491503208875656\n",
      "Epoch 6, Loss: 0.10368790477514267\n",
      "Epoch 3, Loss: 0.4454350173473358\n",
      "Epoch 2, Loss: 0.41041621565818787\n",
      "Epoch 2, Loss: 0.2861475348472595\n",
      "Epoch 2, Loss: 0.05186762660741806\n",
      "Epoch 5, Loss: 0.04474181681871414\n",
      "Epoch 5, Loss: 0.7346910238265991\n",
      "Epoch 7, Loss: 0.03591853380203247\n",
      "Epoch 5, Loss: 0.9962434768676758\n",
      "Epoch 3, Loss: 0.5589197278022766\n",
      "Epoch 4, Loss: 3.3835604190826416\n",
      "Epoch 7, Loss: 0.09556944668292999\n",
      "Epoch 4, Loss: 0.19431351125240326\n",
      "Epoch 4, Loss: 0.3456764221191406\n",
      "Epoch 3, Loss: 0.28858521580696106\n",
      "Epoch 8, Loss: 0.04877331480383873\n",
      "Epoch 6, Loss: 0.053900983184576035\n",
      "Epoch 3, Loss: 0.04489458352327347\n",
      "Epoch 3, Loss: 0.21342463791370392\n",
      "Epoch 6, Loss: 0.817926287651062\n",
      "Epoch 6, Loss: 0.5513246655464172\n",
      "Epoch 5, Loss: 2.9975807666778564\n",
      "Epoch 9, Loss: 0.05708670616149902\n",
      "Epoch 4, Loss: 0.4213567078113556\n",
      "Epoch 8, Loss: 0.09420465677976608\n",
      "Epoch 5, Loss: 0.1260920912027359\n",
      "Epoch 5, Loss: 0.26638633012771606\n",
      "Epoch 4, Loss: 0.19020625948905945\n",
      "Epoch 7, Loss: 0.06391044706106186\n",
      "Epoch 7, Loss: 0.40119487047195435\n",
      "Epoch 7, Loss: 0.6611220240592957\n",
      "Epoch 10, Loss: 0.060256533324718475\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.22982778933503878, feed_forward_dim=512, head_dim=32, lr=5.838964591726091e-05, num_heads=8, num_layers=2; total time=   1.0s\n",
      "Epoch 4, Loss: 0.16066178679466248\n",
      "Epoch 9, Loss: 0.0930798351764679\n",
      "Epoch 4, Loss: 0.03808906674385071\n",
      "Epoch 6, Loss: 0.08086932450532913\n",
      "Epoch 8, Loss: 0.0671599954366684\n",
      "Epoch 5, Loss: 0.29710593819618225\n",
      "Epoch 6, Loss: 2.631549596786499\n",
      "Epoch 6, Loss: 0.2102104276418686\n",
      "Epoch 8, Loss: 0.272346556186676\n",
      "Epoch 8, Loss: 0.5286877155303955\n",
      "Epoch 5, Loss: 0.11226382106542587\n",
      "Epoch 10, Loss: 0.09938760101795197\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.22982778933503878, feed_forward_dim=512, head_dim=32, lr=5.838964591726091e-05, num_heads=8, num_layers=2; total time=   1.1s\n",
      "Epoch 7, Loss: 0.056343112140893936\n",
      "Epoch 9, Loss: 0.06534464657306671\n",
      "Epoch 5, Loss: 0.11936332285404205\n",
      "Epoch 5, Loss: 0.031124969944357872\n",
      "Epoch 7, Loss: 2.282684564590454\n",
      "Epoch 9, Loss: 0.17526045441627502\n",
      "Epoch 7, Loss: 0.16915857791900635\n",
      "Epoch 9, Loss: 0.41472113132476807\n",
      "Epoch 8, Loss: 0.04772423207759857\n",
      "Epoch 6, Loss: 0.20640771090984344\n",
      "Epoch 6, Loss: 0.062231648713350296\n",
      "Epoch 10, Loss: 0.054459478706121445\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.22982778933503878, feed_forward_dim=512, head_dim=32, lr=5.838964591726091e-05, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 10, Loss: 0.10232482850551605\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.22982778933503878, feed_forward_dim=512, head_dim=32, lr=5.838964591726091e-05, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 6, Loss: 0.09807244688272476\n",
      "Epoch 8, Loss: 0.14826209843158722\n",
      "Epoch 10, Loss: 0.32448041439056396\n",
      "Epoch 6, Loss: 0.026106562465429306\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.22982778933503878, feed_forward_dim=512, head_dim=32, lr=5.838964591726091e-05, num_heads=8, num_layers=2; total time=   1.4s\n",
      "Epoch 9, Loss: 0.05140933394432068\n",
      "Epoch 8, Loss: 1.9756371974945068\n",
      "Epoch 7, Loss: 0.03158121556043625\n",
      "Epoch 7, Loss: 0.1323321908712387\n",
      "Epoch 7, Loss: 0.0912434309720993\n",
      "Epoch 7, Loss: 0.02025192603468895\n",
      "Epoch 9, Loss: 0.13785579800605774\n",
      "Epoch 10, Loss: 0.06140211597084999\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.22982778933503878, feed_forward_dim=512, head_dim=32, lr=5.838964591726091e-05, num_heads=8, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 1.685038447380066\n",
      "Epoch 8, Loss: 0.020990626886487007\n",
      "Epoch 8, Loss: 0.08009067177772522\n",
      "Epoch 8, Loss: 0.09260325133800507\n",
      "Epoch 10, Loss: 0.1375238448381424\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.22982778933503878, feed_forward_dim=512, head_dim=32, lr=5.838964591726091e-05, num_heads=8, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 1.4215577840805054\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.22982778933503878, feed_forward_dim=512, head_dim=32, lr=5.838964591726091e-05, num_heads=8, num_layers=2; total time=   1.6s\n",
      "Epoch 8, Loss: 0.01640562154352665\n",
      "Epoch 9, Loss: 0.04637879505753517\n",
      "Epoch 9, Loss: 0.025217361748218536\n",
      "Epoch 9, Loss: 0.09751539677381516\n",
      "Epoch 10, Loss: 0.0300612710416317\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.22982778933503878, feed_forward_dim=512, head_dim=32, lr=5.838964591726091e-05, num_heads=8, num_layers=2; total time=   1.7s\n",
      "Epoch 10, Loss: 0.03568568080663681\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.22982778933503878, feed_forward_dim=512, head_dim=32, lr=5.838964591726091e-05, num_heads=8, num_layers=2; total time=   1.7s\n",
      "Epoch 9, Loss: 0.012601679190993309\n",
      "Epoch 10, Loss: 0.10387570410966873\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.22982778933503878, feed_forward_dim=512, head_dim=32, lr=5.838964591726091e-05, num_heads=8, num_layers=2; total time=   1.7s\n",
      "Epoch 10, Loss: 0.009846080094575882\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.22982778933503878, feed_forward_dim=512, head_dim=32, lr=5.838964591726091e-05, num_heads=8, num_layers=2; total time=   1.8s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 1.346977949142456\n",
      "Epoch 1, Loss: 3.0803382396698\n",
      "Epoch 1, Loss: 0.05595451965928078\n",
      "Epoch 1, Loss: 0.09076863527297974\n",
      "Epoch 1, Loss: 1.3846133947372437\n",
      "Epoch 2, Loss: 0.6686549186706543\n",
      "Epoch 2, Loss: 0.18210627138614655\n",
      "Epoch 1, Loss: 3.7225773334503174\n",
      "Epoch 2, Loss: 0.2633873224258423\n",
      "Epoch 1, Loss: 0.08663393557071686\n",
      "Epoch 3, Loss: 0.0700799971818924\n",
      "Epoch 2, Loss: 0.22985756397247314\n",
      "Epoch 1, Loss: 0.2389562875032425\n",
      "Epoch 3, Loss: 0.13860030472278595\n",
      "Epoch 2, Loss: 0.18332013487815857\n",
      "Epoch 1, Loss: 0.004076741170138121\n",
      "Epoch 2, Loss: 1.5986804962158203\n",
      "Epoch 3, Loss: 0.054453328251838684\n",
      "Epoch 4, Loss: 0.3949241042137146\n",
      "Epoch 4, Loss: 0.41854411363601685\n",
      "Epoch 3, Loss: 0.07734858244657516\n",
      "Epoch 2, Loss: 0.4367869794368744\n",
      "Epoch 2, Loss: 0.28328317403793335\n",
      "Epoch 3, Loss: 0.2934059202671051\n",
      "Epoch 4, Loss: 0.04806599020957947\n",
      "Epoch 2, Loss: 0.794562041759491\n",
      "Epoch 5, Loss: 0.6719086766242981\n",
      "Epoch 3, Loss: 0.4238910973072052\n",
      "Epoch 5, Loss: 0.4425974190235138\n",
      "Epoch 1, Loss: 0.3086663484573364\n",
      "Epoch 4, Loss: 0.02708105370402336\n",
      "Epoch 1, Loss: 0.8945850729942322\n",
      "Epoch 4, Loss: 0.5406162738800049\n",
      "Epoch 3, Loss: 0.07563653588294983\n",
      "Epoch 6, Loss: 0.6641498804092407\n",
      "Epoch 3, Loss: 0.15356114506721497\n",
      "Epoch 6, Loss: 0.2934700548648834\n",
      "Epoch 5, Loss: 0.12256243824958801\n",
      "Epoch 1, Loss: 0.3497365117073059\n",
      "Epoch 4, Loss: 0.07461883127689362\n",
      "Epoch 3, Loss: 0.05818245932459831\n",
      "Epoch 5, Loss: 0.09356067329645157\n",
      "Epoch 7, Loss: 0.5037725567817688\n",
      "Epoch 7, Loss: 0.12769700586795807\n",
      "Epoch 6, Loss: 0.08393681794404984\n",
      "Epoch 2, Loss: 0.167842835187912\n",
      "Epoch 5, Loss: 0.4311770796775818\n",
      "Epoch 2, Loss: 0.11453954875469208\n",
      "Epoch 4, Loss: 0.07245267927646637\n",
      "Epoch 4, Loss: 0.04047997668385506\n",
      "Epoch 8, Loss: 0.03427876904606819\n",
      "Epoch 5, Loss: 0.2287786304950714\n",
      "Epoch 8, Loss: 0.3049040734767914\n",
      "Epoch 4, Loss: 0.172164186835289\n",
      "Epoch 6, Loss: 0.08665214478969574\n",
      "Epoch 2, Loss: 0.06620620936155319\n",
      "Epoch 7, Loss: 0.02637662924826145\n",
      "Epoch 6, Loss: 0.20743823051452637\n",
      "Epoch 5, Loss: 0.19050061702728271\n",
      "Epoch 9, Loss: 0.14353720843791962\n",
      "Epoch 9, Loss: 0.029179895296692848\n",
      "Epoch 6, Loss: 0.46531033515930176\n",
      "Epoch 7, Loss: 0.031780313700437546\n",
      "Epoch 3, Loss: 0.16461899876594543\n",
      "Epoch 3, Loss: 0.210176020860672\n",
      "Epoch 5, Loss: 0.3774746358394623\n",
      "Epoch 5, Loss: 0.07832533866167068\n",
      "Epoch 8, Loss: 0.016313564032316208\n",
      "Epoch 10, Loss: 0.07638384401798248\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3340206617200667, feed_forward_dim=1024, head_dim=8, lr=0.000467012906943623, num_heads=4, num_layers=3; total time=   1.1s\n",
      "Epoch 3, Loss: 0.2220379263162613\n",
      "Epoch 10, Loss: 0.05511196330189705\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3340206617200667, feed_forward_dim=1024, head_dim=8, lr=0.000467012906943623, num_heads=4, num_layers=3; total time=   1.1s\n",
      "Epoch 7, Loss: 0.5675037503242493\n",
      "Epoch 6, Loss: 0.13465651869773865\n",
      "Epoch 7, Loss: 0.061705343425273895\n",
      "Epoch 9, Loss: 0.04202871024608612\n",
      "Epoch 6, Loss: 0.27193570137023926\n",
      "Epoch 4, Loss: 0.08129287511110306\n",
      "Epoch 6, Loss: 0.09367818385362625\n",
      "Epoch 8, Loss: 0.011090409010648727\n",
      "Epoch 10, Loss: 0.058985985815525055\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3340206617200667, feed_forward_dim=1024, head_dim=8, lr=0.000467012906943623, num_heads=4, num_layers=3; total time=   1.2s\n",
      "Epoch 8, Loss: 0.03241807222366333\n",
      "Epoch 8, Loss: 0.5412776470184326\n",
      "Epoch 4, Loss: 0.325652152299881\n",
      "Epoch 4, Loss: 0.15334519743919373\n",
      "Epoch 7, Loss: 0.04620656371116638\n",
      "Epoch 7, Loss: 0.09013640880584717\n",
      "Epoch 7, Loss: 0.035287488251924515\n",
      "Epoch 9, Loss: 0.034644581377506256\n",
      "Epoch 5, Loss: 0.029362056404352188\n",
      "Epoch 9, Loss: 0.43318960070610046\n",
      "Epoch 8, Loss: 0.010513831861317158\n",
      "Epoch 10, Loss: 0.0539042204618454\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3340206617200667, feed_forward_dim=1024, head_dim=8, lr=0.000467012906943623, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Epoch 5, Loss: 0.04531756788492203\n",
      "Epoch 8, Loss: 0.01121708657592535\n",
      "Epoch 9, Loss: 0.07867629081010818\n",
      "Epoch 8, Loss: 0.006033481564372778\n",
      "Epoch 5, Loss: 0.2920517921447754\n",
      "Epoch 10, Loss: 0.3040406107902527\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3340206617200667, feed_forward_dim=1024, head_dim=8, lr=0.000467012906943623, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Epoch 6, Loss: 0.06877042353153229\n",
      "Epoch 9, Loss: 0.02259986475110054\n",
      "Epoch 9, Loss: 0.03353484347462654\n",
      "Epoch 9, Loss: 0.05400008335709572\n",
      "Epoch 6, Loss: 0.01709449477493763\n",
      "Epoch 10, Loss: 0.13355417549610138\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3340206617200667, feed_forward_dim=1024, head_dim=8, lr=0.000467012906943623, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 6, Loss: 0.16582238674163818\n",
      "Epoch 10, Loss: 0.04714220017194748\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3340206617200667, feed_forward_dim=1024, head_dim=8, lr=0.000467012906943623, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 7, Loss: 0.08516857028007507\n",
      "Epoch 10, Loss: 0.08720526844263077\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3340206617200667, feed_forward_dim=1024, head_dim=8, lr=0.000467012906943623, num_heads=4, num_layers=3; total time=   1.6s\n",
      "Epoch 10, Loss: 0.10017682611942291\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3340206617200667, feed_forward_dim=1024, head_dim=8, lr=0.000467012906943623, num_heads=4, num_layers=3; total time=   1.6s\n",
      "Epoch 7, Loss: 0.05723227187991142\n",
      "Epoch 7, Loss: 0.05762582644820213\n",
      "Epoch 8, Loss: 0.0447135865688324\n",
      "Epoch 8, Loss: 0.0864051952958107\n",
      "Epoch 8, Loss: 0.017553331330418587\n",
      "Epoch 9, Loss: 0.009129534475505352\n",
      "Epoch 9, Loss: 0.072189100086689\n",
      "Epoch 9, Loss: 0.04010237753391266\n",
      "Epoch 10, Loss: 0.015189706347882748\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3340206617200667, feed_forward_dim=1024, head_dim=8, lr=0.000467012906943623, num_heads=4, num_layers=3; total time=   1.7s\n",
      "Epoch 10, Loss: 0.03272966295480728\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3340206617200667, feed_forward_dim=1024, head_dim=8, lr=0.000467012906943623, num_heads=4, num_layers=3; total time=   1.6s\n",
      "Epoch 10, Loss: 0.08479098975658417\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3340206617200667, feed_forward_dim=1024, head_dim=8, lr=0.000467012906943623, num_heads=4, num_layers=3; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.5434615612030029\n",
      "Epoch 1, Loss: 0.15213125944137573\n",
      "Epoch 1, Loss: 0.11182219535112381\n",
      "Epoch 1, Loss: 0.09662086516618729\n",
      "Epoch 1, Loss: 0.1858021467924118\n",
      "Epoch 2, Loss: 0.05617984011769295\n",
      "Epoch 2, Loss: 0.22260601818561554\n",
      "Epoch 1, Loss: 0.04407193139195442\n",
      "Epoch 1, Loss: 0.7002934217453003\n",
      "Epoch 2, Loss: 0.08017345517873764\n",
      "Epoch 1, Loss: 0.10760260373353958\n",
      "Epoch 2, Loss: 0.17554447054862976\n",
      "Epoch 1, Loss: 0.5158002972602844\n",
      "Epoch 3, Loss: 0.08597777783870697\n",
      "Epoch 3, Loss: 0.07127595692873001\n",
      "Epoch 2, Loss: 0.19356395304203033\n",
      "Epoch 1, Loss: 0.9309372305870056\n",
      "Epoch 2, Loss: 0.19234339892864227\n",
      "Epoch 2, Loss: 0.04213093966245651\n",
      "Epoch 1, Loss: 0.6266406178474426\n",
      "Epoch 2, Loss: 0.10877637565135956\n",
      "Epoch 3, Loss: 0.03910879045724869\n",
      "Epoch 3, Loss: 0.02562173269689083\n",
      "Epoch 4, Loss: 0.06338784098625183\n",
      "Epoch 1, Loss: 0.5171288847923279\n",
      "Epoch 2, Loss: 0.2711041271686554\n",
      "Epoch 4, Loss: 0.22179542481899261\n",
      "Epoch 2, Loss: 0.19218958914279938\n",
      "Epoch 4, Loss: 0.03511578217148781\n",
      "Epoch 3, Loss: 0.08919945359230042\n",
      "Epoch 3, Loss: 0.18363520503044128\n",
      "Epoch 3, Loss: 0.03273553401231766\n",
      "Epoch 5, Loss: 0.18835300207138062\n",
      "Epoch 2, Loss: 0.16207706928253174\n",
      "Epoch 5, Loss: 0.08876878023147583\n",
      "Epoch 3, Loss: 0.08047148585319519\n",
      "Epoch 4, Loss: 0.058404430747032166\n",
      "Epoch 3, Loss: 0.29487112164497375\n",
      "Epoch 6, Loss: 0.05187365785241127\n",
      "Epoch 3, Loss: 0.08283568173646927\n",
      "Epoch 5, Loss: 0.011488905176520348\n",
      "Epoch 6, Loss: 0.08998069912195206\n",
      "Epoch 4, Loss: 0.07572925835847855\n",
      "Epoch 4, Loss: 0.02548288367688656\n",
      "Epoch 4, Loss: 0.2749524712562561\n",
      "Epoch 3, Loss: 0.13236090540885925\n",
      "Epoch 2, Loss: 0.10409865528345108\n",
      "Epoch 5, Loss: 0.07286546379327774\n",
      "Epoch 7, Loss: 0.017657915130257607\n",
      "Epoch 4, Loss: 0.017954260110855103\n",
      "Epoch 7, Loss: 0.019029969349503517\n",
      "Epoch 6, Loss: 0.01307754684239626\n",
      "Epoch 4, Loss: 0.23951168358325958\n",
      "Epoch 4, Loss: 0.2502009868621826\n",
      "Epoch 5, Loss: 0.07470489293336868\n",
      "Epoch 8, Loss: 0.033756762742996216\n",
      "Epoch 5, Loss: 0.26834559440612793\n",
      "Epoch 5, Loss: 0.012687812559306622\n",
      "Epoch 6, Loss: 0.026214512065052986\n",
      "Epoch 8, Loss: 0.01219157874584198\n",
      "Epoch 3, Loss: 0.11483835428953171\n",
      "Epoch 4, Loss: 0.2340017557144165\n",
      "Epoch 9, Loss: 0.05208105593919754\n",
      "Epoch 7, Loss: 0.02457188069820404\n",
      "Epoch 9, Loss: 0.0432300791144371\n",
      "Epoch 5, Loss: 0.03061840496957302\n",
      "Epoch 6, Loss: 0.040750812739133835\n",
      "Epoch 7, Loss: 0.010749596171081066\n",
      "Epoch 6, Loss: 0.1887347400188446\n",
      "Epoch 5, Loss: 0.14668598771095276\n",
      "Epoch 5, Loss: 0.32696276903152466\n",
      "Epoch 6, Loss: 0.02576429210603237\n",
      "Epoch 10, Loss: 0.0479365698993206\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3818335477703929, feed_forward_dim=512, head_dim=32, lr=0.00030436545568995335, num_heads=4, num_layers=3; total time=   1.1s\n",
      "Epoch 4, Loss: 0.20916622877120972\n",
      "Epoch 10, Loss: 0.07634872943162918\n",
      "Epoch 8, Loss: 0.017021091654896736\n",
      "Epoch 5, Loss: 0.23925048112869263\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3818335477703929, feed_forward_dim=512, head_dim=32, lr=0.00030436545568995335, num_heads=4, num_layers=3; total time=   1.1s\n",
      "Epoch 8, Loss: 0.03412168473005295\n",
      "Epoch 7, Loss: 0.01862708292901516\n",
      "Epoch 7, Loss: 0.10247983783483505\n",
      "Epoch 6, Loss: 0.2744293510913849\n",
      "Epoch 9, Loss: 0.014519448392093182\n",
      "Epoch 6, Loss: 0.052225030958652496\n",
      "Epoch 6, Loss: 0.08780931681394577\n",
      "Epoch 7, Loss: 0.019559653475880623\n",
      "Epoch 5, Loss: 0.20039908587932587\n",
      "Epoch 9, Loss: 0.044534940272569656\n",
      "Epoch 6, Loss: 0.1588338315486908\n",
      "Epoch 8, Loss: 0.028927812352776527\n",
      "Epoch 10, Loss: 0.020675841718912125\n",
      "Epoch 8, Loss: 0.053143467754125595\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3818335477703929, feed_forward_dim=512, head_dim=32, lr=0.00030436545568995335, num_heads=4, num_layers=3; total time=   1.3s\n",
      "Epoch 8, Loss: 0.011334302835166454\n",
      "Epoch 7, Loss: 0.16856198012828827\n",
      "Epoch 10, Loss: 0.02850734442472458\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3818335477703929, feed_forward_dim=512, head_dim=32, lr=0.00030436545568995335, num_heads=4, num_layers=3; total time=   1.3s\n",
      "Epoch 7, Loss: 0.07975280284881592\n",
      "Epoch 7, Loss: 0.03314390033483505\n",
      "Epoch 9, Loss: 0.033630866557359695\n",
      "Epoch 6, Loss: 0.12410755455493927\n",
      "Epoch 7, Loss: 0.0731281191110611\n",
      "Epoch 9, Loss: 0.048247095197439194\n",
      "Epoch 9, Loss: 0.017951929941773415\n",
      "Epoch 8, Loss: 0.0792917013168335\n",
      "Epoch 8, Loss: 0.008642930537462234\n",
      "Epoch 8, Loss: 0.08727940171957016\n",
      "Epoch 10, Loss: 0.022879857569932938\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3818335477703929, feed_forward_dim=512, head_dim=32, lr=0.00030436545568995335, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.06966764479875565\n",
      "Epoch 10, Loss: 0.01891106739640236\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3818335477703929, feed_forward_dim=512, head_dim=32, lr=0.00030436545568995335, num_heads=4, num_layers=3; total time=   1.4s\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3818335477703929, feed_forward_dim=512, head_dim=32, lr=0.00030436545568995335, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 7, Loss: 0.0535820871591568\n",
      "Epoch 8, Loss: 0.027142515406012535\n",
      "Epoch 9, Loss: 0.038534875959157944\n",
      "Epoch 9, Loss: 0.01023427676409483\n",
      "Epoch 9, Loss: 0.07699120789766312\n",
      "Epoch 9, Loss: 0.02743782103061676\n",
      "Epoch 8, Loss: 0.02565528079867363\n",
      "Epoch 10, Loss: 0.04494410753250122\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3818335477703929, feed_forward_dim=512, head_dim=32, lr=0.00030436545568995335, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.025323158130049706\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3818335477703929, feed_forward_dim=512, head_dim=32, lr=0.00030436545568995335, num_heads=4, num_layers=3; total time=   1.6s\n",
      "Epoch 10, Loss: 0.05009983852505684\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3818335477703929, feed_forward_dim=512, head_dim=32, lr=0.00030436545568995335, num_heads=4, num_layers=3; total time=   1.6s\n",
      "Epoch 10, Loss: 0.05540483817458153\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3818335477703929, feed_forward_dim=512, head_dim=32, lr=0.00030436545568995335, num_heads=4, num_layers=3; total time=   1.6s\n",
      "Epoch 9, Loss: 0.037884823977947235\n",
      "Epoch 10, Loss: 0.06572141498327255\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3818335477703929, feed_forward_dim=512, head_dim=32, lr=0.00030436545568995335, num_heads=4, num_layers=3; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.7700734734535217\n",
      "Epoch 1, Loss: 0.153458833694458\n",
      "Epoch 1, Loss: 0.2512769401073456\n",
      "Epoch 2, Loss: 0.2514593005180359\n",
      "Epoch 1, Loss: 0.5197927951812744\n",
      "Epoch 1, Loss: 0.025455983355641365\n",
      "Epoch 2, Loss: 0.03211509436368942\n",
      "Epoch 1, Loss: 1.6234005689620972\n",
      "Epoch 3, Loss: 0.1485394537448883\n",
      "Epoch 2, Loss: 0.019919147714972496\n",
      "Epoch 1, Loss: 0.1635430008172989\n",
      "Epoch 1, Loss: 1.3740617036819458\n",
      "Epoch 2, Loss: 0.17962495982646942\n",
      "Epoch 4, Loss: 0.2527318298816681\n",
      "Epoch 2, Loss: 0.2095744013786316\n",
      "Epoch 1, Loss: 0.27498388290405273\n",
      "Epoch 1, Loss: 1.6961333751678467\n",
      "Epoch 3, Loss: 0.08761988580226898\n",
      "Epoch 2, Loss: 0.8327122330665588\n",
      "Epoch 1, Loss: 0.06900256127119064\n",
      "Epoch 3, Loss: 0.12326373904943466\n",
      "Epoch 2, Loss: 0.5153329372406006\n",
      "Epoch 5, Loss: 0.28349989652633667\n",
      "Epoch 3, Loss: 0.0301152803003788\n",
      "Epoch 2, Loss: 0.14523252844810486\n",
      "Epoch 1, Loss: 2.2781732082366943\n",
      "Epoch 3, Loss: 0.2137136161327362\n",
      "Epoch 2, Loss: 0.021055670455098152\n",
      "Epoch 4, Loss: 0.07155495136976242\n",
      "Epoch 3, Loss: 0.36492398381233215\n",
      "Epoch 2, Loss: 0.7346386313438416\n",
      "Epoch 4, Loss: 0.13131941854953766\n",
      "Epoch 6, Loss: 0.2256167232990265\n",
      "Epoch 2, Loss: 0.054086048156023026\n",
      "Epoch 4, Loss: 0.035837382078170776\n",
      "Epoch 3, Loss: 0.09844819456338882\n",
      "Epoch 4, Loss: 0.25639522075653076\n",
      "Epoch 3, Loss: 0.12121831625699997\n",
      "Epoch 7, Loss: 0.1360148787498474\n",
      "Epoch 5, Loss: 0.06336583942174911\n",
      "Epoch 5, Loss: 0.02400776743888855\n",
      "Epoch 4, Loss: 0.19340717792510986\n",
      "Epoch 3, Loss: 0.10478231310844421\n",
      "Epoch 3, Loss: 0.1917218565940857\n",
      "Epoch 2, Loss: 0.8725677132606506\n",
      "Epoch 5, Loss: 0.10110396146774292\n",
      "Epoch 5, Loss: 0.20136265456676483\n",
      "Epoch 4, Loss: 0.037425972521305084\n",
      "Epoch 3, Loss: 0.05497298017144203\n",
      "Epoch 8, Loss: 0.0671992376446724\n",
      "Epoch 6, Loss: 0.01459357887506485\n",
      "Epoch 6, Loss: 0.007135483901947737\n",
      "Epoch 5, Loss: 0.21949699521064758\n",
      "Epoch 4, Loss: 0.06940014660358429\n",
      "Epoch 9, Loss: 0.04151274636387825\n",
      "Epoch 6, Loss: 0.11682651191949844\n",
      "Epoch 6, Loss: 0.07193582504987717\n",
      "Epoch 7, Loss: 0.026266707107424736\n",
      "Epoch 4, Loss: 0.045030541718006134\n",
      "Epoch 4, Loss: 0.14611922204494476\n",
      "Epoch 7, Loss: 0.020999951288104057\n",
      "Epoch 3, Loss: 0.2263898104429245\n",
      "Epoch 6, Loss: 0.3088497519493103\n",
      "Epoch 5, Loss: 0.1692114770412445\n",
      "Epoch 4, Loss: 0.013330389745533466\n",
      "Epoch 10, Loss: 0.0527368001639843\n",
      "Epoch 8, Loss: 0.04111891984939575\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.29417927134029886, feed_forward_dim=128, head_dim=16, lr=0.0002761454964503469, num_heads=4, num_layers=4; total time=   1.0s\n",
      "Epoch 5, Loss: 0.059993840754032135\n",
      "Epoch 7, Loss: 0.06546884030103683\n",
      "Epoch 8, Loss: 0.05367812141776085\n",
      "Epoch 7, Loss: 0.01989760622382164\n",
      "Epoch 7, Loss: 0.36446046829223633\n",
      "Epoch 9, Loss: 0.03227008134126663\n",
      "Epoch 5, Loss: 0.14392822980880737\n",
      "Epoch 5, Loss: 0.08715977519750595\n",
      "Epoch 4, Loss: 0.16889561712741852\n",
      "Epoch 6, Loss: 0.290028840303421\n",
      "Epoch 8, Loss: 0.062059707939624786\n",
      "Epoch 5, Loss: 0.01517647784203291\n",
      "Epoch 9, Loss: 0.06602360308170319\n",
      "Epoch 6, Loss: 0.06509999930858612\n",
      "Epoch 10, Loss: 0.014021070674061775\n",
      "Epoch 8, Loss: 0.365794837474823\n",
      "Epoch 8, Loss: 0.008393370546400547\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.29417927134029886, feed_forward_dim=128, head_dim=16, lr=0.0002761454964503469, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 7, Loss: 0.3255523443222046\n",
      "Epoch 6, Loss: 0.28267645835876465\n",
      "Epoch 10, Loss: 0.047900278121232986\n",
      "Epoch 6, Loss: 0.027490835636854172\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.29417927134029886, feed_forward_dim=128, head_dim=16, lr=0.0002761454964503469, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 5, Loss: 0.37213635444641113\n",
      "Epoch 9, Loss: 0.03468944504857063\n",
      "Epoch 9, Loss: 0.07916327565908432\n",
      "Epoch 6, Loss: 0.03332943841814995\n",
      "Epoch 9, Loss: 0.31850627064704895\n",
      "Epoch 7, Loss: 0.050353702157735825\n",
      "Epoch 8, Loss: 0.2823851406574249\n",
      "Epoch 10, Loss: 0.05235647037625313\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.29417927134029886, feed_forward_dim=128, head_dim=16, lr=0.0002761454964503469, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 10, Loss: 0.2517281472682953\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.29417927134029886, feed_forward_dim=128, head_dim=16, lr=0.0002761454964503469, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 10, Loss: 0.08895131945610046\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.29417927134029886, feed_forward_dim=128, head_dim=16, lr=0.0002761454964503469, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 7, Loss: 0.3472200930118561\n",
      "Epoch 7, Loss: 0.013056203722953796\n",
      "Epoch 7, Loss: 0.025017695501446724\n",
      "Epoch 6, Loss: 0.5293478965759277\n",
      "Epoch 9, Loss: 0.20340321958065033\n",
      "Epoch 8, Loss: 0.027535611763596535\n",
      "Epoch 8, Loss: 0.009448172524571419\n",
      "Epoch 7, Loss: 0.5415034294128418\n",
      "Epoch 10, Loss: 0.12012945115566254\n",
      "Epoch 8, Loss: 0.3285606801509857\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.29417927134029886, feed_forward_dim=128, head_dim=16, lr=0.0002761454964503469, num_heads=4, num_layers=4; total time=   1.6s\n",
      "Epoch 8, Loss: 0.037173401564359665\n",
      "Epoch 9, Loss: 0.022719474509358406\n",
      "Epoch 9, Loss: 0.25926679372787476\n",
      "Epoch 8, Loss: 0.4553980529308319\n",
      "Epoch 9, Loss: 0.06036237254738808\n",
      "Epoch 9, Loss: 0.0085414107888937\n",
      "Epoch 10, Loss: 0.028772475197911263\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.29417927134029886, feed_forward_dim=128, head_dim=16, lr=0.0002761454964503469, num_heads=4, num_layers=4; total time=   1.7s\n",
      "Epoch 10, Loss: 0.1743800938129425\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.29417927134029886, feed_forward_dim=128, head_dim=16, lr=0.0002761454964503469, num_heads=4, num_layers=4; total time=   1.7s\n",
      "Epoch 9, Loss: 0.31999409198760986\n",
      "Epoch 10, Loss: 0.05940915271639824\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.29417927134029886, feed_forward_dim=128, head_dim=16, lr=0.0002761454964503469, num_heads=4, num_layers=4; total time=   1.8s\n",
      "Epoch 10, Loss: 0.0172111876308918\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.29417927134029886, feed_forward_dim=128, head_dim=16, lr=0.0002761454964503469, num_heads=4, num_layers=4; total time=   1.7s\n",
      "Epoch 10, Loss: 0.18820792436599731\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.29417927134029886, feed_forward_dim=128, head_dim=16, lr=0.0002761454964503469, num_heads=4, num_layers=4; total time=   1.8s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.19594630599021912\n",
      "Epoch 1, Loss: 0.36093413829803467\n",
      "Epoch 1, Loss: 1.3639804124832153\n",
      "Epoch 1, Loss: 1.2318532466888428\n",
      "Epoch 2, Loss: 0.3471645712852478\n",
      "Epoch 2, Loss: 0.2627505660057068\n",
      "Epoch 1, Loss: 0.01673240214586258\n",
      "Epoch 1, Loss: 2.197523355484009\n",
      "Epoch 2, Loss: 0.028536658734083176\n",
      "Epoch 1, Loss: 1.761742353439331\n",
      "Epoch 3, Loss: 0.060423173010349274\n",
      "Epoch 2, Loss: 0.04061765596270561\n",
      "Epoch 1, Loss: 0.10664360970258713\n",
      "Epoch 3, Loss: 0.2932896614074707\n",
      "Epoch 1, Loss: 0.6728105545043945\n",
      "Epoch 2, Loss: 0.7400351762771606\n",
      "Epoch 1, Loss: 0.09371604770421982\n",
      "Epoch 3, Loss: 0.37971144914627075\n",
      "Epoch 4, Loss: 0.21546149253845215\n",
      "Epoch 1, Loss: 0.07614162564277649\n",
      "Epoch 2, Loss: 0.3544304370880127\n",
      "Epoch 1, Loss: 0.16776873171329498\n",
      "Epoch 4, Loss: 0.07311639934778214\n",
      "Epoch 3, Loss: 0.2603453993797302\n",
      "Epoch 2, Loss: 0.16354486346244812\n",
      "Epoch 5, Loss: 0.11345864087343216\n",
      "Epoch 3, Loss: 0.053150877356529236\n",
      "Epoch 2, Loss: 0.7640365362167358\n",
      "Epoch 4, Loss: 0.5492947697639465\n",
      "Epoch 2, Loss: 0.3066727817058563\n",
      "Epoch 6, Loss: 0.01785220205783844\n",
      "Epoch 5, Loss: 0.02475731447339058\n",
      "Epoch 2, Loss: 0.6891033053398132\n",
      "Epoch 3, Loss: 0.37729811668395996\n",
      "Epoch 4, Loss: 0.4505712687969208\n",
      "Epoch 2, Loss: 0.5278287529945374\n",
      "Epoch 2, Loss: 0.27955639362335205\n",
      "Epoch 3, Loss: 0.3088657259941101\n",
      "Epoch 4, Loss: 0.15856418013572693\n",
      "Epoch 5, Loss: 0.3677671551704407\n",
      "Epoch 3, Loss: 0.08432545512914658\n",
      "Epoch 7, Loss: 0.06149850785732269\n",
      "Epoch 6, Loss: 0.11216971278190613\n",
      "Epoch 3, Loss: 0.41541364789009094\n",
      "Epoch 5, Loss: 0.3453807532787323\n",
      "Epoch 3, Loss: 0.10293576866388321\n",
      "Epoch 5, Loss: 0.3526306748390198\n",
      "Epoch 4, Loss: 0.5855923295021057\n",
      "Epoch 4, Loss: 0.6958022117614746\n",
      "Epoch 6, Loss: 0.13973841071128845\n",
      "Epoch 8, Loss: 0.10247642546892166\n",
      "Epoch 3, Loss: 0.13041815161705017\n",
      "Epoch 3, Loss: 0.07174171507358551\n",
      "Epoch 7, Loss: 0.1376730501651764\n",
      "Epoch 4, Loss: 0.1768852323293686\n",
      "Epoch 6, Loss: 0.16430574655532837\n",
      "Epoch 7, Loss: 0.025300532579421997\n",
      "Epoch 4, Loss: 0.19696281850337982\n",
      "Epoch 5, Loss: 0.4812963604927063\n",
      "Epoch 9, Loss: 0.06504913419485092\n",
      "Epoch 5, Loss: 0.6407755613327026\n",
      "Epoch 6, Loss: 0.26299676299095154\n",
      "Epoch 4, Loss: 0.12617731094360352\n",
      "Epoch 8, Loss: 0.08105551451444626\n",
      "Epoch 4, Loss: 0.030838027596473694\n",
      "Epoch 5, Loss: 0.34764716029167175\n",
      "Epoch 7, Loss: 0.04545936733484268\n",
      "Epoch 8, Loss: 0.036803826689720154\n",
      "Epoch 10, Loss: 0.018227417021989822\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.21707927015650846, feed_forward_dim=1024, head_dim=8, lr=0.000562380040306245, num_heads=8, num_layers=4; total time=   1.1s\n",
      "Epoch 4, Loss: 0.09464171528816223\n",
      "Epoch 6, Loss: 0.4051823914051056\n",
      "Epoch 6, Loss: 0.2541390657424927\n",
      "Epoch 5, Loss: 0.07059889286756516\n",
      "Epoch 7, Loss: 0.09868510067462921\n",
      "Epoch 9, Loss: 0.020471863448619843\n",
      "Epoch 9, Loss: 0.10865432769060135\n",
      "Epoch 8, Loss: 0.020171204581856728\n",
      "Epoch 5, Loss: 0.29648271203041077\n",
      "Epoch 7, Loss: 0.18280088901519775\n",
      "Epoch 6, Loss: 0.2433076649904251\n",
      "Epoch 10, Loss: 0.01220613345503807\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.21707927015650846, feed_forward_dim=1024, head_dim=8, lr=0.000562380040306245, num_heads=8, num_layers=4; total time=   1.2s\n",
      "Epoch 5, Loss: 0.09450463205575943\n",
      "Epoch 10, Loss: 0.16555462777614594\n",
      "Epoch 6, Loss: 0.10300157964229584\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.21707927015650846, feed_forward_dim=1024, head_dim=8, lr=0.000562380040306245, num_heads=8, num_layers=4; total time=   1.2s\n",
      "Epoch 5, Loss: 0.22844040393829346\n",
      "Epoch 8, Loss: 0.014247596263885498\n",
      "Epoch 7, Loss: 0.08163781464099884\n",
      "Epoch 9, Loss: 0.0611516609787941\n",
      "Epoch 8, Loss: 0.06781652569770813\n",
      "Epoch 6, Loss: 0.19821138679981232\n",
      "Epoch 7, Loss: 0.08042789250612259\n",
      "Epoch 7, Loss: 0.1493721604347229\n",
      "Epoch 6, Loss: 0.14172665774822235\n",
      "Epoch 10, Loss: 0.11529051512479782\n",
      "Epoch 6, Loss: 0.11500543355941772\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.21707927015650846, feed_forward_dim=1024, head_dim=8, lr=0.000562380040306245, num_heads=8, num_layers=4; total time=   1.3s\n",
      "Epoch 9, Loss: 0.0372389480471611\n",
      "Epoch 8, Loss: 0.03011401556432247\n",
      "Epoch 9, Loss: 0.060583051294088364\n",
      "Epoch 7, Loss: 0.05327490717172623\n",
      "Epoch 8, Loss: 0.01671500690281391\n",
      "Epoch 8, Loss: 0.12685447931289673\n",
      "Epoch 10, Loss: 0.10163498669862747\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.21707927015650846, feed_forward_dim=1024, head_dim=8, lr=0.000562380040306245, num_heads=8, num_layers=4; total time=   1.4s\n",
      "Epoch 10, Loss: 0.11661038547754288\n",
      "Epoch 7, Loss: 0.05582262575626373\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.21707927015650846, feed_forward_dim=1024, head_dim=8, lr=0.000562380040306245, num_heads=8, num_layers=4; total time=   1.4s\n",
      "Epoch 7, Loss: 0.027950743213295937\n",
      "Epoch 9, Loss: 0.0734601691365242\n",
      "Epoch 8, Loss: 0.01574530266225338\n",
      "Epoch 9, Loss: 0.058010004460811615\n",
      "Epoch 9, Loss: 0.06688094139099121\n",
      "Epoch 10, Loss: 0.14203892648220062\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.21707927015650846, feed_forward_dim=1024, head_dim=8, lr=0.000562380040306245, num_heads=8, num_layers=4; total time=   1.5s\n",
      "Epoch 8, Loss: 0.012782401405274868\n",
      "Epoch 9, Loss: 0.0693703144788742\n",
      "Epoch 8, Loss: 0.0149072939530015\n",
      "Epoch 10, Loss: 0.022812852635979652\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.21707927015650846, feed_forward_dim=1024, head_dim=8, lr=0.000562380040306245, num_heads=8, num_layers=4; total time=   1.6s\n",
      "Epoch 10, Loss: 0.11747292429208755\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.21707927015650846, feed_forward_dim=1024, head_dim=8, lr=0.000562380040306245, num_heads=8, num_layers=4; total time=   1.6s\n",
      "Epoch 9, Loss: 0.025260701775550842\n",
      "Epoch 10, Loss: 0.11835253238677979\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.21707927015650846, feed_forward_dim=1024, head_dim=8, lr=0.000562380040306245, num_heads=8, num_layers=4; total time=   1.6s\n",
      "Epoch 9, Loss: 0.0683615505695343\n",
      "Epoch 10, Loss: 0.05472194030880928\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.21707927015650846, feed_forward_dim=1024, head_dim=8, lr=0.000562380040306245, num_heads=8, num_layers=4; total time=   1.7s\n",
      "Epoch 10, Loss: 0.10001972317695618\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.21707927015650846, feed_forward_dim=1024, head_dim=8, lr=0.000562380040306245, num_heads=8, num_layers=4; total time=   1.8s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.19725777208805084\n",
      "Epoch 1, Loss: 3.6790809631347656\n",
      "Epoch 1, Loss: 0.19324499368667603\n",
      "Epoch 1, Loss: 0.08884194493293762\n",
      "Epoch 2, Loss: 0.058080513030290604\n",
      "Epoch 2, Loss: 2.8819215297698975\n",
      "Epoch 1, Loss: 0.523801863193512\n",
      "Epoch 1, Loss: 0.045415543019771576\n",
      "Epoch 1, Loss: 0.09596778452396393\n",
      "Epoch 2, Loss: 0.045967310667037964\n",
      "Epoch 3, Loss: 0.04508867487311363\n",
      "Epoch 2, Loss: 0.06732457876205444\n",
      "Epoch 1, Loss: 1.750592589378357\n",
      "Epoch 3, Loss: 2.183974266052246\n",
      "Epoch 1, Loss: 1.2010196447372437\n",
      "Epoch 2, Loss: 0.2396145462989807\n",
      "Epoch 1, Loss: 0.4837864935398102\n",
      "Epoch 2, Loss: 0.0695965439081192\n",
      "Epoch 3, Loss: 0.005966149736195803\n",
      "Epoch 1, Loss: 0.22239971160888672\n",
      "Epoch 1, Loss: 0.3423466384410858\n",
      "Epoch 4, Loss: 0.08234728127717972\n",
      "Epoch 3, Loss: 0.056482281535863876\n",
      "Epoch 2, Loss: 1.1926262378692627\n",
      "Epoch 2, Loss: 0.04904811829328537\n",
      "Epoch 4, Loss: 1.5930771827697754\n",
      "Epoch 2, Loss: 0.6684066653251648\n",
      "Epoch 3, Loss: 0.03160650655627251\n",
      "Epoch 2, Loss: 0.24266476929187775\n",
      "Epoch 4, Loss: 0.03216233849525452\n",
      "Epoch 3, Loss: 0.07326212525367737\n",
      "Epoch 5, Loss: 0.08944731950759888\n",
      "Epoch 4, Loss: 0.03636835142970085\n",
      "Epoch 2, Loss: 0.08139519393444061\n",
      "Epoch 5, Loss: 1.1015950441360474\n",
      "Epoch 2, Loss: 0.11905863881111145\n",
      "Epoch 6, Loss: 0.06608930230140686\n",
      "Epoch 5, Loss: 0.061993684619665146\n",
      "Epoch 4, Loss: 0.03316384181380272\n",
      "Epoch 3, Loss: 0.11041507869958878\n",
      "Epoch 3, Loss: 0.7412665486335754\n",
      "Epoch 4, Loss: 0.011584754101932049\n",
      "Epoch 6, Loss: 0.7124671339988708\n",
      "Epoch 5, Loss: 0.02566409297287464\n",
      "Epoch 3, Loss: 0.3123689591884613\n",
      "Epoch 3, Loss: 0.06524228304624557\n",
      "Epoch 7, Loss: 0.038762304931879044\n",
      "Epoch 6, Loss: 0.0659903734922409\n",
      "Epoch 3, Loss: 0.0673263818025589\n",
      "Epoch 5, Loss: 0.03511856123805046\n",
      "Epoch 3, Loss: 0.03408382833003998\n",
      "Epoch 8, Loss: 0.021475523710250854\n",
      "Epoch 5, Loss: 0.031905945390462875\n",
      "Epoch 4, Loss: 0.07001998275518417\n",
      "Epoch 6, Loss: 0.02395971119403839\n",
      "Epoch 4, Loss: 0.058539606630802155\n",
      "Epoch 4, Loss: 0.41840028762817383\n",
      "Epoch 7, Loss: 0.048454415053129196\n",
      "Epoch 7, Loss: 0.4331313669681549\n",
      "Epoch 4, Loss: 0.11967246979475021\n",
      "Epoch 9, Loss: 0.021066369488835335\n",
      "Epoch 4, Loss: 0.10209553688764572\n",
      "Epoch 8, Loss: 0.023975299671292305\n",
      "Epoch 6, Loss: 0.022485176101326942\n",
      "Epoch 6, Loss: 0.08499383926391602\n",
      "Epoch 7, Loss: 0.020576393231749535\n",
      "Epoch 8, Loss: 0.2507009208202362\n",
      "Epoch 5, Loss: 0.039062872529029846\n",
      "Epoch 4, Loss: 0.04789574071764946\n",
      "Epoch 5, Loss: 0.19146385788917542\n",
      "Epoch 5, Loss: 0.09089973568916321\n",
      "Epoch 10, Loss: 0.031248658895492554\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2536470334632758, feed_forward_dim=256, head_dim=32, lr=0.00014404618316629278, num_heads=2, num_layers=1; total time=   1.0s\n",
      "Epoch 5, Loss: 0.06457488983869553\n",
      "Epoch 9, Loss: 0.008176942355930805\n",
      "Epoch 7, Loss: 0.12010101974010468\n",
      "Epoch 9, Loss: 0.15225671231746674\n",
      "Epoch 7, Loss: 0.01351791899651289\n",
      "Epoch 8, Loss: 0.015298128128051758\n",
      "Epoch 5, Loss: 0.10412705689668655\n",
      "Epoch 6, Loss: 0.027954120188951492\n",
      "Epoch 5, Loss: 0.09170060604810715\n",
      "Epoch 6, Loss: 0.08028186112642288\n",
      "Epoch 10, Loss: 0.004510346334427595\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2536470334632758, feed_forward_dim=256, head_dim=32, lr=0.00014404618316629278, num_heads=2, num_layers=1; total time=   1.1s\n",
      "Epoch 8, Loss: 0.12894587218761444\n",
      "Epoch 10, Loss: 0.11957132071256638\n",
      "Epoch 6, Loss: 0.12572650611400604\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2536470334632758, feed_forward_dim=256, head_dim=32, lr=0.00014404618316629278, num_heads=2, num_layers=1; total time=   1.1s\n",
      "Epoch 9, Loss: 0.013632356189191341\n",
      "Epoch 8, Loss: 0.01516325119882822\n",
      "Epoch 6, Loss: 0.09906192123889923\n",
      "Epoch 6, Loss: 0.07844236493110657\n",
      "Epoch 7, Loss: 0.054961636662483215\n",
      "Epoch 10, Loss: 0.017192598432302475\n",
      "Epoch 7, Loss: 0.030018212273716927\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2536470334632758, feed_forward_dim=256, head_dim=32, lr=0.00014404618316629278, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 9, Loss: 0.10925514996051788\n",
      "Epoch 6, Loss: 0.10903758555650711\n",
      "Epoch 9, Loss: 0.019010359421372414\n",
      "Epoch 7, Loss: 0.14409580826759338\n",
      "Epoch 7, Loss: 0.1657770872116089\n",
      "Epoch 8, Loss: 0.0911603644490242\n",
      "Epoch 10, Loss: 0.0748756155371666\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2536470334632758, feed_forward_dim=256, head_dim=32, lr=0.00014404618316629278, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 7, Loss: 0.04845103248953819\n",
      "Epoch 8, Loss: 0.03277003392577171\n",
      "Epoch 10, Loss: 0.01721496880054474\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2536470334632758, feed_forward_dim=256, head_dim=32, lr=0.00014404618316629278, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 8, Loss: 0.13634683191776276\n",
      "Epoch 7, Loss: 0.09775194525718689\n",
      "Epoch 9, Loss: 0.15256546437740326\n",
      "Epoch 8, Loss: 0.2163178026676178\n",
      "Epoch 9, Loss: 0.029851796105504036\n",
      "Epoch 8, Loss: 0.030862461775541306\n",
      "Epoch 9, Loss: 0.11448191106319427\n",
      "Epoch 8, Loss: 0.06283091753721237\n",
      "Epoch 9, Loss: 0.240640327334404\n",
      "Epoch 10, Loss: 0.21157628297805786\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2536470334632758, feed_forward_dim=256, head_dim=32, lr=0.00014404618316629278, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 10, Loss: 0.021723229438066483\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2536470334632758, feed_forward_dim=256, head_dim=32, lr=0.00014404618316629278, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 9, Loss: 0.030544141307473183\n",
      "Epoch 10, Loss: 0.08088500052690506\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2536470334632758, feed_forward_dim=256, head_dim=32, lr=0.00014404618316629278, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.2245679795742035\n",
      "Epoch 9, Loss: 0.03337773680686951\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2536470334632758, feed_forward_dim=256, head_dim=32, lr=0.00014404618316629278, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.03850783780217171\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2536470334632758, feed_forward_dim=256, head_dim=32, lr=0.00014404618316629278, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.012952441349625587\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2536470334632758, feed_forward_dim=256, head_dim=32, lr=0.00014404618316629278, num_heads=2, num_layers=1; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.2508681118488312\n",
      "Epoch 1, Loss: 0.5977452397346497\n",
      "Epoch 1, Loss: 0.5733849406242371\n",
      "Epoch 2, Loss: 1.020504117012024\n",
      "Epoch 1, Loss: 0.15876220166683197\n",
      "Epoch 2, Loss: 0.7225800156593323\n",
      "Epoch 1, Loss: 0.4021349549293518\n",
      "Epoch 3, Loss: 0.30004313588142395\n",
      "Epoch 1, Loss: 0.5453408360481262\n",
      "Epoch 1, Loss: 0.1312524676322937\n",
      "Epoch 2, Loss: 0.6896078586578369\n",
      "Epoch 2, Loss: 0.959343671798706\n",
      "Epoch 1, Loss: 0.16755066812038422\n",
      "Epoch 3, Loss: 0.4592718183994293\n",
      "Epoch 1, Loss: 0.6936641335487366\n",
      "Epoch 2, Loss: 1.4869078397750854\n",
      "Epoch 2, Loss: 0.7758999466896057\n",
      "Epoch 3, Loss: 0.2442387342453003\n",
      "Epoch 1, Loss: 0.22903114557266235\n",
      "Epoch 3, Loss: 0.4603325128555298\n",
      "Epoch 4, Loss: 0.04567372053861618\n",
      "Epoch 1, Loss: 0.0920187458395958\n",
      "Epoch 2, Loss: 0.8134539127349854\n",
      "Epoch 2, Loss: 0.5806714296340942\n",
      "Epoch 1, Loss: 1.0610053539276123\n",
      "Epoch 4, Loss: 0.07395650446414948\n",
      "Epoch 4, Loss: 0.07823442667722702\n",
      "Epoch 3, Loss: 0.3142753839492798\n",
      "Epoch 2, Loss: 0.7024691104888916\n",
      "Epoch 3, Loss: 0.24061907827854156\n",
      "Epoch 5, Loss: 0.2599787712097168\n",
      "Epoch 3, Loss: 0.4034948945045471\n",
      "Epoch 4, Loss: 0.036816973239183426\n",
      "Epoch 2, Loss: 0.3466264307498932\n",
      "Epoch 3, Loss: 0.21416068077087402\n",
      "Epoch 2, Loss: 0.8784775733947754\n",
      "Epoch 6, Loss: 0.32051634788513184\n",
      "Epoch 5, Loss: 0.04320009797811508\n",
      "Epoch 2, Loss: 0.2456023395061493\n",
      "Epoch 5, Loss: 0.06237588822841644\n",
      "Epoch 4, Loss: 0.1408979594707489\n",
      "Epoch 4, Loss: 0.09547794610261917\n",
      "Epoch 4, Loss: 0.022868739441037178\n",
      "Epoch 5, Loss: 0.25537535548210144\n",
      "Epoch 7, Loss: 0.19088639318943024\n",
      "Epoch 6, Loss: 0.16267749667167664\n",
      "Epoch 4, Loss: 0.020648904144763947\n",
      "Epoch 6, Loss: 0.18666014075279236\n",
      "Epoch 3, Loss: 0.39731109142303467\n",
      "Epoch 3, Loss: 0.22687534987926483\n",
      "Epoch 3, Loss: 0.5132678151130676\n",
      "Epoch 3, Loss: 0.5456748604774475\n",
      "Epoch 8, Loss: 0.0653117373585701\n",
      "Epoch 6, Loss: 0.2779715061187744\n",
      "Epoch 7, Loss: 0.2080206722021103\n",
      "Epoch 5, Loss: 0.5109759569168091\n",
      "Epoch 5, Loss: 0.12346489727497101\n",
      "Epoch 7, Loss: 0.19707968831062317\n",
      "Epoch 5, Loss: 0.0925435945391655\n",
      "Epoch 9, Loss: 0.03209364041686058\n",
      "Epoch 8, Loss: 0.1345127671957016\n",
      "Epoch 4, Loss: 0.07547427713871002\n",
      "Epoch 5, Loss: 0.21435093879699707\n",
      "Epoch 7, Loss: 0.14257004857063293\n",
      "Epoch 4, Loss: 0.11788556724786758\n",
      "Epoch 4, Loss: 0.17228271067142487\n",
      "Epoch 4, Loss: 0.3042941391468048\n",
      "Epoch 6, Loss: 0.43515801429748535\n",
      "Epoch 6, Loss: 0.21725746989250183\n",
      "Epoch 6, Loss: 0.19069010019302368\n",
      "Epoch 8, Loss: 0.13081704080104828\n",
      "Epoch 9, Loss: 0.05288673937320709\n",
      "Epoch 8, Loss: 0.032896287739276886\n",
      "Epoch 6, Loss: 0.24770653247833252\n",
      "Epoch 10, Loss: 0.07653312385082245\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.18586640966134682, feed_forward_dim=512, head_dim=8, lr=0.0008850834340495921, num_heads=4, num_layers=2; total time=   1.0s\n",
      "Epoch 5, Loss: 0.26546570658683777\n",
      "Epoch 5, Loss: 0.08371084183454514\n",
      "Epoch 7, Loss: 0.18175014853477478\n",
      "Epoch 7, Loss: 0.168803408741951\n",
      "Epoch 5, Loss: 0.013849363662302494\n",
      "Epoch 5, Loss: 0.05971680209040642\n",
      "Epoch 7, Loss: 0.17908640205860138\n",
      "Epoch 9, Loss: 0.04814194142818451\n",
      "Epoch 10, Loss: 0.020363569259643555\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.18586640966134682, feed_forward_dim=512, head_dim=8, lr=0.0008850834340495921, num_heads=4, num_layers=2; total time=   1.1s\n",
      "Epoch 9, Loss: 0.019444342702627182\n",
      "Epoch 6, Loss: 0.2432875633239746\n",
      "Epoch 7, Loss: 0.12232469022274017\n",
      "Epoch 8, Loss: 0.10256680101156235\n",
      "Epoch 10, Loss: 0.011128985323011875\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.18586640966134682, feed_forward_dim=512, head_dim=8, lr=0.0008850834340495921, num_heads=4, num_layers=2; total time=   1.1s\n",
      "Epoch 8, Loss: 0.07260219752788544\n",
      "Epoch 8, Loss: 0.028501402586698532\n",
      "Epoch 6, Loss: 0.05342169106006622\n",
      "Epoch 10, Loss: 0.06515015661716461\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.18586640966134682, feed_forward_dim=512, head_dim=8, lr=0.0008850834340495921, num_heads=4, num_layers=2; total time=   1.1s\n",
      "Epoch 6, Loss: 0.16877593100070953\n",
      "Epoch 6, Loss: 0.13001979887485504\n",
      "Epoch 8, Loss: 0.020526213571429253\n",
      "Epoch 7, Loss: 0.1077643483877182\n",
      "Epoch 9, Loss: 0.016597697511315346\n",
      "Epoch 9, Loss: 0.03894976153969765\n",
      "Epoch 9, Loss: 0.05198998749256134\n",
      "Epoch 7, Loss: 0.21158376336097717\n",
      "Epoch 9, Loss: 0.01825408637523651\n",
      "Epoch 7, Loss: 0.1391587257385254\n",
      "Epoch 7, Loss: 0.1258554905653\n",
      "Epoch 10, Loss: 0.0276933666318655\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.18586640966134682, feed_forward_dim=512, head_dim=8, lr=0.0008850834340495921, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 10, Loss: 0.03567205369472504\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.18586640966134682, feed_forward_dim=512, head_dim=8, lr=0.0008850834340495921, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 8, Loss: 0.026488207280635834\n",
      "Epoch 10, Loss: 0.14718332886695862\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.18586640966134682, feed_forward_dim=512, head_dim=8, lr=0.0008850834340495921, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 10, Loss: 0.07362629473209381\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.18586640966134682, feed_forward_dim=512, head_dim=8, lr=0.0008850834340495921, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 8, Loss: 0.052000921219587326\n",
      "Epoch 8, Loss: 0.15253092348575592\n",
      "Epoch 8, Loss: 0.1731351912021637\n",
      "Epoch 9, Loss: 0.04580877348780632\n",
      "Epoch 9, Loss: 0.009797179140150547\n",
      "Epoch 9, Loss: 0.06633512675762177\n",
      "Epoch 10, Loss: 0.10042119771242142\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.18586640966134682, feed_forward_dim=512, head_dim=8, lr=0.0008850834340495921, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 0.15289746224880219\n",
      "Epoch 10, Loss: 0.022950366139411926\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.18586640966134682, feed_forward_dim=512, head_dim=8, lr=0.0008850834340495921, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.04468735307455063\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.18586640966134682, feed_forward_dim=512, head_dim=8, lr=0.0008850834340495921, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.0957036092877388\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.18586640966134682, feed_forward_dim=512, head_dim=8, lr=0.0008850834340495921, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.36083176732063293\n",
      "Epoch 1, Loss: 0.9806062579154968\n",
      "Epoch 1, Loss: 0.09307114779949188\n",
      "Epoch 1, Loss: 1.2654941082000732\n",
      "Epoch 1, Loss: 0.11044441908597946\n",
      "Epoch 2, Loss: 0.2829362750053406\n",
      "Epoch 1, Loss: 0.6060414910316467\n",
      "Epoch 2, Loss: 0.8236487507820129\n",
      "Epoch 1, Loss: 0.07187514007091522\n",
      "Epoch 1, Loss: 2.672813653945923\n",
      "Epoch 2, Loss: 0.08117145299911499\n",
      "Epoch 2, Loss: 1.088883399963379\n",
      "Epoch 3, Loss: 0.22012034058570862\n",
      "Epoch 3, Loss: 0.6783556938171387\n",
      "Epoch 2, Loss: 0.07414686679840088\n",
      "Epoch 2, Loss: 0.4921192228794098\n",
      "Epoch 1, Loss: 0.08280931413173676\n",
      "Epoch 1, Loss: 0.11874546110630035\n",
      "Epoch 1, Loss: 0.8761079907417297\n",
      "Epoch 2, Loss: 0.05878125876188278\n",
      "Epoch 1, Loss: 1.0470162630081177\n",
      "Epoch 3, Loss: 0.06960553675889969\n",
      "Epoch 4, Loss: 0.17155559360980988\n",
      "Epoch 3, Loss: 0.9300074577331543\n",
      "Epoch 4, Loss: 0.5473219156265259\n",
      "Epoch 2, Loss: 2.3970179557800293\n",
      "Epoch 3, Loss: 0.05227801576256752\n",
      "Epoch 3, Loss: 0.3949582576751709\n",
      "Epoch 2, Loss: 0.05145428329706192\n",
      "Epoch 5, Loss: 0.13003529608249664\n",
      "Epoch 5, Loss: 0.4342152774333954\n",
      "Epoch 2, Loss: 0.10839608311653137\n",
      "Epoch 4, Loss: 0.0619194470345974\n",
      "Epoch 4, Loss: 0.7822165489196777\n",
      "Epoch 3, Loss: 0.05675918981432915\n",
      "Epoch 4, Loss: 0.045057959854602814\n",
      "Epoch 2, Loss: 0.7096316814422607\n",
      "Epoch 6, Loss: 0.10537431389093399\n",
      "Epoch 2, Loss: 0.8949776291847229\n",
      "Epoch 3, Loss: 2.1439547538757324\n",
      "Epoch 5, Loss: 0.05458315461874008\n",
      "Epoch 4, Loss: 0.30609434843063354\n",
      "Epoch 6, Loss: 0.33311429619789124\n",
      "Epoch 5, Loss: 0.660052478313446\n",
      "Epoch 3, Loss: 0.034642543643713\n",
      "Epoch 5, Loss: 0.045288242399692535\n",
      "Epoch 7, Loss: 0.09098394215106964\n",
      "Epoch 4, Loss: 0.05422137305140495\n",
      "Epoch 3, Loss: 0.10010865330696106\n",
      "Epoch 6, Loss: 0.04802367463707924\n",
      "Epoch 3, Loss: 0.7522789239883423\n",
      "Epoch 3, Loss: 0.5673159956932068\n",
      "Epoch 6, Loss: 0.5350673794746399\n",
      "Epoch 7, Loss: 0.25036516785621643\n",
      "Epoch 5, Loss: 0.23382778465747833\n",
      "Epoch 8, Loss: 0.0862160176038742\n",
      "Epoch 7, Loss: 0.04128826782107353\n",
      "Epoch 6, Loss: 0.0504411980509758\n",
      "Epoch 4, Loss: 1.9033417701721191\n",
      "Epoch 5, Loss: 0.04848482459783554\n",
      "Epoch 4, Loss: 0.032936833798885345\n",
      "Epoch 4, Loss: 0.09274036437273026\n",
      "Epoch 9, Loss: 0.08926772326231003\n",
      "Epoch 8, Loss: 0.18388675153255463\n",
      "Epoch 7, Loss: 0.43877556920051575\n",
      "Epoch 8, Loss: 0.035372935235500336\n",
      "Epoch 4, Loss: 0.44074562191963196\n",
      "Epoch 6, Loss: 0.1705114096403122\n",
      "Epoch 4, Loss: 0.6256488561630249\n",
      "Epoch 10, Loss: 0.09286493062973022\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=5e-05, num_heads=4, num_layers=2; total time=   1.0s\n",
      "Epoch 7, Loss: 0.05338231101632118\n",
      "Epoch 5, Loss: 1.671384572982788\n",
      "Epoch 6, Loss: 0.04284122586250305\n",
      "Epoch 9, Loss: 0.1295720338821411\n",
      "Epoch 9, Loss: 0.03079047054052353\n",
      "Epoch 8, Loss: 0.3570486307144165\n",
      "Epoch 5, Loss: 0.035169366747140884\n",
      "Epoch 5, Loss: 0.08289023488759995\n",
      "Epoch 8, Loss: 0.04983488470315933\n",
      "Epoch 7, Loss: 0.03805067017674446\n",
      "Epoch 5, Loss: 0.33173784613609314\n",
      "Epoch 7, Loss: 0.11875567585229874\n",
      "Epoch 6, Loss: 1.4609918594360352\n",
      "Epoch 10, Loss: 0.0878920704126358\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=5e-05, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 9, Loss: 0.2798391878604889\n",
      "Epoch 10, Loss: 0.02631659433245659\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=5e-05, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 9, Loss: 0.04558654874563217\n",
      "Epoch 6, Loss: 0.0381104052066803\n",
      "Epoch 6, Loss: 0.07669919729232788\n",
      "Epoch 5, Loss: 0.5100669860839844\n",
      "Epoch 8, Loss: 0.0343477725982666\n",
      "Epoch 6, Loss: 0.23734088242053986\n",
      "Epoch 10, Loss: 0.22567209601402283\n",
      "Epoch 7, Loss: 1.2627652883529663\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=5e-05, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 8, Loss: 0.0805022120475769\n",
      "Epoch 10, Loss: 0.04099954664707184\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=5e-05, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 7, Loss: 0.0693463683128357\n",
      "Epoch 7, Loss: 0.03722519427537918\n",
      "Epoch 9, Loss: 0.03145891800522804\n",
      "Epoch 6, Loss: 0.4074084460735321\n",
      "Epoch 7, Loss: 0.16167747974395752\n",
      "Epoch 8, Loss: 1.0794697999954224\n",
      "Epoch 9, Loss: 0.05314423888921738\n",
      "Epoch 8, Loss: 0.06209632009267807\n",
      "Epoch 8, Loss: 0.03465414419770241\n",
      "Epoch 10, Loss: 0.028252771124243736\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=5e-05, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 10, Loss: 0.03442748636007309\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=5e-05, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 7, Loss: 0.3239939510822296\n",
      "Epoch 8, Loss: 0.10235461592674255\n",
      "Epoch 9, Loss: 0.9213142991065979\n",
      "Epoch 9, Loss: 0.0573265440762043\n",
      "Epoch 9, Loss: 0.028576888144016266\n",
      "Epoch 10, Loss: 0.7659889459609985\n",
      "Epoch 8, Loss: 0.24638256430625916\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=5e-05, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 9, Loss: 0.059208065271377563\n",
      "Epoch 10, Loss: 0.052019331604242325\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=5e-05, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.024094048887491226\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=5e-05, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 9, Loss: 0.18527543544769287\n",
      "Epoch 10, Loss: 0.030230525881052017\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=5e-05, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.13454601168632507\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=5e-05, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.22014681994915009\n",
      "Epoch 1, Loss: 1.0989735126495361\n",
      "Epoch 1, Loss: 0.14883632957935333\n",
      "Epoch 1, Loss: 2.8710598945617676\n",
      "Epoch 2, Loss: 11.737732887268066\n",
      "Epoch 2, Loss: 7.164861679077148\n",
      "Epoch 1, Loss: 0.6061421632766724\n",
      "Epoch 1, Loss: 0.11789286881685257\n",
      "Epoch 1, Loss: 0.16926857829093933\n",
      "Epoch 2, Loss: 12.83524227142334\n",
      "Epoch 3, Loss: 2.1118996143341064\n",
      "Epoch 1, Loss: 0.059022631496191025\n",
      "Epoch 3, Loss: 1.6741242408752441\n",
      "Epoch 2, Loss: 7.852908134460449\n",
      "Epoch 2, Loss: 8.885883331298828\n",
      "Epoch 1, Loss: 1.9970155954360962\n",
      "Epoch 1, Loss: 0.2226932942867279\n",
      "Epoch 2, Loss: 10.143342971801758\n",
      "Epoch 3, Loss: 2.8787667751312256\n",
      "Epoch 1, Loss: 2.4460806846618652\n",
      "Epoch 4, Loss: 0.1455126255750656\n",
      "Epoch 2, Loss: 11.679742813110352\n",
      "Epoch 1, Loss: 0.5000635981559753\n",
      "Epoch 3, Loss: 2.5748767852783203\n",
      "Epoch 2, Loss: 2.94903826713562\n",
      "Epoch 3, Loss: 2.1669795513153076\n",
      "Epoch 4, Loss: 0.07584942877292633\n",
      "Epoch 4, Loss: 0.09096213430166245\n",
      "Epoch 2, Loss: 8.596465110778809\n",
      "Epoch 2, Loss: 9.217297554016113\n",
      "Epoch 5, Loss: 0.8172767162322998\n",
      "Epoch 3, Loss: 0.12059593200683594\n",
      "Epoch 3, Loss: 2.182007074356079\n",
      "Epoch 2, Loss: 9.984990119934082\n",
      "Epoch 4, Loss: 0.2135644555091858\n",
      "Epoch 5, Loss: 0.7216872572898865\n",
      "Epoch 5, Loss: 1.1182458400726318\n",
      "Epoch 3, Loss: 6.586933612823486\n",
      "Epoch 4, Loss: 0.05281154438853264\n",
      "Epoch 6, Loss: 0.639093816280365\n",
      "Epoch 3, Loss: 0.3365088999271393\n",
      "Epoch 4, Loss: 2.3129467964172363\n",
      "Epoch 6, Loss: 0.6136548519134521\n",
      "Epoch 3, Loss: 3.10614275932312\n",
      "Epoch 2, Loss: 9.86962604522705\n",
      "Epoch 6, Loss: 0.7736257314682007\n",
      "Epoch 4, Loss: 0.31878650188446045\n",
      "Epoch 7, Loss: 0.23802347481250763\n",
      "Epoch 5, Loss: 0.30582693219184875\n",
      "Epoch 5, Loss: 0.6629524230957031\n",
      "Epoch 7, Loss: 0.23688893020153046\n",
      "Epoch 3, Loss: 2.9820542335510254\n",
      "Epoch 4, Loss: 1.4846991300582886\n",
      "Epoch 7, Loss: 0.25790923833847046\n",
      "Epoch 5, Loss: 0.9556632041931152\n",
      "Epoch 4, Loss: 1.2851848602294922\n",
      "Epoch 4, Loss: 0.3681361675262451\n",
      "Epoch 8, Loss: 0.06775946170091629\n",
      "Epoch 5, Loss: 0.8082247972488403\n",
      "Epoch 6, Loss: 0.7366214394569397\n",
      "Epoch 6, Loss: 0.6022596955299377\n",
      "Epoch 8, Loss: 0.06444830447435379\n",
      "Epoch 8, Loss: 0.06538517773151398\n",
      "Epoch 3, Loss: 2.2482056617736816\n",
      "Epoch 9, Loss: 0.12680572271347046\n",
      "Epoch 5, Loss: 0.08043289929628372\n",
      "Epoch 5, Loss: 0.22863931953907013\n",
      "Epoch 6, Loss: 0.2949499189853668\n",
      "Epoch 6, Loss: 0.13965743780136108\n",
      "Epoch 9, Loss: 0.10905002057552338\n",
      "Epoch 4, Loss: 0.09623607248067856\n",
      "Epoch 9, Loss: 0.11287147551774979\n",
      "Epoch 5, Loss: 0.8164072632789612\n",
      "Epoch 7, Loss: 0.39075663685798645\n",
      "Epoch 7, Loss: 0.3967931270599365\n",
      "Epoch 10, Loss: 0.21416285634040833\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=0.004999999999999999, num_heads=8, num_layers=3; total time=   1.0s\n",
      "Epoch 4, Loss: 0.09588011354207993\n",
      "Epoch 10, Loss: 0.18943388760089874\n",
      "Epoch 7, Loss: 0.051051996648311615\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=0.004999999999999999, num_heads=8, num_layers=3; total time=   1.0s\n",
      "Epoch 8, Loss: 0.14012345671653748\n",
      "Epoch 6, Loss: 0.257654070854187\n",
      "Epoch 8, Loss: 0.1254815310239792\n",
      "Epoch 10, Loss: 0.19202983379364014\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=0.004999999999999999, num_heads=8, num_layers=3; total time=   1.0s\n",
      "Epoch 5, Loss: 0.6515912413597107\n",
      "Epoch 6, Loss: 0.5854676961898804\n",
      "Epoch 7, Loss: 0.07322502881288528\n",
      "Epoch 6, Loss: 0.1972784548997879\n",
      "Epoch 8, Loss: 0.10599032789468765\n",
      "Epoch 9, Loss: 0.06310145556926727\n",
      "Epoch 9, Loss: 0.0556083545088768\n",
      "Epoch 8, Loss: 0.1873459666967392\n",
      "Epoch 5, Loss: 0.8965843319892883\n",
      "Epoch 7, Loss: 0.37722399830818176\n",
      "Epoch 7, Loss: 0.47181621193885803\n",
      "Epoch 6, Loss: 0.8293812870979309\n",
      "Epoch 10, Loss: 0.11680899560451508\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=0.004999999999999999, num_heads=8, num_layers=3; total time=   1.2s\n",
      "Epoch 7, Loss: 0.053630977869033813\n",
      "Epoch 10, Loss: 0.10912609845399857\n",
      "Epoch 9, Loss: 0.17340226471424103\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=0.004999999999999999, num_heads=8, num_layers=3; total time=   1.2s\n",
      "Epoch 9, Loss: 0.1965000033378601\n",
      "Epoch 6, Loss: 0.6447907090187073\n",
      "Epoch 8, Loss: 0.13129055500030518\n",
      "Epoch 8, Loss: 0.37533220648765564\n",
      "Epoch 7, Loss: 0.4358016848564148\n",
      "Epoch 8, Loss: 0.17071449756622314\n",
      "Epoch 10, Loss: 0.12896032631397247\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=0.004999999999999999, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 10, Loss: 0.14272929728031158\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=0.004999999999999999, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 9, Loss: 0.1819387525320053\n",
      "Epoch 7, Loss: 0.19054150581359863\n",
      "Epoch 9, Loss: 0.23403248190879822\n",
      "Epoch 9, Loss: 0.05829437077045441\n",
      "Epoch 8, Loss: 0.12582793831825256\n",
      "Epoch 8, Loss: 0.06242517754435539\n",
      "Epoch 10, Loss: 0.18781471252441406\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=0.004999999999999999, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.07014867663383484\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=0.004999999999999999, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.0992237776517868\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=0.004999999999999999, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 9, Loss: 0.060196928679943085\n",
      "Epoch 9, Loss: 0.15244841575622559\n",
      "Epoch 10, Loss: 0.13706307113170624\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=0.004999999999999999, num_heads=8, num_layers=3; total time=   1.6s\n",
      "Epoch 10, Loss: 0.20956726372241974\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=0.004999999999999999, num_heads=8, num_layers=3; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.1475876122713089\n",
      "Epoch 1, Loss: 0.46274641156196594\n",
      "Epoch 1, Loss: 1.152349829673767\n",
      "Epoch 2, Loss: 11.471636772155762\n",
      "Epoch 1, Loss: 0.14404943585395813\n",
      "Epoch 2, Loss: 9.99677848815918\n",
      "Epoch 1, Loss: 0.2698257565498352\n",
      "Epoch 3, Loss: 2.506157159805298\n",
      "Epoch 2, Loss: 9.272664070129395\n",
      "Epoch 1, Loss: 0.17937920987606049\n",
      "Epoch 1, Loss: 0.41743865609169006\n",
      "Epoch 1, Loss: 0.16842412948608398\n",
      "Epoch 1, Loss: 1.255394458770752\n",
      "Epoch 2, Loss: 11.174887657165527\n",
      "Epoch 3, Loss: 1.108536958694458\n",
      "Epoch 1, Loss: 0.1168094128370285\n",
      "Epoch 2, Loss: 11.838215827941895\n",
      "Epoch 4, Loss: 0.11935056746006012\n",
      "Epoch 2, Loss: 19.16004180908203\n",
      "Epoch 3, Loss: 2.0491671562194824\n",
      "Epoch 2, Loss: 10.539388656616211\n",
      "Epoch 4, Loss: 0.7123057246208191\n",
      "Epoch 2, Loss: 11.601912498474121\n",
      "Epoch 2, Loss: 16.015216827392578\n",
      "Epoch 1, Loss: 0.12937819957733154\n",
      "Epoch 1, Loss: 2.388237714767456\n",
      "Epoch 3, Loss: 1.5101795196533203\n",
      "Epoch 3, Loss: 5.743617057800293\n",
      "Epoch 5, Loss: 0.9094650149345398\n",
      "Epoch 4, Loss: 0.12884162366390228\n",
      "Epoch 3, Loss: 2.866332769393921\n",
      "Epoch 2, Loss: 9.316384315490723\n",
      "Epoch 3, Loss: 2.5024051666259766\n",
      "Epoch 5, Loss: 0.9698547124862671\n",
      "Epoch 4, Loss: 0.8348801136016846\n",
      "Epoch 3, Loss: 4.546838283538818\n",
      "Epoch 6, Loss: 0.5522615313529968\n",
      "Epoch 4, Loss: 0.059671781957149506\n",
      "Epoch 2, Loss: 9.25322437286377\n",
      "Epoch 4, Loss: 0.4409458637237549\n",
      "Epoch 3, Loss: 3.078111410140991\n",
      "Epoch 4, Loss: 0.07666399329900742\n",
      "Epoch 5, Loss: 0.8636946678161621\n",
      "Epoch 2, Loss: 8.857544898986816\n",
      "Epoch 3, Loss: 0.1739756166934967\n",
      "Epoch 6, Loss: 0.43319013714790344\n",
      "Epoch 5, Loss: 0.9930704236030579\n",
      "Epoch 7, Loss: 0.16967402398586273\n",
      "Epoch 5, Loss: 0.8375735878944397\n",
      "Epoch 6, Loss: 0.49354249238967896\n",
      "Epoch 5, Loss: 0.5660527348518372\n",
      "Epoch 4, Loss: 0.27143532037734985\n",
      "Epoch 3, Loss: 0.9502845406532288\n",
      "Epoch 7, Loss: 0.1181928962469101\n",
      "Epoch 5, Loss: 0.955228328704834\n",
      "Epoch 8, Loss: 0.061262525618076324\n",
      "Epoch 4, Loss: 0.06416993588209152\n",
      "Epoch 6, Loss: 0.3852512240409851\n",
      "Epoch 4, Loss: 0.595004141330719\n",
      "Epoch 7, Loss: 0.11412074416875839\n",
      "Epoch 3, Loss: 1.7906290292739868\n",
      "Epoch 9, Loss: 0.13441729545593262\n",
      "Epoch 6, Loss: 1.0149884223937988\n",
      "Epoch 6, Loss: 0.7178560495376587\n",
      "Epoch 5, Loss: 0.5326678156852722\n",
      "Epoch 8, Loss: 0.06726505607366562\n",
      "Epoch 4, Loss: 0.8164405226707458\n",
      "Epoch 6, Loss: 0.7422172427177429\n",
      "Epoch 5, Loss: 0.9509329795837402\n",
      "Epoch 7, Loss: 0.09105153381824493\n",
      "Epoch 8, Loss: 0.0767926499247551\n",
      "Epoch 10, Loss: 0.1808812916278839\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16686408106453104, feed_forward_dim=256, head_dim=8, lr=0.004999999999999999, num_heads=8, num_layers=4; total time=   1.0s\n",
      "Epoch 7, Loss: 0.2897041440010071\n",
      "Epoch 5, Loss: 0.11628993600606918\n",
      "Epoch 9, Loss: 0.1311822235584259\n",
      "Epoch 7, Loss: 0.6307726502418518\n",
      "Epoch 7, Loss: 0.31113842129707336\n",
      "Epoch 4, Loss: 0.1039653792977333\n",
      "Epoch 6, Loss: 0.7756226658821106\n",
      "Epoch 8, Loss: 0.07242926955223083\n",
      "Epoch 5, Loss: 0.7543805241584778\n",
      "Epoch 6, Loss: 0.9385588765144348\n",
      "Epoch 10, Loss: 0.18276233971118927\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16686408106453104, feed_forward_dim=256, head_dim=8, lr=0.004999999999999999, num_heads=8, num_layers=4; total time=   1.1s\n",
      "Epoch 8, Loss: 0.06353955715894699\n",
      "Epoch 9, Loss: 0.17477411031723022\n",
      "Epoch 6, Loss: 0.10113301128149033\n",
      "Epoch 8, Loss: 0.19785557687282562\n",
      "Epoch 10, Loss: 0.1905268132686615\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16686408106453104, feed_forward_dim=256, head_dim=8, lr=0.004999999999999999, num_heads=8, num_layers=4; total time=   1.1s\n",
      "Epoch 9, Loss: 0.07512631267309189\n",
      "Epoch 8, Loss: 0.08867178857326508\n",
      "Epoch 7, Loss: 0.2955577075481415\n",
      "Epoch 7, Loss: 0.5723185539245605\n",
      "Epoch 9, Loss: 0.12910149991512299\n",
      "Epoch 5, Loss: 0.7867969870567322\n",
      "Epoch 6, Loss: 0.23155345022678375\n",
      "Epoch 9, Loss: 0.0529622808098793\n",
      "Epoch 10, Loss: 0.14774924516677856\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16686408106453104, feed_forward_dim=256, head_dim=8, lr=0.004999999999999999, num_heads=8, num_layers=4; total time=   1.2s\n",
      "Epoch 9, Loss: 0.0521504245698452\n",
      "Epoch 7, Loss: 0.19542615115642548\n",
      "Epoch 8, Loss: 0.07302410900592804\n",
      "Epoch 10, Loss: 0.16940824687480927\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16686408106453104, feed_forward_dim=256, head_dim=8, lr=0.004999999999999999, num_heads=8, num_layers=4; total time=   1.3s\n",
      "Epoch 8, Loss: 0.21922215819358826\n",
      "Epoch 10, Loss: 0.1498069167137146\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16686408106453104, feed_forward_dim=256, head_dim=8, lr=0.004999999999999999, num_heads=8, num_layers=4; total time=   1.3s\n",
      "Epoch 6, Loss: 0.5075758099555969\n",
      "Epoch 9, Loss: 0.06166525185108185\n",
      "Epoch 8, Loss: 0.12296648323535919\n",
      "Epoch 7, Loss: 0.057338930666446686\n",
      "Epoch 9, Loss: 0.06728038191795349\n",
      "Epoch 10, Loss: 0.0976448655128479\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16686408106453104, feed_forward_dim=256, head_dim=8, lr=0.004999999999999999, num_heads=8, num_layers=4; total time=   1.4s\n",
      "Epoch 10, Loss: 0.12642771005630493\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16686408106453104, feed_forward_dim=256, head_dim=8, lr=0.004999999999999999, num_heads=8, num_layers=4; total time=   1.4s\n",
      "Epoch 7, Loss: 0.10974141955375671\n",
      "Epoch 9, Loss: 0.06182163953781128\n",
      "Epoch 10, Loss: 0.0800652727484703\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16686408106453104, feed_forward_dim=256, head_dim=8, lr=0.004999999999999999, num_heads=8, num_layers=4; total time=   1.4s\n",
      "Epoch 8, Loss: 0.12625209987163544\n",
      "Epoch 10, Loss: 0.09448603540658951\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16686408106453104, feed_forward_dim=256, head_dim=8, lr=0.004999999999999999, num_heads=8, num_layers=4; total time=   1.5s\n",
      "Epoch 8, Loss: 0.08724188059568405\n",
      "Epoch 9, Loss: 0.16734352707862854\n",
      "Epoch 9, Loss: 0.2169739156961441\n",
      "Epoch 10, Loss: 0.13257640600204468\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16686408106453104, feed_forward_dim=256, head_dim=8, lr=0.004999999999999999, num_heads=8, num_layers=4; total time=   1.6s\n",
      "Epoch 10, Loss: 0.24508778750896454\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.16686408106453104, feed_forward_dim=256, head_dim=8, lr=0.004999999999999999, num_heads=8, num_layers=4; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 3.7933406829833984\n",
      "Epoch 1, Loss: 0.18279194831848145\n",
      "Epoch 1, Loss: 0.05666134133934975\n",
      "Epoch 2, Loss: 2.377702474594116\n",
      "Epoch 1, Loss: 0.07663244754076004\n",
      "Epoch 1, Loss: 0.19562530517578125\n",
      "Epoch 1, Loss: 0.09709207713603973\n",
      "Epoch 2, Loss: 0.023986810818314552\n",
      "Epoch 2, Loss: 0.07254566252231598\n",
      "Epoch 1, Loss: 0.631896436214447\n",
      "Epoch 3, Loss: 1.3119661808013916\n",
      "Epoch 2, Loss: 0.03338107839226723\n",
      "Epoch 1, Loss: 0.22274306416511536\n",
      "Epoch 2, Loss: 0.006306704133749008\n",
      "Epoch 2, Loss: 0.08368688076734543\n",
      "Epoch 1, Loss: 0.13817976415157318\n",
      "Epoch 3, Loss: 0.09910090267658234\n",
      "Epoch 1, Loss: 1.1059849262237549\n",
      "Epoch 3, Loss: 0.03394768759608269\n",
      "Epoch 4, Loss: 0.5843890905380249\n",
      "Epoch 1, Loss: 1.543700098991394\n",
      "Epoch 2, Loss: 0.18254441022872925\n",
      "Epoch 3, Loss: 0.059808578342199326\n",
      "Epoch 1, Loss: 0.9312646389007568\n",
      "Epoch 2, Loss: 0.012884807772934437\n",
      "Epoch 5, Loss: 0.22339661419391632\n",
      "Epoch 4, Loss: 0.09845894575119019\n",
      "Epoch 3, Loss: 0.07037663459777832\n",
      "Epoch 3, Loss: 0.09184882789850235\n",
      "Epoch 2, Loss: 0.13855695724487305\n",
      "Epoch 4, Loss: 0.014807498082518578\n",
      "Epoch 2, Loss: 0.33155882358551025\n",
      "Epoch 6, Loss: 0.14517822861671448\n",
      "Epoch 4, Loss: 0.03270401805639267\n",
      "Epoch 5, Loss: 0.04303881525993347\n",
      "Epoch 2, Loss: 0.8359111547470093\n",
      "Epoch 3, Loss: 0.02825850248336792\n",
      "Epoch 5, Loss: 0.02619079500436783\n",
      "Epoch 4, Loss: 0.02963441051542759\n",
      "Epoch 2, Loss: 0.37882572412490845\n",
      "Epoch 3, Loss: 0.10062485188245773\n",
      "Epoch 3, Loss: 0.08588460087776184\n",
      "Epoch 4, Loss: 0.10306081175804138\n",
      "Epoch 7, Loss: 0.2459069937467575\n",
      "Epoch 5, Loss: 0.012048427946865559\n",
      "Epoch 6, Loss: 0.013324403204023838\n",
      "Epoch 3, Loss: 0.021757032722234726\n",
      "Epoch 4, Loss: 0.08163680136203766\n",
      "Epoch 8, Loss: 0.3913913369178772\n",
      "Epoch 6, Loss: 0.02306635119020939\n",
      "Epoch 3, Loss: 0.35868319869041443\n",
      "Epoch 4, Loss: 0.12113633006811142\n",
      "Epoch 5, Loss: 0.029704462736845016\n",
      "Epoch 4, Loss: 0.05861387401819229\n",
      "Epoch 5, Loss: 0.04741479456424713\n",
      "Epoch 3, Loss: 0.12409388273954391\n",
      "Epoch 6, Loss: 0.018924852833151817\n",
      "Epoch 7, Loss: 0.024807343259453773\n",
      "Epoch 9, Loss: 0.5016172528266907\n",
      "Epoch 5, Loss: 0.1711275577545166\n",
      "Epoch 7, Loss: 0.00984792411327362\n",
      "Epoch 7, Loss: 0.02883496694266796\n",
      "Epoch 4, Loss: 0.061763860285282135\n",
      "Epoch 6, Loss: 0.04206926003098488\n",
      "Epoch 4, Loss: 0.11361087113618851\n",
      "Epoch 10, Loss: 0.5376418232917786\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.395100291572427, feed_forward_dim=1024, head_dim=8, lr=0.0002329159045204976, num_heads=4, num_layers=1; total time=   1.0s\n",
      "Epoch 5, Loss: 0.06110671907663345\n",
      "Epoch 8, Loss: 0.04657424986362457\n",
      "Epoch 5, Loss: 0.05754341185092926\n",
      "Epoch 8, Loss: 0.009089179337024689\n",
      "Epoch 6, Loss: 0.008273216895759106\n",
      "Epoch 4, Loss: 0.11564509570598602\n",
      "Epoch 6, Loss: 0.19888094067573547\n",
      "Epoch 8, Loss: 0.021755192428827286\n",
      "Epoch 7, Loss: 0.02972313016653061\n",
      "Epoch 9, Loss: 0.04957690089941025\n",
      "Epoch 6, Loss: 0.015611718408763409\n",
      "Epoch 5, Loss: 0.21346549689769745\n",
      "Epoch 7, Loss: 0.01412682980298996\n",
      "Epoch 9, Loss: 0.016980377957224846\n",
      "Epoch 6, Loss: 0.04326746240258217\n",
      "Epoch 7, Loss: 0.16111686825752258\n",
      "Epoch 5, Loss: 0.20749887824058533\n",
      "Epoch 10, Loss: 0.03429873660206795\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.395100291572427, feed_forward_dim=1024, head_dim=8, lr=0.0002329159045204976, num_heads=4, num_layers=1; total time=   1.2s\n",
      "Epoch 5, Loss: 0.06452391296625137\n",
      "Epoch 8, Loss: 0.01401965320110321\n",
      "Epoch 9, Loss: 0.00966834556311369\n",
      "Epoch 10, Loss: 0.019165437668561935\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.395100291572427, feed_forward_dim=1024, head_dim=8, lr=0.0002329159045204976, num_heads=4, num_layers=1; total time=   1.2s\n",
      "Epoch 6, Loss: 0.29378563165664673\n",
      "Epoch 7, Loss: 0.018106788396835327\n",
      "Epoch 8, Loss: 0.03989271819591522\n",
      "Epoch 7, Loss: 0.02351946011185646\n",
      "Epoch 8, Loss: 0.10028206557035446\n",
      "Epoch 10, Loss: 0.006724693812429905\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.395100291572427, feed_forward_dim=1024, head_dim=8, lr=0.0002329159045204976, num_heads=4, num_layers=1; total time=   1.2s\n",
      "Epoch 9, Loss: 0.01484602689743042\n",
      "Epoch 6, Loss: 0.26731982827186584\n",
      "Epoch 6, Loss: 0.13622793555259705\n",
      "Epoch 9, Loss: 0.05040590092539787\n",
      "Epoch 9, Loss: 0.047088075429201126\n",
      "Epoch 8, Loss: 0.045762769877910614\n",
      "Epoch 7, Loss: 0.27027955651283264\n",
      "Epoch 8, Loss: 0.017512207850813866\n",
      "Epoch 10, Loss: 0.025993499904870987\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.395100291572427, feed_forward_dim=1024, head_dim=8, lr=0.0002329159045204976, num_heads=4, num_layers=1; total time=   1.4s\n",
      "Epoch 10, Loss: 0.040798407047986984\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.395100291572427, feed_forward_dim=1024, head_dim=8, lr=0.0002329159045204976, num_heads=4, num_layers=1; total time=   1.4s\n",
      "Epoch 7, Loss: 0.2382754683494568\n",
      "Epoch 7, Loss: 0.2536243498325348\n",
      "Epoch 9, Loss: 0.06009563058614731\n",
      "Epoch 10, Loss: 0.019090833142399788\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.395100291572427, feed_forward_dim=1024, head_dim=8, lr=0.0002329159045204976, num_heads=4, num_layers=1; total time=   1.4s\n",
      "Epoch 9, Loss: 0.022577546536922455\n",
      "Epoch 8, Loss: 0.18856479227542877\n",
      "Epoch 10, Loss: 0.04850492253899574\n",
      "Epoch 8, Loss: 0.2977108061313629\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.395100291572427, feed_forward_dim=1024, head_dim=8, lr=0.0002329159045204976, num_heads=4, num_layers=1; total time=   1.5s\n",
      "Epoch 8, Loss: 0.1966332644224167\n",
      "Epoch 10, Loss: 0.019740883260965347\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.395100291572427, feed_forward_dim=1024, head_dim=8, lr=0.0002329159045204976, num_heads=4, num_layers=1; total time=   1.5s\n",
      "Epoch 9, Loss: 0.1014825776219368\n",
      "Epoch 9, Loss: 0.3015289604663849\n",
      "Epoch 9, Loss: 0.12561044096946716\n",
      "Epoch 10, Loss: 0.03599901497364044\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.395100291572427, feed_forward_dim=1024, head_dim=8, lr=0.0002329159045204976, num_heads=4, num_layers=1; total time=   1.6s\n",
      "Epoch 10, Loss: 0.2691692113876343\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.395100291572427, feed_forward_dim=1024, head_dim=8, lr=0.0002329159045204976, num_heads=4, num_layers=1; total time=   1.6s\n",
      "Epoch 10, Loss: 0.06801158934831619\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.395100291572427, feed_forward_dim=1024, head_dim=8, lr=0.0002329159045204976, num_heads=4, num_layers=1; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.5392249822616577\n",
      "Epoch 1, Loss: 0.4484799802303314\n",
      "Epoch 1, Loss: 0.4909963309764862\n",
      "Epoch 2, Loss: 0.015289632603526115\n",
      "Epoch 1, Loss: 0.7888510823249817\n",
      "Epoch 1, Loss: 0.044450946152210236\n",
      "Epoch 2, Loss: 0.04575001820921898\n",
      "Epoch 3, Loss: 0.15881949663162231\n",
      "Epoch 1, Loss: 1.194229006767273\n",
      "Epoch 2, Loss: 0.11042730510234833\n",
      "Epoch 1, Loss: 1.2119927406311035\n",
      "Epoch 1, Loss: 0.24375320971012115\n",
      "Epoch 1, Loss: 0.14467649161815643\n",
      "Epoch 2, Loss: 0.1129089891910553\n",
      "Epoch 3, Loss: 0.189697265625\n",
      "Epoch 2, Loss: 0.20299243927001953\n",
      "Epoch 4, Loss: 0.25484201312065125\n",
      "Epoch 3, Loss: 0.21299278736114502\n",
      "Epoch 2, Loss: 0.33309581875801086\n",
      "Epoch 1, Loss: 0.17530347406864166\n",
      "Epoch 1, Loss: 0.6393381357192993\n",
      "Epoch 4, Loss: 0.21720315515995026\n",
      "Epoch 2, Loss: 0.03352102264761925\n",
      "Epoch 5, Loss: 0.18130972981452942\n",
      "Epoch 1, Loss: 0.10404010117053986\n",
      "Epoch 3, Loss: 0.03703688085079193\n",
      "Epoch 4, Loss: 0.2416064739227295\n",
      "Epoch 2, Loss: 0.33016955852508545\n",
      "Epoch 3, Loss: 0.11111093312501907\n",
      "Epoch 2, Loss: 0.0955611914396286\n",
      "Epoch 5, Loss: 0.1184222623705864\n",
      "Epoch 3, Loss: 0.11054534465074539\n",
      "Epoch 2, Loss: 0.09812524169683456\n",
      "Epoch 2, Loss: 0.13083845376968384\n",
      "Epoch 6, Loss: 0.06878326088190079\n",
      "Epoch 5, Loss: 0.15656645596027374\n",
      "Epoch 3, Loss: 0.1584310233592987\n",
      "Epoch 2, Loss: 0.05525072291493416\n",
      "Epoch 3, Loss: 0.14017657935619354\n",
      "Epoch 4, Loss: 0.04421741142868996\n",
      "Epoch 4, Loss: 0.27969613671302795\n",
      "Epoch 6, Loss: 0.035654567182064056\n",
      "Epoch 7, Loss: 0.008997220546007156\n",
      "Epoch 6, Loss: 0.0648253858089447\n",
      "Epoch 4, Loss: 0.2578319013118744\n",
      "Epoch 3, Loss: 0.2711760699748993\n",
      "Epoch 3, Loss: 0.13948078453540802\n",
      "Epoch 5, Loss: 0.2849135398864746\n",
      "Epoch 5, Loss: 0.09714473783969879\n",
      "Epoch 7, Loss: 0.02530144713819027\n",
      "Epoch 4, Loss: 0.2926124036312103\n",
      "Epoch 3, Loss: 0.05011068284511566\n",
      "Epoch 3, Loss: 0.06998700648546219\n",
      "Epoch 8, Loss: 0.023767197504639626\n",
      "Epoch 7, Loss: 0.0364040844142437\n",
      "Epoch 4, Loss: 0.1105237677693367Epoch 6, Loss: 0.1844184249639511\n",
      "\n",
      "Epoch 5, Loss: 0.36394765973091125\n",
      "Epoch 6, Loss: 0.0652737095952034\n",
      "Epoch 9, Loss: 0.06976012885570526\n",
      "Epoch 4, Loss: 0.3203622102737427\n",
      "Epoch 8, Loss: 0.05924141779541969\n",
      "Epoch 5, Loss: 0.3980253040790558\n",
      "Epoch 4, Loss: 0.06428665667772293\n",
      "Epoch 7, Loss: 0.07666414231061935\n",
      "Epoch 8, Loss: 0.06516849249601364\n",
      "Epoch 10, Loss: 0.09817736595869064\n",
      "Epoch 5, Loss: 0.025614198297262192\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3247033009208613, feed_forward_dim=256, head_dim=16, lr=0.0003460898050872787, num_heads=2, num_layers=1; total time=   0.9s\n",
      "Epoch 7, Loss: 0.018481940031051636\n",
      "Epoch 4, Loss: 0.03243115544319153\n",
      "Epoch 6, Loss: 0.33261796832084656\n",
      "Epoch 9, Loss: 0.08732971549034119\n",
      "Epoch 4, Loss: 0.012386391870677471\n",
      "Epoch 8, Loss: 0.02064170502126217\n",
      "Epoch 6, Loss: 0.3672889769077301\n",
      "Epoch 5, Loss: 0.1940055936574936\n",
      "Epoch 9, Loss: 0.09627196937799454\n",
      "Epoch 5, Loss: 0.04567975923418999\n",
      "Epoch 7, Loss: 0.2232481986284256\n",
      "Epoch 10, Loss: 0.08284406363964081\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3247033009208613, feed_forward_dim=256, head_dim=16, lr=0.0003460898050872787, num_heads=2, num_layers=1; total time=   1.1s\n",
      "Epoch 6, Loss: 0.01417869795113802\n",
      "Epoch 5, Loss: 0.01996486634016037\n",
      "Epoch 9, Loss: 0.030638158321380615\n",
      "Epoch 8, Loss: 0.0108344666659832\n",
      "Epoch 5, Loss: 0.021977584809064865\n",
      "Epoch 10, Loss: 0.09181900322437286\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3247033009208613, feed_forward_dim=256, head_dim=16, lr=0.0003460898050872787, num_heads=2, num_layers=1; total time=   1.1s\n",
      "Epoch 7, Loss: 0.26384082436561584\n",
      "Epoch 6, Loss: 0.06908083707094193\n",
      "Epoch 6, Loss: 0.06853224337100983\n",
      "Epoch 8, Loss: 0.11338074505329132\n",
      "Epoch 7, Loss: 0.05298125371336937\n",
      "Epoch 9, Loss: 0.03723754733800888\n",
      "Epoch 10, Loss: 0.07351062446832657\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3247033009208613, feed_forward_dim=256, head_dim=16, lr=0.0003460898050872787, num_heads=2, num_layers=1; total time=   1.1s\n",
      "Epoch 6, Loss: 0.037780821323394775\n",
      "Epoch 10, Loss: 0.04863381385803223\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3247033009208613, feed_forward_dim=256, head_dim=16, lr=0.0003460898050872787, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 9, Loss: 0.04729204997420311\n",
      "Epoch 8, Loss: 0.1517690271139145\n",
      "Epoch 7, Loss: 0.06298711150884628\n",
      "Epoch 8, Loss: 0.06978064030408859\n",
      "Epoch 7, Loss: 0.031751297414302826\n",
      "Epoch 6, Loss: 0.02395528368651867\n",
      "Epoch 7, Loss: 0.0182292852550745\n",
      "Epoch 10, Loss: 0.0313037671148777\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3247033009208613, feed_forward_dim=256, head_dim=16, lr=0.0003460898050872787, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 9, Loss: 0.07842893153429031\n",
      "Epoch 9, Loss: 0.04793756827712059\n",
      "Epoch 8, Loss: 0.03279712796211243\n",
      "Epoch 8, Loss: 0.06837870925664902\n",
      "Epoch 8, Loss: 0.021294360980391502\n",
      "Epoch 7, Loss: 0.013697799295186996\n",
      "Epoch 10, Loss: 0.016574598848819733\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3247033009208613, feed_forward_dim=256, head_dim=16, lr=0.0003460898050872787, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 10, Loss: 0.05728926137089729\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3247033009208613, feed_forward_dim=256, head_dim=16, lr=0.0003460898050872787, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 9, Loss: 0.01695006713271141\n",
      "Epoch 9, Loss: 0.033696845173835754\n",
      "Epoch 9, Loss: 0.10881068557500839\n",
      "Epoch 8, Loss: 0.024755777791142464\n",
      "Epoch 10, Loss: 0.024982867762446404\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3247033009208613, feed_forward_dim=256, head_dim=16, lr=0.0003460898050872787, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.02242569997906685\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3247033009208613, feed_forward_dim=256, head_dim=16, lr=0.0003460898050872787, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.10457689315080643\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3247033009208613, feed_forward_dim=256, head_dim=16, lr=0.0003460898050872787, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 9, Loss: 0.023271135985851288\n",
      "Epoch 10, Loss: 0.012737366370856762\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3247033009208613, feed_forward_dim=256, head_dim=16, lr=0.0003460898050872787, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.16863247752189636\n",
      "Epoch 1, Loss: 0.4504672586917877\n",
      "Epoch 2, Loss: 0.10445849597454071\n",
      "Epoch 1, Loss: 0.25501489639282227\n",
      "Epoch 1, Loss: 2.403498888015747\n",
      "Epoch 2, Loss: 0.35895466804504395\n",
      "Epoch 1, Loss: 0.09148219972848892\n",
      "Epoch 3, Loss: 0.058800529688596725\n",
      "Epoch 1, Loss: 3.3063814640045166\n",
      "Epoch 2, Loss: 0.1946861743927002\n",
      "Epoch 2, Loss: 2.149589776992798\n",
      "Epoch 1, Loss: 0.10375014692544937\n",
      "Epoch 1, Loss: 0.9265261292457581\n",
      "Epoch 4, Loss: 0.028995823115110397\n",
      "Epoch 2, Loss: 0.07164669781923294\n",
      "Epoch 3, Loss: 0.2841947674751282\n",
      "Epoch 1, Loss: 0.16164946556091309\n",
      "Epoch 3, Loss: 0.1492343693971634\n",
      "Epoch 1, Loss: 2.3511247634887695\n",
      "Epoch 2, Loss: 3.0412304401397705\n",
      "Epoch 1, Loss: 0.1491284817457199\n",
      "Epoch 3, Loss: 1.925871729850769\n",
      "Epoch 5, Loss: 0.011174215003848076\n",
      "Epoch 3, Loss: 0.06206899508833885\n",
      "Epoch 4, Loss: 0.22021767497062683\n",
      "Epoch 2, Loss: 0.0812859833240509\n",
      "Epoch 4, Loss: 0.11092055588960648\n",
      "Epoch 2, Loss: 0.7663412690162659\n",
      "Epoch 1, Loss: 0.5564746856689453\n",
      "Epoch 2, Loss: 2.0837626457214355\n",
      "Epoch 3, Loss: 2.786417007446289\n",
      "Epoch 2, Loss: 0.12867408990859985\n",
      "Epoch 4, Loss: 1.7160004377365112\n",
      "Epoch 6, Loss: 0.0074937776662409306\n",
      "Epoch 5, Loss: 0.17011071741580963\n",
      "Epoch 2, Loss: 0.10175979882478714\n",
      "Epoch 5, Loss: 0.08373729139566422\n",
      "Epoch 3, Loss: 0.06629765033721924\n",
      "Epoch 4, Loss: 0.05997969210147858\n",
      "Epoch 4, Loss: 2.5517168045043945\n",
      "Epoch 7, Loss: 0.012111121788620949\n",
      "Epoch 5, Loss: 1.493636965751648\n",
      "Epoch 3, Loss: 1.831764817237854\n",
      "Epoch 3, Loss: 0.6214507818222046\n",
      "Epoch 2, Loss: 0.42180466651916504\n",
      "Epoch 3, Loss: 0.05876854807138443\n",
      "Epoch 6, Loss: 0.13415804505348206\n",
      "Epoch 6, Loss: 0.06648927927017212\n",
      "Epoch 4, Loss: 0.05954047664999962\n",
      "Epoch 3, Loss: 0.11810938268899918\n",
      "Epoch 5, Loss: 0.06022388115525246\n",
      "Epoch 8, Loss: 0.020322181284427643\n",
      "Epoch 5, Loss: 2.3193788528442383\n",
      "Epoch 7, Loss: 0.10841898620128632\n",
      "Epoch 6, Loss: 1.3115077018737793\n",
      "Epoch 4, Loss: 0.4981592893600464\n",
      "Epoch 7, Loss: 0.057056084275245667\n",
      "Epoch 4, Loss: 1.5954158306121826\n",
      "Epoch 4, Loss: 0.03328821435570717\n",
      "Epoch 3, Loss: 0.3137962222099304\n",
      "Epoch 5, Loss: 0.05849076807498932\n",
      "Epoch 9, Loss: 0.029682038351893425\n",
      "Epoch 6, Loss: 0.0570753738284111\n",
      "Epoch 4, Loss: 0.10777736455202103\n",
      "Epoch 7, Loss: 1.1294134855270386\n",
      "Epoch 8, Loss: 0.09269038587808609\n",
      "Epoch 5, Loss: 0.39369720220565796\n",
      "Epoch 8, Loss: 0.05388723313808441\n",
      "Epoch 6, Loss: 2.1014857292175293\n",
      "Epoch 10, Loss: 0.03467804193496704\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.2305667210095791, feed_forward_dim=128, head_dim=16, lr=5.01114460727821e-05, num_heads=2, num_layers=1; total time=   1.0s\n",
      "Epoch 5, Loss: 0.02338181622326374\n",
      "Epoch 7, Loss: 0.05339370295405388\n",
      "Epoch 6, Loss: 0.060204148292541504\n",
      "Epoch 4, Loss: 0.21943379938602448\n",
      "Epoch 5, Loss: 1.3808993101119995\n",
      "Epoch 9, Loss: 0.08371313661336899\n",
      "Epoch 9, Loss: 0.05528442934155464\n",
      "Epoch 8, Loss: 0.9705990552902222\n",
      "Epoch 5, Loss: 0.09971527755260468\n",
      "Epoch 7, Loss: 1.8940104246139526\n",
      "Epoch 6, Loss: 0.3019822835922241\n",
      "Epoch 10, Loss: 0.08118083328008652\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.2305667210095791, feed_forward_dim=128, head_dim=16, lr=5.01114460727821e-05, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 10, Loss: 0.05742606520652771\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.2305667210095791, feed_forward_dim=128, head_dim=16, lr=5.01114460727821e-05, num_heads=2, num_layers=1; total time=   1.1s\n",
      "Epoch 8, Loss: 0.049259427934885025\n",
      "Epoch 7, Loss: 0.060252878814935684\n",
      "Epoch 6, Loss: 0.022824859246611595\n",
      "Epoch 8, Loss: 1.7069934606552124\n",
      "Epoch 9, Loss: 0.8192388415336609\n",
      "Epoch 5, Loss: 0.15180525183677673\n",
      "Epoch 7, Loss: 0.2317325919866562\n",
      "Epoch 6, Loss: 1.1730420589447021\n",
      "Epoch 6, Loss: 0.09104485809803009\n",
      "Epoch 7, Loss: 0.02902803011238575\n",
      "Epoch 8, Loss: 0.05833538994193077\n",
      "Epoch 9, Loss: 1.5206471681594849\n",
      "Epoch 9, Loss: 0.04419136047363281\n",
      "Epoch 10, Loss: 0.6877196431159973\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.2305667210095791, feed_forward_dim=128, head_dim=16, lr=5.01114460727821e-05, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 6, Loss: 0.10269894450902939\n",
      "Epoch 8, Loss: 0.1744874119758606\n",
      "Epoch 7, Loss: 0.983587384223938\n",
      "Epoch 10, Loss: 0.03890141099691391\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.2305667210095791, feed_forward_dim=128, head_dim=16, lr=5.01114460727821e-05, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 8, Loss: 0.03587302565574646\n",
      "Epoch 9, Loss: 0.05565057694911957\n",
      "Epoch 10, Loss: 1.3465728759765625\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.2305667210095791, feed_forward_dim=128, head_dim=16, lr=5.01114460727821e-05, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 7, Loss: 0.08077895641326904\n",
      "Epoch 9, Loss: 0.13432449102401733\n",
      "Epoch 7, Loss: 0.07151688635349274\n",
      "Epoch 9, Loss: 0.039677590131759644\n",
      "Epoch 8, Loss: 0.8140785098075867\n",
      "Epoch 10, Loss: 0.05063636973500252\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.2305667210095791, feed_forward_dim=128, head_dim=16, lr=5.01114460727821e-05, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.10515402257442474\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.2305667210095791, feed_forward_dim=128, head_dim=16, lr=5.01114460727821e-05, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 8, Loss: 0.05402977764606476\n",
      "Epoch 8, Loss: 0.07060068100690842\n",
      "Epoch 9, Loss: 0.6611496210098267\n",
      "Epoch 10, Loss: 0.03912515193223953\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.2305667210095791, feed_forward_dim=128, head_dim=16, lr=5.01114460727821e-05, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 9, Loss: 0.05008139833807945\n",
      "Epoch 9, Loss: 0.0634830892086029\n",
      "Epoch 10, Loss: 0.5296491384506226\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.2305667210095791, feed_forward_dim=128, head_dim=16, lr=5.01114460727821e-05, num_heads=2, num_layers=1; total time=   1.6s\n",
      "Epoch 10, Loss: 0.055739764124155045\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.2305667210095791, feed_forward_dim=128, head_dim=16, lr=5.01114460727821e-05, num_heads=2, num_layers=1; total time=   1.6s\n",
      "Epoch 10, Loss: 0.05383312329649925\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.2305667210095791, feed_forward_dim=128, head_dim=16, lr=5.01114460727821e-05, num_heads=2, num_layers=1; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.2652554214000702\n",
      "Epoch 1, Loss: 1.5537301301956177\n",
      "Epoch 1, Loss: 0.18381941318511963\n",
      "Epoch 2, Loss: 0.0497598797082901\n",
      "Epoch 1, Loss: 1.5324550867080688\n",
      "Epoch 1, Loss: 1.174163818359375\n",
      "Epoch 1, Loss: 0.7268146276473999\n",
      "Epoch 2, Loss: 0.24347585439682007\n",
      "Epoch 1, Loss: 1.0950332880020142\n",
      "Epoch 3, Loss: 0.17798882722854614\n",
      "Epoch 2, Loss: 0.2822796404361725\n",
      "Epoch 1, Loss: 0.17722970247268677\n",
      "Epoch 1, Loss: 0.06369172036647797\n",
      "Epoch 2, Loss: 0.43231308460235596\n",
      "Epoch 2, Loss: 0.22265899181365967\n",
      "Epoch 2, Loss: 0.08585935831069946\n",
      "Epoch 1, Loss: 1.1285669803619385\n",
      "Epoch 4, Loss: 0.12860390543937683\n",
      "Epoch 3, Loss: 0.06975635141134262\n",
      "Epoch 3, Loss: 0.11423982679843903\n",
      "Epoch 1, Loss: 1.0230951309204102\n",
      "Epoch 2, Loss: 0.19686077535152435\n",
      "Epoch 1, Loss: 0.32861608266830444\n",
      "Epoch 2, Loss: 0.23883283138275146\n",
      "Epoch 3, Loss: 0.030742913484573364\n",
      "Epoch 2, Loss: 0.049548983573913574\n",
      "Epoch 5, Loss: 0.03901878371834755\n",
      "Epoch 3, Loss: 0.08016032725572586\n",
      "Epoch 4, Loss: 0.05482456460595131\n",
      "Epoch 3, Loss: 0.08872586488723755\n",
      "Epoch 4, Loss: 0.3610776364803314\n",
      "Epoch 2, Loss: 0.245510533452034\n",
      "Epoch 3, Loss: 0.08900950103998184\n",
      "Epoch 6, Loss: 0.019819358363747597\n",
      "Epoch 4, Loss: 0.12628678977489471\n",
      "Epoch 5, Loss: 0.10644271224737167\n",
      "Epoch 5, Loss: 0.5056964159011841\n",
      "Epoch 2, Loss: 0.1615767776966095\n",
      "Epoch 2, Loss: 0.3005425035953522\n",
      "Epoch 3, Loss: 0.030183138325810432\n",
      "Epoch 4, Loss: 0.2504695653915405\n",
      "Epoch 4, Loss: 0.3012859523296356\n",
      "Epoch 7, Loss: 0.05603879317641258\n",
      "Epoch 3, Loss: 0.13059796392917633\n",
      "Epoch 4, Loss: 0.2948461174964905\n",
      "Epoch 6, Loss: 0.4228954315185547\n",
      "Epoch 6, Loss: 0.08793780207633972\n",
      "Epoch 3, Loss: 0.03062201663851738\n",
      "Epoch 8, Loss: 0.0781584233045578\n",
      "Epoch 3, Loss: 0.2318945676088333\n",
      "Epoch 5, Loss: 0.3245042860507965\n",
      "Epoch 4, Loss: 0.16349458694458008\n",
      "Epoch 5, Loss: 0.2562020719051361\n",
      "Epoch 5, Loss: 0.389679491519928\n",
      "Epoch 3, Loss: 0.21339020133018494\n",
      "Epoch 7, Loss: 0.2616904079914093\n",
      "Epoch 5, Loss: 0.38295063376426697\n",
      "Epoch 7, Loss: 0.030547132715582848\n",
      "Epoch 9, Loss: 0.058487050235271454\n",
      "Epoch 4, Loss: 0.05631155148148537\n",
      "Epoch 6, Loss: 0.15913765132427216\n",
      "Epoch 6, Loss: 0.3914814293384552\n",
      "Epoch 4, Loss: 0.4095890522003174\n",
      "Epoch 8, Loss: 0.11098074167966843\n",
      "Epoch 4, Loss: 0.1988949179649353\n",
      "Epoch 5, Loss: 0.12445808947086334\n",
      "Epoch 6, Loss: 0.31838956475257874\n",
      "Epoch 8, Loss: 0.01226664986461401\n",
      "Epoch 10, Loss: 0.026050258427858353\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=512, head_dim=16, lr=0.00037439026058877544, num_heads=8, num_layers=4; total time=   1.0s\n",
      "Epoch 4, Loss: 0.06383255124092102\n",
      "Epoch 6, Loss: 0.3238668739795685\n",
      "Epoch 9, Loss: 0.032771170139312744\n",
      "Epoch 7, Loss: 0.3457126021385193\n",
      "Epoch 7, Loss: 0.06166210398077965\n",
      "Epoch 5, Loss: 0.005226934794336557\n",
      "Epoch 9, Loss: 0.036337099969387054\n",
      "Epoch 5, Loss: 0.3503611087799072\n",
      "Epoch 7, Loss: 0.1870913803577423\n",
      "Epoch 6, Loss: 0.03103363700211048\n",
      "Epoch 5, Loss: 0.3267565965652466\n",
      "Epoch 7, Loss: 0.20332111418247223\n",
      "Epoch 10, Loss: 0.028050078079104424\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=512, head_dim=16, lr=0.00037439026058877544, num_heads=8, num_layers=4; total time=   1.1s\n",
      "Epoch 8, Loss: 0.019451657310128212\n",
      "Epoch 5, Loss: 0.05932839587330818\n",
      "Epoch 8, Loss: 0.23745864629745483\n",
      "Epoch 6, Loss: 0.03155185654759407\n",
      "Epoch 10, Loss: 0.04855521768331528\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=512, head_dim=16, lr=0.00037439026058877544, num_heads=8, num_layers=4; total time=   1.2s\n",
      "Epoch 8, Loss: 0.08007901906967163\n",
      "Epoch 8, Loss: 0.09832888096570969\n",
      "Epoch 6, Loss: 0.30752381682395935\n",
      "Epoch 7, Loss: 0.028994427993893623\n",
      "Epoch 6, Loss: 0.18824930489063263\n",
      "Epoch 9, Loss: 0.13024580478668213\n",
      "Epoch 9, Loss: 0.03257468342781067\n",
      "Epoch 7, Loss: 0.060489531606435776\n",
      "Epoch 9, Loss: 0.03142678737640381\n",
      "Epoch 6, Loss: 0.09227333217859268\n",
      "Epoch 9, Loss: 0.04402009770274162\n",
      "Epoch 10, Loss: 0.05408966913819313\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=512, head_dim=16, lr=0.00037439026058877544, num_heads=8, num_layers=4; total time=   1.3s\n",
      "Epoch 10, Loss: 0.07215748727321625\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=512, head_dim=16, lr=0.00037439026058877544, num_heads=8, num_layers=4; total time=   1.3s\n",
      "Epoch 7, Loss: 0.06783291697502136\n",
      "Epoch 7, Loss: 0.21001547574996948\n",
      "Epoch 10, Loss: 0.03869622200727463\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=512, head_dim=16, lr=0.00037439026058877544, num_heads=8, num_layers=4; total time=   1.4s\n",
      "Epoch 8, Loss: 0.07786688208580017\n",
      "Epoch 10, Loss: 0.04700654745101929\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=512, head_dim=16, lr=0.00037439026058877544, num_heads=8, num_layers=4; total time=   1.4s\n",
      "Epoch 7, Loss: 0.06025160476565361\n",
      "Epoch 8, Loss: 0.0498700775206089\n",
      "Epoch 8, Loss: 0.040741823613643646\n",
      "Epoch 8, Loss: 0.10548647493124008\n",
      "Epoch 9, Loss: 0.07793492078781128\n",
      "Epoch 8, Loss: 0.01393156498670578\n",
      "Epoch 9, Loss: 0.019238531589508057\n",
      "Epoch 9, Loss: 0.08064399659633636\n",
      "Epoch 9, Loss: 0.036845188587903976\n",
      "Epoch 10, Loss: 0.04024432972073555\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=512, head_dim=16, lr=0.00037439026058877544, num_heads=8, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.004480695817619562\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=512, head_dim=16, lr=0.00037439026058877544, num_heads=8, num_layers=4; total time=   1.6s\n",
      "Epoch 9, Loss: 0.013390138745307922\n",
      "Epoch 10, Loss: 0.12871427834033966\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=512, head_dim=16, lr=0.00037439026058877544, num_heads=8, num_layers=4; total time=   1.6s\n",
      "Epoch 10, Loss: 0.014684507623314857\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=512, head_dim=16, lr=0.00037439026058877544, num_heads=8, num_layers=4; total time=   1.6s\n",
      "Epoch 10, Loss: 0.042353153228759766\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.4, feed_forward_dim=512, head_dim=16, lr=0.00037439026058877544, num_heads=8, num_layers=4; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.9682736396789551\n",
      "Epoch 1, Loss: 0.16583029925823212\n",
      "Epoch 1, Loss: 0.05497872084379196\n",
      "Epoch 2, Loss: 0.20018301904201508\n",
      "Epoch 1, Loss: 0.12375391274690628\n",
      "Epoch 1, Loss: 0.05052110552787781\n",
      "Epoch 2, Loss: 0.12120948731899261\n",
      "Epoch 1, Loss: 0.9929731488227844\n",
      "Epoch 3, Loss: 0.19150210916996002\n",
      "Epoch 1, Loss: 0.17470355331897736\n",
      "Epoch 2, Loss: 0.17082001268863678\n",
      "Epoch 2, Loss: 0.1944691389799118\n",
      "Epoch 2, Loss: 0.1478230506181717\n",
      "Epoch 1, Loss: 0.6980534791946411\n",
      "Epoch 3, Loss: 0.13053292036056519\n",
      "Epoch 1, Loss: 0.23721854388713837\n",
      "Epoch 4, Loss: 0.3476245105266571\n",
      "Epoch 2, Loss: 0.05089541897177696\n",
      "Epoch 2, Loss: 0.1949336677789688\n",
      "Epoch 3, Loss: 0.03508106991648674\n",
      "Epoch 3, Loss: 0.031014099717140198\n",
      "Epoch 4, Loss: 0.05370372533798218\n",
      "Epoch 5, Loss: 0.335506796836853Epoch 3, Loss: 0.09512351453304291\n",
      "\n",
      "Epoch 2, Loss: 0.21544934809207916\n",
      "Epoch 4, Loss: 0.05275483429431915\n",
      "Epoch 3, Loss: 0.11153063923120499\n",
      "Epoch 4, Loss: 0.05703001841902733\n",
      "Epoch 1, Loss: 0.22271628677845\n",
      "Epoch 5, Loss: 0.037492118775844574\n",
      "Epoch 6, Loss: 0.22136756777763367\n",
      "Epoch 1, Loss: 1.1339114904403687\n",
      "Epoch 3, Loss: 0.17272986471652985\n",
      "Epoch 4, Loss: 0.01884613372385502\n",
      "Epoch 1, Loss: 0.37369242310523987\n",
      "Epoch 2, Loss: 0.14602349698543549\n",
      "Epoch 3, Loss: 0.29724979400634766\n",
      "Epoch 5, Loss: 0.0958954468369484\n",
      "Epoch 4, Loss: 0.057006146758794785\n",
      "Epoch 5, Loss: 0.08498107641935349\n",
      "Epoch 7, Loss: 0.09732841700315475\n",
      "Epoch 6, Loss: 0.06252521276473999\n",
      "Epoch 4, Loss: 0.39137449860572815\n",
      "Epoch 2, Loss: 0.014341352507472038\n",
      "Epoch 5, Loss: 0.046412453055381775\n",
      "Epoch 2, Loss: 0.258721262216568\n",
      "Epoch 8, Loss: 0.034676551818847656\n",
      "Epoch 6, Loss: 0.04366064816713333\n",
      "Epoch 2, Loss: 0.014302736148238182\n",
      "Epoch 7, Loss: 0.058701083064079285\n",
      "Epoch 6, Loss: 0.05037824064493179\n",
      "Epoch 4, Loss: 0.3382687270641327\n",
      "Epoch 3, Loss: 0.1789865791797638\n",
      "Epoch 5, Loss: 0.07156345248222351\n",
      "Epoch 9, Loss: 0.0368705578148365\n",
      "Epoch 5, Loss: 0.34035423398017883\n",
      "Epoch 7, Loss: 0.008792445994913578\n",
      "Epoch 6, Loss: 0.07094228267669678\n",
      "Epoch 3, Loss: 0.1287986934185028\n",
      "Epoch 7, Loss: 0.010334755294024944\n",
      "Epoch 8, Loss: 0.031157517805695534\n",
      "Epoch 10, Loss: 0.07186859101057053\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.00033843040920723225, num_heads=4, num_layers=4; total time=   0.8s\n",
      "Epoch 3, Loss: 0.04078197106719017\n",
      "Epoch 6, Loss: 0.06597726792097092\n",
      "Epoch 5, Loss: 0.2422935664653778\n",
      "Epoch 3, Loss: 0.1855858415365219\n",
      "Epoch 4, Loss: 0.07914059609174728\n",
      "Epoch 6, Loss: 0.17634238302707672\n",
      "Epoch 7, Loss: 0.04076537489891052\n",
      "Epoch 8, Loss: 0.019975721836090088\n",
      "Epoch 8, Loss: 0.018194790929555893\n",
      "Epoch 4, Loss: 0.1093730628490448\n",
      "Epoch 9, Loss: 0.011989746242761612\n",
      "Epoch 9, Loss: 0.04027503356337547\n",
      "Epoch 6, Loss: 0.12172331660985947\n",
      "Epoch 7, Loss: 0.0451592393219471\n",
      "Epoch 7, Loss: 0.03182743862271309\n",
      "Epoch 9, Loss: 0.044607166200876236\n",
      "Epoch 8, Loss: 0.010874425061047077\n",
      "Epoch 5, Loss: 0.037971172481775284\n",
      "Epoch 4, Loss: 0.1890891045331955\n",
      "Epoch 4, Loss: 0.20032614469528198\n",
      "Epoch 5, Loss: 0.039440322667360306\n",
      "Epoch 10, Loss: 0.022284306585788727\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.00033843040920723225, num_heads=4, num_layers=4; total time=   1.0s\n",
      "Epoch 10, Loss: 0.037761345505714417\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.00033843040920723225, num_heads=4, num_layers=4; total time=   1.0s\n",
      "Epoch 10, Loss: 0.04498705267906189\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.00033843040920723225, num_heads=4, num_layers=4; total time=   1.0s\n",
      "Epoch 8, Loss: 0.007616796065121889\n",
      "Epoch 8, Loss: 0.014378601685166359\n",
      "Epoch 9, Loss: 0.015203465707600117\n",
      "Epoch 7, Loss: 0.06315900385379791\n",
      "Epoch 6, Loss: 0.007327895145863295\n",
      "Epoch 5, Loss: 0.07888563722372055\n",
      "Epoch 5, Loss: 0.3330695927143097\n",
      "Epoch 6, Loss: 0.07691635191440582\n",
      "Epoch 9, Loss: 0.04359118640422821\n",
      "Epoch 9, Loss: 0.024951189756393433\n",
      "Epoch 10, Loss: 0.0352865606546402\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.00033843040920723225, num_heads=4, num_layers=4; total time=   1.2s\n",
      "Epoch 8, Loss: 0.07220063358545303\n",
      "Epoch 7, Loss: 0.028750143945217133\n",
      "Epoch 6, Loss: 0.3290727436542511\n",
      "Epoch 6, Loss: 0.013370133936405182\n",
      "Epoch 10, Loss: 0.032040536403656006\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.00033843040920723225, num_heads=4, num_layers=4; total time=   1.2s\n",
      "Epoch 10, Loss: 0.09986583143472672\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.00033843040920723225, num_heads=4, num_layers=4; total time=   1.2s\n",
      "Epoch 7, Loss: 0.0867655947804451\n",
      "Epoch 9, Loss: 0.10594039410352707\n",
      "Epoch 8, Loss: 0.0556400902569294\n",
      "Epoch 7, Loss: 0.2349126636981964\n",
      "Epoch 7, Loss: 0.028630517423152924\n",
      "Epoch 8, Loss: 0.05310198292136192\n",
      "Epoch 10, Loss: 0.1154211238026619\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.00033843040920723225, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 9, Loss: 0.05530383065342903\n",
      "Epoch 8, Loss: 0.12690697610378265\n",
      "Epoch 8, Loss: 0.07441472262144089\n",
      "Epoch 9, Loss: 0.023492395877838135\n",
      "Epoch 10, Loss: 0.032941676676273346\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.00033843040920723225, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 9, Loss: 0.048679329454898834\n",
      "Epoch 10, Loss: 0.028178786858916283\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.00033843040920723225, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Epoch 9, Loss: 0.09205010533332825\n",
      "Epoch 10, Loss: 0.020549383014440536\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.00033843040920723225, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 10, Loss: 0.06713715940713882\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.00033843040920723225, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.7451083064079285\n",
      "Epoch 1, Loss: 0.1247854009270668\n",
      "Epoch 1, Loss: 0.39849653840065\n",
      "Epoch 1, Loss: 0.15595977008342743\n",
      "Epoch 2, Loss: 0.10823957622051239\n",
      "Epoch 1, Loss: 2.1972007751464844\n",
      "Epoch 2, Loss: 0.4499402642250061\n",
      "Epoch 2, Loss: 0.3402464985847473\n",
      "Epoch 3, Loss: 0.314432293176651\n",
      "Epoch 1, Loss: 0.03105013631284237\n",
      "Epoch 1, Loss: 0.92976313829422\n",
      "Epoch 2, Loss: 0.34484928846359253\n",
      "Epoch 1, Loss: 1.500247836112976\n",
      "Epoch 2, Loss: 0.5415627956390381\n",
      "Epoch 3, Loss: 0.30631640553474426\n",
      "Epoch 1, Loss: 0.9014214873313904\n",
      "Epoch 3, Loss: 0.10192184150218964\n",
      "Epoch 1, Loss: 1.1080498695373535\n",
      "Epoch 4, Loss: 0.34987208247184753\n",
      "Epoch 2, Loss: 0.5768498778343201\n",
      "Epoch 3, Loss: 0.10805240273475647\n",
      "Epoch 2, Loss: 0.160781130194664\n",
      "Epoch 3, Loss: 0.034892648458480835\n",
      "Epoch 4, Loss: 0.04537644237279892\n",
      "Epoch 1, Loss: 2.3493547439575195\n",
      "Epoch 2, Loss: 0.02919248677790165\n",
      "Epoch 5, Loss: 0.20559023320674896\n",
      "Epoch 4, Loss: 0.10904398560523987\n",
      "Epoch 1, Loss: 1.0490063428878784\n",
      "Epoch 3, Loss: 0.05524294078350067\n",
      "Epoch 3, Loss: 0.27604061365127563\n",
      "Epoch 4, Loss: 0.04496015980839729\n",
      "Epoch 2, Loss: 0.23923157155513763\n",
      "Epoch 2, Loss: 0.11499816179275513\n",
      "Epoch 4, Loss: 0.2680860161781311\n",
      "Epoch 5, Loss: 0.0786462128162384\n",
      "Epoch 6, Loss: 0.0787721574306488\n",
      "Epoch 3, Loss: 0.2849534749984741\n",
      "Epoch 5, Loss: 0.17730821669101715\n",
      "Epoch 2, Loss: 0.4567875564098358\n",
      "Epoch 2, Loss: 0.06371764838695526\n",
      "Epoch 6, Loss: 0.14009495079517365\n",
      "Epoch 5, Loss: 0.1254131942987442\n",
      "Epoch 5, Loss: 0.5194929838180542\n",
      "Epoch 4, Loss: 0.10644431412220001\n",
      "Epoch 4, Loss: 0.5277494788169861\n",
      "Epoch 7, Loss: 0.04636310786008835\n",
      "Epoch 3, Loss: 0.21980750560760498\n",
      "Epoch 3, Loss: 0.15812529623508453\n",
      "Epoch 6, Loss: 0.13810831308364868\n",
      "Epoch 7, Loss: 0.12978723645210266\n",
      "Epoch 6, Loss: 0.10803282260894775\n",
      "Epoch 4, Loss: 0.40387260913848877\n",
      "Epoch 5, Loss: 0.4628603160381317\n",
      "Epoch 5, Loss: 0.2668713331222534\n",
      "Epoch 6, Loss: 0.5367627143859863\n",
      "Epoch 3, Loss: 0.16123700141906738\n",
      "Epoch 8, Loss: 0.09020446985960007\n",
      "Epoch 3, Loss: 0.3651372790336609\n",
      "Epoch 7, Loss: 0.03838971629738808\n",
      "Epoch 7, Loss: 0.03551894426345825\n",
      "Epoch 8, Loss: 0.0583970807492733\n",
      "Epoch 6, Loss: 0.20759032666683197\n",
      "Epoch 6, Loss: 0.2690806984901428\n",
      "Epoch 4, Loss: 0.336386114358902\n",
      "Epoch 4, Loss: 0.3506159782409668\n",
      "Epoch 5, Loss: 0.2603902220726013\n",
      "Epoch 7, Loss: 0.4015275239944458\n",
      "Epoch 9, Loss: 0.13342463970184326\n",
      "Epoch 4, Loss: 0.5334159135818481\n",
      "Epoch 8, Loss: 0.007998139597475529\n",
      "Epoch 8, Loss: 0.009783902205526829\n",
      "Epoch 9, Loss: 0.0208269190043211\n",
      "Epoch 4, Loss: 0.4744863212108612\n",
      "Epoch 7, Loss: 0.1046576201915741\n",
      "Epoch 7, Loss: 0.07735402882099152\n",
      "Epoch 6, Loss: 0.08966965228319168\n",
      "Epoch 10, Loss: 0.1318352073431015\n",
      "Epoch 8, Loss: 0.2295781970024109\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=8, lr=0.0004918700384025091, num_heads=4, num_layers=3; total time=   1.0s\n",
      "Epoch 9, Loss: 0.049077510833740234\n",
      "Epoch 5, Loss: 0.31925928592681885\n",
      "Epoch 9, Loss: 0.03257463499903679\n",
      "Epoch 5, Loss: 0.3308509886264801\n",
      "Epoch 10, Loss: 0.03848908096551895\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=8, lr=0.0004918700384025091, num_heads=4, num_layers=3; total time=   1.1s\n",
      "Epoch 5, Loss: 0.6785638332366943\n",
      "Epoch 10, Loss: 0.0807407945394516\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=8, lr=0.0004918700384025091, num_heads=4, num_layers=3; total time=   1.1s\n",
      "Epoch 8, Loss: 0.03784637525677681\n",
      "Epoch 9, Loss: 0.09668195247650146\n",
      "Epoch 8, Loss: 0.008654201403260231\n",
      "Epoch 5, Loss: 0.29374486207962036\n",
      "Epoch 7, Loss: 0.014713876880705357\n",
      "Epoch 6, Loss: 0.21656514704227448\n",
      "Epoch 6, Loss: 0.19451428949832916\n",
      "Epoch 10, Loss: 0.057124022394418716\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=8, lr=0.0004918700384025091, num_heads=4, num_layers=3; total time=   1.2s\n",
      "Epoch 6, Loss: 0.5545676946640015\n",
      "Epoch 10, Loss: 0.033349547535181046\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=8, lr=0.0004918700384025091, num_heads=4, num_layers=3; total time=   1.2s\n",
      "Epoch 9, Loss: 0.06384003907442093\n",
      "Epoch 8, Loss: 0.03633144497871399\n",
      "Epoch 9, Loss: 0.03635645657777786\n",
      "Epoch 6, Loss: 0.10668882727622986\n",
      "Epoch 7, Loss: 0.07966156303882599\n",
      "Epoch 7, Loss: 0.3337370455265045\n",
      "Epoch 7, Loss: 0.10200472176074982\n",
      "Epoch 10, Loss: 0.1251734346151352\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=8, lr=0.0004918700384025091, num_heads=4, num_layers=3; total time=   1.3s\n",
      "Epoch 9, Loss: 0.09168302267789841\n",
      "Epoch 10, Loss: 0.09407452493906021\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=8, lr=0.0004918700384025091, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Epoch 8, Loss: 0.02945965714752674\n",
      "Epoch 7, Loss: 0.034377917647361755\n",
      "Epoch 8, Loss: 0.037243038415908813\n",
      "Epoch 10, Loss: 0.12728501856327057\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=8, lr=0.0004918700384025091, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Epoch 8, Loss: 0.14675647020339966\n",
      "Epoch 9, Loss: 0.04259287565946579\n",
      "Epoch 9, Loss: 0.03225230425596237\n",
      "Epoch 8, Loss: 0.06682834774255753\n",
      "Epoch 9, Loss: 0.05934751778841019\n",
      "Epoch 10, Loss: 0.08331605046987534\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=8, lr=0.0004918700384025091, num_heads=4, num_layers=3; total time=   1.6s\n",
      "Epoch 10, Loss: 0.06398807466030121\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=8, lr=0.0004918700384025091, num_heads=4, num_layers=3; total time=   1.6s\n",
      "Epoch 9, Loss: 0.13169339299201965\n",
      "Epoch 10, Loss: 0.06420250236988068\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=8, lr=0.0004918700384025091, num_heads=4, num_layers=3; total time=   1.6s\n",
      "Epoch 10, Loss: 0.16224728524684906\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=8, lr=0.0004918700384025091, num_heads=4, num_layers=3; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.17897173762321472\n",
      "Epoch 1, Loss: 0.9555855393409729\n",
      "Epoch 1, Loss: 1.6961274147033691\n",
      "Epoch 1, Loss: 0.15404747426509857\n",
      "Epoch 2, Loss: 9.13549518585205\n",
      "Epoch 1, Loss: 0.29041752219200134\n",
      "Epoch 1, Loss: 0.2372637540102005\n",
      "Epoch 2, Loss: 9.2548189163208\n",
      "Epoch 2, Loss: 7.960031509399414\n",
      "Epoch 1, Loss: 0.08608797937631607\n",
      "Epoch 1, Loss: 0.46674206852912903\n",
      "Epoch 3, Loss: 1.1927825212478638\n",
      "Epoch 2, Loss: 8.707350730895996\n",
      "Epoch 3, Loss: 1.886744737625122\n",
      "Epoch 2, Loss: 11.881795883178711\n",
      "Epoch 1, Loss: 0.10987643152475357\n",
      "Epoch 1, Loss: 0.2651447057723999\n",
      "Epoch 3, Loss: 1.9895178079605103\n",
      "Epoch 2, Loss: 11.247851371765137\n",
      "Epoch 1, Loss: 0.064440056681633\n",
      "Epoch 2, Loss: 8.726729393005371\n",
      "Epoch 4, Loss: 0.09024016559123993\n",
      "Epoch 4, Loss: 0.7387120127677917\n",
      "Epoch 3, Loss: 1.1826274394989014\n",
      "Epoch 2, Loss: 12.119529724121094\n",
      "Epoch 3, Loss: 2.170736074447632\n",
      "Epoch 1, Loss: 0.151579812169075\n",
      "Epoch 4, Loss: 0.06358519941568375\n",
      "Epoch 2, Loss: 18.849153518676758\n",
      "Epoch 5, Loss: 0.8436906337738037\n",
      "Epoch 3, Loss: 0.6960057616233826\n",
      "Epoch 5, Loss: 0.7677310705184937\n",
      "Epoch 4, Loss: 0.5170105695724487\n",
      "Epoch 2, Loss: 10.34852409362793\n",
      "Epoch 4, Loss: 0.3597492277622223\n",
      "Epoch 2, Loss: 11.498438835144043\n",
      "Epoch 3, Loss: 1.8035287857055664\n",
      "Epoch 3, Loss: 1.6512742042541504\n",
      "Epoch 6, Loss: 0.31099966168403625\n",
      "Epoch 2, Loss: 11.443387031555176\n",
      "Epoch 5, Loss: 0.8059096336364746\n",
      "Epoch 5, Loss: 0.6126894950866699\n",
      "Epoch 6, Loss: 0.6491336226463318\n",
      "Epoch 4, Loss: 2.728219509124756\n",
      "Epoch 7, Loss: 0.0743989571928978\n",
      "Epoch 3, Loss: 5.029306411743164\n",
      "Epoch 4, Loss: 0.6815881133079529\n",
      "Epoch 6, Loss: 0.5848803520202637\n",
      "Epoch 5, Loss: 0.8861604332923889\n",
      "Epoch 3, Loss: 2.4302265644073486\n",
      "Epoch 7, Loss: 0.24900345504283905\n",
      "Epoch 3, Loss: 2.748023748397827\n",
      "Epoch 6, Loss: 0.3307127356529236\n",
      "Epoch 4, Loss: 0.17914897203445435\n",
      "Epoch 8, Loss: 0.09950213134288788\n",
      "Epoch 3, Loss: 0.8217810988426208\n",
      "Epoch 9, Loss: 0.1760444939136505\n",
      "Epoch 5, Loss: 1.066521167755127\n",
      "Epoch 7, Loss: 0.2278466373682022\n",
      "Epoch 5, Loss: 1.0001229047775269\n",
      "Epoch 6, Loss: 0.32418784499168396\n",
      "Epoch 8, Loss: 0.06696467846632004\n",
      "Epoch 4, Loss: 0.06289965659379959\n",
      "Epoch 4, Loss: 0.06295590847730637\n",
      "Epoch 5, Loss: 0.8712164759635925\n",
      "Epoch 4, Loss: 1.6986945867538452\n",
      "Epoch 7, Loss: 0.0707816630601883\n",
      "Epoch 10, Loss: 0.1857927292585373\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17041194054058628, feed_forward_dim=512, head_dim=16, lr=0.004999999999999999, num_heads=2, num_layers=1; total time=   0.9s\n",
      "Epoch 8, Loss: 0.06221581995487213\n",
      "Epoch 6, Loss: 0.1427488923072815\n",
      "Epoch 4, Loss: 0.07238996028900146\n",
      "Epoch 6, Loss: 0.3802368640899658\n",
      "Epoch 7, Loss: 0.057787735015153885\n",
      "Epoch 9, Loss: 0.11393339931964874\n",
      "Epoch 5, Loss: 1.2767478227615356\n",
      "Epoch 8, Loss: 0.09164606034755707\n",
      "Epoch 6, Loss: 0.5628520250320435\n",
      "Epoch 5, Loss: 1.022462248802185\n",
      "Epoch 9, Loss: 0.10512787103652954\n",
      "Epoch 5, Loss: 0.8975600600242615\n",
      "Epoch 10, Loss: 0.20367008447647095\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17041194054058628, feed_forward_dim=512, head_dim=16, lr=0.004999999999999999, num_heads=2, num_layers=1; total time=   1.0s\n",
      "Epoch 7, Loss: 0.07018647342920303\n",
      "Epoch 7, Loss: 0.08767039328813553\n",
      "Epoch 8, Loss: 0.11304742842912674\n",
      "Epoch 5, Loss: 0.7082325220108032\n",
      "Epoch 6, Loss: 1.0815478563308716\n",
      "Epoch 9, Loss: 0.17929060757160187\n",
      "Epoch 10, Loss: 0.16648685932159424\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17041194054058628, feed_forward_dim=512, head_dim=16, lr=0.004999999999999999, num_heads=2, num_layers=1; total time=   1.1s\n",
      "Epoch 7, Loss: 0.1927175521850586\n",
      "Epoch 8, Loss: 0.08948182314634323\n",
      "Epoch 8, Loss: 0.23554515838623047\n",
      "Epoch 9, Loss: 0.18369561433792114\n",
      "Epoch 6, Loss: 0.25176098942756653\n",
      "Epoch 10, Loss: 0.19130292534828186\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17041194054058628, feed_forward_dim=512, head_dim=16, lr=0.004999999999999999, num_heads=2, num_layers=1; total time=   1.1s\n",
      "Epoch 7, Loss: 0.3901442885398865\n",
      "Epoch 8, Loss: 0.053990740329027176\n",
      "Epoch 6, Loss: 0.48441869020462036\n",
      "Epoch 6, Loss: 0.5789744853973389\n",
      "Epoch 10, Loss: 0.1560819000005722\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17041194054058628, feed_forward_dim=512, head_dim=16, lr=0.004999999999999999, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 9, Loss: 0.18338832259178162\n",
      "Epoch 9, Loss: 0.22837409377098083\n",
      "Epoch 7, Loss: 0.05664798244833946\n",
      "Epoch 8, Loss: 0.06597216427326202\n",
      "Epoch 9, Loss: 0.08272234350442886\n",
      "Epoch 10, Loss: 0.18680457770824432\n",
      "Epoch 7, Loss: 0.18615812063217163\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17041194054058628, feed_forward_dim=512, head_dim=16, lr=0.004999999999999999, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 10, Loss: 0.12708911299705505\n",
      "Epoch 7, Loss: 0.15976674854755402\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17041194054058628, feed_forward_dim=512, head_dim=16, lr=0.004999999999999999, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 8, Loss: 0.14926104247570038\n",
      "Epoch 10, Loss: 0.13947910070419312\n",
      "Epoch 9, Loss: 0.12990792095661163\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17041194054058628, feed_forward_dim=512, head_dim=16, lr=0.004999999999999999, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 8, Loss: 0.056214019656181335\n",
      "Epoch 8, Loss: 0.05746089294552803\n",
      "Epoch 9, Loss: 0.20889654755592346\n",
      "Epoch 10, Loss: 0.2557825744152069\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17041194054058628, feed_forward_dim=512, head_dim=16, lr=0.004999999999999999, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 9, Loss: 0.09302174299955368\n",
      "Epoch 9, Loss: 0.11138038337230682\n",
      "Epoch 10, Loss: 0.1655583530664444\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17041194054058628, feed_forward_dim=512, head_dim=16, lr=0.004999999999999999, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 10, Loss: 0.14104916155338287\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17041194054058628, feed_forward_dim=512, head_dim=16, lr=0.004999999999999999, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.15265682339668274\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17041194054058628, feed_forward_dim=512, head_dim=16, lr=0.004999999999999999, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.5013628602027893\n",
      "Epoch 1, Loss: 0.020239025354385376\n",
      "Epoch 1, Loss: 0.9926155805587769\n",
      "Epoch 2, Loss: 0.2865281403064728\n",
      "Epoch 1, Loss: 1.349588394165039\n",
      "Epoch 1, Loss: 0.18518216907978058\n",
      "Epoch 1, Loss: 0.22791920602321625\n",
      "Epoch 2, Loss: 0.40265244245529175\n",
      "Epoch 1, Loss: 1.0931257009506226\n",
      "Epoch 3, Loss: 0.34432661533355713\n",
      "Epoch 2, Loss: 0.12190651148557663\n",
      "Epoch 1, Loss: 0.11852319538593292\n",
      "Epoch 3, Loss: 0.025175459682941437\n",
      "Epoch 2, Loss: 0.3355100750923157\n",
      "Epoch 1, Loss: 0.6083707809448242\n",
      "Epoch 2, Loss: 0.08090678602457047\n",
      "Epoch 1, Loss: 1.9382538795471191\n",
      "Epoch 4, Loss: 0.16649441421031952\n",
      "Epoch 2, Loss: 0.11959698796272278\n",
      "Epoch 2, Loss: 0.16440758109092712\n",
      "Epoch 1, Loss: 0.21384753286838531\n",
      "Epoch 4, Loss: 0.12021420150995255\n",
      "Epoch 3, Loss: 0.2746058702468872\n",
      "Epoch 1, Loss: 0.4781036078929901\n",
      "Epoch 3, Loss: 0.13550668954849243\n",
      "Epoch 3, Loss: 0.1454271525144577\n",
      "Epoch 2, Loss: 0.011019367724657059\n",
      "Epoch 2, Loss: 0.2898300290107727\n",
      "Epoch 2, Loss: 0.3363642990589142\n",
      "Epoch 5, Loss: 0.06159014254808426\n",
      "Epoch 5, Loss: 0.20649991929531097\n",
      "Epoch 4, Loss: 0.4225787818431854\n",
      "Epoch 3, Loss: 0.1649964600801468\n",
      "Epoch 3, Loss: 0.13211975991725922\n",
      "Epoch 4, Loss: 0.0668424516916275\n",
      "Epoch 4, Loss: 0.40889641642570496\n",
      "Epoch 3, Loss: 0.27470555901527405\n",
      "Epoch 2, Loss: 0.08189190179109573\n",
      "Epoch 6, Loss: 0.11011113226413727\n",
      "Epoch 6, Loss: 0.09024009853601456\n",
      "Epoch 3, Loss: 0.06607189029455185\n",
      "Epoch 3, Loss: 0.09736417979001999\n",
      "Epoch 2, Loss: 0.123094342648983\n",
      "Epoch 5, Loss: 0.4188562333583832\n",
      "Epoch 5, Loss: 0.33163684606552124\n",
      "Epoch 4, Loss: 0.3279015123844147\n",
      "Epoch 4, Loss: 0.03830988332629204\n",
      "Epoch 5, Loss: 0.12378209829330444\n",
      "Epoch 7, Loss: 0.1295827031135559\n",
      "Epoch 7, Loss: 0.019258972257375717\n",
      "Epoch 4, Loss: 0.28378069400787354\n",
      "Epoch 3, Loss: 0.3031628131866455\n",
      "Epoch 4, Loss: 0.04848029837012291\n",
      "Epoch 6, Loss: 0.28180015087127686\n",
      "Epoch 6, Loss: 0.17414629459381104\n",
      "Epoch 4, Loss: 0.3980984687805176\n",
      "Epoch 8, Loss: 0.10594440251588821\n",
      "Epoch 5, Loss: 0.014096611179411411\n",
      "Epoch 8, Loss: 0.014155799522995949\n",
      "Epoch 5, Loss: 0.3624010682106018\n",
      "Epoch 6, Loss: 0.11208213120698929\n",
      "Epoch 3, Loss: 0.15445153415203094\n",
      "Epoch 5, Loss: 0.12666727602481842\n",
      "Epoch 7, Loss: 0.12675747275352478\n",
      "Epoch 9, Loss: 0.049028314650058746\n",
      "Epoch 7, Loss: 0.06422113627195358\n",
      "Epoch 5, Loss: 0.11721455305814743\n",
      "Epoch 6, Loss: 0.066706582903862\n",
      "Epoch 8, Loss: 0.033546581864356995\n",
      "Epoch 5, Loss: 0.5432383418083191\n",
      "Epoch 4, Loss: 0.17748808860778809\n",
      "Epoch 9, Loss: 0.05795367807149887\n",
      "Epoch 8, Loss: 0.04381612315773964\n",
      "Epoch 6, Loss: 0.26929035782814026\n",
      "Epoch 7, Loss: 0.04947453737258911\n",
      "Epoch 6, Loss: 0.01868910901248455\n",
      "Epoch 10, Loss: 0.013991194777190685\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3581182397196627, feed_forward_dim=512, head_dim=16, lr=0.000495823136270293, num_heads=8, num_layers=1; total time=   1.0s\n",
      "Epoch 4, Loss: 0.054882925003767014\n",
      "Epoch 9, Loss: 0.01446698047220707\n",
      "Epoch 6, Loss: 0.10422993451356888\n",
      "Epoch 10, Loss: 0.08547727763652802\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3581182397196627, feed_forward_dim=512, head_dim=16, lr=0.000495823136270293, num_heads=8, num_layers=1; total time=   1.0s\n",
      "Epoch 7, Loss: 0.07988985627889633\n",
      "Epoch 6, Loss: 0.4492790400981903\n",
      "Epoch 7, Loss: 0.1543504297733307\n",
      "Epoch 8, Loss: 0.019796550273895264\n",
      "Epoch 9, Loss: 0.0815206989645958\n",
      "Epoch 5, Loss: 0.03618122637271881\n",
      "Epoch 10, Loss: 0.04840776324272156\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3581182397196627, feed_forward_dim=512, head_dim=16, lr=0.000495823136270293, num_heads=8, num_layers=1; total time=   1.1s\n",
      "Epoch 7, Loss: 0.024732787162065506\n",
      "Epoch 7, Loss: 0.04250345751643181\n",
      "Epoch 5, Loss: 0.020359091460704803\n",
      "Epoch 10, Loss: 0.1252209097146988\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3581182397196627, feed_forward_dim=512, head_dim=16, lr=0.000495823136270293, num_heads=8, num_layers=1; total time=   1.1s\n",
      "Epoch 9, Loss: 0.04145177826285362\n",
      "Epoch 7, Loss: 0.2714897692203522\n",
      "Epoch 8, Loss: 0.06967969238758087\n",
      "Epoch 8, Loss: 0.0419914610683918\n",
      "Epoch 6, Loss: 0.03398677706718445\n",
      "Epoch 6, Loss: 0.052890531718730927\n",
      "Epoch 10, Loss: 0.0627986267209053\n",
      "Epoch 8, Loss: 0.08485164493322372\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3581182397196627, feed_forward_dim=512, head_dim=16, lr=0.000495823136270293, num_heads=8, num_layers=1; total time=   1.2s\n",
      "Epoch 8, Loss: 0.018652746453881264\n",
      "Epoch 8, Loss: 0.1145055741071701\n",
      "Epoch 9, Loss: 0.03830738738179207\n",
      "Epoch 9, Loss: 0.011101868934929371\n",
      "Epoch 7, Loss: 0.09980786591768265\n",
      "Epoch 9, Loss: 0.03717813268303871\n",
      "Epoch 9, Loss: 0.11934955418109894\n",
      "Epoch 7, Loss: 0.06789585947990417\n",
      "Epoch 10, Loss: 0.05043499544262886\n",
      "Epoch 9, Loss: 0.03157881274819374\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3581182397196627, feed_forward_dim=512, head_dim=16, lr=0.000495823136270293, num_heads=8, num_layers=1; total time=   1.3s\n",
      "Epoch 10, Loss: 0.012002559378743172\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3581182397196627, feed_forward_dim=512, head_dim=16, lr=0.000495823136270293, num_heads=8, num_layers=1; total time=   1.4s\n",
      "Epoch 10, Loss: 0.05711555480957031\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3581182397196627, feed_forward_dim=512, head_dim=16, lr=0.000495823136270293, num_heads=8, num_layers=1; total time=   1.4s\n",
      "Epoch 8, Loss: 0.12440858781337738\n",
      "Epoch 8, Loss: 0.043069854378700256\n",
      "Epoch 10, Loss: 0.02296779304742813\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3581182397196627, feed_forward_dim=512, head_dim=16, lr=0.000495823136270293, num_heads=8, num_layers=1; total time=   1.4s\n",
      "Epoch 10, Loss: 0.10256964713335037\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3581182397196627, feed_forward_dim=512, head_dim=16, lr=0.000495823136270293, num_heads=8, num_layers=1; total time=   1.4s\n",
      "Epoch 9, Loss: 0.09152882546186447\n",
      "Epoch 9, Loss: 0.01621571183204651\n",
      "Epoch 10, Loss: 0.04112245887517929\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3581182397196627, feed_forward_dim=512, head_dim=16, lr=0.000495823136270293, num_heads=8, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.01144507434219122\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3581182397196627, feed_forward_dim=512, head_dim=16, lr=0.000495823136270293, num_heads=8, num_layers=1; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.07280903309583664\n",
      "Epoch 1, Loss: 2.8435487747192383\n",
      "Epoch 1, Loss: 0.10914157330989838\n",
      "Epoch 2, Loss: 0.038657791912555695\n",
      "Epoch 1, Loss: 3.2651212215423584\n",
      "Epoch 2, Loss: 1.6021685600280762\n",
      "Epoch 1, Loss: 0.1049761027097702\n",
      "Epoch 1, Loss: 0.5327731370925903\n",
      "Epoch 3, Loss: 0.03790365159511566\n",
      "Epoch 2, Loss: 0.09980855882167816\n",
      "Epoch 1, Loss: 0.4925868511199951\n",
      "Epoch 1, Loss: 2.335969924926758\n",
      "Epoch 2, Loss: 1.7878347635269165\n",
      "Epoch 1, Loss: 0.12335827201604843\n",
      "Epoch 4, Loss: 0.015063509345054626\n",
      "Epoch 3, Loss: 0.7461445331573486\n",
      "Epoch 2, Loss: 0.15796899795532227\n",
      "Epoch 1, Loss: 1.2917534112930298\n",
      "Epoch 3, Loss: 0.08086632192134857\n",
      "Epoch 2, Loss: 0.1068674847483635\n",
      "Epoch 1, Loss: 0.3055652379989624\n",
      "Epoch 2, Loss: 0.17212022840976715\n",
      "Epoch 4, Loss: 0.2836918234825134\n",
      "Epoch 5, Loss: 0.02750171720981598\n",
      "Epoch 1, Loss: 0.8422825932502747\n",
      "Epoch 3, Loss: 0.04592832177877426\n",
      "Epoch 2, Loss: 1.2155755758285522\n",
      "Epoch 4, Loss: 0.041764821857213974\n",
      "Epoch 3, Loss: 0.7520275115966797\n",
      "Epoch 3, Loss: 0.08451716601848602\n",
      "Epoch 2, Loss: 0.12471272051334381\n",
      "Epoch 2, Loss: 0.5023308396339417\n",
      "Epoch 5, Loss: 0.13233493268489838\n",
      "Epoch 6, Loss: 0.016674280166625977\n",
      "Epoch 5, Loss: 0.03736528754234314\n",
      "Epoch 3, Loss: 0.13991746306419373\n",
      "Epoch 3, Loss: 0.49184370040893555\n",
      "Epoch 4, Loss: 0.19288963079452515\n",
      "Epoch 2, Loss: 0.19041775166988373\n",
      "Epoch 4, Loss: 0.09940963983535767\n",
      "Epoch 2, Loss: 0.04071944206953049\n",
      "Epoch 4, Loss: 0.02400786429643631\n",
      "Epoch 6, Loss: 0.1923265904188156\n",
      "Epoch 7, Loss: 0.020403651520609856\n",
      "Epoch 6, Loss: 0.04230679199099541\n",
      "Epoch 4, Loss: 0.20459629595279694\n",
      "Epoch 3, Loss: 0.1706211417913437\n",
      "Epoch 3, Loss: 0.05947725474834442\n",
      "Epoch 5, Loss: 0.16398070752620697\n",
      "Epoch 5, Loss: 0.042190246284008026\n",
      "Epoch 7, Loss: 0.32708725333213806\n",
      "Epoch 3, Loss: 0.07612593472003937\n",
      "Epoch 8, Loss: 0.025358542799949646\n",
      "Epoch 4, Loss: 0.1337510198354721\n",
      "Epoch 5, Loss: 0.03703303262591362\n",
      "Epoch 3, Loss: 0.14640584588050842\n",
      "Epoch 7, Loss: 0.029172277078032494\n",
      "Epoch 9, Loss: 0.017377136275172234\n",
      "Epoch 8, Loss: 0.4333550035953522\n",
      "Epoch 6, Loss: 0.14918585121631622\n",
      "Epoch 5, Loss: 0.21061062812805176\n",
      "Epoch 6, Loss: 0.05766577273607254\n",
      "Epoch 6, Loss: 0.17056715488433838\n",
      "Epoch 8, Loss: 0.013184587471187115\n",
      "Epoch 4, Loss: 0.20359356701374054\n",
      "Epoch 4, Loss: 0.167254239320755\n",
      "Epoch 5, Loss: 0.07720161974430084\n",
      "Epoch 10, Loss: 0.01578357256948948\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.30408984040783593, feed_forward_dim=128, head_dim=32, lr=0.0002666569940523827, num_heads=8, num_layers=1; total time=   0.9s\n",
      "Epoch 7, Loss: 0.3286106288433075\n",
      "Epoch 4, Loss: 0.22406692802906036\n",
      "Epoch 4, Loss: 0.07553684711456299\n",
      "Epoch 9, Loss: 0.4711476266384125\n",
      "Epoch 9, Loss: 0.013044596649706364\n",
      "Epoch 6, Loss: 0.16676917672157288\n",
      "Epoch 7, Loss: 0.0388612374663353\n",
      "Epoch 7, Loss: 0.13301540911197662\n",
      "Epoch 5, Loss: 0.3374581038951874\n",
      "Epoch 6, Loss: 0.1922442764043808\n",
      "Epoch 8, Loss: 0.4551982581615448\n",
      "Epoch 10, Loss: 0.019228551536798477\n",
      "Epoch 10, Loss: 0.43752312660217285\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.30408984040783593, feed_forward_dim=128, head_dim=32, lr=0.0002666569940523827, num_heads=8, num_layers=1; total time=   1.0s\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.30408984040783593, feed_forward_dim=128, head_dim=32, lr=0.0002666569940523827, num_heads=8, num_layers=1; total time=   1.0s\n",
      "Epoch 5, Loss: 0.0910310223698616\n",
      "Epoch 5, Loss: 0.30632665753364563\n",
      "Epoch 8, Loss: 0.01530526950955391\n",
      "Epoch 7, Loss: 0.10499022901058197\n",
      "Epoch 5, Loss: 0.04309390112757683\n",
      "Epoch 9, Loss: 0.49074187874794006\n",
      "Epoch 6, Loss: 0.3905908763408661\n",
      "Epoch 8, Loss: 0.08359954506158829\n",
      "Epoch 7, Loss: 0.3354848623275757\n",
      "Epoch 9, Loss: 0.017524734139442444\n",
      "Epoch 6, Loss: 0.2605540454387665\n",
      "Epoch 8, Loss: 0.06298787891864777\n",
      "Epoch 10, Loss: 0.4516584873199463\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.30408984040783593, feed_forward_dim=128, head_dim=32, lr=0.0002666569940523827, num_heads=8, num_layers=1; total time=   1.1s\n",
      "Epoch 6, Loss: 0.022335980087518692\n",
      "Epoch 6, Loss: 0.029555723071098328\n",
      "Epoch 9, Loss: 0.044193368405103683\n",
      "Epoch 7, Loss: 0.3432193100452423\n",
      "Epoch 10, Loss: 0.031746286898851395\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.30408984040783593, feed_forward_dim=128, head_dim=32, lr=0.0002666569940523827, num_heads=8, num_layers=1; total time=   1.2s\n",
      "Epoch 9, Loss: 0.04987906664609909\n",
      "Epoch 7, Loss: 0.16332228481769562\n",
      "Epoch 8, Loss: 0.408986896276474\n",
      "Epoch 10, Loss: 0.0268691573292017\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.30408984040783593, feed_forward_dim=128, head_dim=32, lr=0.0002666569940523827, num_heads=8, num_layers=1; total time=   1.2s\n",
      "Epoch 7, Loss: 0.031497396528720856\n",
      "Epoch 7, Loss: 0.024594884365797043\n",
      "Epoch 8, Loss: 0.24524377286434174\n",
      "Epoch 10, Loss: 0.05990856885910034\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.30408984040783593, feed_forward_dim=128, head_dim=32, lr=0.0002666569940523827, num_heads=8, num_layers=1; total time=   1.3s\n",
      "Epoch 9, Loss: 0.40485262870788574\n",
      "Epoch 8, Loss: 0.07119432091712952\n",
      "Epoch 8, Loss: 0.029557714238762856\n",
      "Epoch 8, Loss: 0.05633743107318878\n",
      "Epoch 9, Loss: 0.15176938474178314\n",
      "Epoch 10, Loss: 0.3464733362197876\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.30408984040783593, feed_forward_dim=128, head_dim=32, lr=0.0002666569940523827, num_heads=8, num_layers=1; total time=   1.4s\n",
      "Epoch 9, Loss: 0.027314113453030586\n",
      "Epoch 9, Loss: 0.015413036569952965\n",
      "Epoch 9, Loss: 0.07443227618932724\n",
      "Epoch 10, Loss: 0.08747339993715286\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.30408984040783593, feed_forward_dim=128, head_dim=32, lr=0.0002666569940523827, num_heads=8, num_layers=1; total time=   1.4s\n",
      "Epoch 10, Loss: 0.015338494442403316\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.30408984040783593, feed_forward_dim=128, head_dim=32, lr=0.0002666569940523827, num_heads=8, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.03387638181447983\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.30408984040783593, feed_forward_dim=128, head_dim=32, lr=0.0002666569940523827, num_heads=8, num_layers=1; total time=   1.4s\n",
      "Epoch 10, Loss: 0.059448543936014175\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.30408984040783593, feed_forward_dim=128, head_dim=32, lr=0.0002666569940523827, num_heads=8, num_layers=1; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 1.037635087966919\n",
      "Epoch 1, Loss: 0.07667350023984909\n",
      "Epoch 1, Loss: 0.11498285084962845\n",
      "Epoch 2, Loss: 0.41197359561920166\n",
      "Epoch 1, Loss: 1.2967031002044678\n",
      "Epoch 1, Loss: 0.49639666080474854\n",
      "Epoch 1, Loss: 1.4938308000564575\n",
      "Epoch 2, Loss: 0.13991449773311615\n",
      "Epoch 3, Loss: 0.12103865295648575\n",
      "Epoch 1, Loss: 0.15964898467063904\n",
      "Epoch 1, Loss: 0.2778668999671936\n",
      "Epoch 2, Loss: 0.04764293506741524\n",
      "Epoch 2, Loss: 0.46019819378852844\n",
      "Epoch 1, Loss: 0.040084537118673325\n",
      "Epoch 2, Loss: 0.06143806129693985\n",
      "Epoch 2, Loss: 0.5388650298118591\n",
      "Epoch 4, Loss: 0.09899867326021194\n",
      "Epoch 3, Loss: 0.03864254429936409\n",
      "Epoch 1, Loss: 1.4440885782241821\n",
      "Epoch 1, Loss: 0.42482659220695496\n",
      "Epoch 2, Loss: 0.1392756998538971\n",
      "Epoch 3, Loss: 0.08913347125053406\n",
      "Epoch 1, Loss: 0.5979333519935608\n",
      "Epoch 2, Loss: 0.11367505043745041\n",
      "Epoch 3, Loss: 0.15056423842906952\n",
      "Epoch 3, Loss: 0.06257858872413635\n",
      "Epoch 5, Loss: 0.1942022293806076\n",
      "Epoch 3, Loss: 0.11513110250234604\n",
      "Epoch 4, Loss: 0.05428634211421013\n",
      "Epoch 2, Loss: 0.11306195706129074\n",
      "Epoch 2, Loss: 0.05200314521789551\n",
      "Epoch 3, Loss: 0.11044971644878387\n",
      "Epoch 4, Loss: 0.045949384570121765\n",
      "Epoch 3, Loss: 0.19328588247299194\n",
      "Epoch 6, Loss: 0.27206143736839294\n",
      "Epoch 4, Loss: 0.22677282989025116\n",
      "Epoch 2, Loss: 0.10446896404027939\n",
      "Epoch 5, Loss: 0.06308676302433014\n",
      "Epoch 2, Loss: 0.5920451283454895\n",
      "Epoch 4, Loss: 0.12923750281333923\n",
      "Epoch 4, Loss: 0.18778187036514282\n",
      "Epoch 5, Loss: 0.013154487125575542\n",
      "Epoch 4, Loss: 0.05537834018468857\n",
      "Epoch 7, Loss: 0.2729501724243164\n",
      "Epoch 5, Loss: 0.37515565752983093\n",
      "Epoch 3, Loss: 0.04784039407968521\n",
      "Epoch 6, Loss: 0.027708599343895912\n",
      "Epoch 3, Loss: 0.026568859815597534\n",
      "Epoch 4, Loss: 0.14938266575336456\n",
      "Epoch 6, Loss: 0.02755524031817913\n",
      "Epoch 5, Loss: 0.29994839429855347\n",
      "Epoch 6, Loss: 0.3950653076171875\n",
      "Epoch 5, Loss: 0.18551000952720642\n",
      "Epoch 3, Loss: 0.1290373057126999\n",
      "Epoch 7, Loss: 0.008957384154200554\n",
      "Epoch 8, Loss: 0.22471509873867035\n",
      "Epoch 3, Loss: 0.06498663872480392\n",
      "Epoch 5, Loss: 0.05197400227189064\n",
      "Epoch 7, Loss: 0.04446927085518837\n",
      "Epoch 4, Loss: 0.14799931645393372\n",
      "Epoch 4, Loss: 0.030605953186750412\n",
      "Epoch 9, Loss: 0.15306226909160614\n",
      "Epoch 5, Loss: 0.07842161506414413\n",
      "Epoch 6, Loss: 0.3972219228744507\n",
      "Epoch 8, Loss: 0.024310816079378128\n",
      "Epoch 6, Loss: 0.11257357895374298\n",
      "Epoch 7, Loss: 0.31946033239364624\n",
      "Epoch 6, Loss: 0.05806589871644974\n",
      "Epoch 8, Loss: 0.03306977078318596\n",
      "Epoch 4, Loss: 0.011611584573984146\n",
      "Epoch 4, Loss: 0.188458651304245\n",
      "Epoch 10, Loss: 0.0948382169008255\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00026619783054756944, num_heads=8, num_layers=1; total time=   1.0s\n",
      "Epoch 5, Loss: 0.16759704053401947\n",
      "Epoch 6, Loss: 0.0590219646692276\n",
      "Epoch 8, Loss: 0.20465435087680817\n",
      "Epoch 9, Loss: 0.03404548764228821\n",
      "Epoch 7, Loss: 0.37759482860565186\n",
      "Epoch 7, Loss: 0.03949274495244026\n",
      "Epoch 5, Loss: 0.0553259514272213\n",
      "Epoch 9, Loss: 0.012014709413051605\n",
      "Epoch 7, Loss: 0.04037122055888176\n",
      "Epoch 10, Loss: 0.02246973291039467\n",
      "Epoch 9, Loss: 0.10987858474254608\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00026619783054756944, num_heads=8, num_layers=1; total time=   1.1s\n",
      "Epoch 8, Loss: 0.011240988969802856\n",
      "Epoch 5, Loss: 0.11107917129993439\n",
      "Epoch 5, Loss: 0.22401922941207886\n",
      "Epoch 6, Loss: 0.11825182288885117\n",
      "Epoch 7, Loss: 0.07826340198516846\n",
      "Epoch 6, Loss: 0.029407557100057602\n",
      "Epoch 10, Loss: 0.006927327252924442\n",
      "Epoch 8, Loss: 0.281664103269577\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00026619783054756944, num_heads=8, num_layers=1; total time=   1.2s\n",
      "Epoch 10, Loss: 0.05402427539229393\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00026619783054756944, num_heads=8, num_layers=1; total time=   1.2s\n",
      "Epoch 9, Loss: 0.026566412299871445\n",
      "Epoch 8, Loss: 0.0186456385999918\n",
      "Epoch 8, Loss: 0.08707181364297867\n",
      "Epoch 7, Loss: 0.054852213710546494\n",
      "Epoch 9, Loss: 0.17019549012184143\n",
      "Epoch 7, Loss: 0.005746579263359308\n",
      "Epoch 10, Loss: 0.056910932064056396\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00026619783054756944, num_heads=8, num_layers=1; total time=   1.3s\n",
      "Epoch 6, Loss: 0.2450973391532898\n",
      "Epoch 6, Loss: 0.1635747104883194\n",
      "Epoch 9, Loss: 0.018999911844730377\n",
      "Epoch 9, Loss: 0.06624351441860199\n",
      "Epoch 8, Loss: 0.015602675266563892\n",
      "Epoch 10, Loss: 0.08274092525243759\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00026619783054756944, num_heads=8, num_layers=1; total time=   1.4s\n",
      "Epoch 7, Loss: 0.3051568567752838\n",
      "Epoch 8, Loss: 0.013587091118097305\n",
      "Epoch 10, Loss: 0.029032934457063675\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00026619783054756944, num_heads=8, num_layers=1; total time=   1.4s\n",
      "Epoch 10, Loss: 0.03617987409234047\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00026619783054756944, num_heads=8, num_layers=1; total time=   1.4s\n",
      "Epoch 9, Loss: 0.009707323275506496\n",
      "Epoch 7, Loss: 0.07868150621652603\n",
      "Epoch 9, Loss: 0.028154803439974785\n",
      "Epoch 8, Loss: 0.2831755578517914\n",
      "Epoch 10, Loss: 0.03009699657559395\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00026619783054756944, num_heads=8, num_layers=1; total time=   1.6s\n",
      "Epoch 8, Loss: 0.02215469628572464\n",
      "Epoch 10, Loss: 0.02402154542505741\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00026619783054756944, num_heads=8, num_layers=1; total time=   1.6s\n",
      "Epoch 9, Loss: 0.2167503982782364\n",
      "Epoch 9, Loss: 0.011660914868116379\n",
      "Epoch 10, Loss: 0.13493873178958893\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00026619783054756944, num_heads=8, num_layers=1; total time=   1.7s\n",
      "Epoch 10, Loss: 0.034545838832855225\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00026619783054756944, num_heads=8, num_layers=1; total time=   1.8s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.5535289645195007\n",
      "Epoch 1, Loss: 0.45936110615730286\n",
      "Epoch 1, Loss: 0.05163685977458954\n",
      "Epoch 2, Loss: 0.26943376660346985\n",
      "Epoch 2, Loss: 0.1825999766588211\n",
      "Epoch 1, Loss: 0.36689454317092896\n",
      "Epoch 1, Loss: 0.04473791643977165\n",
      "Epoch 1, Loss: 0.18184621632099152\n",
      "Epoch 1, Loss: 2.041455030441284\n",
      "Epoch 2, Loss: 0.041996631771326065\n",
      "Epoch 1, Loss: 0.5200827717781067\n",
      "Epoch 3, Loss: 0.1284516453742981\n",
      "Epoch 1, Loss: 1.0799421072006226\n",
      "Epoch 1, Loss: 1.4750969409942627\n",
      "Epoch 2, Loss: 0.09513355046510696\n",
      "Epoch 2, Loss: 0.04583263769745827\n",
      "Epoch 3, Loss: 0.08022116124629974\n",
      "Epoch 1, Loss: 0.38444653153419495\n",
      "Epoch 2, Loss: 0.051634781062603\n",
      "Epoch 3, Loss: 0.02700400911271572\n",
      "Epoch 4, Loss: 0.10883788019418716\n",
      "Epoch 2, Loss: 1.2740386724472046\n",
      "Epoch 1, Loss: 1.5932787656784058\n",
      "Epoch 3, Loss: 0.020354624837636948\n",
      "Epoch 2, Loss: 0.21534571051597595\n",
      "Epoch 5, Loss: 0.14782704412937164\n",
      "Epoch 4, Loss: 0.10061900317668915\n",
      "Epoch 2, Loss: 0.8221873641014099\n",
      "Epoch 4, Loss: 0.0218184981495142\n",
      "Epoch 3, Loss: 0.08273503929376602\n",
      "Epoch 3, Loss: 0.007562357001006603\n",
      "Epoch 2, Loss: 0.49243295192718506\n",
      "Epoch 2, Loss: 0.08642897754907608\n",
      "Epoch 3, Loss: 0.6981022357940674\n",
      "Epoch 6, Loss: 0.17957204580307007\n",
      "Epoch 5, Loss: 0.15016289055347443\n",
      "Epoch 4, Loss: 0.026809079572558403\n",
      "Epoch 5, Loss: 0.011343239806592464\n",
      "Epoch 2, Loss: 0.9183038473129272\n",
      "Epoch 4, Loss: 0.0571989081799984\n",
      "Epoch 3, Loss: 0.08055346459150314\n",
      "Epoch 3, Loss: 0.3721338212490082\n",
      "Epoch 4, Loss: 0.10092780739068985\n",
      "Epoch 3, Loss: 0.1686658263206482\n",
      "Epoch 7, Loss: 0.17280030250549316\n",
      "Epoch 4, Loss: 0.3215850293636322\n",
      "Epoch 3, Loss: 0.015822043642401695\n",
      "Epoch 6, Loss: 0.16576208174228668\n",
      "Epoch 5, Loss: 0.01725853979587555\n",
      "Epoch 6, Loss: 0.010630115866661072\n",
      "Epoch 5, Loss: 0.11773750931024551\n",
      "Epoch 8, Loss: 0.14455284178256989\n",
      "Epoch 3, Loss: 0.44842979311943054\n",
      "Epoch 4, Loss: 0.11844883114099503\n",
      "Epoch 5, Loss: 0.07119607925415039\n",
      "Epoch 7, Loss: 0.008173862472176552\n",
      "Epoch 7, Loss: 0.14321757853031158\n",
      "Epoch 4, Loss: 0.0823083147406578\n",
      "Epoch 6, Loss: 0.008718148805201054\n",
      "Epoch 5, Loss: 0.12408596277236938\n",
      "Epoch 4, Loss: 0.09267516434192657\n",
      "Epoch 9, Loss: 0.10300082713365555\n",
      "Epoch 6, Loss: 0.1211528331041336\n",
      "Epoch 4, Loss: 0.08164676278829575\n",
      "Epoch 8, Loss: 0.0054053012281656265\n",
      "Epoch 5, Loss: 0.13835948705673218\n",
      "Epoch 8, Loss: 0.10495441406965256\n",
      "Epoch 7, Loss: 0.012921804562211037\n",
      "Epoch 4, Loss: 0.17126795649528503\n",
      "Epoch 5, Loss: 0.03233852982521057\n",
      "Epoch 6, Loss: 0.07768028229475021\n",
      "Epoch 6, Loss: 0.03563561290502548\n",
      "Epoch 10, Loss: 0.06886092573404312\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=512, head_dim=16, lr=0.00017789149929057165, num_heads=8, num_layers=2; total time=   1.0s\n",
      "Epoch 7, Loss: 0.08504492044448853\n",
      "Epoch 9, Loss: 0.0070610083639621735\n",
      "Epoch 9, Loss: 0.06455402821302414\n",
      "Epoch 5, Loss: 0.13495665788650513\n",
      "Epoch 6, Loss: 0.17243319749832153\n",
      "Epoch 8, Loss: 0.01351886335760355\n",
      "Epoch 5, Loss: 0.16422335803508759\n",
      "Epoch 7, Loss: 0.021276425570249557\n",
      "Epoch 7, Loss: 0.12580376863479614\n",
      "Epoch 10, Loss: 0.008004000410437584\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=512, head_dim=16, lr=0.00017789149929057165, num_heads=8, num_layers=2; total time=   1.1s\n",
      "Epoch 8, Loss: 0.040657009929418564\n",
      "Epoch 5, Loss: 0.06484635174274445\n",
      "Epoch 10, Loss: 0.03597606346011162\n",
      "Epoch 6, Loss: 0.06505245715379715\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=512, head_dim=16, lr=0.00017789149929057165, num_heads=8, num_layers=2; total time=   1.1s\n",
      "Epoch 9, Loss: 0.010104821063578129\n",
      "Epoch 6, Loss: 0.12398438155651093\n",
      "Epoch 9, Loss: 0.013384480029344559\n",
      "Epoch 8, Loss: 0.2122138887643814\n",
      "Epoch 7, Loss: 0.16107062995433807\n",
      "Epoch 8, Loss: 0.02915845438838005\n",
      "Epoch 6, Loss: 0.25469568371772766\n",
      "Epoch 6, Loss: 0.08961419761180878\n",
      "Epoch 10, Loss: 0.009078397415578365\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=512, head_dim=16, lr=0.00017789149929057165, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 7, Loss: 0.15240098536014557\n",
      "Epoch 10, Loss: 0.007265494205057621\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=512, head_dim=16, lr=0.00017789149929057165, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 9, Loss: 0.04045925661921501\n",
      "Epoch 7, Loss: 0.07807003706693649\n",
      "Epoch 9, Loss: 0.2906178832054138\n",
      "Epoch 7, Loss: 0.2967316210269928\n",
      "Epoch 8, Loss: 0.12240287661552429\n",
      "Epoch 7, Loss: 0.17115822434425354\n",
      "Epoch 10, Loss: 0.04050712287425995\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=512, head_dim=16, lr=0.00017789149929057165, num_heads=8, num_layers=2; total time=   1.4s\n",
      "Epoch 8, Loss: 0.23401586711406708\n",
      "Epoch 10, Loss: 0.3293483555316925\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=512, head_dim=16, lr=0.00017789149929057165, num_heads=8, num_layers=2; total time=   1.4s\n",
      "Epoch 8, Loss: 0.2766033113002777\n",
      "Epoch 8, Loss: 0.032865218818187714\n",
      "Epoch 9, Loss: 0.07911829650402069\n",
      "Epoch 8, Loss: 0.25194329023361206\n",
      "Epoch 9, Loss: 0.276613712310791\n",
      "Epoch 9, Loss: 0.22145365178585052\n",
      "Epoch 9, Loss: 0.008131596259772778\n",
      "Epoch 10, Loss: 0.04718022048473358\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=512, head_dim=16, lr=0.00017789149929057165, num_heads=8, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 0.29918843507766724\n",
      "Epoch 10, Loss: 0.269085556268692\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=512, head_dim=16, lr=0.00017789149929057165, num_heads=8, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.15443634986877441\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=512, head_dim=16, lr=0.00017789149929057165, num_heads=8, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.009650161489844322\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=512, head_dim=16, lr=0.00017789149929057165, num_heads=8, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.2955939769744873\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=512, head_dim=16, lr=0.00017789149929057165, num_heads=8, num_layers=2; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.16626642644405365\n",
      "Epoch 1, Loss: 0.038086019456386566\n",
      "Epoch 1, Loss: 0.6859847903251648\n",
      "Epoch 1, Loss: 0.2877257168292999\n",
      "Epoch 1, Loss: 0.15985803306102753\n",
      "Epoch 2, Loss: 0.10556095838546753\n",
      "Epoch 1, Loss: 1.7536735534667969\n",
      "Epoch 1, Loss: 2.3165078163146973\n",
      "Epoch 2, Loss: 0.1433979719877243\n",
      "Epoch 2, Loss: 0.015518411062657833\n",
      "Epoch 2, Loss: 0.38253965973854065\n",
      "Epoch 1, Loss: 0.31365981698036194\n",
      "Epoch 3, Loss: 0.07504025101661682\n",
      "Epoch 1, Loss: 0.22814896702766418\n",
      "Epoch 2, Loss: 0.13561123609542847\n",
      "Epoch 2, Loss: 0.34977400302886963\n",
      "Epoch 1, Loss: 0.3812776207923889\n",
      "Epoch 3, Loss: 0.06572646647691727\n",
      "Epoch 2, Loss: 0.9114366173744202\n",
      "Epoch 1, Loss: 1.3619519472122192\n",
      "Epoch 4, Loss: 0.03168654069304466\n",
      "Epoch 1, Loss: 0.0520990751683712\n",
      "Epoch 3, Loss: 0.12213113903999329\n",
      "Epoch 3, Loss: 0.2681196928024292\n",
      "Epoch 4, Loss: 0.11270193010568619\n",
      "Epoch 2, Loss: 0.07376187294721603\n",
      "Epoch 2, Loss: 0.08901270478963852\n",
      "Epoch 3, Loss: 0.18860287964344025\n",
      "Epoch 2, Loss: 0.2279675006866455\n",
      "Epoch 3, Loss: 0.11487400531768799\n",
      "Epoch 4, Loss: 0.3262193500995636\n",
      "Epoch 5, Loss: 0.024471521377563477\n",
      "Epoch 2, Loss: 0.16134171187877655\n",
      "Epoch 3, Loss: 0.22097574174404144\n",
      "Epoch 4, Loss: 0.039647843688726425\n",
      "Epoch 2, Loss: 0.36115074157714844\n",
      "Epoch 5, Loss: 0.021309390664100647\n",
      "Epoch 6, Loss: 0.03467726334929466\n",
      "Epoch 3, Loss: 0.16053542494773865\n",
      "Epoch 4, Loss: 0.07275383919477463\n",
      "Epoch 3, Loss: 0.21707592904567719\n",
      "Epoch 4, Loss: 0.07803373038768768\n",
      "Epoch 5, Loss: 0.17453308403491974\n",
      "Epoch 4, Loss: 0.4078541100025177\n",
      "Epoch 5, Loss: 0.13436859846115112\n",
      "Epoch 3, Loss: 0.2331964522600174\n",
      "Epoch 6, Loss: 0.02912158891558647\n",
      "Epoch 7, Loss: 0.01210743561387062\n",
      "Epoch 5, Loss: 0.2596171796321869\n",
      "Epoch 3, Loss: 0.24261681735515594\n",
      "Epoch 3, Loss: 0.05903403088450432\n",
      "Epoch 4, Loss: 0.07507599890232086\n",
      "Epoch 7, Loss: 0.06671522557735443\n",
      "Epoch 5, Loss: 0.5507723689079285\n",
      "Epoch 5, Loss: 0.012630406767129898\n",
      "Epoch 6, Loss: 0.12686499953269958\n",
      "Epoch 8, Loss: 0.023295996710658073\n",
      "Epoch 6, Loss: 0.04433254152536392\n",
      "Epoch 8, Loss: 0.042053788900375366\n",
      "Epoch 4, Loss: 0.47029048204421997\n",
      "Epoch 6, Loss: 0.41952255368232727\n",
      "Epoch 4, Loss: 0.05338640883564949\n",
      "Epoch 5, Loss: 0.017550310119986534\n",
      "Epoch 6, Loss: 0.4771982431411743\n",
      "Epoch 7, Loss: 0.017756059765815735\n",
      "Epoch 4, Loss: 0.1206139400601387\n",
      "Epoch 6, Loss: 0.06576595455408096\n",
      "Epoch 4, Loss: 0.15037935972213745\n",
      "Epoch 7, Loss: 0.447299599647522\n",
      "Epoch 9, Loss: 0.028388336300849915\n",
      "Epoch 7, Loss: 0.0444120317697525\n",
      "Epoch 5, Loss: 0.4592851996421814\n",
      "Epoch 8, Loss: 0.06541028618812561\n",
      "Epoch 9, Loss: 0.011749060824513435\n",
      "Epoch 10, Loss: 0.014962523244321346\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0004367638733052606, num_heads=4, num_layers=1; total time=   1.5s\n",
      "Epoch 5, Loss: 0.028036030009388924\n",
      "Epoch 7, Loss: 0.30683279037475586\n",
      "Epoch 7, Loss: 0.10221811383962631\n",
      "Epoch 8, Loss: 0.37950316071510315\n",
      "Epoch 5, Loss: 0.16110524535179138\n",
      "Epoch 9, Loss: 0.11545867472887039\n",
      "Epoch 5, Loss: 0.05792493373155594\n",
      "Epoch 8, Loss: 0.0068648383021354675\n",
      "Epoch 10, Loss: 0.01647677831351757\n",
      "Epoch 6, Loss: 0.040400028228759766\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0004367638733052606, num_heads=4, num_layers=1; total time=   1.6s\n",
      "Epoch 6, Loss: 0.295082688331604\n",
      "Epoch 8, Loss: 0.07071147859096527\n",
      "Epoch 8, Loss: 0.14943084120750427\n",
      "Epoch 6, Loss: 0.03600737079977989\n",
      "Epoch 10, Loss: 0.12327692657709122\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0004367638733052606, num_heads=4, num_layers=1; total time=   1.7s\n",
      "Epoch 9, Loss: 0.2714971601963043\n",
      "Epoch 6, Loss: 0.11949370801448822\n",
      "Epoch 6, Loss: 0.05109228938817978\n",
      "Epoch 9, Loss: 0.03411409258842468\n",
      "Epoch 7, Loss: 0.0709121897816658\n",
      "Epoch 9, Loss: 0.023200340569019318\n",
      "Epoch 7, Loss: 0.12723137438297272\n",
      "Epoch 10, Loss: 0.1638982892036438\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0004367638733052606, num_heads=4, num_layers=1; total time=   1.8s\n",
      "Epoch 9, Loss: 0.06046823039650917\n",
      "Epoch 7, Loss: 0.08429063856601715\n",
      "Epoch 10, Loss: 0.06766311079263687\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0004367638733052606, num_heads=4, num_layers=1; total time=   1.9s\n",
      "Epoch 7, Loss: 0.03373919054865837\n",
      "Epoch 8, Loss: 0.05595612898468971\n",
      "Epoch 10, Loss: 0.007382236421108246\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0004367638733052606, num_heads=4, num_layers=1; total time=   1.9s\n",
      "Epoch 7, Loss: 0.08810535073280334\n",
      "Epoch 10, Loss: 0.04325050488114357\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0004367638733052606, num_heads=4, num_layers=1; total time=   1.9s\n",
      "Epoch 8, Loss: 0.08909658342599869\n",
      "Epoch 9, Loss: 0.02173006534576416\n",
      "Epoch 8, Loss: 0.040579408407211304\n",
      "Epoch 8, Loss: 0.09267504513263702\n",
      "Epoch 8, Loss: 0.009153702296316624\n",
      "Epoch 9, Loss: 0.05155687406659126\n",
      "Epoch 10, Loss: 0.005215178243815899\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0004367638733052606, num_heads=4, num_layers=1; total time=   2.1s\n",
      "Epoch 9, Loss: 0.04296315833926201\n",
      "Epoch 9, Loss: 0.05758839473128319\n",
      "Epoch 9, Loss: 0.04319646582007408\n",
      "Epoch 10, Loss: 0.015928957611322403\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0004367638733052606, num_heads=4, num_layers=1; total time=   2.2s\n",
      "Epoch 10, Loss: 0.022420069202780724\n",
      "Epoch 10, Loss: 0.08943624049425125\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0004367638733052606, num_heads=4, num_layers=1; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0004367638733052606, num_heads=4, num_layers=1; total time=   2.1s\n",
      "Epoch 10, Loss: 0.07205258309841156\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0004367638733052606, num_heads=4, num_layers=1; total time=   2.2s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.03179074823856354\n",
      "Epoch 1, Loss: 0.7249543070793152\n",
      "Epoch 1, Loss: 1.2920386791229248\n",
      "Epoch 1, Loss: 0.3145253658294678\n",
      "Epoch 2, Loss: 0.16855385899543762\n",
      "Epoch 1, Loss: 0.9593662023544312\n",
      "Epoch 2, Loss: 0.02044741064310074\n",
      "Epoch 1, Loss: 1.1468931436538696\n",
      "Epoch 1, Loss: 0.029975205659866333\n",
      "Epoch 3, Loss: 0.011703915894031525\n",
      "Epoch 2, Loss: 0.10541870445013046\n",
      "Epoch 1, Loss: 0.06601711362600327\n",
      "Epoch 2, Loss: 0.18234482407569885\n",
      "Epoch 1, Loss: 1.694334626197815\n",
      "Epoch 3, Loss: 0.23467010259628296\n",
      "Epoch 1, Loss: 0.07446150481700897\n",
      "Epoch 2, Loss: 0.06695468723773956\n",
      "Epoch 4, Loss: 0.12756474316120148\n",
      "Epoch 2, Loss: 0.19727197289466858\n",
      "Epoch 1, Loss: 3.4887032508850098\n",
      "Epoch 3, Loss: 0.1733814924955368\n",
      "Epoch 1, Loss: 0.1596725732088089\n",
      "Epoch 2, Loss: 0.42959725856781006\n",
      "Epoch 2, Loss: 0.4307709038257599\n",
      "Epoch 3, Loss: 0.2221488058567047\n",
      "Epoch 4, Loss: 0.3396041989326477\n",
      "Epoch 5, Loss: 0.07545577734708786\n",
      "Epoch 2, Loss: 0.3425881862640381\n",
      "Epoch 3, Loss: 0.13515403866767883\n",
      "Epoch 2, Loss: 0.3985435664653778\n",
      "Epoch 3, Loss: 0.2812080681324005\n",
      "Epoch 5, Loss: 0.22389644384384155\n",
      "Epoch 4, Loss: 0.07451633363962173\n",
      "Epoch 4, Loss: 0.4502508342266083\n",
      "Epoch 3, Loss: 0.04887434095144272\n",
      "Epoch 2, Loss: 1.3600231409072876\n",
      "Epoch 2, Loss: 0.19085681438446045\n",
      "Epoch 6, Loss: 0.008611309342086315\n",
      "Epoch 3, Loss: 0.06950003653764725\n",
      "Epoch 4, Loss: 0.35305556654930115\n",
      "Epoch 6, Loss: 0.0794750452041626\n",
      "Epoch 5, Loss: 0.40255266427993774\n",
      "Epoch 5, Loss: 0.02763461135327816\n",
      "Epoch 3, Loss: 0.07040903717279434\n",
      "Epoch 3, Loss: 0.05304193124175072\n",
      "Epoch 4, Loss: 0.4488878548145294\n",
      "Epoch 7, Loss: 0.031175147742033005\n",
      "Epoch 4, Loss: 0.06192195788025856\n",
      "Epoch 3, Loss: 0.2711784541606903\n",
      "Epoch 4, Loss: 0.06910238415002823\n",
      "Epoch 7, Loss: 0.014389928430318832\n",
      "Epoch 5, Loss: 0.32254812121391296\n",
      "Epoch 6, Loss: 0.21561680734157562\n",
      "Epoch 6, Loss: 0.083544060587883\n",
      "Epoch 3, Loss: 0.12021084874868393\n",
      "Epoch 8, Loss: 0.06544391810894012\n",
      "Epoch 5, Loss: 0.3641195595264435\n",
      "Epoch 4, Loss: 0.04777155816555023\n",
      "Epoch 4, Loss: 0.2394864708185196\n",
      "Epoch 8, Loss: 0.03924756497144699\n",
      "Epoch 7, Loss: 0.0649661049246788\n",
      "Epoch 9, Loss: 0.052535273134708405\n",
      "Epoch 7, Loss: 0.09717217087745667\n",
      "Epoch 6, Loss: 0.18424688279628754\n",
      "Epoch 5, Loss: 0.1862710416316986\n",
      "Epoch 5, Loss: 0.1965869665145874\n",
      "Epoch 4, Loss: 0.09185045957565308\n",
      "Epoch 10, Loss: 0.016237497329711914\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0004368366500887769, num_heads=4, num_layers=1; total time=   1.1s\n",
      "Epoch 6, Loss: 0.19012218713760376\n",
      "Epoch 4, Loss: 0.02078641951084137\n",
      "Epoch 9, Loss: 0.09659403562545776\n",
      "Epoch 8, Loss: 0.04811170697212219\n",
      "Epoch 8, Loss: 0.013527605682611465\n",
      "Epoch 5, Loss: 0.15096326172351837\n",
      "Epoch 7, Loss: 0.05611743777990341\n",
      "Epoch 5, Loss: 0.4180595874786377\n",
      "Epoch 6, Loss: 0.14139220118522644\n",
      "Epoch 10, Loss: 0.12568646669387817\n",
      "Epoch 6, Loss: 0.13448646664619446\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0004368366500887769, num_heads=4, num_layers=1; total time=   1.2s\n",
      "Epoch 7, Loss: 0.06389407068490982\n",
      "Epoch 5, Loss: 0.3608754575252533\n",
      "Epoch 9, Loss: 0.00859341211616993\n",
      "Epoch 9, Loss: 0.0465955026447773\n",
      "Epoch 8, Loss: 0.008316680788993835\n",
      "Epoch 5, Loss: 0.048615701496601105\n",
      "Epoch 7, Loss: 0.04478393867611885\n",
      "Epoch 6, Loss: 0.10928283631801605\n",
      "Epoch 6, Loss: 0.4321611821651459\n",
      "Epoch 8, Loss: 0.03297054395079613\n",
      "Epoch 10, Loss: 0.016994014382362366\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0004368366500887769, num_heads=4, num_layers=1; total time=   1.3s\n",
      "Epoch 7, Loss: 0.030873769894242287\n",
      "Epoch 10, Loss: 0.10765676200389862\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0004368366500887769, num_heads=4, num_layers=1; total time=   1.3s\n",
      "Epoch 6, Loss: 0.5881415009498596\n",
      "Epoch 8, Loss: 0.005234230775386095\n",
      "Epoch 9, Loss: 0.03173532336950302\n",
      "Epoch 6, Loss: 0.08100094646215439\n",
      "Epoch 7, Loss: 0.33155393600463867\n",
      "Epoch 9, Loss: 0.06970421969890594\n",
      "Epoch 7, Loss: 0.026047464460134506\n",
      "Epoch 7, Loss: 0.6241143345832825\n",
      "Epoch 9, Loss: 0.03080219216644764\n",
      "Epoch 10, Loss: 0.07987260818481445\n",
      "Epoch 8, Loss: 0.0104207843542099\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0004368366500887769, num_heads=4, num_layers=1; total time=   1.5s\n",
      "Epoch 7, Loss: 0.047165513038635254\n",
      "Epoch 10, Loss: 0.1161440759897232\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0004368366500887769, num_heads=4, num_layers=1; total time=   1.5s\n",
      "Epoch 8, Loss: 0.19894003868103027\n",
      "Epoch 8, Loss: 0.010126017034053802\n",
      "Epoch 10, Loss: 0.06763724237680435\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0004368366500887769, num_heads=4, num_layers=1; total time=   1.6s\n",
      "Epoch 8, Loss: 0.5266134738922119\n",
      "Epoch 9, Loss: 0.057798270136117935\n",
      "Epoch 9, Loss: 0.09504922479391098\n",
      "Epoch 8, Loss: 0.010333334095776081\n",
      "Epoch 9, Loss: 0.04752526059746742\n",
      "Epoch 10, Loss: 0.08773951232433319\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0004368366500887769, num_heads=4, num_layers=1; total time=   1.8s\n",
      "Epoch 9, Loss: 0.37703049182891846\n",
      "Epoch 10, Loss: 0.03644049912691116\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0004368366500887769, num_heads=4, num_layers=1; total time=   1.8s\n",
      "Epoch 9, Loss: 0.014991204254329205\n",
      "Epoch 10, Loss: 0.07004386186599731\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0004368366500887769, num_heads=4, num_layers=1; total time=   1.9s\n",
      "Epoch 10, Loss: 0.23197674751281738\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0004368366500887769, num_heads=4, num_layers=1; total time=   1.9s\n",
      "Epoch 10, Loss: 0.03871674835681915\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0004368366500887769, num_heads=4, num_layers=1; total time=   1.9s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.8854162096977234\n",
      "Epoch 1, Loss: 0.6043781042098999\n",
      "Epoch 1, Loss: 1.2661110162734985\n",
      "Epoch 1, Loss: 1.0667201280593872\n",
      "Epoch 2, Loss: 0.04488472267985344\n",
      "Epoch 1, Loss: 0.1559486985206604\n",
      "Epoch 1, Loss: 0.12192164361476898\n",
      "Epoch 2, Loss: 0.05381174758076668\n",
      "Epoch 2, Loss: 0.34455427527427673\n",
      "Epoch 1, Loss: 0.3820948004722595\n",
      "Epoch 3, Loss: 0.170684814453125\n",
      "Epoch 2, Loss: 0.07509095966815948\n",
      "Epoch 3, Loss: 0.21482814848423004\n",
      "Epoch 2, Loss: 0.26522019505500793\n",
      "Epoch 2, Loss: 0.258012056350708\n",
      "Epoch 1, Loss: 0.19220532476902008\n",
      "Epoch 1, Loss: 0.07224579155445099\n",
      "Epoch 1, Loss: 0.03433101251721382\n",
      "Epoch 3, Loss: 0.2973287105560303\n",
      "Epoch 4, Loss: 0.3551862835884094\n",
      "Epoch 3, Loss: 0.13646890223026276\n",
      "Epoch 1, Loss: 0.4993634819984436\n",
      "Epoch 4, Loss: 0.2878798842430115\n",
      "Epoch 2, Loss: 0.07558990269899368\n",
      "Epoch 1, Loss: 1.779466986656189\n",
      "Epoch 5, Loss: 0.2944144606590271\n",
      "Epoch 3, Loss: 0.09611264616250992\n",
      "Epoch 4, Loss: 0.461603045463562\n",
      "Epoch 2, Loss: 0.21518965065479279\n",
      "Epoch 2, Loss: 0.24273580312728882\n",
      "Epoch 4, Loss: 0.3789103627204895\n",
      "Epoch 2, Loss: 0.010829572565853596\n",
      "Epoch 3, Loss: 0.04922180995345116\n",
      "Epoch 5, Loss: 0.1903093159198761\n",
      "Epoch 3, Loss: 0.23654647171497345\n",
      "Epoch 5, Loss: 0.4334038496017456\n",
      "Epoch 6, Loss: 0.13893629610538483\n",
      "Epoch 4, Loss: 0.06309503316879272\n",
      "Epoch 2, Loss: 0.4063154458999634\n",
      "Epoch 5, Loss: 0.3637864887714386\n",
      "Epoch 2, Loss: 0.21953490376472473\n",
      "Epoch 3, Loss: 0.21093888580799103\n",
      "Epoch 3, Loss: 0.05749852582812309\n",
      "Epoch 6, Loss: 0.06323903053998947\n",
      "Epoch 7, Loss: 0.031008509919047356\n",
      "Epoch 4, Loss: 0.08215987682342529\n",
      "Epoch 4, Loss: 0.17685483396053314\n",
      "Epoch 3, Loss: 0.12995842099189758\n",
      "Epoch 5, Loss: 0.0966743603348732\n",
      "Epoch 6, Loss: 0.2897965908050537\n",
      "Epoch 6, Loss: 0.21382863819599152\n",
      "Epoch 3, Loss: 0.3434359133243561\n",
      "Epoch 8, Loss: 0.010239829309284687\n",
      "Epoch 7, Loss: 0.01574876718223095\n",
      "Epoch 4, Loss: 0.052098412066698074\n",
      "Epoch 5, Loss: 0.11968174576759338\n",
      "Epoch 4, Loss: 0.013265429064631462\n",
      "Epoch 3, Loss: 0.10130622237920761\n",
      "Epoch 6, Loss: 0.06899278610944748\n",
      "Epoch 7, Loss: 0.15210239589214325\n",
      "Epoch 5, Loss: 0.05996287986636162\n",
      "Epoch 4, Loss: 0.0331437885761261\n",
      "Epoch 7, Loss: 0.07507476210594177\n",
      "Epoch 9, Loss: 0.05087234824895859\n",
      "Epoch 8, Loss: 0.04490973800420761\n",
      "Epoch 6, Loss: 0.050271812826395035\n",
      "Epoch 7, Loss: 0.02314119040966034\n",
      "Epoch 8, Loss: 0.07819845527410507\n",
      "Epoch 5, Loss: 0.10193027555942535\n",
      "Epoch 5, Loss: 0.11662596464157104\n",
      "Epoch 6, Loss: 0.02487454190850258\n",
      "Epoch 4, Loss: 0.19139672815799713\n",
      "Epoch 10, Loss: 0.10071878135204315\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3060342873113327, feed_forward_dim=128, head_dim=8, lr=0.0004010876424123401, num_heads=4, num_layers=3; total time=   1.1s\n",
      "Epoch 4, Loss: 0.32889240980148315\n",
      "Epoch 8, Loss: 0.014013909734785557\n",
      "Epoch 5, Loss: 0.07566705346107483\n",
      "Epoch 9, Loss: 0.0933288186788559\n",
      "Epoch 9, Loss: 0.0704098492860794\n",
      "Epoch 7, Loss: 0.011668380349874496\n",
      "Epoch 8, Loss: 0.01911378651857376\n",
      "Epoch 6, Loss: 0.06922917813062668\n",
      "Epoch 6, Loss: 0.12247449904680252\n",
      "Epoch 7, Loss: 0.06529288738965988\n",
      "Epoch 10, Loss: 0.10790950804948807\n",
      "Epoch 9, Loss: 0.03085116669535637\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3060342873113327, feed_forward_dim=128, head_dim=8, lr=0.0004010876424123401, num_heads=4, num_layers=3; total time=   1.2s\n",
      "Epoch 10, Loss: 0.09713603556156158\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3060342873113327, feed_forward_dim=128, head_dim=8, lr=0.0004010876424123401, num_heads=4, num_layers=3; total time=   1.2s\n",
      "Epoch 5, Loss: 0.06186404824256897\n",
      "Epoch 6, Loss: 0.09012305736541748\n",
      "Epoch 5, Loss: 0.4906724989414215\n",
      "Epoch 8, Loss: 0.03567349538207054\n",
      "Epoch 9, Loss: 0.0428195483982563\n",
      "Epoch 10, Loss: 0.08165263384580612\n",
      "Epoch 8, Loss: 0.09794758260250092\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3060342873113327, feed_forward_dim=128, head_dim=8, lr=0.0004010876424123401, num_heads=4, num_layers=3; total time=   1.3s\n",
      "Epoch 7, Loss: 0.023396896198391914\n",
      "Epoch 7, Loss: 0.035923734307289124\n",
      "Epoch 7, Loss: 0.04465484246611595\n",
      "Epoch 10, Loss: 0.046466656029224396\n",
      "Epoch 6, Loss: 0.06484191864728928\n",
      "Epoch 9, Loss: 0.062193017452955246\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3060342873113327, feed_forward_dim=128, head_dim=8, lr=0.0004010876424123401, num_heads=4, num_layers=3; total time=   1.3s\n",
      "Epoch 8, Loss: 0.017409702762961388\n",
      "Epoch 6, Loss: 0.4603661298751831\n",
      "Epoch 9, Loss: 0.082465760409832\n",
      "Epoch 8, Loss: 0.007321054581552744\n",
      "Epoch 8, Loss: 0.017599331215023994\n",
      "Epoch 7, Loss: 0.11590497195720673\n",
      "Epoch 9, Loss: 0.038307394832372665\n",
      "Epoch 9, Loss: 0.0480765737593174\n",
      "Epoch 7, Loss: 0.3304019868373871\n",
      "Epoch 10, Loss: 0.05120603367686272\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3060342873113327, feed_forward_dim=128, head_dim=8, lr=0.0004010876424123401, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.040491484105587006\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3060342873113327, feed_forward_dim=128, head_dim=8, lr=0.0004010876424123401, num_heads=4, num_layers=3; total time=   1.6s\n",
      "Epoch 9, Loss: 0.03776960074901581\n",
      "Epoch 8, Loss: 0.11197259277105331\n",
      "Epoch 10, Loss: 0.04783325269818306\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3060342873113327, feed_forward_dim=128, head_dim=8, lr=0.0004010876424123401, num_heads=4, num_layers=3; total time=   1.6s\n",
      "Epoch 10, Loss: 0.06790519505739212\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3060342873113327, feed_forward_dim=128, head_dim=8, lr=0.0004010876424123401, num_heads=4, num_layers=3; total time=   1.6s\n",
      "Epoch 8, Loss: 0.19259576499462128\n",
      "Epoch 10, Loss: 0.059999752789735794\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3060342873113327, feed_forward_dim=128, head_dim=8, lr=0.0004010876424123401, num_heads=4, num_layers=3; total time=   1.6s\n",
      "Epoch 9, Loss: 0.05781009793281555\n",
      "Epoch 9, Loss: 0.08866143226623535\n",
      "Epoch 10, Loss: 0.015171041712164879\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3060342873113327, feed_forward_dim=128, head_dim=8, lr=0.0004010876424123401, num_heads=4, num_layers=3; total time=   1.7s\n",
      "Epoch 10, Loss: 0.04067184403538704\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3060342873113327, feed_forward_dim=128, head_dim=8, lr=0.0004010876424123401, num_heads=4, num_layers=3; total time=   1.8s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 2.0654609203338623\n",
      "Epoch 1, Loss: 0.1574735939502716\n",
      "Epoch 1, Loss: 2.2523367404937744\n",
      "Epoch 2, Loss: 0.48448580503463745\n",
      "Epoch 1, Loss: 0.6868850588798523\n",
      "Epoch 1, Loss: 0.09825093299150467\n",
      "Epoch 1, Loss: 0.22185437381267548\n",
      "Epoch 2, Loss: 0.07265936583280563\n",
      "Epoch 1, Loss: 0.6900041103363037\n",
      "Epoch 2, Loss: 0.41816359758377075\n",
      "Epoch 3, Loss: 0.06900432705879211\n",
      "Epoch 2, Loss: 0.172352597117424\n",
      "Epoch 2, Loss: 0.18362878262996674\n",
      "Epoch 1, Loss: 1.3289240598678589\n",
      "Epoch 1, Loss: 0.1403203010559082\n",
      "Epoch 1, Loss: 0.0768374502658844\n",
      "Epoch 2, Loss: 0.14249403774738312\n",
      "Epoch 3, Loss: 0.11471512913703918\n",
      "Epoch 1, Loss: 0.007758105639368296\n",
      "Epoch 2, Loss: 0.20748640596866608\n",
      "Epoch 1, Loss: 0.11514195799827576\n",
      "Epoch 4, Loss: 0.32771337032318115\n",
      "Epoch 3, Loss: 0.07433480769395828\n",
      "Epoch 3, Loss: 0.2942505180835724\n",
      "Epoch 3, Loss: 0.07909467071294785\n",
      "Epoch 4, Loss: 0.03193749487400055\n",
      "Epoch 2, Loss: 0.26844486594200134\n",
      "Epoch 3, Loss: 0.16313758492469788\n",
      "Epoch 2, Loss: 0.1972087025642395\n",
      "Epoch 5, Loss: 0.5338947176933289\n",
      "Epoch 4, Loss: 0.46900323033332825\n",
      "Epoch 2, Loss: 0.27333852648735046\n",
      "Epoch 3, Loss: 0.29883530735969543\n",
      "Epoch 4, Loss: 0.31599193811416626\n",
      "Epoch 2, Loss: 0.43555977940559387\n",
      "Epoch 5, Loss: 0.008805687539279461\n",
      "Epoch 6, Loss: 0.5152299404144287\n",
      "Epoch 2, Loss: 0.08205888420343399\n",
      "Epoch 4, Loss: 0.004513473249971867\n",
      "Epoch 4, Loss: 0.0523577481508255\n",
      "Epoch 5, Loss: 0.6764765977859497\n",
      "Epoch 3, Loss: 0.10034693777561188\n",
      "Epoch 5, Loss: 0.20472106337547302\n",
      "Epoch 3, Loss: 0.10802369564771652\n",
      "Epoch 6, Loss: 0.04511401802301407\n",
      "Epoch 7, Loss: 0.3702918589115143\n",
      "Epoch 3, Loss: 0.025544995442032814\n",
      "Epoch 6, Loss: 0.5817788243293762\n",
      "Epoch 5, Loss: 0.05561352148652077\n",
      "Epoch 5, Loss: 0.02175227738916874\n",
      "Epoch 3, Loss: 0.034661389887332916\n",
      "Epoch 4, Loss: 0.3301607370376587\n",
      "Epoch 7, Loss: 0.05746107175946236\n",
      "Epoch 3, Loss: 0.08910961449146271\n",
      "Epoch 4, Loss: 0.3234667181968689\n",
      "Epoch 8, Loss: 0.20429085195064545\n",
      "Epoch 6, Loss: 0.09677866101264954\n",
      "Epoch 8, Loss: 0.03263748809695244\n",
      "Epoch 7, Loss: 0.35640189051628113\n",
      "Epoch 5, Loss: 0.2285960167646408\n",
      "Epoch 6, Loss: 0.07620830833911896\n",
      "Epoch 4, Loss: 0.010889480821788311\n",
      "Epoch 4, Loss: 0.14094236493110657\n",
      "Epoch 6, Loss: 0.06709560006856918\n",
      "Epoch 9, Loss: 0.07535097002983093\n",
      "Epoch 4, Loss: 0.09963645786046982\n",
      "Epoch 9, Loss: 0.00775184715166688\n",
      "Epoch 4, Loss: 0.01989683322608471\n",
      "Epoch 8, Loss: 0.15299078822135925\n",
      "Epoch 7, Loss: 0.060636941343545914\n",
      "Epoch 5, Loss: 0.4157305955886841\n",
      "Epoch 7, Loss: 0.039022549986839294\n",
      "Epoch 6, Loss: 0.12277614325284958\n",
      "Epoch 10, Loss: 0.02203654870390892\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0004063554238745226, num_heads=8, num_layers=3; total time=   1.0s\n",
      "Epoch 10, Loss: 0.0082083810120821\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0004063554238745226, num_heads=8, num_layers=3; total time=   1.0s\n",
      "Epoch 5, Loss: 0.1458425670862198\n",
      "Epoch 9, Loss: 0.03811537101864815\n",
      "Epoch 7, Loss: 0.07306073606014252\n",
      "Epoch 8, Loss: 0.08651231229305267\n",
      "Epoch 5, Loss: 0.06102633848786354\n",
      "Epoch 6, Loss: 0.3441880941390991\n",
      "Epoch 5, Loss: 0.22475123405456543\n",
      "Epoch 10, Loss: 0.02006624825298786\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0004063554238745226, num_heads=8, num_layers=3; total time=   1.1s\n",
      "Epoch 7, Loss: 0.0700979083776474\n",
      "Epoch 8, Loss: 0.036289338022470474\n",
      "Epoch 8, Loss: 0.006905538495630026\n",
      "Epoch 5, Loss: 0.01486562192440033\n",
      "Epoch 6, Loss: 0.04573387652635574\n",
      "Epoch 9, Loss: 0.11982831358909607\n",
      "Epoch 7, Loss: 0.2089327573776245\n",
      "Epoch 9, Loss: 0.010495622642338276\n",
      "Epoch 6, Loss: 0.1545758992433548\n",
      "Epoch 8, Loss: 0.07441873103380203\n",
      "Epoch 6, Loss: 0.08799497038125992\n",
      "Epoch 6, Loss: 0.04483618214726448\n",
      "Epoch 9, Loss: 0.008496139198541641\n",
      "Epoch 10, Loss: 0.12251092493534088\n",
      "Epoch 8, Loss: 0.09788069128990173\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0004063554238745226, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 7, Loss: 0.013126553036272526\n",
      "Epoch 10, Loss: 0.03156115487217903\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0004063554238745226, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 9, Loss: 0.09902199357748032\n",
      "Epoch 7, Loss: 0.04712929576635361\n",
      "Epoch 10, Loss: 0.014460857957601547\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0004063554238745226, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Epoch 7, Loss: 0.04655345529317856\n",
      "Epoch 7, Loss: 0.04209357500076294\n",
      "Epoch 9, Loss: 0.04223303496837616\n",
      "Epoch 10, Loss: 0.10409241914749146\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0004063554238745226, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Epoch 8, Loss: 0.05804695934057236\n",
      "Epoch 8, Loss: 0.006919963750988245\n",
      "Epoch 8, Loss: 0.015727370977401733\n",
      "Epoch 8, Loss: 0.010512360371649265\n",
      "Epoch 10, Loss: 0.03915147855877876\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0004063554238745226, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 9, Loss: 0.08272786438465118\n",
      "Epoch 9, Loss: 0.03652976080775261\n",
      "Epoch 9, Loss: 0.01699545606970787\n",
      "Epoch 9, Loss: 0.0036017494276165962\n",
      "Epoch 10, Loss: 0.054672516882419586\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0004063554238745226, num_heads=8, num_layers=3; total time=   1.6s\n",
      "Epoch 10, Loss: 0.08048070222139359\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0004063554238745226, num_heads=8, num_layers=3; total time=   1.6s\n",
      "Epoch 10, Loss: 0.043424755334854126\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0004063554238745226, num_heads=8, num_layers=3; total time=   1.6s\n",
      "Epoch 10, Loss: 0.015174590982496738\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0004063554238745226, num_heads=8, num_layers=3; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.6952021718025208\n",
      "Epoch 1, Loss: 1.0423667430877686\n",
      "Epoch 1, Loss: 0.1394083946943283\n",
      "Epoch 1, Loss: 1.1067746877670288\n",
      "Epoch 2, Loss: 0.6564934849739075\n",
      "Epoch 1, Loss: 0.09335752576589584\n",
      "Epoch 2, Loss: 0.08268816769123077\n",
      "Epoch 1, Loss: 1.2925337553024292\n",
      "Epoch 1, Loss: 0.17867091298103333\n",
      "Epoch 3, Loss: 0.5277471542358398\n",
      "Epoch 2, Loss: 0.0802948921918869\n",
      "Epoch 1, Loss: 0.32694151997566223\n",
      "Epoch 2, Loss: 0.10277856141328812\n",
      "Epoch 3, Loss: 0.44862133264541626\n",
      "Epoch 4, Loss: 0.13074661791324615\n",
      "Epoch 1, Loss: 1.2189620733261108\n",
      "Epoch 2, Loss: 1.0337005853652954\n",
      "Epoch 2, Loss: 0.663068413734436\n",
      "Epoch 3, Loss: 0.18333938717842102\n",
      "Epoch 1, Loss: 2.6655826568603516\n",
      "Epoch 2, Loss: 0.08568202704191208\n",
      "Epoch 1, Loss: 0.2257777899503708\n",
      "Epoch 1, Loss: 0.29878392815589905\n",
      "Epoch 2, Loss: 1.0282196998596191\n",
      "Epoch 5, Loss: 0.08649028837680817\n",
      "Epoch 3, Loss: 0.5458564758300781\n",
      "Epoch 4, Loss: 0.3693554699420929\n",
      "Epoch 3, Loss: 0.1713998019695282\n",
      "Epoch 4, Loss: 0.025721890851855278\n",
      "Epoch 2, Loss: 0.16057339310646057\n",
      "Epoch 3, Loss: 0.14545567333698273\n",
      "Epoch 6, Loss: 0.2179233431816101\n",
      "Epoch 2, Loss: 0.4009046256542206\n",
      "Epoch 3, Loss: 0.5655571818351746\n",
      "Epoch 4, Loss: 0.3689323365688324\n",
      "Epoch 5, Loss: 0.14121200144290924\n",
      "Epoch 3, Loss: 0.2921489179134369\n",
      "Epoch 2, Loss: 0.3039117455482483\n",
      "Epoch 5, Loss: 0.06276828050613403\n",
      "Epoch 2, Loss: 0.588425874710083\n",
      "Epoch 4, Loss: 0.08929352462291718\n",
      "Epoch 7, Loss: 0.23113520443439484\n",
      "Epoch 3, Loss: 0.5880324840545654\n",
      "Epoch 5, Loss: 0.1012246385216713\n",
      "Epoch 4, Loss: 0.5024837255477905\n",
      "Epoch 4, Loss: 0.06974803656339645\n",
      "Epoch 6, Loss: 0.03434223681688309\n",
      "Epoch 3, Loss: 0.05319962650537491\n",
      "Epoch 6, Loss: 0.08028911799192429\n",
      "Epoch 4, Loss: 0.045087579637765884\n",
      "Epoch 8, Loss: 0.1253453940153122\n",
      "Epoch 5, Loss: 0.3680284321308136\n",
      "Epoch 3, Loss: 0.3804824650287628\n",
      "Epoch 6, Loss: 0.007390574086457491\n",
      "Epoch 7, Loss: 0.06115899235010147\n",
      "Epoch 3, Loss: 0.25313782691955566\n",
      "Epoch 5, Loss: 0.21450626850128174\n",
      "Epoch 5, Loss: 0.2081025093793869\n",
      "Epoch 4, Loss: 0.4209778308868408\n",
      "Epoch 9, Loss: 0.033918656408786774\n",
      "Epoch 7, Loss: 0.01719040609896183\n",
      "Epoch 8, Loss: 0.1268714964389801\n",
      "Epoch 6, Loss: 0.3179703950881958\n",
      "Epoch 7, Loss: 0.06662255525588989\n",
      "Epoch 5, Loss: 0.27279308438301086\n",
      "Epoch 4, Loss: 0.2458527386188507\n",
      "Epoch 6, Loss: 0.0465075746178627\n",
      "Epoch 10, Loss: 0.025586003437638283\n",
      "Epoch 5, Loss: 0.1274300217628479\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3531517450110653, feed_forward_dim=128, head_dim=16, lr=0.0007350002708323324, num_heads=2, num_layers=3; total time=   0.9s\n",
      "Epoch 6, Loss: 0.2051115334033966\n",
      "Epoch 4, Loss: 0.78780198097229\n",
      "Epoch 4, Loss: 0.040299031883478165\n",
      "Epoch 8, Loss: 0.017475994303822517\n",
      "Epoch 9, Loss: 0.14900735020637512\n",
      "Epoch 8, Loss: 0.1475895345211029\n",
      "Epoch 7, Loss: 0.12287753075361252\n",
      "Epoch 6, Loss: 0.3236747086048126\n",
      "Epoch 7, Loss: 0.05558861792087555\n",
      "Epoch 5, Loss: 0.10587071627378464\n",
      "Epoch 9, Loss: 0.0503629632294178\n",
      "Epoch 10, Loss: 0.12177062034606934\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3531517450110653, feed_forward_dim=128, head_dim=16, lr=0.0007350002708323324, num_heads=2, num_layers=3; total time=   1.1s\n",
      "Epoch 6, Loss: 0.019844315946102142\n",
      "Epoch 7, Loss: 0.10936156660318375\n",
      "Epoch 5, Loss: 0.7079986333847046\n",
      "Epoch 9, Loss: 0.16975700855255127\n",
      "Epoch 7, Loss: 0.17460227012634277\n",
      "Epoch 8, Loss: 0.01607670448720455\n",
      "Epoch 10, Loss: 0.03803716599941254\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3531517450110653, feed_forward_dim=128, head_dim=16, lr=0.0007350002708323324, num_heads=2, num_layers=3; total time=   1.1s\n",
      "Epoch 5, Loss: 0.1301974505186081\n",
      "Epoch 8, Loss: 0.14265719056129456\n",
      "Epoch 7, Loss: 0.09009623527526855\n",
      "Epoch 10, Loss: 0.12784089148044586\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3531517450110653, feed_forward_dim=128, head_dim=16, lr=0.0007350002708323324, num_heads=2, num_layers=3; total time=   1.2s\n",
      "Epoch 8, Loss: 0.03360492363572121\n",
      "Epoch 6, Loss: 0.007443629205226898\n",
      "Epoch 9, Loss: 0.04295877739787102\n",
      "Epoch 6, Loss: 0.41666170954704285\n",
      "Epoch 8, Loss: 0.039596572518348694\n",
      "Epoch 6, Loss: 0.19674959778785706\n",
      "Epoch 9, Loss: 0.19735661149024963\n",
      "Epoch 10, Loss: 0.11628573387861252\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3531517450110653, feed_forward_dim=128, head_dim=16, lr=0.0007350002708323324, num_heads=2, num_layers=3; total time=   1.3s\n",
      "Epoch 9, Loss: 0.027114005759358406\n",
      "Epoch 8, Loss: 0.1769351214170456\n",
      "Epoch 7, Loss: 0.16120220720767975\n",
      "Epoch 9, Loss: 0.01876031793653965\n",
      "Epoch 7, Loss: 0.06771823018789291\n",
      "Epoch 10, Loss: 0.18028590083122253\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3531517450110653, feed_forward_dim=128, head_dim=16, lr=0.0007350002708323324, num_heads=2, num_layers=3; total time=   1.4s\n",
      "Epoch 10, Loss: 0.06392347812652588\n",
      "Epoch 7, Loss: 0.1350429803133011\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3531517450110653, feed_forward_dim=128, head_dim=16, lr=0.0007350002708323324, num_heads=2, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.18464410305023193\n",
      "Epoch 8, Loss: 0.04793047159910202\n",
      "Epoch 8, Loss: 0.10965393483638763\n",
      "Epoch 10, Loss: 0.07714638859033585\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3531517450110653, feed_forward_dim=128, head_dim=16, lr=0.0007350002708323324, num_heads=2, num_layers=3; total time=   1.5s\n",
      "Epoch 8, Loss: 0.04526550695300102\n",
      "Epoch 10, Loss: 0.12558521330356598\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3531517450110653, feed_forward_dim=128, head_dim=16, lr=0.0007350002708323324, num_heads=2, num_layers=3; total time=   1.5s\n",
      "Epoch 9, Loss: 0.060518257319927216\n",
      "Epoch 9, Loss: 0.06617644429206848\n",
      "Epoch 9, Loss: 0.012410301715135574\n",
      "Epoch 10, Loss: 0.01487107202410698\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3531517450110653, feed_forward_dim=128, head_dim=16, lr=0.0007350002708323324, num_heads=2, num_layers=3; total time=   1.6s\n",
      "Epoch 10, Loss: 0.13611960411071777\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3531517450110653, feed_forward_dim=128, head_dim=16, lr=0.0007350002708323324, num_heads=2, num_layers=3; total time=   1.6s\n",
      "Epoch 10, Loss: 0.03912101686000824\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3531517450110653, feed_forward_dim=128, head_dim=16, lr=0.0007350002708323324, num_heads=2, num_layers=3; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.17262329161167145\n",
      "Epoch 1, Loss: 3.297588586807251\n",
      "Epoch 1, Loss: 0.06365707516670227\n",
      "Epoch 1, Loss: 0.19369271397590637\n",
      "Epoch 2, Loss: 0.10064693540334702\n",
      "Epoch 1, Loss: 0.06774727255105972\n",
      "Epoch 2, Loss: 1.4566881656646729\n",
      "Epoch 1, Loss: 0.07301607728004456\n",
      "Epoch 1, Loss: 0.8725630640983582\n",
      "Epoch 2, Loss: 0.2080463469028473\n",
      "Epoch 2, Loss: 0.14506390690803528\n",
      "Epoch 1, Loss: 0.8802784085273743\n",
      "Epoch 3, Loss: 0.12255948781967163\n",
      "Epoch 1, Loss: 0.12134801596403122\n",
      "Epoch 2, Loss: 0.17045024037361145\n",
      "Epoch 3, Loss: 0.3716130256652832\n",
      "Epoch 1, Loss: 0.9391283988952637\n",
      "Epoch 2, Loss: 0.2428993284702301\n",
      "Epoch 4, Loss: 0.025427015498280525\n",
      "Epoch 1, Loss: 0.44075632095336914\n",
      "Epoch 3, Loss: 0.049755290150642395\n",
      "Epoch 3, Loss: 0.13964669406414032\n",
      "Epoch 2, Loss: 0.049567773938179016\n",
      "Epoch 1, Loss: 0.6436657905578613\n",
      "Epoch 2, Loss: 0.13856525719165802\n",
      "Epoch 4, Loss: 0.008460142649710178\n",
      "Epoch 3, Loss: 0.021531464532017708\n",
      "Epoch 5, Loss: 0.020557692274451256\n",
      "Epoch 3, Loss: 0.03678432106971741\n",
      "Epoch 4, Loss: 0.04577359929680824\n",
      "Epoch 4, Loss: 0.04122525826096535\n",
      "Epoch 2, Loss: 0.2236226499080658\n",
      "Epoch 5, Loss: 0.1491774469614029\n",
      "Epoch 2, Loss: 0.2075105458498001\n",
      "Epoch 3, Loss: 0.08641860634088516\n",
      "Epoch 3, Loss: 0.17484036087989807\n",
      "Epoch 2, Loss: 0.14867596328258514\n",
      "Epoch 6, Loss: 0.060853682458400726\n",
      "Epoch 2, Loss: 0.04339342564344406\n",
      "Epoch 4, Loss: 0.10335090011358261\n",
      "Epoch 5, Loss: 0.03695646673440933\n",
      "Epoch 4, Loss: 0.08766236156225204\n",
      "Epoch 5, Loss: 0.09917628020048141\n",
      "Epoch 6, Loss: 0.4179074764251709\n",
      "Epoch 7, Loss: 0.06028369814157486\n",
      "Epoch 4, Loss: 0.26938894391059875\n",
      "Epoch 3, Loss: 0.2754526734352112\n",
      "Epoch 4, Loss: 0.34799522161483765\n",
      "Epoch 6, Loss: 0.0648302510380745\n",
      "Epoch 3, Loss: 0.20139440894126892\n",
      "Epoch 3, Loss: 0.25392597913742065\n",
      "Epoch 5, Loss: 0.06970095634460449\n",
      "Epoch 5, Loss: 0.1283310055732727\n",
      "Epoch 8, Loss: 0.026193562895059586\n",
      "Epoch 6, Loss: 0.07114552706480026\n",
      "Epoch 3, Loss: 0.08837202936410904\n",
      "Epoch 7, Loss: 0.5604057908058167\n",
      "Epoch 5, Loss: 0.31033164262771606\n",
      "Epoch 7, Loss: 0.018553953617811203\n",
      "Epoch 7, Loss: 0.05926194041967392\n",
      "Epoch 9, Loss: 0.007776308339089155\n",
      "Epoch 6, Loss: 0.06423574686050415\n",
      "Epoch 8, Loss: 0.5474967956542969\n",
      "Epoch 5, Loss: 0.2787511348724365\n",
      "Epoch 4, Loss: 0.3037396967411041\n",
      "Epoch 4, Loss: 0.39170655608177185\n",
      "Epoch 6, Loss: 0.009331580251455307\n",
      "Epoch 4, Loss: 0.03536975383758545\n",
      "Epoch 4, Loss: 0.19082078337669373\n",
      "Epoch 8, Loss: 0.021831370890140533\n",
      "Epoch 10, Loss: 0.020200032740831375\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00037768700316093124, num_heads=8, num_layers=4; total time=   0.9s\n",
      "Epoch 6, Loss: 0.23023773729801178\n",
      "Epoch 8, Loss: 0.024683600291609764\n",
      "Epoch 9, Loss: 0.43436485528945923\n",
      "Epoch 7, Loss: 0.021083898842334747\n",
      "Epoch 7, Loss: 0.015854666009545326\n",
      "Epoch 6, Loss: 0.12571914494037628\n",
      "Epoch 5, Loss: 0.1906498372554779\n",
      "Epoch 5, Loss: 0.3192911744117737\n",
      "Epoch 5, Loss: 0.07976830750703812\n",
      "Epoch 9, Loss: 0.010301470756530762\n",
      "Epoch 7, Loss: 0.11955706030130386\n",
      "Epoch 10, Loss: 0.2906384766101837\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00037768700316093124, num_heads=8, num_layers=4; total time=   1.1s\n",
      "Epoch 5, Loss: 0.09828629344701767\n",
      "Epoch 9, Loss: 0.04667288810014725\n",
      "Epoch 8, Loss: 0.053973790258169174\n",
      "Epoch 8, Loss: 0.03040926717221737\n",
      "Epoch 7, Loss: 0.027837131172418594\n",
      "Epoch 10, Loss: 0.02525310590863228\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00037768700316093124, num_heads=8, num_layers=4; total time=   1.1s\n",
      "Epoch 6, Loss: 0.05996750667691231\n",
      "Epoch 8, Loss: 0.04346979409456253\n",
      "Epoch 6, Loss: 0.07051403075456619\n",
      "Epoch 10, Loss: 0.051554955542087555\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00037768700316093124, num_heads=8, num_layers=4; total time=   1.2s\n",
      "Epoch 6, Loss: 0.16673576831817627\n",
      "Epoch 9, Loss: 0.043821562081575394\n",
      "Epoch 6, Loss: 0.07242404669523239\n",
      "Epoch 8, Loss: 0.015368149615824223\n",
      "Epoch 9, Loss: 0.06385722756385803\n",
      "Epoch 9, Loss: 0.023226983845233917\n",
      "Epoch 7, Loss: 0.015346217900514603\n",
      "Epoch 10, Loss: 0.01406837534159422\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00037768700316093124, num_heads=8, num_layers=4; total time=   1.3s\n",
      "Epoch 7, Loss: 0.025201108306646347\n",
      "Epoch 9, Loss: 0.05947740748524666\n",
      "Epoch 10, Loss: 0.06127827614545822\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00037768700316093124, num_heads=8, num_layers=4; total time=   1.3s\n",
      "Epoch 7, Loss: 0.08935171365737915\n",
      "Epoch 7, Loss: 0.04936118796467781\n",
      "Epoch 10, Loss: 0.04599554464221001\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00037768700316093124, num_heads=8, num_layers=4; total time=   1.3s\n",
      "Epoch 8, Loss: 0.013237451203167439\n",
      "Epoch 10, Loss: 0.10376431047916412\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00037768700316093124, num_heads=8, num_layers=4; total time=   1.4s\n",
      "Epoch 8, Loss: 0.05134620517492294\n",
      "Epoch 8, Loss: 0.09178048372268677\n",
      "Epoch 8, Loss: 0.02887420728802681\n",
      "Epoch 9, Loss: 0.03585979714989662\n",
      "Epoch 9, Loss: 0.10056362301111221\n",
      "Epoch 9, Loss: 0.06446023285388947\n",
      "Epoch 9, Loss: 0.07675587385892868\n",
      "Epoch 10, Loss: 0.04625462740659714\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00037768700316093124, num_heads=8, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.11445032060146332\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00037768700316093124, num_heads=8, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.03127420321106911\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00037768700316093124, num_heads=8, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.1266331523656845\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00037768700316093124, num_heads=8, num_layers=4; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.19366540014743805\n",
      "Epoch 1, Loss: 0.35647818446159363\n",
      "Epoch 1, Loss: 0.09088015556335449\n",
      "Epoch 1, Loss: 0.5358642339706421\n",
      "Epoch 1, Loss: 1.0931439399719238\n",
      "Epoch 1, Loss: 0.9843317270278931\n",
      "Epoch 2, Loss: 0.10416129231452942\n",
      "Epoch 2, Loss: 0.15106450021266937\n",
      "Epoch 1, Loss: 0.16427546739578247\n",
      "Epoch 1, Loss: 0.880876898765564\n",
      "Epoch 2, Loss: 0.22859139740467072\n",
      "Epoch 2, Loss: 0.08252578973770142\n",
      "Epoch 2, Loss: 0.24451737105846405\n",
      "Epoch 3, Loss: 0.22366279363632202\n",
      "Epoch 2, Loss: 0.20103894174098969\n",
      "Epoch 1, Loss: 1.9013845920562744\n",
      "Epoch 3, Loss: 0.13213130831718445\n",
      "Epoch 2, Loss: 0.19186559319496155\n",
      "Epoch 2, Loss: 0.18642280995845795\n",
      "Epoch 4, Loss: 0.12956464290618896\n",
      "Epoch 3, Loss: 0.03193727508187294\n",
      "Epoch 3, Loss: 0.1649872213602066\n",
      "Epoch 3, Loss: 0.1825772225856781\n",
      "Epoch 3, Loss: 0.07419411092996597\n",
      "Epoch 4, Loss: 0.05067307874560356\n",
      "Epoch 1, Loss: 0.22799262404441833\n",
      "Epoch 5, Loss: 0.03577641397714615\n",
      "Epoch 2, Loss: 0.6482586860656738\n",
      "Epoch 4, Loss: 0.1806851178407669\n",
      "Epoch 3, Loss: 0.16904035210609436\n",
      "Epoch 4, Loss: 0.020983032882213593\n",
      "Epoch 3, Loss: 0.1176484003663063\n",
      "Epoch 1, Loss: 0.06784296780824661\n",
      "Epoch 4, Loss: 0.25158217549324036\n",
      "Epoch 4, Loss: 0.36774417757987976\n",
      "Epoch 6, Loss: 0.030266333371400833\n",
      "Epoch 5, Loss: 0.04088002070784569\n",
      "Epoch 1, Loss: 0.7913307547569275\n",
      "Epoch 5, Loss: 0.08920339494943619\n",
      "Epoch 4, Loss: 0.30246540904045105\n",
      "Epoch 2, Loss: 0.08093786239624023\n",
      "Epoch 5, Loss: 0.307635635137558\n",
      "Epoch 2, Loss: 0.2198595106601715\n",
      "Epoch 5, Loss: 0.18513035774230957\n",
      "Epoch 3, Loss: 0.14000314474105835\n",
      "Epoch 6, Loss: 0.05952912196516991\n",
      "Epoch 7, Loss: 0.06580549478530884\n",
      "Epoch 5, Loss: 0.3530312180519104\n",
      "Epoch 4, Loss: 0.03630954772233963\n",
      "Epoch 6, Loss: 0.08087486773729324\n",
      "Epoch 2, Loss: 0.07848159968852997\n",
      "Epoch 7, Loss: 0.046171873807907104\n",
      "Epoch 6, Loss: 0.2973610460758209\n",
      "Epoch 5, Loss: 0.2957821786403656\n",
      "Epoch 6, Loss: 0.21516729891300201\n",
      "Epoch 3, Loss: 0.16439880430698395\n",
      "Epoch 8, Loss: 0.07398685812950134\n",
      "Epoch 6, Loss: 0.08923017978668213\n",
      "Epoch 7, Loss: 0.027460603043437004\n",
      "Epoch 3, Loss: 0.03487721458077431\n",
      "Epoch 8, Loss: 0.01738319918513298\n",
      "Epoch 4, Loss: 0.17795556783676147\n",
      "Epoch 5, Loss: 0.05680878460407257\n",
      "Epoch 3, Loss: 0.13075384497642517\n",
      "Epoch 7, Loss: 0.210614874958992\n",
      "Epoch 9, Loss: 0.010637631639838219\n",
      "Epoch 8, Loss: 0.005991349928081036\n",
      "Epoch 7, Loss: 0.03608201816678047\n",
      "Epoch 9, Loss: 0.04342476278543472\n",
      "Epoch 6, Loss: 0.19007638096809387\n",
      "Epoch 7, Loss: 0.09640559554100037\n",
      "Epoch 5, Loss: 0.3722905218601227\n",
      "Epoch 4, Loss: 0.08395105600357056\n",
      "Epoch 9, Loss: 0.03007173351943493\n",
      "Epoch 10, Loss: 0.026008231565356255\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0003835109606914849, num_heads=8, num_layers=3; total time=   1.0s\n",
      "Epoch 4, Loss: 0.10383309423923492\n",
      "Epoch 4, Loss: 0.2883138656616211\n",
      "Epoch 8, Loss: 0.11273311823606491\n",
      "Epoch 10, Loss: 0.014284770004451275\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0003835109606914849, num_heads=8, num_layers=3; total time=   1.0s\n",
      "Epoch 6, Loss: 0.07407312095165253\n",
      "Epoch 8, Loss: 0.04494953155517578\n",
      "Epoch 8, Loss: 0.03987488895654678\n",
      "Epoch 7, Loss: 0.08493293076753616\n",
      "Epoch 10, Loss: 0.04934636503458023\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0003835109606914849, num_heads=8, num_layers=3; total time=   1.1s\n",
      "Epoch 6, Loss: 0.46081024408340454\n",
      "Epoch 5, Loss: 0.019590310752391815\n",
      "Epoch 9, Loss: 0.04422316327691078\n",
      "Epoch 9, Loss: 0.06998514384031296\n",
      "Epoch 9, Loss: 0.05879313126206398\n",
      "Epoch 5, Loss: 0.26329946517944336\n",
      "Epoch 7, Loss: 0.039340559393167496\n",
      "Epoch 5, Loss: 0.11401768028736115\n",
      "Epoch 8, Loss: 0.027103561908006668\n",
      "Epoch 10, Loss: 0.0879366397857666\n",
      "Epoch 10, Loss: 0.09872157871723175\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0003835109606914849, num_heads=8, num_layers=3; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0003835109606914849, num_heads=8, num_layers=3; total time=   1.2s\n",
      "Epoch 10, Loss: 0.020091738551855087\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0003835109606914849, num_heads=8, num_layers=3; total time=   1.2s\n",
      "Epoch 7, Loss: 0.4139822721481323\n",
      "Epoch 6, Loss: 0.03974122926592827\n",
      "Epoch 8, Loss: 0.010404417291283607\n",
      "Epoch 6, Loss: 0.044394031167030334\n",
      "Epoch 9, Loss: 0.03218263387680054\n",
      "Epoch 6, Loss: 0.15008151531219482\n",
      "Epoch 9, Loss: 0.01610659994184971\n",
      "Epoch 8, Loss: 0.29965370893478394\n",
      "Epoch 7, Loss: 0.07256858795881271\n",
      "Epoch 10, Loss: 0.0678180530667305\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0003835109606914849, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 7, Loss: 0.016589472070336342\n",
      "Epoch 10, Loss: 0.03490952402353287\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0003835109606914849, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Epoch 7, Loss: 0.04655154049396515\n",
      "Epoch 8, Loss: 0.0621965192258358\n",
      "Epoch 9, Loss: 0.17993731796741486\n",
      "Epoch 8, Loss: 0.046154726296663284\n",
      "Epoch 9, Loss: 0.025351349264383316\n",
      "Epoch 8, Loss: 0.007775404956191778\n",
      "Epoch 10, Loss: 0.09707175195217133\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0003835109606914849, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 9, Loss: 0.0635797381401062\n",
      "Epoch 10, Loss: 0.00847678817808628\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0003835109606914849, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.027130920439958572\n",
      "Epoch 10, Loss: 0.047606516629457474\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0003835109606914849, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Epoch 10, Loss: 0.0711045116186142\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0003835109606914849, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 2.4358134269714355\n",
      "Epoch 1, Loss: 1.1643189191818237\n",
      "Epoch 1, Loss: 0.06781262904405594\n",
      "Epoch 2, Loss: 2.180269241333008\n",
      "Epoch 1, Loss: 0.3854512870311737\n",
      "Epoch 1, Loss: 0.2013702243566513\n",
      "Epoch 1, Loss: 0.510172963142395\n",
      "Epoch 2, Loss: 1.0190253257751465\n",
      "Epoch 2, Loss: 0.04607056826353073\n",
      "Epoch 3, Loss: 1.9240822792053223\n",
      "Epoch 1, Loss: 0.4056532680988312\n",
      "Epoch 1, Loss: 0.4755938947200775\n",
      "Epoch 1, Loss: 0.194286048412323\n",
      "Epoch 2, Loss: 0.1452580690383911\n",
      "Epoch 2, Loss: 0.30789852142333984\n",
      "Epoch 1, Loss: 0.6178646683692932\n",
      "Epoch 4, Loss: 1.6980493068695068\n",
      "Epoch 3, Loss: 0.8876159191131592\n",
      "Epoch 2, Loss: 0.38982754945755005\n",
      "Epoch 3, Loss: 0.040094539523124695\n",
      "Epoch 2, Loss: 0.3920290768146515\n",
      "Epoch 2, Loss: 0.3008543848991394\n",
      "Epoch 1, Loss: 0.3382498025894165\n",
      "Epoch 1, Loss: 0.07896359264850616\n",
      "Epoch 5, Loss: 1.4789060354232788\n",
      "Epoch 3, Loss: 0.0986008569598198\n",
      "Epoch 4, Loss: 0.7674642205238342\n",
      "Epoch 3, Loss: 0.2431318610906601\n",
      "Epoch 4, Loss: 0.040595151484012604\n",
      "Epoch 2, Loss: 0.14772550761699677\n",
      "Epoch 3, Loss: 0.2879260182380676\n",
      "Epoch 3, Loss: 0.21843279898166656\n",
      "Epoch 2, Loss: 0.47678032517433167\n",
      "Epoch 6, Loss: 1.2788186073303223\n",
      "Epoch 3, Loss: 0.32394739985466003\n",
      "Epoch 4, Loss: 0.06532477587461472\n",
      "Epoch 5, Loss: 0.6559982299804688\n",
      "Epoch 2, Loss: 0.03636952117085457\n",
      "Epoch 4, Loss: 0.19249826669692993\n",
      "Epoch 5, Loss: 0.0383305624127388\n",
      "Epoch 2, Loss: 0.2641376852989197\n",
      "Epoch 3, Loss: 0.11285961419343948\n",
      "Epoch 4, Loss: 0.20430386066436768\n",
      "Epoch 7, Loss: 1.0949443578720093\n",
      "Epoch 4, Loss: 0.14973805844783783\n",
      "Epoch 6, Loss: 0.5549139976501465\n",
      "Epoch 5, Loss: 0.15380319952964783\n",
      "Epoch 4, Loss: 0.256536066532135\n",
      "Epoch 5, Loss: 0.04394908994436264\n",
      "Epoch 6, Loss: 0.034235671162605286\n",
      "Epoch 3, Loss: 0.012331406585872173\n",
      "Epoch 3, Loss: 0.3495759665966034\n",
      "Epoch 8, Loss: 0.92569500207901\n",
      "Epoch 4, Loss: 0.08854670822620392\n",
      "Epoch 5, Loss: 0.14244642853736877\n",
      "Epoch 7, Loss: 0.46427738666534424\n",
      "Epoch 7, Loss: 0.02761281654238701\n",
      "Epoch 5, Loss: 0.09384091943502426\n",
      "Epoch 6, Loss: 0.03222033008933067\n",
      "Epoch 6, Loss: 0.1251787543296814\n",
      "Epoch 9, Loss: 0.7796542644500732\n",
      "Epoch 5, Loss: 0.20513863861560822\n",
      "Epoch 3, Loss: 0.20139862596988678\n",
      "Epoch 4, Loss: 0.24946314096450806\n",
      "Epoch 8, Loss: 0.39013999700546265\n",
      "Epoch 4, Loss: 0.006650321651250124\n",
      "Epoch 8, Loss: 0.022781595587730408\n",
      "Epoch 5, Loss: 0.07708407938480377\n",
      "Epoch 6, Loss: 0.09301533550024033\n",
      "Epoch 7, Loss: 0.11006572842597961\n",
      "Epoch 10, Loss: 0.6373856067657471\n",
      "Epoch 6, Loss: 0.05322031304240227\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.11484596297023839, feed_forward_dim=512, head_dim=8, lr=5.002950722987459e-05, num_heads=8, num_layers=1; total time=   1.1s\n",
      "Epoch 7, Loss: 0.028567161411046982\n",
      "Epoch 9, Loss: 0.3197222650051117\n",
      "Epoch 9, Loss: 0.01894506625831127\n",
      "Epoch 6, Loss: 0.16377292573451996\n",
      "Epoch 5, Loss: 0.16601866483688354\n",
      "Epoch 4, Loss: 0.14801748096942902\n",
      "Epoch 5, Loss: 0.013812997378408909\n",
      "Epoch 8, Loss: 0.0990605428814888\n",
      "Epoch 7, Loss: 0.06397499889135361\n",
      "Epoch 6, Loss: 0.07278051227331161\n",
      "Epoch 7, Loss: 0.02883286401629448\n",
      "Epoch 10, Loss: 0.017866920679807663\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.11484596297023839, feed_forward_dim=512, head_dim=8, lr=5.002950722987459e-05, num_heads=8, num_layers=1; total time=   1.3s\n",
      "Epoch 10, Loss: 0.26329851150512695\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.11484596297023839, feed_forward_dim=512, head_dim=8, lr=5.002950722987459e-05, num_heads=8, num_layers=1; total time=   1.3s\n",
      "Epoch 8, Loss: 0.032280318439006805\n",
      "Epoch 7, Loss: 0.13567164540290833\n",
      "Epoch 9, Loss: 0.0965496376156807\n",
      "Epoch 6, Loss: 0.09946022927761078\n",
      "Epoch 8, Loss: 0.04670875146985054\n",
      "Epoch 6, Loss: 0.021561050787568092\n",
      "Epoch 9, Loss: 0.03839455172419548\n",
      "Epoch 5, Loss: 0.10805162042379379\n",
      "Epoch 8, Loss: 0.11353901028633118\n",
      "Epoch 8, Loss: 0.01542084850370884\n",
      "Epoch 10, Loss: 0.09828628599643707\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.11484596297023839, feed_forward_dim=512, head_dim=8, lr=5.002950722987459e-05, num_heads=8, num_layers=1; total time=   1.4s\n",
      "Epoch 7, Loss: 0.07320541143417358\n",
      "Epoch 7, Loss: 0.0586654357612133\n",
      "Epoch 9, Loss: 0.042913783341646194\n",
      "Epoch 10, Loss: 0.042732615023851395\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.11484596297023839, feed_forward_dim=512, head_dim=8, lr=5.002950722987459e-05, num_heads=8, num_layers=1; total time=   1.5s\n",
      "Epoch 7, Loss: 0.0265983734279871\n",
      "Epoch 9, Loss: 0.10055969655513763\n",
      "Epoch 9, Loss: 0.010532785207033157\n",
      "Epoch 6, Loss: 0.07761766761541367\n",
      "Epoch 8, Loss: 0.027918925508856773\n",
      "Epoch 8, Loss: 0.07472413033246994\n",
      "Epoch 10, Loss: 0.09434320777654648\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.11484596297023839, feed_forward_dim=512, head_dim=8, lr=5.002950722987459e-05, num_heads=8, num_layers=1; total time=   1.6s\n",
      "Epoch 10, Loss: 0.04461055248975754\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.11484596297023839, feed_forward_dim=512, head_dim=8, lr=5.002950722987459e-05, num_heads=8, num_layers=1; total time=   1.6s\n",
      "Epoch 8, Loss: 0.024111827835440636\n",
      "Epoch 10, Loss: 0.014471620321273804\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.11484596297023839, feed_forward_dim=512, head_dim=8, lr=5.002950722987459e-05, num_heads=8, num_layers=1; total time=   1.6s\n",
      "Epoch 9, Loss: 0.01522815227508545\n",
      "Epoch 9, Loss: 0.07582750916481018\n",
      "Epoch 7, Loss: 0.05705130100250244\n",
      "Epoch 9, Loss: 0.019455859437584877\n",
      "Epoch 10, Loss: 0.074276402592659\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.11484596297023839, feed_forward_dim=512, head_dim=8, lr=5.002950722987459e-05, num_heads=8, num_layers=1; total time=   1.7s\n",
      "Epoch 10, Loss: 0.012882713228464127\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.11484596297023839, feed_forward_dim=512, head_dim=8, lr=5.002950722987459e-05, num_heads=8, num_layers=1; total time=   1.7s\n",
      "Epoch 8, Loss: 0.045374657958745956\n",
      "Epoch 10, Loss: 0.013897519558668137\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.11484596297023839, feed_forward_dim=512, head_dim=8, lr=5.002950722987459e-05, num_heads=8, num_layers=1; total time=   1.7s\n",
      "Epoch 9, Loss: 0.039872147142887115\n",
      "Epoch 10, Loss: 0.040455494076013565\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.11484596297023839, feed_forward_dim=512, head_dim=8, lr=5.002950722987459e-05, num_heads=8, num_layers=1; total time=   1.8s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.9229599833488464\n",
      "Epoch 1, Loss: 0.08302426338195801\n",
      "Epoch 1, Loss: 1.391503930091858\n",
      "Epoch 1, Loss: 0.37778419256210327\n",
      "Epoch 1, Loss: 0.0581107921898365\n",
      "Epoch 2, Loss: 0.12280213832855225\n",
      "Epoch 1, Loss: 2.2921125888824463\n",
      "Epoch 2, Loss: 0.2126290202140808\n",
      "Epoch 2, Loss: 0.10090130567550659\n",
      "Epoch 2, Loss: 0.4654847979545593\n",
      "Epoch 1, Loss: 0.17634961009025574\n",
      "Epoch 3, Loss: 0.11426696181297302\n",
      "Epoch 1, Loss: 2.630358934402466\n",
      "Epoch 1, Loss: 0.0146644813939929\n",
      "Epoch 1, Loss: 0.2970156967639923\n",
      "Epoch 3, Loss: 0.06203573942184448\n",
      "Epoch 2, Loss: 0.6402702927589417\n",
      "Epoch 3, Loss: 0.12975572049617767\n",
      "Epoch 3, Loss: 0.2559494376182556\n",
      "Epoch 2, Loss: 0.2549481987953186\n",
      "Epoch 1, Loss: 1.4576352834701538\n",
      "Epoch 1, Loss: 0.24156086146831512\n",
      "Epoch 4, Loss: 0.306423157453537\n",
      "Epoch 4, Loss: 0.015186258591711521\n",
      "Epoch 2, Loss: 0.08859171718358994\n",
      "Epoch 4, Loss: 0.21677887439727783\n",
      "Epoch 2, Loss: 0.09509380906820297\n",
      "Epoch 4, Loss: 0.15871122479438782\n",
      "Epoch 2, Loss: 0.6981739401817322\n",
      "Epoch 3, Loss: 0.1622401624917984\n",
      "Epoch 2, Loss: 0.22729294002056122\n",
      "Epoch 3, Loss: 0.04313323646783829\n",
      "Epoch 5, Loss: 0.31249451637268066\n",
      "Epoch 5, Loss: 0.07670991122722626\n",
      "Epoch 2, Loss: 0.10652463883161545\n",
      "Epoch 2, Loss: 0.39051634073257446\n",
      "Epoch 5, Loss: 0.3680001497268677\n",
      "Epoch 5, Loss: 0.04874950647354126\n",
      "Epoch 6, Loss: 0.20287877321243286\n",
      "Epoch 3, Loss: 0.06736575812101364\n",
      "Epoch 4, Loss: 0.35883650183677673\n",
      "Epoch 6, Loss: 0.07621076703071594\n",
      "Epoch 3, Loss: 0.040224697440862656\n",
      "Epoch 3, Loss: 0.19583208858966827\n",
      "Epoch 4, Loss: 0.04688688740134239\n",
      "Epoch 3, Loss: 0.01617518998682499\n",
      "Epoch 6, Loss: 0.38327884674072266\n",
      "Epoch 7, Loss: 0.08767213672399521\n",
      "Epoch 3, Loss: 0.14929232001304626\n",
      "Epoch 6, Loss: 0.046684715896844864\n",
      "Epoch 4, Loss: 0.017024515196681023\n",
      "Epoch 7, Loss: 0.025750456377863884\n",
      "Epoch 3, Loss: 0.16678734123706818\n",
      "Epoch 5, Loss: 0.5690712332725525\n",
      "Epoch 7, Loss: 0.3029111921787262\n",
      "Epoch 8, Loss: 0.026289604604244232\n",
      "Epoch 5, Loss: 0.11223918199539185\n",
      "Epoch 4, Loss: 0.12446089088916779\n",
      "Epoch 4, Loss: 0.07672890275716782\n",
      "Epoch 4, Loss: 0.25947636365890503\n",
      "Epoch 7, Loss: 0.09660647064447403\n",
      "Epoch 8, Loss: 0.005322143901139498\n",
      "Epoch 9, Loss: 0.029649823904037476\n",
      "Epoch 4, Loss: 0.3525356650352478\n",
      "Epoch 8, Loss: 0.19483551383018494\n",
      "Epoch 6, Loss: 0.5908725261688232\n",
      "Epoch 5, Loss: 0.031717512756586075\n",
      "Epoch 6, Loss: 0.08211246132850647\n",
      "Epoch 4, Loss: 0.10234244912862778\n",
      "Epoch 5, Loss: 0.03900716453790665\n",
      "Epoch 8, Loss: 0.10994070768356323\n",
      "Epoch 5, Loss: 0.5712494254112244\n",
      "Epoch 10, Loss: 0.06875618547201157\n",
      "Epoch 9, Loss: 0.023343989625573158\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=0.0003927350679573379, num_heads=4, num_layers=2; total time=   1.1s\n",
      "Epoch 5, Loss: 0.12520264089107513\n",
      "Epoch 9, Loss: 0.10348090529441833\n",
      "Epoch 7, Loss: 0.46849504113197327\n",
      "Epoch 9, Loss: 0.07333056628704071\n",
      "Epoch 10, Loss: 0.04318736493587494\n",
      "Epoch 7, Loss: 0.024794509634375572\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=0.0003927350679573379, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 5, Loss: 0.039510466158390045\n",
      "Epoch 6, Loss: 0.040535133332014084\n",
      "Epoch 5, Loss: 0.47201526165008545\n",
      "Epoch 6, Loss: 0.03335431590676308\n",
      "Epoch 6, Loss: 0.6562308073043823\n",
      "Epoch 10, Loss: 0.05522928386926651\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=0.0003927350679573379, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 10, Loss: 0.03081820160150528\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=0.0003927350679573379, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 8, Loss: 0.30446186661720276\n",
      "Epoch 8, Loss: 0.008117292076349258\n",
      "Epoch 6, Loss: 0.06959789991378784\n",
      "Epoch 7, Loss: 0.06829440593719482\n",
      "Epoch 6, Loss: 0.40512359142303467\n",
      "Epoch 7, Loss: 0.024396346881985664\n",
      "Epoch 6, Loss: 0.041023045778274536\n",
      "Epoch 9, Loss: 0.16266265511512756\n",
      "Epoch 7, Loss: 0.5514623522758484\n",
      "Epoch 9, Loss: 0.0345054529607296\n",
      "Epoch 8, Loss: 0.038514066487550735\n",
      "Epoch 7, Loss: 0.014069882221519947\n",
      "Epoch 8, Loss: 0.07087349891662598\n",
      "Epoch 7, Loss: 0.2612604796886444\n",
      "Epoch 7, Loss: 0.06570935249328613\n",
      "Epoch 10, Loss: 0.08153050392866135\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=0.0003927350679573379, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 10, Loss: 0.056193940341472626\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=0.0003927350679573379, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 0.03417003154754639\n",
      "Epoch 8, Loss: 0.01257302612066269\n",
      "Epoch 9, Loss: 0.043995801359415054\n",
      "Epoch 8, Loss: 0.3761753439903259\n",
      "Epoch 8, Loss: 0.12622082233428955\n",
      "Epoch 8, Loss: 0.06019740551710129\n",
      "Epoch 10, Loss: 0.017236290499567986\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=0.0003927350679573379, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.014402740634977818\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=0.0003927350679573379, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 9, Loss: 0.041308533400297165\n",
      "Epoch 9, Loss: 0.19972270727157593\n",
      "Epoch 9, Loss: 0.05820908024907112\n",
      "Epoch 9, Loss: 0.030412999913096428\n",
      "Epoch 10, Loss: 0.05749077349901199\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=0.0003927350679573379, num_heads=4, num_layers=2; total time=   1.7s\n",
      "Epoch 10, Loss: 0.07829451560974121\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=0.0003927350679573379, num_heads=4, num_layers=2; total time=   1.7s\n",
      "Epoch 10, Loss: 0.0555201880633831\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=0.0003927350679573379, num_heads=4, num_layers=2; total time=   1.7s\n",
      "Epoch 10, Loss: 0.011525986716151237\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=0.0003927350679573379, num_heads=4, num_layers=2; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 2.806382894515991\n",
      "Epoch 1, Loss: 1.2890985012054443\n",
      "Epoch 1, Loss: 1.468178391456604\n",
      "Epoch 1, Loss: 0.09685233235359192\n",
      "Epoch 1, Loss: 0.6463795304298401\n",
      "Epoch 2, Loss: 0.09711359441280365\n",
      "Epoch 1, Loss: 0.8512772917747498\n",
      "Epoch 2, Loss: 0.09328644722700119\n",
      "Epoch 2, Loss: 0.07940707355737686\n",
      "Epoch 1, Loss: 0.10723236948251724\n",
      "Epoch 3, Loss: 0.3989896774291992\n",
      "Epoch 2, Loss: 1.001540184020996\n",
      "Epoch 2, Loss: 0.13280031085014343\n",
      "Epoch 3, Loss: 0.510487973690033\n",
      "Epoch 1, Loss: 0.4231899380683899\n",
      "Epoch 1, Loss: 0.3836701810359955\n",
      "Epoch 2, Loss: 0.09804952889680862\n",
      "Epoch 4, Loss: 0.7451227903366089\n",
      "Epoch 1, Loss: 0.28902366757392883\n",
      "Epoch 1, Loss: 0.09562233835458755\n",
      "Epoch 2, Loss: 0.8744481205940247\n",
      "Epoch 3, Loss: 0.5206970572471619\n",
      "Epoch 4, Loss: 0.5091440677642822\n",
      "Epoch 3, Loss: 0.17965790629386902\n",
      "Epoch 3, Loss: 0.3701712191104889\n",
      "Epoch 1, Loss: 1.0298665761947632\n",
      "Epoch 2, Loss: 0.4232161045074463\n",
      "Epoch 5, Loss: 0.6092365980148315\n",
      "Epoch 2, Loss: 0.29638370871543884\n",
      "Epoch 5, Loss: 0.25065794587135315\n",
      "Epoch 3, Loss: 0.4298555850982666\n",
      "Epoch 4, Loss: 0.20375628769397736\n",
      "Epoch 2, Loss: 0.6324954032897949\n",
      "Epoch 3, Loss: 0.16101618111133575\n",
      "Epoch 4, Loss: 0.08097407966852188\n",
      "Epoch 2, Loss: 0.8184535503387451\n",
      "Epoch 4, Loss: 0.5882492065429688\n",
      "Epoch 6, Loss: 0.06619551032781601\n",
      "Epoch 6, Loss: 0.3331851661205292\n",
      "Epoch 2, Loss: 0.12246399372816086\n",
      "Epoch 5, Loss: 0.03952857479453087\n",
      "Epoch 5, Loss: 0.3258085250854492\n",
      "Epoch 3, Loss: 0.2530910074710846\n",
      "Epoch 4, Loss: 0.06869231164455414\n",
      "Epoch 7, Loss: 0.04056113213300705\n",
      "Epoch 7, Loss: 0.11328204721212387\n",
      "Epoch 3, Loss: 0.2464679777622223\n",
      "Epoch 5, Loss: 0.3469100892543793\n",
      "Epoch 3, Loss: 0.08047124743461609\n",
      "Epoch 3, Loss: 0.2526417374610901\n",
      "Epoch 4, Loss: 0.32073187828063965\n",
      "Epoch 6, Loss: 0.10049941390752792\n",
      "Epoch 8, Loss: 0.11443069577217102\n",
      "Epoch 3, Loss: 0.5461106300354004\n",
      "Epoch 5, Loss: 0.29890158772468567\n",
      "Epoch 8, Loss: 0.02230888418853283\n",
      "Epoch 6, Loss: 0.0332220122218132\n",
      "Epoch 4, Loss: 0.06858912110328674\n",
      "Epoch 6, Loss: 0.28736475110054016\n",
      "Epoch 4, Loss: 0.05060722306370735\n",
      "Epoch 7, Loss: 0.030526647344231606\n",
      "Epoch 4, Loss: 0.17096316814422607\n",
      "Epoch 9, Loss: 0.1780725121498108\n",
      "Epoch 5, Loss: 0.10449434071779251\n",
      "Epoch 9, Loss: 0.045866578817367554\n",
      "Epoch 7, Loss: 0.10011842846870422\n",
      "Epoch 4, Loss: 0.04285447299480438\n",
      "Epoch 7, Loss: 0.09776661545038223\n",
      "Epoch 5, Loss: 0.054925642907619476\n",
      "Epoch 4, Loss: 0.34515857696533203\n",
      "Epoch 8, Loss: 0.0781971737742424\n",
      "Epoch 6, Loss: 0.2727286219596863\n",
      "Epoch 5, Loss: 0.08783261477947235\n",
      "Epoch 10, Loss: 0.11542560160160065\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.35039684607620103, feed_forward_dim=256, head_dim=32, lr=0.000701862594731524, num_heads=4, num_layers=1; total time=   1.0s\n",
      "Epoch 10, Loss: 0.1765676736831665\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.35039684607620103, feed_forward_dim=256, head_dim=32, lr=0.000701862594731524, num_heads=4, num_layers=1; total time=   0.9s\n",
      "Epoch 5, Loss: 0.3466763496398926\n",
      "Epoch 8, Loss: 0.1281055361032486\n",
      "Epoch 6, Loss: 0.027060886844992638\n",
      "Epoch 9, Loss: 0.14690591394901276\n",
      "Epoch 6, Loss: 0.10919924825429916\n",
      "Epoch 5, Loss: 0.15560221672058105\n",
      "Epoch 8, Loss: 0.009764395654201508\n",
      "Epoch 5, Loss: 0.08450336754322052\n",
      "Epoch 6, Loss: 0.13886700570583344\n",
      "Epoch 7, Loss: 0.11702124029397964\n",
      "Epoch 9, Loss: 0.0934886485338211\n",
      "Epoch 7, Loss: 0.07925941795110703\n",
      "Epoch 6, Loss: 0.2321731299161911\n",
      "Epoch 10, Loss: 0.1726515293121338\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.35039684607620103, feed_forward_dim=256, head_dim=32, lr=0.000701862594731524, num_heads=4, num_layers=1; total time=   1.1s\n",
      "Epoch 7, Loss: 0.10980883240699768\n",
      "Epoch 9, Loss: 0.04136618599295616\n",
      "Epoch 6, Loss: 0.21765898168087006\n",
      "Epoch 10, Loss: 0.04095713794231415\n",
      "Epoch 6, Loss: 0.03089844062924385\n",
      "Epoch 8, Loss: 0.020903291180729866\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.35039684607620103, feed_forward_dim=256, head_dim=32, lr=0.000701862594731524, num_heads=4, num_layers=1; total time=   1.1s\n",
      "Epoch 7, Loss: 0.10184323787689209\n",
      "Epoch 8, Loss: 0.14856788516044617\n",
      "Epoch 8, Loss: 0.06129077076911926\n",
      "Epoch 10, Loss: 0.10538575798273087\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.35039684607620103, feed_forward_dim=256, head_dim=32, lr=0.000701862594731524, num_heads=4, num_layers=1; total time=   1.2s\n",
      "Epoch 9, Loss: 0.028574373573064804\n",
      "Epoch 7, Loss: 0.07311766594648361\n",
      "Epoch 8, Loss: 0.03571902960538864\n",
      "Epoch 7, Loss: 0.11606236547231674\n",
      "Epoch 9, Loss: 0.15364155173301697\n",
      "Epoch 9, Loss: 0.018431412056088448\n",
      "Epoch 7, Loss: 0.1354741007089615\n",
      "Epoch 10, Loss: 0.08293862640857697\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.35039684607620103, feed_forward_dim=256, head_dim=32, lr=0.000701862594731524, num_heads=4, num_layers=1; total time=   1.3s\n",
      "Epoch 10, Loss: 0.1067686602473259\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.35039684607620103, feed_forward_dim=256, head_dim=32, lr=0.000701862594731524, num_heads=4, num_layers=1; total time=   1.4s\n",
      "Epoch 9, Loss: 0.010102907195687294\n",
      "Epoch 10, Loss: 0.01980729214847088\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.35039684607620103, feed_forward_dim=256, head_dim=32, lr=0.000701862594731524, num_heads=4, num_layers=1; total time=   1.4s\n",
      "Epoch 8, Loss: 0.18378205597400665\n",
      "Epoch 8, Loss: 0.014696779660880566\n",
      "Epoch 8, Loss: 0.04129883274435997\n",
      "Epoch 10, Loss: 0.03424124792218208\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.35039684607620103, feed_forward_dim=256, head_dim=32, lr=0.000701862594731524, num_heads=4, num_layers=1; total time=   1.4s\n",
      "Epoch 9, Loss: 0.05716441571712494\n",
      "Epoch 9, Loss: 0.17577414214611053\n",
      "Epoch 9, Loss: 0.01834838092327118\n",
      "Epoch 10, Loss: 0.11481180787086487\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.35039684607620103, feed_forward_dim=256, head_dim=32, lr=0.000701862594731524, num_heads=4, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.11327651143074036\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.35039684607620103, feed_forward_dim=256, head_dim=32, lr=0.000701862594731524, num_heads=4, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.052096251398324966\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.35039684607620103, feed_forward_dim=256, head_dim=32, lr=0.000701862594731524, num_heads=4, num_layers=1; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.5015150308609009\n",
      "Epoch 1, Loss: 0.11259975284337997\n",
      "Epoch 1, Loss: 0.49629831314086914\n",
      "Epoch 2, Loss: 0.060807161033153534\n",
      "Epoch 1, Loss: 0.17670293152332306\n",
      "Epoch 1, Loss: 0.5675541162490845\n",
      "Epoch 1, Loss: 0.07541893422603607\n",
      "Epoch 2, Loss: 0.3394218385219574\n",
      "Epoch 2, Loss: 0.12443171441555023\n",
      "Epoch 1, Loss: 0.044474054127931595\n",
      "Epoch 1, Loss: 0.21125133335590363\n",
      "Epoch 3, Loss: 0.18242129683494568\n",
      "Epoch 2, Loss: 0.18834905326366425\n",
      "Epoch 2, Loss: 0.28806570172309875\n",
      "Epoch 1, Loss: 0.08504266291856766\n",
      "Epoch 2, Loss: 0.2649571895599365\n",
      "Epoch 3, Loss: 0.06247112527489662\n",
      "Epoch 3, Loss: 0.26082876324653625\n",
      "Epoch 1, Loss: 0.03923088312149048\n",
      "Epoch 2, Loss: 0.04443417116999626\n",
      "Epoch 1, Loss: 0.42971715331077576\n",
      "Epoch 4, Loss: 0.24625536799430847\n",
      "Epoch 1, Loss: 0.943764865398407\n",
      "Epoch 2, Loss: 0.33116450905799866\n",
      "Epoch 3, Loss: 0.1204216480255127\n",
      "Epoch 4, Loss: 0.08083611726760864\n",
      "Epoch 3, Loss: 0.27346572279930115\n",
      "Epoch 3, Loss: 0.07059171795845032\n",
      "Epoch 4, Loss: 0.23831291496753693\n",
      "Epoch 5, Loss: 0.1548181027173996\n",
      "Epoch 2, Loss: 0.17499038577079773\n",
      "Epoch 3, Loss: 0.04375313222408295\n",
      "Epoch 2, Loss: 0.14336606860160828\n",
      "Epoch 5, Loss: 0.14938922226428986\n",
      "Epoch 4, Loss: 0.05658271536231041\n",
      "Epoch 3, Loss: 0.13795816898345947\n",
      "Epoch 4, Loss: 0.2661108076572418\n",
      "Epoch 2, Loss: 0.04153016582131386\n",
      "Epoch 6, Loss: 0.05740434676408768\n",
      "Epoch 4, Loss: 0.03727342560887337\n",
      "Epoch 5, Loss: 0.12130577117204666\n",
      "Epoch 2, Loss: 0.1604083925485611\n",
      "Epoch 4, Loss: 0.021829618141055107\n",
      "Epoch 6, Loss: 0.08507407456636429\n",
      "Epoch 3, Loss: 0.02944113314151764\n",
      "Epoch 5, Loss: 0.11333766579627991\n",
      "Epoch 7, Loss: 0.026613881811499596\n",
      "Epoch 3, Loss: 0.03452669084072113\n",
      "Epoch 5, Loss: 0.16916196048259735\n",
      "Epoch 6, Loss: 0.04680567607283592\n",
      "Epoch 4, Loss: 0.08482100069522858\n",
      "Epoch 5, Loss: 0.11554967612028122\n",
      "Epoch 3, Loss: 0.1992974579334259\n",
      "Epoch 8, Loss: 0.05468139424920082\n",
      "Epoch 3, Loss: 0.1843128502368927\n",
      "Epoch 7, Loss: 0.013974037952721119\n",
      "Epoch 6, Loss: 0.08964516967535019\n",
      "Epoch 6, Loss: 0.0847739577293396\n",
      "Epoch 4, Loss: 0.06804319471120834\n",
      "Epoch 7, Loss: 0.04922019690275192\n",
      "Epoch 5, Loss: 0.009190777316689491\n",
      "Epoch 4, Loss: 0.01645507849752903\n",
      "Epoch 9, Loss: 0.09088782966136932\n",
      "Epoch 6, Loss: 0.0884256586432457\n",
      "Epoch 5, Loss: 0.12821555137634277\n",
      "Epoch 8, Loss: 0.01606610417366028\n",
      "Epoch 8, Loss: 0.08537429571151733\n",
      "Epoch 4, Loss: 0.20205065608024597\n",
      "Epoch 7, Loss: 0.02473025768995285\n",
      "Epoch 7, Loss: 0.062155839055776596\n",
      "Epoch 6, Loss: 0.02871369570493698\n",
      "Epoch 10, Loss: 0.09698126465082169\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.00036763456421360394, num_heads=4, num_layers=4; total time=   1.2s\n",
      "Epoch 4, Loss: 0.35308095812797546\n",
      "Epoch 5, Loss: 0.08753526955842972\n",
      "Epoch 9, Loss: 0.05731801316142082\n",
      "Epoch 7, Loss: 0.02311941422522068\n",
      "Epoch 5, Loss: 0.06279920041561127\n",
      "Epoch 6, Loss: 0.09941080957651138\n",
      "Epoch 9, Loss: 0.09732948243618011\n",
      "Epoch 8, Loss: 0.015961764380335808\n",
      "Epoch 10, Loss: 0.06968996673822403\n",
      "Epoch 8, Loss: 0.08185296505689621\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.00036763456421360394, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 6, Loss: 0.04101346433162689\n",
      "Epoch 7, Loss: 0.014331845566630363\n",
      "Epoch 5, Loss: 0.08691410720348358\n",
      "Epoch 8, Loss: 0.011365612968802452\n",
      "Epoch 7, Loss: 0.03915838152170181\n",
      "Epoch 9, Loss: 0.04319591447710991\n",
      "Epoch 10, Loss: 0.07353758811950684\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.00036763456421360394, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 9, Loss: 0.09681998193264008\n",
      "Epoch 5, Loss: 0.3223814070224762\n",
      "Epoch 6, Loss: 0.05017329752445221\n",
      "Epoch 8, Loss: 0.008022768422961235\n",
      "Epoch 7, Loss: 0.020861143246293068\n",
      "Epoch 9, Loss: 0.042317114770412445\n",
      "Epoch 8, Loss: 0.02170085720717907\n",
      "Epoch 10, Loss: 0.05057200789451599\n",
      "Epoch 10, Loss: 0.08515650033950806\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.00036763456421360394, num_heads=4, num_layers=4; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.00036763456421360394, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 6, Loss: 0.015548006631433964\n",
      "Epoch 9, Loss: 0.0195955578237772\n",
      "Epoch 6, Loss: 0.18516358733177185\n",
      "Epoch 9, Loss: 0.04385940358042717\n",
      "Epoch 10, Loss: 0.057753775268793106\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.00036763456421360394, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Epoch 7, Loss: 0.01421315222978592\n",
      "Epoch 8, Loss: 0.04166516289114952\n",
      "Epoch 10, Loss: 0.016735121607780457\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.00036763456421360394, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Epoch 7, Loss: 0.025589637458324432\n",
      "Epoch 10, Loss: 0.053616493940353394\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.00036763456421360394, num_heads=4, num_layers=4; total time=   1.6s\n",
      "Epoch 7, Loss: 0.06241206079721451\n",
      "Epoch 9, Loss: 0.05247662216424942\n",
      "Epoch 8, Loss: 0.006406823638826609\n",
      "Epoch 8, Loss: 0.06960123032331467\n",
      "Epoch 10, Loss: 0.037539709359407425\n",
      "Epoch 8, Loss: 0.016408920288085938\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.00036763456421360394, num_heads=4, num_layers=4; total time=   1.7s\n",
      "Epoch 9, Loss: 0.02379988692700863\n",
      "Epoch 9, Loss: 0.08702580630779266\n",
      "Epoch 9, Loss: 0.04353632032871246\n",
      "Epoch 10, Loss: 0.03243829682469368\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.00036763456421360394, num_heads=4, num_layers=4; total time=   1.9s\n",
      "Epoch 10, Loss: 0.0655011385679245\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.00036763456421360394, num_heads=4, num_layers=4; total time=   1.9s\n",
      "Epoch 10, Loss: 0.095468670129776\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.00036763456421360394, num_heads=4, num_layers=4; total time=   1.9s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.088656947016716\n",
      "Epoch 1, Loss: 0.31166911125183105\n",
      "Epoch 1, Loss: 0.035439927130937576\n",
      "Epoch 2, Loss: 1.0473692417144775\n",
      "Epoch 1, Loss: 0.21021400392055511\n",
      "Epoch 1, Loss: 0.12491840869188309\n",
      "Epoch 2, Loss: 0.7021559476852417\n",
      "Epoch 1, Loss: 0.05152389779686928\n",
      "Epoch 1, Loss: 0.11965293437242508\n",
      "Epoch 1, Loss: 0.9053661227226257\n",
      "Epoch 1, Loss: 0.09478967636823654\n",
      "Epoch 1, Loss: 1.8202158212661743\n",
      "Epoch 3, Loss: 0.14091582596302032\n",
      "Epoch 2, Loss: 0.6328926086425781\n",
      "Epoch 2, Loss: 1.1419588327407837\n",
      "Epoch 1, Loss: 0.16667570173740387\n",
      "Epoch 2, Loss: 1.0172877311706543\n",
      "Epoch 2, Loss: 1.0017451047897339\n",
      "Epoch 3, Loss: 0.2613998353481293\n",
      "Epoch 2, Loss: 0.030570125207304955\n",
      "Epoch 1, Loss: 0.5678187012672424\n",
      "Epoch 2, Loss: 1.047805905342102\n",
      "Epoch 4, Loss: 0.15160800516605377\n",
      "Epoch 2, Loss: 1.1446259021759033\n",
      "Epoch 3, Loss: 0.156546950340271\n",
      "Epoch 3, Loss: 0.14827120304107666\n",
      "Epoch 4, Loss: 0.0691746175289154\n",
      "Epoch 2, Loss: 0.7472367286682129\n",
      "Epoch 5, Loss: 0.4043671190738678\n",
      "Epoch 3, Loss: 0.15418264269828796\n",
      "Epoch 2, Loss: 0.16690227389335632\n",
      "Epoch 4, Loss: 0.13499344885349274\n",
      "Epoch 3, Loss: 0.03195374831557274\n",
      "Epoch 3, Loss: 0.6144899129867554\n",
      "Epoch 3, Loss: 0.11248362064361572\n",
      "Epoch 4, Loss: 0.08157817274332047\n",
      "Epoch 5, Loss: 0.19458824396133423\n",
      "Epoch 6, Loss: 0.28091391921043396\n",
      "Epoch 2, Loss: 0.5228914022445679\n",
      "Epoch 3, Loss: 0.13789783418178558\n",
      "Epoch 5, Loss: 0.428010493516922\n",
      "Epoch 4, Loss: 0.14085225760936737\n",
      "Epoch 4, Loss: 0.39546358585357666\n",
      "Epoch 3, Loss: 0.4464200437068939\n",
      "Epoch 6, Loss: 0.22894643247127533\n",
      "Epoch 3, Loss: 0.19374144077301025\n",
      "Epoch 7, Loss: 0.08179988712072372\n",
      "Epoch 5, Loss: 0.22414308786392212\n",
      "Epoch 4, Loss: 0.2037764936685562\n",
      "Epoch 4, Loss: 0.6676243543624878\n",
      "Epoch 3, Loss: 0.42783960700035095\n",
      "Epoch 4, Loss: 0.2010955959558487\n",
      "Epoch 5, Loss: 0.4538305699825287\n",
      "Epoch 7, Loss: 0.13190409541130066\n",
      "Epoch 6, Loss: 0.31194445490837097\n",
      "Epoch 8, Loss: 0.011605162173509598\n",
      "Epoch 5, Loss: 0.36908918619155884\n",
      "Epoch 4, Loss: 0.31705382466316223\n",
      "Epoch 6, Loss: 0.17480666935443878\n",
      "Epoch 5, Loss: 0.421129435300827\n",
      "Epoch 8, Loss: 0.04325077310204506\n",
      "Epoch 9, Loss: 0.06369571387767792\n",
      "Epoch 5, Loss: 0.44480857253074646\n",
      "Epoch 7, Loss: 0.1016157791018486\n",
      "Epoch 6, Loss: 0.18893572688102722\n",
      "Epoch 4, Loss: 0.05235433578491211\n",
      "Epoch 6, Loss: 0.29306086897850037\n",
      "Epoch 5, Loss: 0.3649013638496399\n",
      "Epoch 7, Loss: 0.057448726147413254\n",
      "Epoch 4, Loss: 0.060888294130563736\n",
      "Epoch 10, Loss: 0.1310921609401703\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2712527371692657, feed_forward_dim=512, head_dim=32, lr=0.0007589464348556687, num_heads=2, num_layers=2; total time=   1.0s\n",
      "Epoch 9, Loss: 0.032686471939086914\n",
      "Epoch 5, Loss: 0.11602620780467987\n",
      "Epoch 6, Loss: 0.2897230088710785\n",
      "Epoch 7, Loss: 0.02449384517967701\n",
      "Epoch 8, Loss: 0.009913348592817783\n",
      "Epoch 6, Loss: 0.3098084330558777\n",
      "Epoch 7, Loss: 0.1271917223930359\n",
      "Epoch 8, Loss: 0.012979205697774887\n",
      "Epoch 6, Loss: 0.1071549579501152\n",
      "Epoch 10, Loss: 0.07503865659236908\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2712527371692657, feed_forward_dim=512, head_dim=32, lr=0.0007589464348556687, num_heads=2, num_layers=2; total time=   1.1s\n",
      "Epoch 9, Loss: 0.036509450525045395\n",
      "Epoch 5, Loss: 0.2331136018037796\n",
      "Epoch 8, Loss: 0.03641161695122719\n",
      "Epoch 7, Loss: 0.09300317615270615\n",
      "Epoch 5, Loss: 0.04222285374999046\n",
      "Epoch 7, Loss: 0.10663523524999619\n",
      "Epoch 6, Loss: 0.047858405858278275\n",
      "Epoch 8, Loss: 0.03449149429798126\n",
      "Epoch 9, Loss: 0.045842334628105164\n",
      "Epoch 10, Loss: 0.10210318863391876\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2712527371692657, feed_forward_dim=512, head_dim=32, lr=0.0007589464348556687, num_heads=2, num_layers=2; total time=   1.2s\n",
      "Epoch 7, Loss: 0.022241095080971718\n",
      "Epoch 9, Loss: 0.11531829088926315\n",
      "Epoch 6, Loss: 0.2351466715335846\n",
      "Epoch 9, Loss: 0.04045364260673523\n",
      "Epoch 8, Loss: 0.015100142918527126\n",
      "Epoch 8, Loss: 0.024361247196793556\n",
      "Epoch 7, Loss: 0.09046676754951477\n",
      "Epoch 6, Loss: 0.18129940330982208\n",
      "Epoch 10, Loss: 0.08690939843654633\n",
      "Epoch 10, Loss: 0.15693482756614685\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2712527371692657, feed_forward_dim=512, head_dim=32, lr=0.0007589464348556687, num_heads=2, num_layers=2; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2712527371692657, feed_forward_dim=512, head_dim=32, lr=0.0007589464348556687, num_heads=2, num_layers=2; total time=   1.4s\n",
      "Epoch 8, Loss: 0.0713169202208519\n",
      "Epoch 10, Loss: 0.09055979549884796\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2712527371692657, feed_forward_dim=512, head_dim=32, lr=0.0007589464348556687, num_heads=2, num_layers=2; total time=   1.4s\n",
      "Epoch 7, Loss: 0.10756175965070724\n",
      "Epoch 9, Loss: 0.06309161335229874\n",
      "Epoch 8, Loss: 0.13860565423965454\n",
      "Epoch 9, Loss: 0.05977049097418785\n",
      "Epoch 7, Loss: 0.19996054470539093\n",
      "Epoch 9, Loss: 0.15526653826236725\n",
      "Epoch 8, Loss: 0.0222387183457613\n",
      "Epoch 10, Loss: 0.13302139937877655\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2712527371692657, feed_forward_dim=512, head_dim=32, lr=0.0007589464348556687, num_heads=2, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.13069894909858704\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2712527371692657, feed_forward_dim=512, head_dim=32, lr=0.0007589464348556687, num_heads=2, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 0.13418789207935333\n",
      "Epoch 10, Loss: 0.20133376121520996\n",
      "Epoch 8, Loss: 0.10880348831415176\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2712527371692657, feed_forward_dim=512, head_dim=32, lr=0.0007589464348556687, num_heads=2, num_layers=2; total time=   1.6s\n",
      "Epoch 9, Loss: 0.034773096442222595\n",
      "Epoch 10, Loss: 0.08863874524831772\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2712527371692657, feed_forward_dim=512, head_dim=32, lr=0.0007589464348556687, num_heads=2, num_layers=2; total time=   1.6s\n",
      "Epoch 9, Loss: 0.026035156100988388\n",
      "Epoch 10, Loss: 0.08881206810474396\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2712527371692657, feed_forward_dim=512, head_dim=32, lr=0.0007589464348556687, num_heads=2, num_layers=2; total time=   1.7s\n",
      "Epoch 10, Loss: 0.012024490162730217\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.2712527371692657, feed_forward_dim=512, head_dim=32, lr=0.0007589464348556687, num_heads=2, num_layers=2; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.21412666141986847\n",
      "Epoch 1, Loss: 1.1142776012420654\n",
      "Epoch 1, Loss: 0.21988171339035034\n",
      "Epoch 1, Loss: 0.07049078494310379\n",
      "Epoch 2, Loss: 0.24228577315807343\n",
      "Epoch 1, Loss: 0.8707378506660461\n",
      "Epoch 2, Loss: 0.1980159878730774\n",
      "Epoch 1, Loss: 0.9219844341278076\n",
      "Epoch 1, Loss: 0.3680253028869629\n",
      "Epoch 2, Loss: 0.2232564240694046\n",
      "Epoch 1, Loss: 1.035287618637085\n",
      "Epoch 2, Loss: 0.2240077406167984\n",
      "Epoch 3, Loss: 0.14477090537548065\n",
      "Epoch 1, Loss: 4.316277980804443\n",
      "Epoch 3, Loss: 0.08114095777273178\n",
      "Epoch 2, Loss: 0.14015033841133118\n",
      "Epoch 3, Loss: 0.17384591698646545\n",
      "Epoch 2, Loss: 0.12916024029254913\n",
      "Epoch 1, Loss: 1.6282374858856201\n",
      "Epoch 4, Loss: 0.044081591069698334\n",
      "Epoch 1, Loss: 0.13075029850006104\n",
      "Epoch 2, Loss: 0.07128384709358215\n",
      "Epoch 3, Loss: 0.025569681078195572\n",
      "Epoch 4, Loss: 0.3076096773147583\n",
      "Epoch 3, Loss: 0.3230023980140686\n",
      "Epoch 1, Loss: 3.4693424701690674\n",
      "Epoch 2, Loss: 0.19155097007751465\n",
      "Epoch 2, Loss: 2.068359136581421\n",
      "Epoch 4, Loss: 0.03725063428282738\n",
      "Epoch 3, Loss: 0.10519776493310928\n",
      "Epoch 5, Loss: 0.3880024254322052\n",
      "Epoch 5, Loss: 0.06872648000717163\n",
      "Epoch 2, Loss: 0.21402311325073242\n",
      "Epoch 4, Loss: 0.1310100555419922\n",
      "Epoch 2, Loss: 0.26789742708206177\n",
      "Epoch 3, Loss: 0.18868285417556763\n",
      "Epoch 5, Loss: 0.057297900319099426\n",
      "Epoch 4, Loss: 0.4076697528362274\n",
      "Epoch 3, Loss: 0.07939865440130234\n",
      "Epoch 3, Loss: 0.7030923366546631\n",
      "Epoch 4, Loss: 0.3043433725833893\n",
      "Epoch 5, Loss: 0.11509206146001816\n",
      "Epoch 6, Loss: 0.08646643161773682\n",
      "Epoch 6, Loss: 0.29591280221939087\n",
      "Epoch 2, Loss: 1.4080685377120972\n",
      "Epoch 6, Loss: 0.1082942932844162\n",
      "Epoch 4, Loss: 0.16203464567661285\n",
      "Epoch 3, Loss: 0.08910980075597763\n",
      "Epoch 3, Loss: 0.06933505833148956\n",
      "Epoch 4, Loss: 0.28491634130477905\n",
      "Epoch 5, Loss: 0.2769920229911804\n",
      "Epoch 7, Loss: 0.04500565305352211\n",
      "Epoch 5, Loss: 0.32743406295776367\n",
      "Epoch 6, Loss: 0.030290406197309494\n",
      "Epoch 7, Loss: 0.1585306078195572Epoch 4, Loss: 0.15167991816997528\n",
      "\n",
      "Epoch 7, Loss: 0.07893115282058716\n",
      "Epoch 4, Loss: 0.03918103873729706\n",
      "Epoch 3, Loss: 0.3402806222438812\n",
      "Epoch 6, Loss: 0.12470658123493195\n",
      "Epoch 8, Loss: 0.009701769798994064\n",
      "Epoch 8, Loss: 0.06141725555062294\n",
      "Epoch 5, Loss: 0.06748311221599579\n",
      "Epoch 5, Loss: 0.35628414154052734\n",
      "Epoch 8, Loss: 0.02263045869767666\n",
      "Epoch 6, Loss: 0.21632835268974304\n",
      "Epoch 9, Loss: 0.016471821814775467\n",
      "Epoch 4, Loss: 0.3808518350124359\n",
      "Epoch 7, Loss: 0.015842970460653305\n",
      "Epoch 7, Loss: 0.04977358877658844\n",
      "Epoch 5, Loss: 0.18058180809020996\n",
      "Epoch 9, Loss: 0.031008251011371613\n",
      "Epoch 6, Loss: 0.0169192086905241\n",
      "Epoch 10, Loss: 0.040009837597608566\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.0003879716077441062, num_heads=4, num_layers=4; total time=   1.0s\n",
      "Epoch 5, Loss: 0.07857544720172882\n",
      "Epoch 9, Loss: 0.0136916758492589\n",
      "Epoch 4, Loss: 0.08171699941158295\n",
      "Epoch 7, Loss: 0.10056907683610916\n",
      "Epoch 6, Loss: 0.27841854095458984\n",
      "Epoch 8, Loss: 0.060305237770080566\n",
      "Epoch 8, Loss: 0.07039296627044678\n",
      "Epoch 5, Loss: 0.5081541538238525\n",
      "Epoch 10, Loss: 0.04123484715819359\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.0003879716077441062, num_heads=4, num_layers=4; total time=   1.1s\n",
      "Epoch 7, Loss: 0.03512439504265785\n",
      "Epoch 6, Loss: 0.06986349076032639\n",
      "Epoch 6, Loss: 0.4408538043498993\n",
      "Epoch 10, Loss: 0.05158485844731331\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.0003879716077441062, num_heads=4, num_layers=4; total time=   1.1s\n",
      "Epoch 8, Loss: 0.03455615043640137\n",
      "Epoch 9, Loss: 0.06959973275661469\n",
      "Epoch 7, Loss: 0.15527869760990143\n",
      "Epoch 5, Loss: 0.2519412338733673\n",
      "Epoch 9, Loss: 0.12105512619018555\n",
      "Epoch 10, Loss: 0.03747715428471565\n",
      "Epoch 9, Loss: 0.028215831145644188\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.0003879716077441062, num_heads=4, num_layers=4; total time=   1.2s\n",
      "Epoch 8, Loss: 0.0695967897772789\n",
      "Epoch 6, Loss: 0.4112135171890259\n",
      "Epoch 8, Loss: 0.06393568962812424\n",
      "Epoch 7, Loss: 0.6308256387710571\n",
      "Epoch 7, Loss: 0.025861240923404694\n",
      "Epoch 10, Loss: 0.14738118648529053\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.0003879716077441062, num_heads=4, num_layers=4; total time=   1.2s\n",
      "Epoch 6, Loss: 0.477516233921051\n",
      "Epoch 10, Loss: 0.059213753789663315\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.0003879716077441062, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 9, Loss: 0.07141755521297455\n",
      "Epoch 9, Loss: 0.03314875438809395\n",
      "Epoch 7, Loss: 0.23092645406723022\n",
      "Epoch 8, Loss: 0.008779480122029781\n",
      "Epoch 10, Loss: 0.046917639672756195\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.0003879716077441062, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 8, Loss: 0.6743424534797668\n",
      "Epoch 7, Loss: 0.5866052508354187\n",
      "Epoch 10, Loss: 0.05153404921293259\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.0003879716077441062, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 8, Loss: 0.08559606224298477\n",
      "Epoch 9, Loss: 0.027752824127674103\n",
      "Epoch 9, Loss: 0.6095123291015625\n",
      "Epoch 8, Loss: 0.571243166923523\n",
      "Epoch 9, Loss: 0.01835227571427822\n",
      "Epoch 10, Loss: 0.038893088698387146\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.0003879716077441062, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.4756796658039093\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.0003879716077441062, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Epoch 9, Loss: 0.47273528575897217\n",
      "Epoch 10, Loss: 0.026749182492494583\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.0003879716077441062, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.34399327635765076\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.0003879716077441062, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.012959983199834824\n",
      "Epoch 1, Loss: 0.0668710395693779\n",
      "Epoch 1, Loss: 0.03242771700024605\n",
      "Epoch 1, Loss: 1.9187372922897339\n",
      "Epoch 2, Loss: 0.11602000892162323\n",
      "Epoch 1, Loss: 0.5708177089691162\n",
      "Epoch 1, Loss: 3.102987289428711\n",
      "Epoch 2, Loss: 0.06106806918978691\n",
      "Epoch 1, Loss: 0.6895397901535034\n",
      "Epoch 2, Loss: 0.09800160676240921\n",
      "Epoch 2, Loss: 1.1744608879089355\n",
      "Epoch 1, Loss: 1.2499284744262695\n",
      "Epoch 3, Loss: 0.01616581901907921\n",
      "Epoch 1, Loss: 0.6732003092765808\n",
      "Epoch 1, Loss: 0.1511434018611908\n",
      "Epoch 3, Loss: 0.03227147459983826\n",
      "Epoch 2, Loss: 0.22157970070838928\n",
      "Epoch 3, Loss: 0.026308540254831314\n",
      "Epoch 1, Loss: 1.0460883378982544\n",
      "Epoch 2, Loss: 2.200227737426758\n",
      "Epoch 1, Loss: 0.14869947731494904\n",
      "Epoch 3, Loss: 0.6179227232933044\n",
      "Epoch 2, Loss: 0.6919660568237305\n",
      "Epoch 4, Loss: 0.028094904497265816\n",
      "Epoch 2, Loss: 0.2033873200416565\n",
      "Epoch 2, Loss: 0.23669998347759247\n",
      "Epoch 4, Loss: 0.03585134074091911\n",
      "Epoch 3, Loss: 0.090810127556324\n",
      "Epoch 4, Loss: 0.027365243062376976\n",
      "Epoch 2, Loss: 0.08128047734498978\n",
      "Epoch 3, Loss: 1.4606883525848389\n",
      "Epoch 4, Loss: 0.27223116159439087\n",
      "Epoch 5, Loss: 0.06405912339687347\n",
      "Epoch 2, Loss: 0.5087730288505554\n",
      "Epoch 5, Loss: 0.01903347484767437\n",
      "Epoch 3, Loss: 0.30913716554641724\n",
      "Epoch 2, Loss: 0.027440393343567848\n",
      "Epoch 3, Loss: 0.01952519081532955\n",
      "Epoch 4, Loss: 0.11660812795162201\n",
      "Epoch 5, Loss: 0.051948871463537216\n",
      "Epoch 3, Loss: 0.0853201225399971\n",
      "Epoch 6, Loss: 0.044333316385746\n",
      "Epoch 4, Loss: 0.8993679881095886\n",
      "Epoch 5, Loss: 0.12124868482351303\n",
      "Epoch 6, Loss: 0.013188336975872517\n",
      "Epoch 3, Loss: 0.10171084105968475\n",
      "Epoch 3, Loss: 0.18925230205059052\n",
      "Epoch 7, Loss: 0.015770375728607178\n",
      "Epoch 4, Loss: 0.10711430758237839\n",
      "Epoch 6, Loss: 0.03080705739557743\n",
      "Epoch 4, Loss: 0.05180296301841736\n",
      "Epoch 5, Loss: 0.17712347209453583\n",
      "Epoch 3, Loss: 0.08094706386327744\n",
      "Epoch 4, Loss: 0.14036959409713745\n",
      "Epoch 7, Loss: 0.016944212839007378\n",
      "Epoch 6, Loss: 0.116380974650383\n",
      "Epoch 8, Loss: 0.008469298481941223\n",
      "Epoch 5, Loss: 0.4949074685573578\n",
      "Epoch 7, Loss: 0.011818235740065575\n",
      "Epoch 5, Loss: 0.15585780143737793\n",
      "Epoch 4, Loss: 0.0631292536854744\n",
      "Epoch 6, Loss: 0.19455376267433167\n",
      "Epoch 5, Loss: 0.05686187371611595\n",
      "Epoch 8, Loss: 0.00982590951025486\n",
      "Epoch 9, Loss: 0.023595018312335014\n",
      "Epoch 4, Loss: 0.070905901491642\n",
      "Epoch 7, Loss: 0.18862105906009674\n",
      "Epoch 5, Loss: 0.21836674213409424\n",
      "Epoch 4, Loss: 0.07759615778923035\n",
      "Epoch 10, Loss: 0.033694300800561905\n",
      "Epoch 6, Loss: 0.23408657312393188\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1373231255911999, feed_forward_dim=512, head_dim=16, lr=0.00019544115671583093, num_heads=2, num_layers=1; total time=   1.1s\n",
      "Epoch 8, Loss: 0.016727406531572342\n",
      "Epoch 9, Loss: 0.005926460959017277\n",
      "Epoch 6, Loss: 0.2105967253446579\n",
      "Epoch 7, Loss: 0.1668822467327118\n",
      "Epoch 6, Loss: 0.1083279624581337\n",
      "Epoch 5, Loss: 0.029408227652311325\n",
      "Epoch 8, Loss: 0.26905277371406555\n",
      "Epoch 6, Loss: 0.2324957698583603\n",
      "Epoch 5, Loss: 0.10365349799394608\n",
      "Epoch 10, Loss: 0.009999607689678669\n",
      "Epoch 9, Loss: 0.0292504969984293\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1373231255911999, feed_forward_dim=512, head_dim=16, lr=0.00019544115671583093, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 7, Loss: 0.09809897840023041\n",
      "Epoch 7, Loss: 0.19205017387866974\n",
      "Epoch 5, Loss: 0.03737669065594673\n",
      "Epoch 7, Loss: 0.19016651809215546\n",
      "Epoch 9, Loss: 0.32265812158584595\n",
      "Epoch 8, Loss: 0.1184253990650177\n",
      "Epoch 6, Loss: 0.028094179928302765\n",
      "Epoch 10, Loss: 0.028342949226498604\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1373231255911999, feed_forward_dim=512, head_dim=16, lr=0.00019544115671583093, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 6, Loss: 0.18736830353736877\n",
      "Epoch 8, Loss: 0.05521632358431816\n",
      "Epoch 7, Loss: 0.18200665712356567\n",
      "Epoch 10, Loss: 0.3377552926540375\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1373231255911999, feed_forward_dim=512, head_dim=16, lr=0.00019544115671583093, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 8, Loss: 0.13427777588367462\n",
      "Epoch 9, Loss: 0.07189992070198059\n",
      "Epoch 8, Loss: 0.2434394210577011\n",
      "Epoch 6, Loss: 0.013938473537564278\n",
      "Epoch 9, Loss: 0.08160154521465302\n",
      "Epoch 7, Loss: 0.03432178497314453\n",
      "Epoch 7, Loss: 0.2393711358308792\n",
      "Epoch 9, Loss: 0.06932397931814194\n",
      "Epoch 8, Loss: 0.11313667893409729\n",
      "Epoch 10, Loss: 0.04360044375061989\n",
      "Epoch 9, Loss: 0.2628471851348877\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1373231255911999, feed_forward_dim=512, head_dim=16, lr=0.00019544115671583093, num_heads=2, num_layers=1; total time=   1.6s\n",
      "Epoch 7, Loss: 0.022675320506095886\n",
      "Epoch 10, Loss: 0.14080220460891724\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1373231255911999, feed_forward_dim=512, head_dim=16, lr=0.00019544115671583093, num_heads=2, num_layers=1; total time=   1.6s\n",
      "Epoch 8, Loss: 0.027144329622387886\n",
      "Epoch 10, Loss: 0.02534872107207775\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1373231255911999, feed_forward_dim=512, head_dim=16, lr=0.00019544115671583093, num_heads=2, num_layers=1; total time=   1.6s\n",
      "Epoch 8, Loss: 0.2427912950515747\n",
      "Epoch 10, Loss: 0.24029354751110077\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1373231255911999, feed_forward_dim=512, head_dim=16, lr=0.00019544115671583093, num_heads=2, num_layers=1; total time=   1.6s\n",
      "Epoch 9, Loss: 0.06041954085230827\n",
      "Epoch 8, Loss: 0.038937970995903015\n",
      "Epoch 9, Loss: 0.01104236301034689\n",
      "Epoch 9, Loss: 0.20213429629802704\n",
      "Epoch 10, Loss: 0.03523905575275421\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1373231255911999, feed_forward_dim=512, head_dim=16, lr=0.00019544115671583093, num_heads=2, num_layers=1; total time=   1.8s\n",
      "Epoch 9, Loss: 0.038449231535196304\n",
      "Epoch 10, Loss: 0.0048345462419092655\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1373231255911999, feed_forward_dim=512, head_dim=16, lr=0.00019544115671583093, num_heads=2, num_layers=1; total time=   1.8s\n",
      "Epoch 10, Loss: 0.14632688462734222\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1373231255911999, feed_forward_dim=512, head_dim=16, lr=0.00019544115671583093, num_heads=2, num_layers=1; total time=   1.8s\n",
      "Epoch 10, Loss: 0.02299237623810768\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1373231255911999, feed_forward_dim=512, head_dim=16, lr=0.00019544115671583093, num_heads=2, num_layers=1; total time=   1.8s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.665493905544281\n",
      "Epoch 1, Loss: 0.13850881159305573\n",
      "Epoch 1, Loss: 0.08466371893882751\n",
      "Epoch 1, Loss: 0.058173540979623795\n",
      "Epoch 2, Loss: 0.5423864722251892\n",
      "Epoch 1, Loss: 0.24302856624126434\n",
      "Epoch 2, Loss: 0.08330836147069931\n",
      "Epoch 1, Loss: 0.09137469530105591\n",
      "Epoch 2, Loss: 0.05699603632092476\n",
      "Epoch 1, Loss: 0.4001822769641876\n",
      "Epoch 3, Loss: 0.43113183975219727\n",
      "Epoch 3, Loss: 0.04249822348356247\n",
      "Epoch 1, Loss: 0.0928497314453125\n",
      "Epoch 2, Loss: 0.04653307422995567\n",
      "Epoch 1, Loss: 0.05812390521168709\n",
      "Epoch 3, Loss: 0.04475700110197067\n",
      "Epoch 2, Loss: 0.17521949112415314\n",
      "Epoch 4, Loss: 0.3382895290851593\n",
      "Epoch 1, Loss: 0.1939680278301239\n",
      "Epoch 1, Loss: 0.03878585621714592\n",
      "Epoch 2, Loss: 0.07993599027395248\n",
      "Epoch 4, Loss: 0.02192324958741665\n",
      "Epoch 1, Loss: 0.10109301656484604\n",
      "Epoch 5, Loss: 0.2559525668621063\n",
      "Epoch 2, Loss: 0.3126452565193176\n",
      "Epoch 3, Loss: 0.043073270469903946\n",
      "Epoch 4, Loss: 0.04336908459663391\n",
      "Epoch 2, Loss: 0.08465089648962021\n",
      "Epoch 5, Loss: 0.014231234788894653\n",
      "Epoch 3, Loss: 0.125102698802948\n",
      "Epoch 2, Loss: 0.04904623702168465\n",
      "Epoch 6, Loss: 0.1921882927417755\n",
      "Epoch 3, Loss: 0.07296517491340637\n",
      "Epoch 5, Loss: 0.047688692808151245\n",
      "Epoch 2, Loss: 0.12848927080631256\n",
      "Epoch 3, Loss: 0.2399570643901825\n",
      "Epoch 2, Loss: 0.033964429050683975\n",
      "Epoch 2, Loss: 0.06486392021179199\n",
      "Epoch 4, Loss: 0.041354626417160034\n",
      "Epoch 6, Loss: 0.0174594484269619\n",
      "Epoch 3, Loss: 0.07699929922819138\n",
      "Epoch 7, Loss: 0.14544981718063354\n",
      "Epoch 4, Loss: 0.08770564943552017\n",
      "Epoch 3, Loss: 0.04038747400045395\n",
      "Epoch 6, Loss: 0.04764469340443611\n",
      "Epoch 4, Loss: 0.06516370177268982\n",
      "Epoch 7, Loss: 0.026098348200321198\n",
      "Epoch 5, Loss: 0.03260339796543121\n",
      "Epoch 4, Loss: 0.17801235616207123\n",
      "Epoch 8, Loss: 0.1100926622748375\n",
      "Epoch 3, Loss: 0.08222303539514542\n",
      "Epoch 3, Loss: 0.028264159336686134\n",
      "Epoch 4, Loss: 0.06838592886924744\n",
      "Epoch 7, Loss: 0.04494258388876915\n",
      "Epoch 5, Loss: 0.06644587218761444\n",
      "Epoch 3, Loss: 0.038363270461559296\n",
      "Epoch 8, Loss: 0.03246992826461792\n",
      "Epoch 9, Loss: 0.08676520735025406\n",
      "Epoch 4, Loss: 0.032796233892440796\n",
      "Epoch 5, Loss: 0.056489672511816025\n",
      "Epoch 6, Loss: 0.026591617614030838\n",
      "Epoch 5, Loss: 0.13139241933822632\n",
      "Epoch 10, Loss: 0.07221537828445435\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   1.1s\n",
      "Epoch 9, Loss: 0.037235625088214874\n",
      "Epoch 8, Loss: 0.04070934280753136\n",
      "Epoch 6, Loss: 0.05912486091256142\n",
      "Epoch 4, Loss: 0.058874987065792084\n",
      "Epoch 4, Loss: 0.025543784722685814\n",
      "Epoch 5, Loss: 0.06063462048768997\n",
      "Epoch 10, Loss: 0.03633294254541397\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   1.1s\n",
      "Epoch 7, Loss: 0.024857649579644203\n",
      "Epoch 5, Loss: 0.026854127645492554\n",
      "Epoch 6, Loss: 0.04959873482584953\n",
      "Epoch 4, Loss: 0.02553718164563179\n",
      "Epoch 9, Loss: 0.03520238772034645\n",
      "Epoch 6, Loss: 0.09817840158939362\n",
      "Epoch 7, Loss: 0.05940188467502594\n",
      "Epoch 8, Loss: 0.022500155493617058\n",
      "Epoch 6, Loss: 0.0549088753759861\n",
      "Epoch 5, Loss: 0.05094650387763977\n",
      "Epoch 5, Loss: 0.021583693102002144\n",
      "Epoch 7, Loss: 0.04299560934305191\n",
      "Epoch 10, Loss: 0.030547581613063812\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   1.3s\n",
      "Epoch 6, Loss: 0.020965255796909332\n",
      "Epoch 7, Loss: 0.07695242762565613\n",
      "Epoch 8, Loss: 0.06506870687007904\n",
      "Epoch 5, Loss: 0.021632546558976173\n",
      "Epoch 7, Loss: 0.04861678555607796\n",
      "Epoch 9, Loss: 0.019228829070925713\n",
      "Epoch 6, Loss: 0.018500162288546562\n",
      "Epoch 8, Loss: 0.038678377866744995\n",
      "Epoch 8, Loss: 0.06647466123104095\n",
      "Epoch 6, Loss: 0.05409079045057297\n",
      "Epoch 9, Loss: 0.06718430668115616\n",
      "Epoch 7, Loss: 0.01669635809957981\n",
      "Epoch 10, Loss: 0.017264829948544502\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   1.5s\n",
      "Epoch 8, Loss: 0.043612103909254074\n",
      "Epoch 9, Loss: 0.06361277401447296\n",
      "Epoch 6, Loss: 0.0245559960603714\n",
      "Epoch 10, Loss: 0.07004232704639435\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   1.6s\n",
      "Epoch 7, Loss: 0.06221834570169449\n",
      "Epoch 9, Loss: 0.03370722383260727\n",
      "Epoch 7, Loss: 0.016079910099506378\n",
      "Epoch 9, Loss: 0.037853118032217026\n",
      "Epoch 10, Loss: 0.06623996794223785\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   1.6s\n",
      "Epoch 8, Loss: 0.01285430509597063\n",
      "Epoch 10, Loss: 0.028613770380616188\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   1.7s\n",
      "Epoch 7, Loss: 0.02876446582376957\n",
      "Epoch 8, Loss: 0.014123710803687572\n",
      "Epoch 9, Loss: 0.010024973191320896\n",
      "Epoch 10, Loss: 0.03385047987103462\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   1.7s\n",
      "Epoch 8, Loss: 0.07079271972179413\n",
      "Epoch 9, Loss: 0.013719265349209309\n",
      "Epoch 8, Loss: 0.03248519450426102\n",
      "Epoch 10, Loss: 0.007645179983228445\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   1.8s\n",
      "Epoch 9, Loss: 0.06755063682794571\n",
      "Epoch 10, Loss: 0.013894770294427872\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   1.8s\n",
      "Epoch 9, Loss: 0.03323386237025261\n",
      "Epoch 10, Loss: 0.06608881056308746\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   1.9s\n",
      "Epoch 10, Loss: 0.031153954565525055\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   1.9s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.13369138538837433\n",
      "Epoch 1, Loss: 0.3967624306678772\n",
      "Epoch 1, Loss: 0.6547967195510864\n",
      "Epoch 1, Loss: 1.0716251134872437\n",
      "Epoch 2, Loss: 0.08825807273387909\n",
      "Epoch 1, Loss: 0.10384612530469894\n",
      "Epoch 2, Loss: 0.29136723279953003\n",
      "Epoch 1, Loss: 0.2982889413833618\n",
      "Epoch 2, Loss: 0.5461485385894775\n",
      "Epoch 1, Loss: 1.1108605861663818\n",
      "Epoch 1, Loss: 2.6529715061187744\n",
      "Epoch 3, Loss: 0.05739529803395271\n",
      "Epoch 1, Loss: 1.3835135698318481\n",
      "Epoch 2, Loss: 0.9011369347572327\n",
      "Epoch 2, Loss: 0.060959089547395706\n",
      "Epoch 3, Loss: 0.4459158480167389\n",
      "Epoch 3, Loss: 0.20733003318309784\n",
      "Epoch 1, Loss: 0.25401145219802856\n",
      "Epoch 1, Loss: 0.3087258040904999\n",
      "Epoch 2, Loss: 0.21238473057746887\n",
      "Epoch 2, Loss: 0.9496193528175354\n",
      "Epoch 4, Loss: 0.03871367126703262\n",
      "Epoch 1, Loss: 0.2376783788204193\n",
      "Epoch 4, Loss: 0.3559451997280121\n",
      "Epoch 4, Loss: 0.13682664930820465\n",
      "Epoch 2, Loss: 2.434993267059326\n",
      "Epoch 3, Loss: 0.03619476407766342\n",
      "Epoch 3, Loss: 0.7460619211196899\n",
      "Epoch 2, Loss: 1.1783151626586914\n",
      "Epoch 3, Loss: 0.1459503322839737\n",
      "Epoch 2, Loss: 0.1785636693239212\n",
      "Epoch 5, Loss: 0.03317224979400635\n",
      "Epoch 2, Loss: 0.21428118646144867\n",
      "Epoch 3, Loss: 0.7949992418289185\n",
      "Epoch 5, Loss: 0.28605517745018005\n",
      "Epoch 5, Loss: 0.08178474009037018\n",
      "Epoch 4, Loss: 0.6118555665016174\n",
      "Epoch 4, Loss: 0.023303983733057976\n",
      "Epoch 3, Loss: 2.2256195545196533\n",
      "Epoch 2, Loss: 0.18128076195716858\n",
      "Epoch 6, Loss: 0.035126641392707825\n",
      "Epoch 4, Loss: 0.0966932475566864\n",
      "Epoch 3, Loss: 0.989561140537262\n",
      "Epoch 6, Loss: 0.22027572989463806\n",
      "Epoch 6, Loss: 0.04317507892847061\n",
      "Epoch 4, Loss: 0.6603626012802124\n",
      "Epoch 3, Loss: 0.11456407606601715\n",
      "Epoch 7, Loss: 0.03968453034758568\n",
      "Epoch 5, Loss: 0.02089839056134224\n",
      "Epoch 3, Loss: 0.1421690285205841\n",
      "Epoch 5, Loss: 0.48139533400535583\n",
      "Epoch 7, Loss: 0.018358634784817696\n",
      "Epoch 7, Loss: 0.16906502842903137\n",
      "Epoch 4, Loss: 2.040250301361084\n",
      "Epoch 3, Loss: 0.14612090587615967\n",
      "Epoch 5, Loss: 0.06571939587593079\n",
      "Epoch 5, Loss: 0.5380209684371948\n",
      "Epoch 8, Loss: 0.04287423565983772\n",
      "Epoch 4, Loss: 0.8250065445899963\n",
      "Epoch 6, Loss: 0.3820616900920868\n",
      "Epoch 6, Loss: 0.02501123771071434\n",
      "Epoch 4, Loss: 0.07024922966957092\n",
      "Epoch 8, Loss: 0.00753639405593276\n",
      "Epoch 8, Loss: 0.1245274767279625\n",
      "Epoch 9, Loss: 0.04474543035030365\n",
      "Epoch 6, Loss: 0.0508342869579792\n",
      "Epoch 6, Loss: 0.4293985962867737\n",
      "Epoch 4, Loss: 0.08648695051670074\n",
      "Epoch 4, Loss: 0.12982524931430817\n",
      "Epoch 7, Loss: 0.029617803171277046\n",
      "Epoch 5, Loss: 1.8498575687408447\n",
      "Epoch 7, Loss: 0.28938454389572144\n",
      "Epoch 9, Loss: 0.09466299414634705\n",
      "Epoch 9, Loss: 0.0065314024686813354\n",
      "Epoch 10, Loss: 0.04060978814959526\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=5e-05, num_heads=2, num_layers=4; total time=   1.2s\n",
      "Epoch 7, Loss: 0.049795765429735184\n",
      "Epoch 7, Loss: 0.3332536220550537\n",
      "Epoch 5, Loss: 0.6746225953102112\n",
      "Epoch 5, Loss: 0.0419379286468029\n",
      "Epoch 5, Loss: 0.048692796379327774\n",
      "Epoch 8, Loss: 0.03166051208972931\n",
      "Epoch 10, Loss: 0.013224824331700802\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=5e-05, num_heads=2, num_layers=4; total time=   1.3s\n",
      "Epoch 10, Loss: 0.07384642213582993\n",
      "Epoch 8, Loss: 0.21590285003185272\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=5e-05, num_heads=2, num_layers=4; total time=   1.3s\n",
      "Epoch 5, Loss: 0.12266930937767029\n",
      "Epoch 6, Loss: 1.670534610748291\n",
      "Epoch 8, Loss: 0.2568688690662384\n",
      "Epoch 8, Loss: 0.05708872899413109\n",
      "Epoch 6, Loss: 0.025690579786896706\n",
      "Epoch 6, Loss: 0.5447276830673218\n",
      "Epoch 9, Loss: 0.028982752934098244\n",
      "Epoch 6, Loss: 0.028152575716376305\n",
      "Epoch 9, Loss: 0.16306394338607788\n",
      "Epoch 9, Loss: 0.18957728147506714\n",
      "Epoch 7, Loss: 1.4994564056396484\n",
      "Epoch 9, Loss: 0.06625911593437195\n",
      "Epoch 6, Loss: 0.12127286940813065\n",
      "Epoch 10, Loss: 0.02612175978720188\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=5e-05, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Epoch 7, Loss: 0.022948861122131348\n",
      "Epoch 10, Loss: 0.12389182299375534\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=5e-05, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Epoch 7, Loss: 0.4303314685821533\n",
      "Epoch 7, Loss: 0.020598482340574265\n",
      "Epoch 10, Loss: 0.13933828473091125\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=5e-05, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.07392098754644394\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=5e-05, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Epoch 8, Loss: 1.3414676189422607\n",
      "Epoch 7, Loss: 0.12422081083059311\n",
      "Epoch 8, Loss: 0.026921838521957397\n",
      "Epoch 8, Loss: 0.33889785408973694\n",
      "Epoch 8, Loss: 0.023837927728891373\n",
      "Epoch 9, Loss: 1.192197561264038\n",
      "Epoch 9, Loss: 0.034735057502985\n",
      "Epoch 9, Loss: 0.2619180381298065\n",
      "Epoch 8, Loss: 0.11930544674396515\n",
      "Epoch 9, Loss: 0.03186675161123276\n",
      "Epoch 10, Loss: 1.0545235872268677\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=5e-05, num_heads=2, num_layers=4; total time=   1.7s\n",
      "Epoch 10, Loss: 0.20042546093463898\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=5e-05, num_heads=2, num_layers=4; total time=   1.7s\n",
      "Epoch 10, Loss: 0.043176356703042984\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=5e-05, num_heads=2, num_layers=4; total time=   1.7s\n",
      "Epoch 9, Loss: 0.11124669760465622\n",
      "Epoch 10, Loss: 0.0426202192902565\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=5e-05, num_heads=2, num_layers=4; total time=   1.7s\n",
      "Epoch 10, Loss: 0.1019739955663681\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=16, lr=5e-05, num_heads=2, num_layers=4; total time=   1.8s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.5670211315155029\n",
      "Epoch 1, Loss: 0.22611407935619354\n",
      "Epoch 1, Loss: 0.15701234340667725\n",
      "Epoch 2, Loss: 0.44504207372665405\n",
      "Epoch 1, Loss: 0.8959323167800903\n",
      "Epoch 1, Loss: 0.5428758859634399\n",
      "Epoch 1, Loss: 0.31172582507133484\n",
      "Epoch 2, Loss: 0.18176081776618958\n",
      "Epoch 3, Loss: 0.34379035234451294\n",
      "Epoch 1, Loss: 1.709427833557129\n",
      "Epoch 1, Loss: 0.8648360967636108\n",
      "Epoch 1, Loss: 0.5417223572731018\n",
      "Epoch 2, Loss: 0.1285560131072998\n",
      "Epoch 2, Loss: 0.40302276611328125\n",
      "Epoch 2, Loss: 0.7406803369522095\n",
      "Epoch 3, Loss: 0.15060704946517944\n",
      "Epoch 4, Loss: 0.2533523738384247\n",
      "Epoch 2, Loss: 0.23667684197425842\n",
      "Epoch 1, Loss: 0.5497504472732544\n",
      "Epoch 2, Loss: 1.4509570598602295\n",
      "Epoch 1, Loss: 1.8126282691955566\n",
      "Epoch 3, Loss: 0.29015466570854187\n",
      "Epoch 4, Loss: 0.13166937232017517\n",
      "Epoch 3, Loss: 0.6032782196998596\n",
      "Epoch 2, Loss: 0.7165305018424988\n",
      "Epoch 3, Loss: 0.11409304291009903\n",
      "Epoch 1, Loss: 0.02222602441906929\n",
      "Epoch 2, Loss: 0.4416595995426178\n",
      "Epoch 5, Loss: 0.18105997145175934\n",
      "Epoch 3, Loss: 0.1727205216884613\n",
      "Epoch 2, Loss: 0.4369576573371887\n",
      "Epoch 4, Loss: 0.4864532947540283\n",
      "Epoch 4, Loss: 0.19964271783828735\n",
      "Epoch 5, Loss: 0.12072053551673889\n",
      "Epoch 3, Loss: 1.2220144271850586\n",
      "Epoch 4, Loss: 0.10995609313249588\n",
      "Epoch 3, Loss: 0.5840432643890381\n",
      "Epoch 2, Loss: 1.5583629608154297\n",
      "Epoch 4, Loss: 0.12270096689462662\n",
      "Epoch 6, Loss: 0.12615619599819183\n",
      "Epoch 3, Loss: 0.35976359248161316\n",
      "Epoch 2, Loss: 0.014545859768986702\n",
      "Epoch 5, Loss: 0.38507238030433655\n",
      "Epoch 5, Loss: 0.13223373889923096\n",
      "Epoch 6, Loss: 0.11432977020740509\n",
      "Epoch 5, Loss: 0.10735467821359634\n",
      "Epoch 4, Loss: 1.0067601203918457\n",
      "Epoch 3, Loss: 0.33690571784973145\n",
      "Epoch 7, Loss: 0.08561675250530243\n",
      "Epoch 4, Loss: 0.4621356427669525\n",
      "Epoch 3, Loss: 1.3218066692352295\n",
      "Epoch 5, Loss: 0.09236902743577957\n",
      "Epoch 7, Loss: 0.11267584562301636\n",
      "Epoch 6, Loss: 0.10469205677509308\n",
      "Epoch 6, Loss: 0.2949623167514801\n",
      "Epoch 4, Loss: 0.2933399975299835\n",
      "Epoch 6, Loss: 0.08384998142719269\n",
      "Epoch 8, Loss: 0.05509094521403313\n",
      "Epoch 5, Loss: 0.821747899055481\n",
      "Epoch 5, Loss: 0.35652145743370056\n",
      "Epoch 3, Loss: 0.015722721815109253\n",
      "Epoch 6, Loss: 0.07207784056663513\n",
      "Epoch 8, Loss: 0.10756611824035645\n",
      "Epoch 9, Loss: 0.03914894536137581\n",
      "Epoch 4, Loss: 0.2565140426158905\n",
      "Epoch 7, Loss: 0.22064094245433807\n",
      "Epoch 4, Loss: 1.110600233078003\n",
      "Epoch 7, Loss: 0.09999313950538635\n",
      "Epoch 7, Loss: 0.05705192685127258\n",
      "Epoch 5, Loss: 0.2407471090555191\n",
      "Epoch 6, Loss: 0.6531777381896973\n",
      "Epoch 9, Loss: 0.10220950096845627\n",
      "Epoch 10, Loss: 0.033739082515239716\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21068847959895232, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 7, Loss: 0.06363420188426971\n",
      "Epoch 8, Loss: 0.16664443910121918\n",
      "Epoch 6, Loss: 0.26568639278411865\n",
      "Epoch 8, Loss: 0.09152213484048843\n",
      "Epoch 4, Loss: 0.015335366129875183\n",
      "Epoch 5, Loss: 0.9209964275360107\n",
      "Epoch 7, Loss: 0.5012004375457764\n",
      "Epoch 8, Loss: 0.04573391377925873\n",
      "Epoch 10, Loss: 0.09511037170886993\n",
      "Epoch 5, Loss: 0.1913396269083023\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21068847959895232, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 9, Loss: 0.1237255409359932\n",
      "Epoch 6, Loss: 0.20160163938999176\n",
      "Epoch 9, Loss: 0.08469611406326294\n",
      "Epoch 7, Loss: 0.1943008154630661\n",
      "Epoch 8, Loss: 0.06650225818157196\n",
      "Epoch 8, Loss: 0.37968915700912476\n",
      "Epoch 5, Loss: 0.01216851081699133\n",
      "Epoch 9, Loss: 0.04704779013991356\n",
      "Epoch 6, Loss: 0.7557801008224487\n",
      "Epoch 10, Loss: 0.07559379190206528\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21068847959895232, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 6, Loss: 0.13948220014572144\n",
      "Epoch 7, Loss: 0.17700953781604767\n",
      "Epoch 10, Loss: 0.09223766624927521\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21068847959895232, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 8, Loss: 0.13573814928531647\n",
      "Epoch 9, Loss: 0.0730201005935669\n",
      "Epoch 10, Loss: 0.054632604122161865\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21068847959895232, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 9, Loss: 0.27815723419189453\n",
      "Epoch 7, Loss: 0.6179105639457703\n",
      "Epoch 8, Loss: 0.15985314548015594\n",
      "Epoch 6, Loss: 0.009605555795133114\n",
      "Epoch 7, Loss: 0.10381139814853668\n",
      "Epoch 10, Loss: 0.0798933133482933\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21068847959895232, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=2, num_layers=1; total time=   1.6s\n",
      "Epoch 8, Loss: 0.4887528121471405\n",
      "Epoch 9, Loss: 0.08943984657526016\n",
      "Epoch 10, Loss: 0.19270725548267365\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21068847959895232, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=2, num_layers=1; total time=   1.6s\n",
      "Epoch 9, Loss: 0.15326307713985443\n",
      "Epoch 7, Loss: 0.009252206422388554\n",
      "Epoch 8, Loss: 0.07873933017253876\n",
      "Epoch 10, Loss: 0.055396419018507004\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21068847959895232, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=2, num_layers=1; total time=   1.6s\n",
      "Epoch 9, Loss: 0.38665008544921875\n",
      "Epoch 10, Loss: 0.1520160287618637\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21068847959895232, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=2, num_layers=1; total time=   1.7s\n",
      "Epoch 8, Loss: 0.009723360650241375\n",
      "Epoch 9, Loss: 0.06670890003442764\n",
      "Epoch 10, Loss: 0.3047220706939697\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21068847959895232, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=2, num_layers=1; total time=   1.6s\n",
      "Epoch 10, Loss: 0.06037702411413193\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21068847959895232, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=2, num_layers=1; total time=   1.7s\n",
      "Epoch 9, Loss: 0.009426546283066273\n",
      "Epoch 10, Loss: 0.008575351908802986\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21068847959895232, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=2, num_layers=1; total time=   1.8s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.6197251081466675\n",
      "Epoch 2, Loss: 0.09898766875267029\n",
      "Epoch 1, Loss: 2.379756212234497\n",
      "Epoch 1, Loss: 0.054960280656814575\n",
      "Epoch 1, Loss: 0.19642944633960724\n",
      "Epoch 1, Loss: 1.2643152475357056\n",
      "Epoch 3, Loss: 0.07843499630689621\n",
      "Epoch 1, Loss: 0.4469457268714905\n",
      "Epoch 1, Loss: 0.9049740433692932\n",
      "Epoch 2, Loss: 1.0573492050170898\n",
      "Epoch 2, Loss: 0.19036266207695007\n",
      "Epoch 4, Loss: 0.21613653004169464\n",
      "Epoch 2, Loss: 0.24533411860466003\n",
      "Epoch 1, Loss: 0.23485903441905975\n",
      "Epoch 3, Loss: 0.31011515855789185\n",
      "Epoch 1, Loss: 0.17769043147563934\n",
      "Epoch 2, Loss: 0.09320052713155746\n",
      "Epoch 5, Loss: 0.23176582157611847\n",
      "Epoch 2, Loss: 0.2096530944108963\n",
      "Epoch 1, Loss: 0.16048896312713623\n",
      "Epoch 2, Loss: 0.43047642707824707\n",
      "Epoch 3, Loss: 0.0378316231071949\n",
      "Epoch 1, Loss: 1.6030157804489136\n",
      "Epoch 1, Loss: 0.5439679622650146\n",
      "Epoch 3, Loss: 0.1333508938550949\n",
      "Epoch 2, Loss: 0.2595922350883484\n",
      "Epoch 6, Loss: 0.15287995338439941\n",
      "Epoch 4, Loss: 0.05550035089254379\n",
      "Epoch 3, Loss: 0.17927610874176025\n",
      "Epoch 4, Loss: 0.035441357642412186\n",
      "Epoch 3, Loss: 0.0874394103884697\n",
      "Epoch 3, Loss: 0.11326894164085388\n",
      "Epoch 2, Loss: 0.16794323921203613\n",
      "Epoch 7, Loss: 0.06429143995046616\n",
      "Epoch 2, Loss: 0.05600408837199211\n",
      "Epoch 5, Loss: 0.15288591384887695\n",
      "Epoch 4, Loss: 0.058417994529008865\n",
      "Epoch 2, Loss: 0.05546775460243225\n",
      "Epoch 2, Loss: 0.5479127168655396\n",
      "Epoch 5, Loss: 0.08259377628564835\n",
      "Epoch 4, Loss: 0.22225897014141083\n",
      "Epoch 3, Loss: 0.1629496067762375\n",
      "Epoch 8, Loss: 0.0171992015093565\n",
      "Epoch 4, Loss: 0.11288411915302277\n",
      "Epoch 3, Loss: 0.12363878637552261\n",
      "Epoch 4, Loss: 0.26690465211868286\n",
      "Epoch 3, Loss: 0.12226372212171555\n",
      "Epoch 6, Loss: 0.34774479269981384\n",
      "Epoch 5, Loss: 0.09090138971805573\n",
      "Epoch 6, Loss: 0.0550517737865448\n",
      "Epoch 3, Loss: 0.20540587604045868\n",
      "Epoch 9, Loss: 0.020194564014673233\n",
      "Epoch 5, Loss: 0.15112490952014923\n",
      "Epoch 4, Loss: 0.09377410262823105\n",
      "Epoch 3, Loss: 0.107756108045578\n",
      "Epoch 7, Loss: 0.46729138493537903\n",
      "Epoch 5, Loss: 0.26340609788894653\n",
      "Epoch 5, Loss: 0.32493504881858826\n",
      "Epoch 7, Loss: 0.011773723177611828\n",
      "Epoch 6, Loss: 0.09040592610836029\n",
      "Epoch 10, Loss: 0.05053224787116051\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.27206150900151505, feed_forward_dim=1024, head_dim=32, lr=0.00031592758789012154, num_heads=8, num_layers=3; total time=   1.0s\n",
      "Epoch 4, Loss: 0.05876845493912697\n",
      "Epoch 4, Loss: 0.04950426146388054\n",
      "Epoch 6, Loss: 0.06694844365119934\n",
      "Epoch 8, Loss: 0.47621262073516846\n",
      "Epoch 8, Loss: 0.008771049790084362\n",
      "Epoch 4, Loss: 0.30226534605026245\n",
      "Epoch 6, Loss: 0.3388983905315399\n",
      "Epoch 5, Loss: 0.09904339909553528\n",
      "Epoch 7, Loss: 0.04241150990128517\n",
      "Epoch 6, Loss: 0.26340451836586\n",
      "Epoch 4, Loss: 0.23821522295475006\n",
      "Epoch 9, Loss: 0.40667176246643066\n",
      "Epoch 7, Loss: 0.03335801512002945\n",
      "Epoch 5, Loss: 0.05613480135798454\n",
      "Epoch 9, Loss: 0.03429520130157471\n",
      "Epoch 7, Loss: 0.31886419653892517\n",
      "Epoch 8, Loss: 0.016651110723614693\n",
      "Epoch 5, Loss: 0.009758412837982178\n",
      "Epoch 6, Loss: 0.08901360630989075\n",
      "Epoch 5, Loss: 0.4446459710597992\n",
      "Epoch 7, Loss: 0.15835770964622498\n",
      "Epoch 10, Loss: 0.2957626283168793\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.27206150900151505, feed_forward_dim=1024, head_dim=32, lr=0.00031592758789012154, num_heads=8, num_layers=3; total time=   1.2s\n",
      "Epoch 10, Loss: 0.0424257330596447\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.27206150900151505, feed_forward_dim=1024, head_dim=32, lr=0.00031592758789012154, num_heads=8, num_layers=3; total time=   1.2s\n",
      "Epoch 5, Loss: 0.20573993027210236\n",
      "Epoch 8, Loss: 0.05099424347281456\n",
      "Epoch 8, Loss: 0.23975828289985657\n",
      "Epoch 7, Loss: 0.05146763101220131\n",
      "Epoch 9, Loss: 0.028560765087604523\n",
      "Epoch 6, Loss: 0.03666549548506737\n",
      "Epoch 6, Loss: 0.46488311886787415\n",
      "Epoch 8, Loss: 0.07575381547212601\n",
      "Epoch 6, Loss: 0.06240389123558998\n",
      "Epoch 9, Loss: 0.07910227030515671\n",
      "Epoch 6, Loss: 0.10178915411233902\n",
      "Epoch 8, Loss: 0.028982076793909073\n",
      "Epoch 9, Loss: 0.15287521481513977\n",
      "Epoch 10, Loss: 0.04364803805947304\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.27206150900151505, feed_forward_dim=1024, head_dim=32, lr=0.00031592758789012154, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 7, Loss: 0.37896865606307983\n",
      "Epoch 9, Loss: 0.04366333410143852\n",
      "Epoch 10, Loss: 0.08052974194288254\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.27206150900151505, feed_forward_dim=1024, head_dim=32, lr=0.00031592758789012154, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 7, Loss: 0.06069790944457054\n",
      "Epoch 7, Loss: 0.02821298874914646\n",
      "Epoch 10, Loss: 0.08417357504367828\n",
      "Epoch 9, Loss: 0.03441770002245903\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.27206150900151505, feed_forward_dim=1024, head_dim=32, lr=0.00031592758789012154, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Epoch 7, Loss: 0.03942896053195\n",
      "Epoch 8, Loss: 0.2532673180103302\n",
      "Epoch 8, Loss: 0.04461676999926567\n",
      "Epoch 10, Loss: 0.05251479893922806\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.27206150900151505, feed_forward_dim=1024, head_dim=32, lr=0.00031592758789012154, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.039340000599622726\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.27206150900151505, feed_forward_dim=1024, head_dim=32, lr=0.00031592758789012154, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Epoch 8, Loss: 0.021860536187887192\n",
      "Epoch 8, Loss: 0.0157597865909338\n",
      "Epoch 9, Loss: 0.014989806339144707\n",
      "Epoch 9, Loss: 0.1409785896539688\n",
      "Epoch 9, Loss: 0.018133658915758133\n",
      "Epoch 9, Loss: 0.05678461119532585\n",
      "Epoch 10, Loss: 0.008988931775093079\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.27206150900151505, feed_forward_dim=1024, head_dim=32, lr=0.00031592758789012154, num_heads=8, num_layers=3; total time=   1.6s\n",
      "Epoch 10, Loss: 0.07012486457824707\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.27206150900151505, feed_forward_dim=1024, head_dim=32, lr=0.00031592758789012154, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.02843167632818222\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.27206150900151505, feed_forward_dim=1024, head_dim=32, lr=0.00031592758789012154, num_heads=8, num_layers=3; total time=   1.6s\n",
      "Epoch 10, Loss: 0.08944951742887497\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.27206150900151505, feed_forward_dim=1024, head_dim=32, lr=0.00031592758789012154, num_heads=8, num_layers=3; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.17222468554973602\n",
      "Epoch 1, Loss: 0.04573936015367508\n",
      "Epoch 1, Loss: 0.4670368432998657\n",
      "Epoch 1, Loss: 0.07049780339002609\n",
      "Epoch 2, Loss: 0.09308183193206787\n",
      "Epoch 1, Loss: 0.6563776135444641\n",
      "Epoch 1, Loss: 0.3410951495170593\n",
      "Epoch 2, Loss: 0.03411503881216049\n",
      "Epoch 1, Loss: 0.08244007080793381\n",
      "Epoch 3, Loss: 0.06060822308063507\n",
      "Epoch 2, Loss: 0.05452887713909149\n",
      "Epoch 1, Loss: 2.372058629989624\n",
      "Epoch 2, Loss: 0.30692359805107117\n",
      "Epoch 1, Loss: 0.025641033425927162\n",
      "Epoch 3, Loss: 0.02281547337770462\n",
      "Epoch 2, Loss: 0.4360106289386749\n",
      "Epoch 2, Loss: 0.198328897356987\n",
      "Epoch 1, Loss: 0.13812194764614105\n",
      "Epoch 2, Loss: 0.06921172142028809\n",
      "Epoch 1, Loss: 0.20163612067699432\n",
      "Epoch 4, Loss: 0.06123223900794983\n",
      "Epoch 3, Loss: 0.1845100224018097\n",
      "Epoch 3, Loss: 0.05210186168551445\n",
      "Epoch 1, Loss: 0.14801685512065887\n",
      "Epoch 2, Loss: 1.912319302558899\n",
      "Epoch 3, Loss: 0.09882901608943939\n",
      "Epoch 4, Loss: 0.017153941094875336\n",
      "Epoch 2, Loss: 0.013663467019796371\n",
      "Epoch 3, Loss: 0.05833084508776665\n",
      "Epoch 4, Loss: 0.10662482678890228\n",
      "Epoch 2, Loss: 0.12241464108228683\n",
      "Epoch 5, Loss: 0.06754717975854874\n",
      "Epoch 2, Loss: 0.08306236565113068\n",
      "Epoch 3, Loss: 0.27071666717529297\n",
      "Epoch 4, Loss: 0.0397726334631443\n",
      "Epoch 4, Loss: 0.03927364572882652\n",
      "Epoch 5, Loss: 0.06586597859859467\n",
      "Epoch 3, Loss: 1.521992802619934\n",
      "Epoch 2, Loss: 0.0845739021897316\n",
      "Epoch 6, Loss: 0.06912454217672348\n",
      "Epoch 5, Loss: 0.012467434629797935\n",
      "Epoch 4, Loss: 0.048825912177562714\n",
      "Epoch 3, Loss: 0.019292496144771576\n",
      "Epoch 5, Loss: 0.029867522418498993\n",
      "Epoch 3, Loss: 0.08473873138427734\n",
      "Epoch 3, Loss: 0.06716891378164291\n",
      "Epoch 7, Loss: 0.0567672997713089\n",
      "Epoch 5, Loss: 0.0163617804646492\n",
      "Epoch 6, Loss: 0.05610434710979462\n",
      "Epoch 4, Loss: 1.1588783264160156\n",
      "Epoch 6, Loss: 0.008652493357658386\n",
      "Epoch 4, Loss: 0.14729079604148865\n",
      "Epoch 5, Loss: 0.0396832637488842\n",
      "Epoch 3, Loss: 0.06499473750591278\n",
      "Epoch 8, Loss: 0.04328934848308563\n",
      "Epoch 6, Loss: 0.026628833264112473\n",
      "Epoch 7, Loss: 0.06793692708015442\n",
      "Epoch 7, Loss: 0.008050333708524704\n",
      "Epoch 6, Loss: 0.020521167665719986\n",
      "Epoch 4, Loss: 0.014723558910191059\n",
      "Epoch 4, Loss: 0.07823339849710464\n",
      "Epoch 5, Loss: 0.0715179368853569\n",
      "Epoch 5, Loss: 0.856957733631134\n",
      "Epoch 4, Loss: 0.0687747597694397\n",
      "Epoch 9, Loss: 0.0303792767226696\n",
      "Epoch 8, Loss: 0.087143674492836\n",
      "Epoch 7, Loss: 0.025265146046876907\n",
      "Epoch 8, Loss: 0.008298761211335659\n",
      "Epoch 6, Loss: 0.032556649297475815\n",
      "Epoch 4, Loss: 0.06942125409841537\n",
      "Epoch 5, Loss: 0.08265441656112671\n",
      "Epoch 7, Loss: 0.038393471390008926\n",
      "Epoch 5, Loss: 0.00900463480502367\n",
      "Epoch 7, Loss: 0.02550508640706539\n",
      "Epoch 9, Loss: 0.10128689557313919\n",
      "Epoch 6, Loss: 0.5993232131004333\n",
      "Epoch 9, Loss: 0.008994543924927711\n",
      "Epoch 10, Loss: 0.02051958255469799\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.34477006760540596, feed_forward_dim=128, head_dim=32, lr=8.663525095363109e-05, num_heads=2, num_layers=3; total time=   1.0s\n",
      "Epoch 8, Loss: 0.02002626843750477\n",
      "Epoch 6, Loss: 0.03701344504952431\n",
      "Epoch 5, Loss: 0.06886769831180573\n",
      "Epoch 8, Loss: 0.060925401747226715\n",
      "Epoch 10, Loss: 0.01034921407699585\n",
      "Epoch 10, Loss: 0.11018180102109909\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.34477006760540596, feed_forward_dim=128, head_dim=32, lr=8.663525095363109e-05, num_heads=2, num_layers=3; total time=   1.1s\n",
      "Epoch 5, Loss: 0.07538099586963654\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.34477006760540596, feed_forward_dim=128, head_dim=32, lr=8.663525095363109e-05, num_heads=2, num_layers=3; total time=   1.1s\n",
      "Epoch 8, Loss: 0.02053464762866497\n",
      "Epoch 9, Loss: 0.016668429598212242\n",
      "Epoch 7, Loss: 0.03004947118461132\n",
      "Epoch 6, Loss: 0.009125575423240662\n",
      "Epoch 7, Loss: 0.4019447863101959\n",
      "Epoch 6, Loss: 0.08145412802696228\n",
      "Epoch 9, Loss: 0.07388007640838623\n",
      "Epoch 10, Loss: 0.015866225585341454\n",
      "Epoch 6, Loss: 0.06053726747632027\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.34477006760540596, feed_forward_dim=128, head_dim=32, lr=8.663525095363109e-05, num_heads=2, num_layers=3; total time=   1.2s\n",
      "Epoch 9, Loss: 0.016307557001709938\n",
      "Epoch 8, Loss: 0.04538942128419876\n",
      "Epoch 8, Loss: 0.24869607388973236\n",
      "Epoch 6, Loss: 0.07076620310544968\n",
      "Epoch 7, Loss: 0.011551011353731155\n",
      "Epoch 7, Loss: 0.07480324804782867\n",
      "Epoch 9, Loss: 0.06982681900262833\n",
      "Epoch 7, Loss: 0.04770295321941376\n",
      "Epoch 10, Loss: 0.07579543441534042\n",
      "Epoch 10, Loss: 0.01340638380497694\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.34477006760540596, feed_forward_dim=128, head_dim=32, lr=8.663525095363109e-05, num_heads=2, num_layers=3; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.34477006760540596, feed_forward_dim=128, head_dim=32, lr=8.663525095363109e-05, num_heads=2, num_layers=3; total time=   1.3s\n",
      "Epoch 9, Loss: 0.1372142881155014\n",
      "Epoch 8, Loss: 0.009861113503575325\n",
      "Epoch 8, Loss: 0.06016060337424278\n",
      "Epoch 7, Loss: 0.05786117911338806\n",
      "Epoch 10, Loss: 0.09437646716833115\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.34477006760540596, feed_forward_dim=128, head_dim=32, lr=8.663525095363109e-05, num_heads=2, num_layers=3; total time=   1.3s\n",
      "Epoch 10, Loss: 0.06623801589012146\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.34477006760540596, feed_forward_dim=128, head_dim=32, lr=8.663525095363109e-05, num_heads=2, num_layers=3; total time=   1.4s\n",
      "Epoch 8, Loss: 0.03369947895407677\n",
      "Epoch 9, Loss: 0.007207312621176243\n",
      "Epoch 9, Loss: 0.04608996957540512\n",
      "Epoch 8, Loss: 0.04470169171690941\n",
      "Epoch 10, Loss: 0.005542318802326918\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.34477006760540596, feed_forward_dim=128, head_dim=32, lr=8.663525095363109e-05, num_heads=2, num_layers=3; total time=   1.4s\n",
      "Epoch 10, Loss: 0.03339318558573723\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.34477006760540596, feed_forward_dim=128, head_dim=32, lr=8.663525095363109e-05, num_heads=2, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.024496598169207573\n",
      "Epoch 9, Loss: 0.03432197868824005\n",
      "Epoch 10, Loss: 0.022736163809895515\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.34477006760540596, feed_forward_dim=128, head_dim=32, lr=8.663525095363109e-05, num_heads=2, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.029200319200754166\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.34477006760540596, feed_forward_dim=128, head_dim=32, lr=8.663525095363109e-05, num_heads=2, num_layers=3; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.2203386276960373\n",
      "Epoch 1, Loss: 0.9751054048538208\n",
      "Epoch 1, Loss: 0.6015478372573853\n",
      "Epoch 1, Loss: 0.02333269640803337\n",
      "Epoch 1, Loss: 0.15181556344032288\n",
      "Epoch 1, Loss: 0.1959221065044403\n",
      "Epoch 2, Loss: 0.11796875298023224\n",
      "Epoch 2, Loss: 0.407630980014801\n",
      "Epoch 1, Loss: 2.020853281021118\n",
      "Epoch 2, Loss: 0.6862710118293762\n",
      "Epoch 1, Loss: 0.3726010322570801\n",
      "Epoch 2, Loss: 0.024068601429462433\n",
      "Epoch 3, Loss: 0.26220816373825073\n",
      "Epoch 3, Loss: 0.05516225844621658\n",
      "Epoch 2, Loss: 0.10088975727558136\n",
      "Epoch 2, Loss: 0.1049182191491127\n",
      "Epoch 3, Loss: 0.45002976059913635\n",
      "Epoch 2, Loss: 1.58745276927948\n",
      "Epoch 1, Loss: 0.46828940510749817\n",
      "Epoch 3, Loss: 0.01457919180393219\n",
      "Epoch 4, Loss: 0.02903398498892784\n",
      "Epoch 4, Loss: 0.15524034202098846\n",
      "Epoch 3, Loss: 0.06006845086812973\n",
      "Epoch 4, Loss: 0.27943140268325806\n",
      "Epoch 3, Loss: 0.09157893806695938\n",
      "Epoch 2, Loss: 0.2323543131351471\n",
      "Epoch 3, Loss: 1.2204769849777222\n",
      "Epoch 4, Loss: 0.014423071406781673\n",
      "Epoch 5, Loss: 0.029883593320846558\n",
      "Epoch 2, Loss: 0.26597920060157776\n",
      "Epoch 5, Loss: 0.0894969180226326\n",
      "Epoch 5, Loss: 0.15227782726287842\n",
      "Epoch 4, Loss: 0.06073316931724548\n",
      "Epoch 6, Loss: 0.04444209858775139\n",
      "Epoch 4, Loss: 0.09281015396118164\n",
      "Epoch 6, Loss: 0.062339503318071365\n",
      "Epoch 5, Loss: 0.011745356023311615\n",
      "Epoch 1, Loss: 0.7452712059020996\n",
      "Epoch 4, Loss: 0.8984549641609192\n",
      "Epoch 3, Loss: 0.1371152698993683\n",
      "Epoch 1, Loss: 0.15551979839801788\n",
      "Epoch 6, Loss: 0.07673391699790955\n",
      "Epoch 1, Loss: 0.024035155773162842\n",
      "Epoch 5, Loss: 0.08948338031768799\n",
      "Epoch 7, Loss: 0.058885373175144196\n",
      "Epoch 5, Loss: 0.0739520788192749\n",
      "Epoch 3, Loss: 0.1304667890071869\n",
      "Epoch 7, Loss: 0.06543392688035965\n",
      "Epoch 4, Loss: 0.07785174250602722\n",
      "Epoch 6, Loss: 0.008654849603772163\n",
      "Epoch 7, Loss: 0.04432077705860138\n",
      "Epoch 5, Loss: 0.6347796320915222\n",
      "Epoch 2, Loss: 0.5113334059715271\n",
      "Epoch 8, Loss: 0.065078504383564\n",
      "Epoch 6, Loss: 0.08001059293746948\n",
      "Epoch 8, Loss: 0.08638624846935272\n",
      "Epoch 6, Loss: 0.08247125893831253\n",
      "Epoch 2, Loss: 0.11043153703212738\n",
      "Epoch 2, Loss: 0.018712546676397324\n",
      "Epoch 7, Loss: 0.007524785120040178\n",
      "Epoch 8, Loss: 0.042562395334243774\n",
      "Epoch 4, Loss: 0.061729468405246735\n",
      "Epoch 9, Loss: 0.06357288360595703\n",
      "Epoch 6, Loss: 0.4316093921661377\n",
      "Epoch 9, Loss: 0.11094503104686737\n",
      "Epoch 7, Loss: 0.06982976943254471\n",
      "Epoch 5, Loss: 0.052138857543468475\n",
      "Epoch 7, Loss: 0.0680265873670578\n",
      "Epoch 10, Loss: 0.05463916063308716\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.10697864752574618, feed_forward_dim=512, head_dim=16, lr=8.943672562223213e-05, num_heads=2, num_layers=3; total time=   1.0s\n",
      "Epoch 3, Loss: 0.32232043147087097\n",
      "Epoch 9, Loss: 0.06197941303253174\n",
      "Epoch 10, Loss: 0.1258745789527893\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.10697864752574618, feed_forward_dim=512, head_dim=16, lr=8.943672562223213e-05, num_heads=2, num_layers=3; total time=   1.0s\n",
      "Epoch 3, Loss: 0.10623440891504288\n",
      "Epoch 8, Loss: 0.008128592744469643\n",
      "Epoch 7, Loss: 0.27337443828582764\n",
      "Epoch 8, Loss: 0.05475950241088867\n",
      "Epoch 6, Loss: 0.05184296518564224\n",
      "Epoch 8, Loss: 0.05654276907444\n",
      "Epoch 3, Loss: 0.012518361210823059\n",
      "Epoch 5, Loss: 0.04406668245792389\n",
      "Epoch 10, Loss: 0.08947241306304932\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.10697864752574618, feed_forward_dim=512, head_dim=16, lr=8.943672562223213e-05, num_heads=2, num_layers=3; total time=   1.1s\n",
      "Epoch 4, Loss: 0.1839413195848465\n",
      "Epoch 9, Loss: 0.0070480178110301495\n",
      "Epoch 8, Loss: 0.17020821571350098\n",
      "Epoch 9, Loss: 0.03953036293387413\n",
      "Epoch 7, Loss: 0.06506998836994171\n",
      "Epoch 9, Loss: 0.04831624776124954\n",
      "Epoch 10, Loss: 0.006656479090452194\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.10697864752574618, feed_forward_dim=512, head_dim=16, lr=8.943672562223213e-05, num_heads=2, num_layers=3; total time=   1.2s\n",
      "Epoch 4, Loss: 0.09614241868257523\n",
      "Epoch 6, Loss: 0.060079775750637054\n",
      "Epoch 4, Loss: 0.010197670198976994\n",
      "Epoch 9, Loss: 0.10576274245977402\n",
      "Epoch 10, Loss: 0.027550069615244865\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.10697864752574618, feed_forward_dim=512, head_dim=16, lr=8.943672562223213e-05, num_heads=2, num_layers=3; total time=   1.2s\n",
      "Epoch 5, Loss: 0.10155095160007477\n",
      "Epoch 8, Loss: 0.08146189153194427\n",
      "Epoch 7, Loss: 0.08966070413589478\n",
      "Epoch 10, Loss: 0.04534795135259628\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.10697864752574618, feed_forward_dim=512, head_dim=16, lr=8.943672562223213e-05, num_heads=2, num_layers=3; total time=   1.3s\n",
      "Epoch 10, Loss: 0.07693582773208618\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.10697864752574618, feed_forward_dim=512, head_dim=16, lr=8.943672562223213e-05, num_heads=2, num_layers=3; total time=   1.3s\n",
      "Epoch 5, Loss: 0.07650824636220932\n",
      "Epoch 5, Loss: 0.006897029001265764\n",
      "Epoch 6, Loss: 0.06056974083185196\n",
      "Epoch 9, Loss: 0.08785276859998703\n",
      "Epoch 8, Loss: 0.11253073066473007\n",
      "Epoch 6, Loss: 0.05713599547743797\n",
      "Epoch 6, Loss: 0.005965040065348148\n",
      "Epoch 7, Loss: 0.05559667944908142\n",
      "Epoch 10, Loss: 0.09055981785058975\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.10697864752574618, feed_forward_dim=512, head_dim=16, lr=8.943672562223213e-05, num_heads=2, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.11638840287923813\n",
      "Epoch 7, Loss: 0.04409275949001312\n",
      "Epoch 8, Loss: 0.07405644655227661\n",
      "Epoch 7, Loss: 0.0052626715041697025\n",
      "Epoch 10, Loss: 0.1101963147521019\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.10697864752574618, feed_forward_dim=512, head_dim=16, lr=8.943672562223213e-05, num_heads=2, num_layers=3; total time=   1.5s\n",
      "Epoch 8, Loss: 0.040711697190999985\n",
      "Epoch 9, Loss: 0.10134117305278778\n",
      "Epoch 8, Loss: 0.004384458996355534\n",
      "Epoch 9, Loss: 0.03657216578722\n",
      "Epoch 10, Loss: 0.12729193270206451\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.10697864752574618, feed_forward_dim=512, head_dim=16, lr=8.943672562223213e-05, num_heads=2, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.005891348700970411\n",
      "Epoch 10, Loss: 0.02998877316713333\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.10697864752574618, feed_forward_dim=512, head_dim=16, lr=8.943672562223213e-05, num_heads=2, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.005801017861813307\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.10697864752574618, feed_forward_dim=512, head_dim=16, lr=8.943672562223213e-05, num_heads=2, num_layers=3; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.42691174149513245\n",
      "Epoch 1, Loss: 2.8967368602752686\n",
      "Epoch 1, Loss: 0.11203823983669281\n",
      "Epoch 2, Loss: 0.9699251651763916\n",
      "Epoch 2, Loss: 2.072054147720337\n",
      "Epoch 1, Loss: 0.11601049453020096\n",
      "Epoch 1, Loss: 0.2148900032043457\n",
      "Epoch 1, Loss: 1.4474091529846191\n",
      "Epoch 2, Loss: 4.791252136230469\n",
      "Epoch 3, Loss: 0.9800558686256409\n",
      "Epoch 3, Loss: 0.6657013893127441\n",
      "Epoch 1, Loss: 0.6150994896888733\n",
      "Epoch 1, Loss: 0.055043600499629974\n",
      "Epoch 2, Loss: 4.202827453613281\n",
      "Epoch 2, Loss: 5.899537563323975\n",
      "Epoch 3, Loss: 0.7015034556388855\n",
      "Epoch 4, Loss: 0.27020028233528137\n",
      "Epoch 1, Loss: 0.23177698254585266\n",
      "Epoch 2, Loss: 3.1013925075531006\n",
      "Epoch 1, Loss: 0.47350063920021057\n",
      "Epoch 4, Loss: 0.05318973585963249\n",
      "Epoch 2, Loss: 3.6446900367736816\n",
      "Epoch 1, Loss: 0.29090869426727295\n",
      "Epoch 4, Loss: 0.2682914137840271\n",
      "Epoch 3, Loss: 0.7927253842353821\n",
      "Epoch 1, Loss: 0.018887879326939583\n",
      "Epoch 3, Loss: 1.4721853733062744\n",
      "Epoch 2, Loss: 6.3340535163879395\n",
      "Epoch 3, Loss: 1.4285110235214233\n",
      "Epoch 5, Loss: 0.2232326716184616\n",
      "Epoch 5, Loss: 0.037589289247989655\n",
      "Epoch 5, Loss: 0.9163022041320801\n",
      "Epoch 2, Loss: 3.218428373336792\n",
      "Epoch 3, Loss: 1.2525591850280762\n",
      "Epoch 2, Loss: 3.1559364795684814\n",
      "Epoch 4, Loss: 0.0365193635225296\n",
      "Epoch 4, Loss: 0.1216442808508873\n",
      "Epoch 6, Loss: 0.3539130687713623\n",
      "Epoch 2, Loss: 4.491435527801514\n",
      "Epoch 6, Loss: 0.2001766711473465\n",
      "Epoch 3, Loss: 0.9186513423919678\n",
      "Epoch 4, Loss: 0.2228955328464508\n",
      "Epoch 6, Loss: 0.7490946650505066\n",
      "Epoch 2, Loss: 4.215927600860596\n",
      "Epoch 5, Loss: 0.6351092457771301\n",
      "Epoch 3, Loss: 0.7375466227531433\n",
      "Epoch 4, Loss: 0.05337304249405861\n",
      "Epoch 4, Loss: 0.5030996203422546\n",
      "Epoch 7, Loss: 0.2715506851673126\n",
      "Epoch 3, Loss: 1.0648536682128906\n",
      "Epoch 7, Loss: 0.3320066034793854\n",
      "Epoch 5, Loss: 0.7344767451286316\n",
      "Epoch 3, Loss: 1.0326114892959595\n",
      "Epoch 7, Loss: 0.32629111409187317\n",
      "Epoch 5, Loss: 0.07032670080661774\n",
      "Epoch 6, Loss: 0.8375797867774963\n",
      "Epoch 3, Loss: 0.10214976966381073\n",
      "Epoch 8, Loss: 0.1275748312473297\n",
      "Epoch 8, Loss: 0.29317280650138855\n",
      "Epoch 5, Loss: 0.3081030547618866\n",
      "Epoch 8, Loss: 0.06722894310951233\n",
      "Epoch 5, Loss: 1.2943564653396606\n",
      "Epoch 4, Loss: 0.05687982216477394\n",
      "Epoch 4, Loss: 0.020053669810295105\n",
      "Epoch 6, Loss: 0.672516405582428\n",
      "Epoch 7, Loss: 0.5546553134918213\n",
      "Epoch 6, Loss: 0.3245183527469635\n",
      "Epoch 9, Loss: 0.16863113641738892\n",
      "Epoch 9, Loss: 0.04928537458181381\n",
      "Epoch 4, Loss: 0.04609290137887001\n",
      "Epoch 4, Loss: 1.7981847524642944\n",
      "Epoch 9, Loss: 0.06678491830825806\n",
      "Epoch 7, Loss: 0.3092884421348572\n",
      "Epoch 10, Loss: 0.06569531559944153\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.10077460895082511, feed_forward_dim=512, head_dim=16, lr=0.0017346753072372864, num_heads=2, num_layers=1; total time=   1.1s\n",
      "Epoch 8, Loss: 0.2211070954799652\n",
      "Epoch 6, Loss: 0.8225159645080566\n",
      "Epoch 6, Loss: 0.6385200619697571\n",
      "Epoch 5, Loss: 0.3825434148311615\n",
      "Epoch 5, Loss: 0.3131611943244934\n",
      "Epoch 10, Loss: 0.053309399634599686\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.10077460895082511, feed_forward_dim=512, head_dim=16, lr=0.0017346753072372864, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 10, Loss: 0.1887112706899643\n",
      "Epoch 7, Loss: 0.4352743625640869\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.10077460895082511, feed_forward_dim=512, head_dim=16, lr=0.0017346753072372864, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 8, Loss: 0.06834999471902847\n",
      "Epoch 9, Loss: 0.05194864794611931\n",
      "Epoch 5, Loss: 1.1442854404449463\n",
      "Epoch 7, Loss: 0.5445051789283752\n",
      "Epoch 5, Loss: 0.6157296895980835\n",
      "Epoch 6, Loss: 0.551491916179657\n",
      "Epoch 8, Loss: 0.3469148278236389\n",
      "Epoch 7, Loss: 0.2421513944864273\n",
      "Epoch 6, Loss: 0.4956890642642975\n",
      "Epoch 9, Loss: 0.04456150159239769\n",
      "Epoch 10, Loss: 0.0649469643831253\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.10077460895082511, feed_forward_dim=512, head_dim=16, lr=0.0017346753072372864, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 8, Loss: 0.283480167388916\n",
      "Epoch 6, Loss: 0.30415844917297363\n",
      "Epoch 6, Loss: 0.7561303973197937\n",
      "Epoch 9, Loss: 0.1879914551973343\n",
      "Epoch 7, Loss: 0.40878286957740784\n",
      "Epoch 10, Loss: 0.1385030895471573\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.10077460895082511, feed_forward_dim=512, head_dim=16, lr=0.0017346753072372864, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 8, Loss: 0.03205013647675514\n",
      "Epoch 7, Loss: 0.3134051263332367\n",
      "Epoch 9, Loss: 0.08266907930374146\n",
      "Epoch 10, Loss: 0.06829414516687393\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.10077460895082511, feed_forward_dim=512, head_dim=16, lr=0.0017346753072372864, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 7, Loss: 0.02356301061809063\n",
      "Epoch 9, Loss: 0.13999804854393005\n",
      "Epoch 7, Loss: 0.46988171339035034\n",
      "Epoch 8, Loss: 0.11601822078227997\n",
      "Epoch 8, Loss: 0.1768830418586731\n",
      "Epoch 10, Loss: 0.028643565252423286\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.10077460895082511, feed_forward_dim=512, head_dim=16, lr=0.0017346753072372864, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 8, Loss: 0.0937974750995636\n",
      "Epoch 9, Loss: 0.033935949206352234\n",
      "Epoch 10, Loss: 0.3039827346801758\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.10077460895082511, feed_forward_dim=512, head_dim=16, lr=0.0017346753072372864, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 9, Loss: 0.053514931350946426\n",
      "Epoch 8, Loss: 0.1661279946565628\n",
      "Epoch 9, Loss: 0.23010100424289703\n",
      "Epoch 10, Loss: 0.0740487352013588\n",
      "Epoch 10, Loss: 0.06855236738920212\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.10077460895082511, feed_forward_dim=512, head_dim=16, lr=0.0017346753072372864, num_heads=2, num_layers=1; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.10077460895082511, feed_forward_dim=512, head_dim=16, lr=0.0017346753072372864, num_heads=2, num_layers=1; total time=   1.6s\n",
      "Epoch 9, Loss: 0.040588680654764175\n",
      "Epoch 10, Loss: 0.2830286920070648\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.10077460895082511, feed_forward_dim=512, head_dim=16, lr=0.0017346753072372864, num_heads=2, num_layers=1; total time=   1.7s\n",
      "Epoch 10, Loss: 0.08699551224708557\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.10077460895082511, feed_forward_dim=512, head_dim=16, lr=0.0017346753072372864, num_heads=2, num_layers=1; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.5738436579704285\n",
      "Epoch 1, Loss: 0.2218254953622818\n",
      "Epoch 2, Loss: 0.28366410732269287\n",
      "Epoch 1, Loss: 2.9257524013519287\n",
      "Epoch 1, Loss: 1.1049913167953491\n",
      "Epoch 1, Loss: 0.49791979789733887\n",
      "Epoch 1, Loss: 1.4927620887756348\n",
      "Epoch 1, Loss: 0.15937286615371704\n",
      "Epoch 2, Loss: 0.42527803778648376\n",
      "Epoch 3, Loss: 0.3478967547416687\n",
      "Epoch 1, Loss: 0.4751749634742737\n",
      "Epoch 2, Loss: 0.7638419270515442\n",
      "Epoch 1, Loss: 0.03045426309108734\n",
      "Epoch 2, Loss: 0.10556233674287796\n",
      "Epoch 4, Loss: 0.19214221835136414\n",
      "Epoch 1, Loss: 1.2645950317382812\n",
      "Epoch 2, Loss: 0.0934869572520256\n",
      "Epoch 3, Loss: 0.11244137585163116\n",
      "Epoch 1, Loss: 0.22198466956615448\n",
      "Epoch 2, Loss: 0.44829681515693665\n",
      "Epoch 3, Loss: 0.1255190670490265\n",
      "Epoch 2, Loss: 0.16412866115570068\n",
      "Epoch 1, Loss: 0.1658262014389038\n",
      "Epoch 5, Loss: 0.07813134789466858\n",
      "Epoch 2, Loss: 0.03612498566508293\n",
      "Epoch 3, Loss: 0.45065566897392273\n",
      "Epoch 4, Loss: 0.14585968852043152\n",
      "Epoch 3, Loss: 0.2986495792865753\n",
      "Epoch 2, Loss: 0.10217359662055969\n",
      "Epoch 2, Loss: 0.4537658989429474\n",
      "Epoch 4, Loss: 0.3748502731323242\n",
      "Epoch 6, Loss: 0.07969402521848679\n",
      "Epoch 3, Loss: 0.2655636668205261\n",
      "Epoch 2, Loss: 0.23939548432826996\n",
      "Epoch 3, Loss: 0.12650589644908905\n",
      "Epoch 5, Loss: 0.18966101109981537\n",
      "Epoch 4, Loss: 0.49951645731925964\n",
      "Epoch 3, Loss: 0.24262113869190216\n",
      "Epoch 4, Loss: 0.21607880294322968\n",
      "Epoch 3, Loss: 0.03144446387887001\n",
      "Epoch 5, Loss: 0.657577633857727\n",
      "Epoch 2, Loss: 0.3529946208000183\n",
      "Epoch 7, Loss: 0.12015995383262634\n",
      "Epoch 3, Loss: 0.14231069386005402\n",
      "Epoch 6, Loss: 0.0951923131942749\n",
      "Epoch 4, Loss: 0.5274789333343506\n",
      "Epoch 5, Loss: 0.26911336183547974\n",
      "Epoch 4, Loss: 0.03756703436374664\n",
      "Epoch 8, Loss: 0.11603660881519318\n",
      "Epoch 3, Loss: 0.14686450362205505\n",
      "Epoch 5, Loss: 0.07046439498662949\n",
      "Epoch 4, Loss: 0.23170703649520874\n",
      "Epoch 6, Loss: 0.6724154353141785\n",
      "Epoch 7, Loss: 0.02559194341301918\n",
      "Epoch 3, Loss: 0.12804396450519562\n",
      "Epoch 4, Loss: 0.4084172546863556\n",
      "Epoch 4, Loss: 0.12010709941387177\n",
      "Epoch 9, Loss: 0.07295532524585724\n",
      "Epoch 7, Loss: 0.5256941914558411\n",
      "Epoch 6, Loss: 0.0791017934679985\n",
      "Epoch 6, Loss: 0.02908479981124401\n",
      "Epoch 5, Loss: 0.15013261139392853\n",
      "Epoch 8, Loss: 0.04518891125917435\n",
      "Epoch 5, Loss: 0.4293970763683319\n",
      "Epoch 4, Loss: 0.014323899522423744\n",
      "Epoch 5, Loss: 0.10482669621706009\n",
      "Epoch 10, Loss: 0.02979307435452938\n",
      "Epoch 8, Loss: 0.3235577642917633\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004924697387708855, num_heads=8, num_layers=2; total time=   1.0s\n",
      "Epoch 9, Loss: 0.08497097343206406\n",
      "Epoch 7, Loss: 0.037592340260744095\n",
      "Epoch 4, Loss: 0.013244546949863434\n",
      "Epoch 7, Loss: 0.07352323085069656\n",
      "Epoch 6, Loss: 0.21313513815402985\n",
      "Epoch 5, Loss: 0.2219582200050354\n",
      "Epoch 5, Loss: 0.3904268145561218\n",
      "Epoch 6, Loss: 0.1542038470506668\n",
      "Epoch 9, Loss: 0.15875065326690674\n",
      "Epoch 10, Loss: 0.07166200131177902\n",
      "Epoch 8, Loss: 0.10270942747592926\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004924697387708855, num_heads=8, num_layers=2; total time=   1.1s\n",
      "Epoch 5, Loss: 0.058069419115781784\n",
      "Epoch 8, Loss: 0.10825527459383011\n",
      "Epoch 6, Loss: 0.021726788952946663\n",
      "Epoch 7, Loss: 0.05751856043934822\n",
      "Epoch 10, Loss: 0.06213212013244629\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004924697387708855, num_heads=8, num_layers=2; total time=   1.2s\n",
      "Epoch 9, Loss: 0.16920365393161774\n",
      "Epoch 7, Loss: 0.06565690040588379\n",
      "Epoch 6, Loss: 0.23090995848178864\n",
      "Epoch 6, Loss: 0.12778477370738983\n",
      "Epoch 5, Loss: 0.11079622060060501\n",
      "Epoch 9, Loss: 0.09834416210651398\n",
      "Epoch 6, Loss: 0.10384097695350647\n",
      "Epoch 7, Loss: 0.027414187788963318\n",
      "Epoch 10, Loss: 0.1705191433429718\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004924697387708855, num_heads=8, num_layers=2; total time=   1.2s\n",
      "Epoch 8, Loss: 0.022427642717957497\n",
      "Epoch 10, Loss: 0.054685868322849274\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004924697387708855, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 7, Loss: 0.024167362600564957\n",
      "Epoch 8, Loss: 0.013916914351284504\n",
      "Epoch 7, Loss: 0.08048593997955322\n",
      "Epoch 8, Loss: 0.07537060976028442\n",
      "Epoch 7, Loss: 0.06640422344207764\n",
      "Epoch 6, Loss: 0.13704156875610352\n",
      "Epoch 9, Loss: 0.0647115632891655\n",
      "Epoch 9, Loss: 0.03721777722239494\n",
      "Epoch 8, Loss: 0.009145050309598446\n",
      "Epoch 9, Loss: 0.10035353153944016\n",
      "Epoch 10, Loss: 0.12168680876493454\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004924697387708855, num_heads=8, num_layers=2; total time=   1.4s\n",
      "Epoch 8, Loss: 0.017871547490358353\n",
      "Epoch 8, Loss: 0.014096307568252087\n",
      "Epoch 10, Loss: 0.07587379217147827\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004924697387708855, num_heads=8, num_layers=2; total time=   1.4s\n",
      "Epoch 9, Loss: 0.05759323015809059\n",
      "Epoch 7, Loss: 0.06760690361261368\n",
      "Epoch 10, Loss: 0.08422651886940002\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004924697387708855, num_heads=8, num_layers=2; total time=   1.4s\n",
      "Epoch 9, Loss: 0.016171230003237724\n",
      "Epoch 9, Loss: 0.02756192535161972\n",
      "Epoch 10, Loss: 0.08999358117580414\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004924697387708855, num_heads=8, num_layers=2; total time=   1.5s\n",
      "Epoch 8, Loss: 0.01295444369316101\n",
      "Epoch 10, Loss: 0.04402545094490051\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004924697387708855, num_heads=8, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.0753549188375473\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004924697387708855, num_heads=8, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 0.022081611678004265\n",
      "Epoch 10, Loss: 0.05775231868028641\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004924697387708855, num_heads=8, num_layers=2; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.03459111228585243\n",
      "Epoch 1, Loss: 0.050196077674627304\n",
      "Epoch 1, Loss: 2.025934934616089\n",
      "Epoch 1, Loss: 2.3589673042297363\n",
      "Epoch 1, Loss: 0.30146220326423645\n",
      "Epoch 1, Loss: 0.0076094260439276695\n",
      "Epoch 2, Loss: 0.0323784239590168\n",
      "Epoch 1, Loss: 0.009434324689209461\n",
      "Epoch 2, Loss: 0.03891543671488762\n",
      "Epoch 1, Loss: 0.6026598811149597\n",
      "Epoch 2, Loss: 1.9598164558410645\n",
      "Epoch 2, Loss: 1.5930322408676147\n",
      "Epoch 1, Loss: 0.8896336555480957\n",
      "Epoch 2, Loss: 0.15807251632213593\n",
      "Epoch 3, Loss: 0.029402032494544983\n",
      "Epoch 3, Loss: 0.02409256249666214\n",
      "Epoch 2, Loss: 0.01731659658253193\n",
      "Epoch 1, Loss: 0.9421212077140808\n",
      "Epoch 2, Loss: 0.012907694093883038\n",
      "Epoch 2, Loss: 0.38276928663253784\n",
      "Epoch 3, Loss: 0.06475967168807983\n",
      "Epoch 3, Loss: 1.6126835346221924\n",
      "Epoch 4, Loss: 0.0190241988748312\n",
      "Epoch 1, Loss: 0.0653337761759758\n",
      "Epoch 4, Loss: 0.0194912888109684\n",
      "Epoch 3, Loss: 1.204789638519287\n",
      "Epoch 3, Loss: 0.005861553829163313\n",
      "Epoch 1, Loss: 2.4496450424194336\n",
      "Epoch 4, Loss: 1.2924628257751465\n",
      "Epoch 4, Loss: 0.022714339196681976\n",
      "Epoch 2, Loss: 0.6281737089157104\n",
      "Epoch 5, Loss: 0.017456039786338806\n",
      "Epoch 3, Loss: 0.008650395087897778\n",
      "Epoch 5, Loss: 0.013815805315971375\n",
      "Epoch 4, Loss: 0.8831589818000793\n",
      "Epoch 3, Loss: 0.22119058668613434\n",
      "Epoch 2, Loss: 0.6960944533348083\n",
      "Epoch 6, Loss: 0.014612455852329731\n",
      "Epoch 5, Loss: 0.016170088201761246\n",
      "Epoch 2, Loss: 0.05948073789477348\n",
      "Epoch 4, Loss: 0.009240104816854\n",
      "Epoch 2, Loss: 2.0507988929748535\n",
      "Epoch 6, Loss: 0.011513227596879005\n",
      "Epoch 4, Loss: 0.006347905844449997\n",
      "Epoch 5, Loss: 1.0073362588882446\n",
      "Epoch 7, Loss: 0.011151116341352463\n",
      "Epoch 5, Loss: 0.6095499396324158\n",
      "Epoch 4, Loss: 0.10939900577068329\n",
      "Epoch 3, Loss: 0.48570775985717773\n",
      "Epoch 6, Loss: 0.03205703943967819\n",
      "Epoch 3, Loss: 0.419702410697937\n",
      "Epoch 5, Loss: 0.010372916236519814\n",
      "Epoch 6, Loss: 0.4061962366104126\n",
      "Epoch 8, Loss: 0.010197953321039677\n",
      "Epoch 5, Loss: 0.007452249526977539\n",
      "Epoch 7, Loss: 0.007921538315713406\n",
      "Epoch 3, Loss: 0.050480086356401443\n",
      "Epoch 6, Loss: 0.7644076347351074\n",
      "Epoch 5, Loss: 0.04227929189801216\n",
      "Epoch 3, Loss: 1.688137173652649\n",
      "Epoch 6, Loss: 0.006890683900564909\n",
      "Epoch 7, Loss: 0.05456480011343956\n",
      "Epoch 7, Loss: 0.24755330383777618\n",
      "Epoch 4, Loss: 0.2629334032535553\n",
      "Epoch 7, Loss: 0.5614376664161682\n",
      "Epoch 4, Loss: 0.3148859143257141\n",
      "Epoch 9, Loss: 0.011041739024221897\n",
      "Epoch 8, Loss: 0.00535447197034955\n",
      "Epoch 4, Loss: 0.042324285954236984\n",
      "Epoch 6, Loss: 0.007312051020562649\n",
      "Epoch 6, Loss: 0.0166782196611166\n",
      "Epoch 8, Loss: 0.14263565838336945\n",
      "Epoch 4, Loss: 1.3615381717681885\n",
      "Epoch 9, Loss: 0.005630276165902615\n",
      "Epoch 8, Loss: 0.06748449802398682\n",
      "Epoch 7, Loss: 0.003873442066833377\n",
      "Epoch 10, Loss: 0.01117263175547123\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.37270877594723206, feed_forward_dim=1024, head_dim=16, lr=8.683324329435656e-05, num_heads=4, num_layers=4; total time=   1.0s\n",
      "Epoch 5, Loss: 0.15648972988128662\n",
      "Epoch 8, Loss: 0.39490458369255066\n",
      "Epoch 9, Loss: 0.0801880806684494\n",
      "Epoch 10, Loss: 0.007463608868420124\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.37270877594723206, feed_forward_dim=1024, head_dim=16, lr=8.683324329435656e-05, num_heads=4, num_layers=4; total time=   1.1s\n",
      "Epoch 5, Loss: 0.03638172149658203\n",
      "Epoch 5, Loss: 0.19188885390758514\n",
      "Epoch 7, Loss: 0.005392443388700485\n",
      "Epoch 8, Loss: 0.005585736129432917\n",
      "Epoch 7, Loss: 0.020823884755373\n",
      "Epoch 9, Loss: 0.26117968559265137\n",
      "Epoch 9, Loss: 0.07281628996133804\n",
      "Epoch 5, Loss: 1.065918207168579\n",
      "Epoch 9, Loss: 0.00756539823487401\n",
      "Epoch 8, Loss: 0.005136449821293354\n",
      "Epoch 10, Loss: 0.16457292437553406\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.37270877594723206, feed_forward_dim=1024, head_dim=16, lr=8.683324329435656e-05, num_heads=4, num_layers=4; total time=   1.2s\n",
      "Epoch 6, Loss: 0.09912109375\n",
      "Epoch 10, Loss: 0.06120828166604042\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.37270877594723206, feed_forward_dim=1024, head_dim=16, lr=8.683324329435656e-05, num_heads=4, num_layers=4; total time=   1.2s\n",
      "Epoch 6, Loss: 0.03187083452939987\n",
      "Epoch 10, Loss: 0.06505042314529419\n",
      "Epoch 8, Loss: 0.04259662702679634\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.37270877594723206, feed_forward_dim=1024, head_dim=16, lr=8.683324329435656e-05, num_heads=4, num_layers=4; total time=   1.2s\n",
      "Epoch 6, Loss: 0.11070352047681808\n",
      "Epoch 10, Loss: 0.005982094444334507\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.37270877594723206, feed_forward_dim=1024, head_dim=16, lr=8.683324329435656e-05, num_heads=4, num_layers=4; total time=   1.2s\n",
      "Epoch 9, Loss: 0.006188556551933289\n",
      "Epoch 9, Loss: 0.06963960081338882\n",
      "Epoch 7, Loss: 0.07994098216295242\n",
      "Epoch 7, Loss: 0.02670668624341488\n",
      "Epoch 6, Loss: 0.8166846632957458\n",
      "Epoch 7, Loss: 0.06593866646289825\n",
      "Epoch 10, Loss: 0.006242634262889624\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.37270877594723206, feed_forward_dim=1024, head_dim=16, lr=8.683324329435656e-05, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 10, Loss: 0.09188693016767502\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.37270877594723206, feed_forward_dim=1024, head_dim=16, lr=8.683324329435656e-05, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 8, Loss: 0.09034748375415802\n",
      "Epoch 8, Loss: 0.02134893834590912\n",
      "Epoch 7, Loss: 0.6119642853736877\n",
      "Epoch 8, Loss: 0.049402687698602676\n",
      "Epoch 9, Loss: 0.11296622455120087\n",
      "Epoch 9, Loss: 0.017211301252245903\n",
      "Epoch 9, Loss: 0.05902882665395737\n",
      "Epoch 8, Loss: 0.4441358745098114\n",
      "Epoch 10, Loss: 0.13508883118629456\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.37270877594723206, feed_forward_dim=1024, head_dim=16, lr=8.683324329435656e-05, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.014459876343607903\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.37270877594723206, feed_forward_dim=1024, head_dim=16, lr=8.683324329435656e-05, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 10, Loss: 0.07988668233156204\n",
      "Epoch 9, Loss: 0.31488320231437683\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.37270877594723206, feed_forward_dim=1024, head_dim=16, lr=8.683324329435656e-05, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.22266609966754913\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.37270877594723206, feed_forward_dim=1024, head_dim=16, lr=8.683324329435656e-05, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.5034313201904297\n",
      "Epoch 1, Loss: 0.8805810213088989\n",
      "Epoch 1, Loss: 0.6611189246177673\n",
      "Epoch 1, Loss: 0.26903587579727173\n",
      "Epoch 1, Loss: 0.024469908326864243\n",
      "Epoch 1, Loss: 1.5051432847976685\n",
      "Epoch 2, Loss: 0.7267605662345886\n",
      "Epoch 2, Loss: 0.40338343381881714\n",
      "Epoch 2, Loss: 0.5310291051864624\n",
      "Epoch 1, Loss: 0.2961267828941345\n",
      "Epoch 2, Loss: 0.19978755712509155\n",
      "Epoch 1, Loss: 2.545863389968872\n",
      "Epoch 3, Loss: 0.5885748267173767\n",
      "Epoch 2, Loss: 0.016110969707369804\n",
      "Epoch 3, Loss: 0.3054742217063904\n",
      "Epoch 2, Loss: 1.308709740638733\n",
      "Epoch 3, Loss: 0.4187205135822296\n",
      "Epoch 1, Loss: 1.9745641946792603\n",
      "Epoch 3, Loss: 0.14749775826931\n",
      "Epoch 1, Loss: 1.1365137100219727\n",
      "Epoch 4, Loss: 0.2255796641111374\n",
      "Epoch 3, Loss: 0.01649092510342598\n",
      "Epoch 4, Loss: 0.47044456005096436\n",
      "Epoch 2, Loss: 0.22611354291439056\n",
      "Epoch 4, Loss: 0.32644155621528625\n",
      "Epoch 1, Loss: 0.8495169878005981\n",
      "Epoch 1, Loss: 0.17133964598178864\n",
      "Epoch 2, Loss: 2.2912869453430176\n",
      "Epoch 3, Loss: 1.1150903701782227\n",
      "Epoch 4, Loss: 0.11106990277767181\n",
      "Epoch 5, Loss: 0.3661348521709442\n",
      "Epoch 5, Loss: 0.16145633161067963\n",
      "Epoch 2, Loss: 1.7528961896896362\n",
      "Epoch 5, Loss: 0.2412642240524292\n",
      "Epoch 4, Loss: 0.015500317327678204\n",
      "Epoch 2, Loss: 0.9496060013771057\n",
      "Epoch 3, Loss: 2.052204132080078\n",
      "Epoch 3, Loss: 0.16628018021583557\n",
      "Epoch 4, Loss: 0.9404651522636414\n",
      "Epoch 6, Loss: 0.2764565944671631\n",
      "Epoch 6, Loss: 0.17631152272224426\n",
      "Epoch 5, Loss: 0.08867676556110382\n",
      "Epoch 5, Loss: 0.01438119262456894\n",
      "Epoch 2, Loss: 0.11922295391559601\n",
      "Epoch 6, Loss: 0.10913354903459549\n",
      "Epoch 3, Loss: 1.5367069244384766\n",
      "Epoch 2, Loss: 0.6928612589836121\n",
      "Epoch 5, Loss: 0.7819364666938782\n",
      "Epoch 4, Loss: 1.8319472074508667\n",
      "Epoch 7, Loss: 0.2065039426088333\n",
      "Epoch 3, Loss: 0.7812734246253967\n",
      "Epoch 7, Loss: 0.1242511197924614\n",
      "Epoch 6, Loss: 0.07796040922403336\n",
      "Epoch 6, Loss: 0.009980756789445877\n",
      "Epoch 4, Loss: 0.12568479776382446\n",
      "Epoch 7, Loss: 0.07596904039382935\n",
      "Epoch 6, Loss: 0.6400918960571289\n",
      "Epoch 4, Loss: 1.3394297361373901\n",
      "Epoch 3, Loss: 0.08539747446775436\n",
      "Epoch 5, Loss: 1.6137887239456177\n",
      "Epoch 8, Loss: 0.14741095900535583\n",
      "Epoch 8, Loss: 0.052025165408849716\n",
      "Epoch 7, Loss: 0.07659997045993805\n",
      "Epoch 8, Loss: 0.08532356470823288\n",
      "Epoch 3, Loss: 0.5504091382026672\n",
      "Epoch 7, Loss: 0.008793940767645836\n",
      "Epoch 5, Loss: 0.10002044588327408\n",
      "Epoch 4, Loss: 0.6230716705322266\n",
      "Epoch 7, Loss: 0.5221753716468811\n",
      "Epoch 9, Loss: 0.03829565271735191\n",
      "Epoch 9, Loss: 0.05822070688009262\n",
      "Epoch 5, Loss: 1.1529288291931152\n",
      "Epoch 9, Loss: 0.10167410224676132\n",
      "Epoch 4, Loss: 0.0668705627322197\n",
      "Epoch 6, Loss: 1.4156574010849\n",
      "Epoch 8, Loss: 0.008761434815824032\n",
      "Epoch 4, Loss: 0.4333372414112091\n",
      "Epoch 10, Loss: 0.04399017244577408\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   1.0s\n",
      "Epoch 8, Loss: 0.08017532527446747\n",
      "Epoch 10, Loss: 0.033002354204654694\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   1.1s\n",
      "Epoch 6, Loss: 0.08761490136384964\n",
      "Epoch 8, Loss: 0.41912874579429626\n",
      "Epoch 6, Loss: 0.9834078550338745\n",
      "Epoch 10, Loss: 0.07301439344882965\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   1.1s\n",
      "Epoch 5, Loss: 0.49101734161376953\n",
      "Epoch 5, Loss: 0.06124310940504074\n",
      "Epoch 7, Loss: 1.2382553815841675\n",
      "Epoch 9, Loss: 0.008550001308321953\n",
      "Epoch 5, Loss: 0.33283913135528564\n",
      "Epoch 9, Loss: 0.08391351252794266\n",
      "Epoch 9, Loss: 0.3283557593822479\n",
      "Epoch 7, Loss: 0.830271303653717\n",
      "Epoch 10, Loss: 0.008263344876468182\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   1.1s\n",
      "Epoch 6, Loss: 0.37479400634765625\n",
      "Epoch 8, Loss: 1.065386414527893\n",
      "Epoch 6, Loss: 0.060233984142541885\n",
      "Epoch 10, Loss: 0.0848320797085762\n",
      "Epoch 7, Loss: 0.08351247012615204\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   1.2s\n",
      "Epoch 6, Loss: 0.24322271347045898\n",
      "Epoch 10, Loss: 0.2542077302932739\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   1.2s\n",
      "Epoch 8, Loss: 0.6880601048469543\n",
      "Epoch 7, Loss: 0.27526938915252686\n",
      "Epoch 9, Loss: 0.9154471158981323\n",
      "Epoch 7, Loss: 0.0646810457110405\n",
      "Epoch 8, Loss: 0.08803778141736984\n",
      "Epoch 7, Loss: 0.17881813645362854\n",
      "Epoch 9, Loss: 0.56362384557724\n",
      "Epoch 10, Loss: 0.7851994037628174\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   1.3s\n",
      "Epoch 8, Loss: 0.1991724967956543\n",
      "Epoch 9, Loss: 0.09598354250192642\n",
      "Epoch 8, Loss: 0.06684480607509613\n",
      "Epoch 8, Loss: 0.12832774221897125\n",
      "Epoch 10, Loss: 0.4515075981616974\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   1.3s\n",
      "Epoch 10, Loss: 0.10083835572004318\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   1.4s\n",
      "Epoch 9, Loss: 0.13494901359081268\n",
      "Epoch 9, Loss: 0.0638280138373375\n",
      "Epoch 9, Loss: 0.0926145613193512\n",
      "Epoch 10, Loss: 0.09057348221540451\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   1.4s\n",
      "Epoch 10, Loss: 0.07342086732387543\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   1.4s\n",
      "Epoch 10, Loss: 0.05758340284228325\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=256, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   1.4s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.25206539034843445\n",
      "Epoch 1, Loss: 0.9509348273277283\n",
      "Epoch 1, Loss: 0.6887738704681396\n",
      "Epoch 1, Loss: 1.903435468673706\n",
      "Epoch 1, Loss: 0.1389220952987671\n",
      "Epoch 1, Loss: 0.8605779409408569\n",
      "Epoch 2, Loss: 0.21737152338027954\n",
      "Epoch 1, Loss: 0.9388468861579895\n",
      "Epoch 1, Loss: 0.15742163360118866\n",
      "Epoch 2, Loss: 0.09991587698459625\n",
      "Epoch 1, Loss: 0.5488224029541016\n",
      "Epoch 2, Loss: 0.767443060874939\n",
      "Epoch 2, Loss: 1.692859172821045\n",
      "Epoch 2, Loss: 0.576606273651123\n",
      "Epoch 2, Loss: 0.7245407700538635\n",
      "Epoch 3, Loss: 0.193820983171463\n",
      "Epoch 1, Loss: 0.2354125827550888\n",
      "Epoch 2, Loss: 0.7385103106498718\n",
      "Epoch 1, Loss: 0.25714462995529175\n",
      "Epoch 4, Loss: 0.18476444482803345\n",
      "Epoch 3, Loss: 1.4795249700546265\n",
      "Epoch 3, Loss: 0.0846322774887085\n",
      "Epoch 2, Loss: 0.10078871250152588\n",
      "Epoch 2, Loss: 0.428602397441864\n",
      "Epoch 3, Loss: 0.6000106930732727\n",
      "Epoch 3, Loss: 0.4789343476295471\n",
      "Epoch 3, Loss: 0.6069368124008179\n",
      "Epoch 1, Loss: 0.11155955493450165\n",
      "Epoch 2, Loss: 0.16175232827663422\n",
      "Epoch 5, Loss: 0.18213337659835815\n",
      "Epoch 4, Loss: 1.2818998098373413\n",
      "Epoch 4, Loss: 0.07992064952850342\n",
      "Epoch 3, Loss: 0.5652259588241577\n",
      "Epoch 4, Loss: 0.40367791056632996\n",
      "Epoch 4, Loss: 0.4585740864276886\n",
      "Epoch 4, Loss: 0.4880083501338959\n",
      "Epoch 2, Loss: 0.2074122130870819\n",
      "Epoch 3, Loss: 0.06576976925134659\n",
      "Epoch 5, Loss: 1.1056891679763794\n",
      "Epoch 6, Loss: 0.17385409772396088\n",
      "Epoch 3, Loss: 0.3300345540046692\n",
      "Epoch 5, Loss: 0.07869412750005722\n",
      "Epoch 4, Loss: 0.4123988449573517\n",
      "Epoch 2, Loss: 0.09953292459249496\n",
      "Epoch 3, Loss: 0.1048278659582138\n",
      "Epoch 7, Loss: 0.16386306285858154\n",
      "Epoch 6, Loss: 0.9352714419364929\n",
      "Epoch 5, Loss: 0.34330737590789795\n",
      "Epoch 5, Loss: 0.3951110243797302\n",
      "Epoch 5, Loss: 0.33778345584869385\n",
      "Epoch 3, Loss: 0.1750374585390091\n",
      "Epoch 4, Loss: 0.04576496779918671\n",
      "Epoch 6, Loss: 0.07777611166238785\n",
      "Epoch 7, Loss: 0.7927716374397278\n",
      "Epoch 8, Loss: 0.1566181778907776\n",
      "Epoch 4, Loss: 0.24333417415618896\n",
      "Epoch 5, Loss: 0.2915174067020416\n",
      "Epoch 6, Loss: 0.2518153190612793\n",
      "Epoch 3, Loss: 0.09155609458684921\n",
      "Epoch 6, Loss: 0.3035255968570709\n",
      "Epoch 7, Loss: 0.072076715528965\n",
      "Epoch 4, Loss: 0.06104046851396561\n",
      "Epoch 8, Loss: 0.6550984978675842\n",
      "Epoch 6, Loss: 0.29025590419769287\n",
      "Epoch 9, Loss: 0.1438940316438675\n",
      "Epoch 5, Loss: 0.04033426567912102\n",
      "Epoch 4, Loss: 0.15600992739200592\n",
      "Epoch 7, Loss: 0.1712617129087448\n",
      "Epoch 9, Loss: 0.5334894061088562\n",
      "Epoch 6, Loss: 0.19387689232826233\n",
      "Epoch 10, Loss: 0.13341553509235382\n",
      "Epoch 8, Loss: 0.06463169306516647\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=5e-05, num_heads=2, num_layers=4; total time=   1.1s\n",
      "Epoch 7, Loss: 0.25865235924720764\n",
      "Epoch 5, Loss: 0.1748589426279068\n",
      "Epoch 7, Loss: 0.23182226717472076\n",
      "Epoch 5, Loss: 0.030785327777266502\n",
      "Epoch 6, Loss: 0.04450700059533119\n",
      "Epoch 4, Loss: 0.0835680440068245\n",
      "Epoch 9, Loss: 0.05644339323043823\n",
      "Epoch 8, Loss: 0.11551506817340851\n",
      "Epoch 10, Loss: 0.4307762384414673\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=5e-05, num_heads=2, num_layers=4; total time=   1.3s\n",
      "Epoch 8, Loss: 0.23848982155323029\n",
      "Epoch 5, Loss: 0.14855335652828217\n",
      "Epoch 7, Loss: 0.12507779896259308\n",
      "Epoch 8, Loss: 0.17151449620723724\n",
      "Epoch 6, Loss: 0.12780368328094482\n",
      "Epoch 6, Loss: 0.013216912746429443\n",
      "Epoch 10, Loss: 0.04754593223333359\n",
      "Epoch 9, Loss: 0.07812715321779251\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=5e-05, num_heads=2, num_layers=4; total time=   1.4s\n",
      "Epoch 7, Loss: 0.050539810210466385\n",
      "Epoch 5, Loss: 0.07720418274402618\n",
      "Epoch 9, Loss: 0.22737930715084076\n",
      "Epoch 8, Loss: 0.07852250337600708\n",
      "Epoch 6, Loss: 0.14638876914978027\n",
      "Epoch 10, Loss: 0.05421111732721329\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=5e-05, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Epoch 9, Loss: 0.12440767139196396\n",
      "Epoch 8, Loss: 0.05452324450016022\n",
      "Epoch 7, Loss: 0.08895672112703323\n",
      "Epoch 10, Loss: 0.22297526895999908\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=5e-05, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Epoch 7, Loss: 0.006917929742485285\n",
      "Epoch 9, Loss: 0.053328435868024826\n",
      "Epoch 6, Loss: 0.06977351009845734\n",
      "Epoch 10, Loss: 0.08607400953769684\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=5e-05, num_heads=2, num_layers=4; total time=   1.6s\n",
      "Epoch 9, Loss: 0.05598730221390724\n",
      "Epoch 7, Loss: 0.14395934343338013\n",
      "Epoch 10, Loss: 0.044301364570856094\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=5e-05, num_heads=2, num_layers=4; total time=   1.6s\n",
      "Epoch 8, Loss: 0.00893335696309805\n",
      "Epoch 8, Loss: 0.06592274457216263\n",
      "Epoch 7, Loss: 0.06290271878242493\n",
      "Epoch 10, Loss: 0.05263463035225868\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=5e-05, num_heads=2, num_layers=4; total time=   1.7s\n",
      "Epoch 8, Loss: 0.13959240913391113\n",
      "Epoch 9, Loss: 0.015751348808407784\n",
      "Epoch 9, Loss: 0.05345120280981064\n",
      "Epoch 8, Loss: 0.056171201169490814\n",
      "Epoch 10, Loss: 0.051859911531209946\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=5e-05, num_heads=2, num_layers=4; total time=   1.8s\n",
      "Epoch 9, Loss: 0.13178539276123047\n",
      "Epoch 10, Loss: 0.02498754858970642\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=5e-05, num_heads=2, num_layers=4; total time=   1.7s\n",
      "Epoch 9, Loss: 0.0505988746881485\n",
      "Epoch 10, Loss: 0.12264847755432129\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=5e-05, num_heads=2, num_layers=4; total time=   1.8s\n",
      "Epoch 10, Loss: 0.046389997005462646\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=5e-05, num_heads=2, num_layers=4; total time=   1.8s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.23782967031002045\n",
      "Epoch 1, Loss: 0.36046838760375977\n",
      "Epoch 1, Loss: 0.11659671366214752\n",
      "Epoch 2, Loss: 1.2214747667312622\n",
      "Epoch 1, Loss: 0.5383633375167847\n",
      "Epoch 2, Loss: 1.4835760593414307\n",
      "Epoch 1, Loss: 0.23464719951152802\n",
      "Epoch 1, Loss: 1.292967677116394\n",
      "Epoch 2, Loss: 1.4681763648986816\n",
      "Epoch 1, Loss: 0.08422750979661942\n",
      "Epoch 1, Loss: 1.1833328008651733\n",
      "Epoch 3, Loss: 0.2962037920951843\n",
      "Epoch 2, Loss: 1.1603693962097168\n",
      "Epoch 1, Loss: 0.10363547503948212\n",
      "Epoch 2, Loss: 1.3330305814743042\n",
      "Epoch 3, Loss: 0.5233707427978516\n",
      "Epoch 1, Loss: 0.27444976568222046\n",
      "Epoch 2, Loss: 2.033585786819458\n",
      "Epoch 2, Loss: 0.4217086136341095\n",
      "Epoch 3, Loss: 0.30032986402511597\n",
      "Epoch 4, Loss: 0.05405687168240547\n",
      "Epoch 1, Loss: 0.06320610642433167\n",
      "Epoch 3, Loss: 0.5025324821472168\n",
      "Epoch 1, Loss: 0.15420286357402802\n",
      "Epoch 4, Loss: 0.03534288331866264\n",
      "Epoch 2, Loss: 0.777595043182373\n",
      "Epoch 4, Loss: 0.0543181337416172\n",
      "Epoch 2, Loss: 0.209987610578537\n",
      "Epoch 5, Loss: 0.3188685476779938\n",
      "Epoch 3, Loss: 0.3756457567214966\n",
      "Epoch 3, Loss: 0.6689363121986389\n",
      "Epoch 4, Loss: 0.04532163590192795\n",
      "Epoch 2, Loss: 1.0840089321136475\n",
      "Epoch 3, Loss: 0.31629225611686707\n",
      "Epoch 2, Loss: 0.07520120590925217\n",
      "Epoch 6, Loss: 0.33667227625846863\n",
      "Epoch 5, Loss: 0.2710621654987335\n",
      "Epoch 2, Loss: 0.4172501862049103\n",
      "Epoch 5, Loss: 0.3784109950065613\n",
      "Epoch 4, Loss: 0.33092668652534485\n",
      "Epoch 5, Loss: 0.13555265963077545\n",
      "Epoch 3, Loss: 0.3149094581604004\n",
      "Epoch 3, Loss: 0.7910809516906738\n",
      "Epoch 7, Loss: 0.16404356062412262\n",
      "Epoch 4, Loss: 0.031057089567184448\n",
      "Epoch 4, Loss: 0.16814030706882477\n",
      "Epoch 6, Loss: 0.3909284770488739\n",
      "Epoch 3, Loss: 0.7255060076713562\n",
      "Epoch 3, Loss: 1.1320480108261108\n",
      "Epoch 6, Loss: 0.2899457812309265\n",
      "Epoch 3, Loss: 0.2528358995914459\n",
      "Epoch 5, Loss: 0.08569841831922531\n",
      "Epoch 8, Loss: 0.03065108135342598\n",
      "Epoch 4, Loss: 0.061632171273231506\n",
      "Epoch 6, Loss: 0.3833026885986328\n",
      "Epoch 7, Loss: 0.25489529967308044\n",
      "Epoch 5, Loss: 0.6255495548248291\n",
      "Epoch 4, Loss: 0.2365555614233017\n",
      "Epoch 5, Loss: 0.29412841796875\n",
      "Epoch 9, Loss: 0.021628128364682198\n",
      "Epoch 7, Loss: 0.27416351437568665\n",
      "Epoch 4, Loss: 0.1375339776277542\n",
      "Epoch 8, Loss: 0.08149285614490509\n",
      "Epoch 6, Loss: 0.07592972368001938\n",
      "Epoch 7, Loss: 0.1903235763311386\n",
      "Epoch 4, Loss: 0.09510468691587448\n",
      "Epoch 5, Loss: 0.2589268982410431\n",
      "Epoch 10, Loss: 0.08536148071289062\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.18983047622245736, feed_forward_dim=128, head_dim=32, lr=0.001034710743376546, num_heads=2, num_layers=4; total time=   0.9s\n",
      "Epoch 4, Loss: 0.27666470408439636\n",
      "Epoch 6, Loss: 0.37805384397506714\n",
      "Epoch 6, Loss: 0.509170413017273\n",
      "Epoch 5, Loss: 0.033944353461265564\n",
      "Epoch 9, Loss: 0.01791544258594513\n",
      "Epoch 7, Loss: 0.16266480088233948\n",
      "Epoch 5, Loss: 0.07064942270517349\n",
      "Epoch 8, Loss: 0.043110329657793045\n",
      "Epoch 8, Loss: 0.1585075557231903\n",
      "Epoch 7, Loss: 0.2327035367488861\n",
      "Epoch 10, Loss: 0.05490677058696747\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.18983047622245736, feed_forward_dim=128, head_dim=32, lr=0.001034710743376546, num_heads=2, num_layers=4; total time=   1.0s\n",
      "Epoch 7, Loss: 0.20884661376476288\n",
      "Epoch 5, Loss: 0.036845315247774124\n",
      "Epoch 5, Loss: 0.26783302426338196\n",
      "Epoch 6, Loss: 0.1494351476430893\n",
      "Epoch 6, Loss: 0.3090130388736725\n",
      "Epoch 8, Loss: 0.2106539011001587\n",
      "Epoch 9, Loss: 0.01970292627811432\n",
      "Epoch 9, Loss: 0.059191860258579254\n",
      "Epoch 8, Loss: 0.07323280721902847\n",
      "Epoch 6, Loss: 0.27170222997665405\n",
      "Epoch 8, Loss: 0.03970193490386009\n",
      "Epoch 7, Loss: 0.2677192986011505\n",
      "Epoch 10, Loss: 0.07558974623680115\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.18983047622245736, feed_forward_dim=128, head_dim=32, lr=0.001034710743376546, num_heads=2, num_layers=4; total time=   1.2s\n",
      "Epoch 10, Loss: 0.027680469676852226\n",
      "Epoch 9, Loss: 0.020784804597496986\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.18983047622245736, feed_forward_dim=128, head_dim=32, lr=0.001034710743376546, num_heads=2, num_layers=4; total time=   1.2s\n",
      "Epoch 6, Loss: 0.06223197281360626\n",
      "Epoch 9, Loss: 0.1828000396490097\n",
      "Epoch 7, Loss: 0.19256313145160675\n",
      "Epoch 6, Loss: 0.42927998304367065\n",
      "Epoch 7, Loss: 0.18518882989883423\n",
      "Epoch 10, Loss: 0.05997256934642792\n",
      "Epoch 8, Loss: 0.2466883510351181\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.18983047622245736, feed_forward_dim=128, head_dim=32, lr=0.001034710743376546, num_heads=2, num_layers=4; total time=   1.3s\n",
      "Epoch 9, Loss: 0.04589150473475456\n",
      "Epoch 7, Loss: 0.1526036262512207\n",
      "Epoch 10, Loss: 0.11436659842729568\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.18983047622245736, feed_forward_dim=128, head_dim=32, lr=0.001034710743376546, num_heads=2, num_layers=4; total time=   1.3s\n",
      "Epoch 8, Loss: 0.07614889740943909\n",
      "Epoch 7, Loss: 0.2022222876548767\n",
      "Epoch 9, Loss: 0.14760465919971466\n",
      "Epoch 8, Loss: 0.0385509692132473\n",
      "Epoch 10, Loss: 0.1316428780555725\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.18983047622245736, feed_forward_dim=128, head_dim=32, lr=0.001034710743376546, num_heads=2, num_layers=4; total time=   1.4s\n",
      "Epoch 9, Loss: 0.04383999854326248\n",
      "Epoch 8, Loss: 0.1137956753373146\n",
      "Epoch 8, Loss: 0.030323278158903122\n",
      "Epoch 10, Loss: 0.05695484206080437\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.18983047622245736, feed_forward_dim=128, head_dim=32, lr=0.001034710743376546, num_heads=2, num_layers=4; total time=   1.4s\n",
      "Epoch 9, Loss: 0.017970295622944832\n",
      "Epoch 10, Loss: 0.07780543714761734\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.18983047622245736, feed_forward_dim=128, head_dim=32, lr=0.001034710743376546, num_heads=2, num_layers=4; total time=   1.4s\n",
      "Epoch 9, Loss: 0.03531961143016815\n",
      "Epoch 10, Loss: 0.08191560953855515\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.18983047622245736, feed_forward_dim=128, head_dim=32, lr=0.001034710743376546, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Epoch 9, Loss: 0.03078843094408512\n",
      "Epoch 10, Loss: 0.020422911271452904\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.18983047622245736, feed_forward_dim=128, head_dim=32, lr=0.001034710743376546, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.10912351310253143\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.18983047622245736, feed_forward_dim=128, head_dim=32, lr=0.001034710743376546, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.14562304317951202\n",
      "Epoch 1, Loss: 2.6140661239624023\n",
      "Epoch 1, Loss: 0.5402688384056091\n",
      "Epoch 2, Loss: 8.604788780212402\n",
      "Epoch 1, Loss: 0.8652141690254211\n",
      "Epoch 1, Loss: 0.08146306872367859\n",
      "Epoch 1, Loss: 2.803995370864868\n",
      "Epoch 2, Loss: 7.733090400695801\n",
      "Epoch 3, Loss: 0.7566416263580322\n",
      "Epoch 1, Loss: 0.1790810078382492\n",
      "Epoch 1, Loss: 1.983185887336731\n",
      "Epoch 2, Loss: 12.550492286682129\n",
      "Epoch 2, Loss: 4.925788879394531\n",
      "Epoch 1, Loss: 0.051712337881326675\n",
      "Epoch 2, Loss: 13.955069541931152\n",
      "Epoch 3, Loss: 2.139643430709839\n",
      "Epoch 4, Loss: 1.3103259801864624\n",
      "Epoch 1, Loss: 0.7096242308616638\n",
      "Epoch 2, Loss: 6.215384006500244\n",
      "Epoch 1, Loss: 1.5025187730789185\n",
      "Epoch 2, Loss: 14.505813598632812\n",
      "Epoch 3, Loss: 2.7496590614318848\n",
      "Epoch 1, Loss: 1.307702898979187\n",
      "Epoch 2, Loss: 9.5142183303833\n",
      "Epoch 4, Loss: 0.05301069840788841\n",
      "Epoch 5, Loss: 0.9161155223846436\n",
      "Epoch 3, Loss: 5.090658664703369\n",
      "Epoch 2, Loss: 11.539789199829102\n",
      "Epoch 3, Loss: 4.177120685577393\n",
      "Epoch 3, Loss: 2.382453441619873\n",
      "Epoch 4, Loss: 0.1313968300819397\n",
      "Epoch 5, Loss: 0.7432217597961426\n",
      "Epoch 2, Loss: 8.222336769104004\n",
      "Epoch 3, Loss: 3.902904987335205\n",
      "Epoch 6, Loss: 0.23250165581703186\n",
      "Epoch 2, Loss: 11.83414363861084\n",
      "Epoch 3, Loss: 2.2037179470062256\n",
      "Epoch 4, Loss: 1.2874914407730103\n",
      "Epoch 4, Loss: 0.18175819516181946\n",
      "Epoch 4, Loss: 0.22422629594802856\n",
      "Epoch 2, Loss: 10.381458282470703\n",
      "Epoch 3, Loss: 2.0312283039093018\n",
      "Epoch 6, Loss: 0.609240710735321\n",
      "Epoch 7, Loss: 0.06031579151749611\n",
      "Epoch 5, Loss: 1.049955129623413\n",
      "Epoch 3, Loss: 1.6654987335205078\n",
      "Epoch 5, Loss: 0.7190733551979065\n",
      "Epoch 3, Loss: 3.0088846683502197\n",
      "Epoch 7, Loss: 0.18226997554302216\n",
      "Epoch 5, Loss: 0.297313928604126\n",
      "Epoch 8, Loss: 0.14852701127529144\n",
      "Epoch 4, Loss: 0.088113933801651\n",
      "Epoch 6, Loss: 0.6491968631744385\n",
      "Epoch 5, Loss: 0.03851677477359772\n",
      "Epoch 4, Loss: 0.053635887801647186\n",
      "Epoch 6, Loss: 1.0130783319473267\n",
      "Epoch 3, Loss: 2.464733362197876\n",
      "Epoch 4, Loss: 0.14052872359752655\n",
      "Epoch 9, Loss: 0.21282567083835602\n",
      "Epoch 6, Loss: 0.36190304160118103\n",
      "Epoch 4, Loss: 0.09699179232120514\n",
      "Epoch 8, Loss: 0.06250708550214767\n",
      "Epoch 6, Loss: 0.6947625279426575\n",
      "Epoch 7, Loss: 0.1683734953403473\n",
      "Epoch 4, Loss: 0.07975722849369049\n",
      "Epoch 5, Loss: 0.7729586958885193\n",
      "Epoch 5, Loss: 0.7180575132369995\n",
      "Epoch 7, Loss: 0.5460396409034729\n",
      "Epoch 10, Loss: 0.1851225197315216\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.33546373906326965, feed_forward_dim=512, head_dim=16, lr=0.00497158480999255, num_heads=8, num_layers=1; total time=   1.1s\n",
      "Epoch 7, Loss: 0.5466766953468323\n",
      "Epoch 7, Loss: 0.5488623380661011\n",
      "Epoch 8, Loss: 0.0670221820473671\n",
      "Epoch 5, Loss: 0.8182771801948547\n",
      "Epoch 9, Loss: 0.15940727293491364\n",
      "Epoch 6, Loss: 0.7794249057769775\n",
      "Epoch 4, Loss: 0.05722524970769882\n",
      "Epoch 8, Loss: 0.14520953595638275\n",
      "Epoch 5, Loss: 0.8155843615531921\n",
      "Epoch 5, Loss: 0.6539155840873718\n",
      "Epoch 6, Loss: 0.7659057378768921\n",
      "Epoch 8, Loss: 0.24648882448673248\n",
      "Epoch 10, Loss: 0.2054726779460907\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.33546373906326965, feed_forward_dim=512, head_dim=16, lr=0.00497158480999255, num_heads=8, num_layers=1; total time=   1.2s\n",
      "Epoch 9, Loss: 0.1718538999557495\n",
      "Epoch 9, Loss: 0.0644569918513298\n",
      "Epoch 7, Loss: 0.31998246908187866\n",
      "Epoch 8, Loss: 0.39861923456192017\n",
      "Epoch 6, Loss: 0.29112449288368225\n",
      "Epoch 6, Loss: 0.5234043002128601\n",
      "Epoch 7, Loss: 0.3678854703903198\n",
      "Epoch 6, Loss: 0.781683623790741\n",
      "Epoch 10, Loss: 0.21788524091243744\n",
      "Epoch 9, Loss: 0.07383906096220016\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.33546373906326965, feed_forward_dim=512, head_dim=16, lr=0.00497158480999255, num_heads=8, num_layers=1; total time=   1.2s\n",
      "Epoch 5, Loss: 0.7364248633384705\n",
      "Epoch 10, Loss: 0.17306987941265106\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.33546373906326965, feed_forward_dim=512, head_dim=16, lr=0.00497158480999255, num_heads=8, num_layers=1; total time=   1.2s\n",
      "Epoch 8, Loss: 0.060137346386909485\n",
      "Epoch 9, Loss: 0.1748386174440384\n",
      "Epoch 7, Loss: 0.1531495451927185\n",
      "Epoch 8, Loss: 0.10062839835882187\n",
      "Epoch 10, Loss: 0.06708111613988876\n",
      "Epoch 7, Loss: 0.05757367983460426\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.33546373906326965, feed_forward_dim=512, head_dim=16, lr=0.00497158480999255, num_heads=8, num_layers=1; total time=   1.3s\n",
      "Epoch 6, Loss: 0.7049776315689087\n",
      "Epoch 7, Loss: 0.3345281183719635\n",
      "Epoch 9, Loss: 0.10895389318466187\n",
      "Epoch 10, Loss: 0.059477876871824265\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.33546373906326965, feed_forward_dim=512, head_dim=16, lr=0.00497158480999255, num_heads=8, num_layers=1; total time=   1.4s\n",
      "Epoch 8, Loss: 0.05923490598797798\n",
      "Epoch 9, Loss: 0.06000226363539696\n",
      "Epoch 7, Loss: 0.3034214377403259\n",
      "Epoch 10, Loss: 0.20273403823375702\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.33546373906326965, feed_forward_dim=512, head_dim=16, lr=0.00497158480999255, num_heads=8, num_layers=1; total time=   1.4s\n",
      "Epoch 8, Loss: 0.08681853115558624\n",
      "Epoch 8, Loss: 0.12465354800224304\n",
      "Epoch 9, Loss: 0.14754696190357208\n",
      "Epoch 10, Loss: 0.13958609104156494\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.33546373906326965, feed_forward_dim=512, head_dim=16, lr=0.00497158480999255, num_heads=8, num_layers=1; total time=   1.5s\n",
      "Epoch 9, Loss: 0.07174676656723022\n",
      "Epoch 8, Loss: 0.07908307760953903\n",
      "Epoch 9, Loss: 0.18001684546470642\n",
      "Epoch 10, Loss: 0.20054800808429718\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.33546373906326965, feed_forward_dim=512, head_dim=16, lr=0.00497158480999255, num_heads=8, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.14939264953136444\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.33546373906326965, feed_forward_dim=512, head_dim=16, lr=0.00497158480999255, num_heads=8, num_layers=1; total time=   1.6s\n",
      "Epoch 10, Loss: 0.13299840688705444\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.33546373906326965, feed_forward_dim=512, head_dim=16, lr=0.00497158480999255, num_heads=8, num_layers=1; total time=   1.5s\n",
      "Epoch 9, Loss: 0.08597216755151749\n",
      "Epoch 10, Loss: 0.17706866562366486\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.33546373906326965, feed_forward_dim=512, head_dim=16, lr=0.00497158480999255, num_heads=8, num_layers=1; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.34807538986206055\n",
      "Epoch 1, Loss: 0.4792177677154541\n",
      "Epoch 1, Loss: 2.545841693878174\n",
      "Epoch 2, Loss: 0.3002655506134033\n",
      "Epoch 1, Loss: 2.239919900894165\n",
      "Epoch 1, Loss: 2.1093928813934326\n",
      "Epoch 1, Loss: 0.08747053891420364\n",
      "Epoch 1, Loss: 0.7965596914291382\n",
      "Epoch 2, Loss: 0.06580638885498047\n",
      "Epoch 2, Loss: 0.48218587040901184\n",
      "Epoch 3, Loss: 0.23516663908958435\n",
      "Epoch 1, Loss: 0.47823768854141235\n",
      "Epoch 2, Loss: 0.4012186527252197\n",
      "Epoch 1, Loss: 0.10152992606163025\n",
      "Epoch 1, Loss: 1.8742682933807373\n",
      "Epoch 2, Loss: 0.04269479960203171\n",
      "Epoch 2, Loss: 0.39816954731941223\n",
      "Epoch 2, Loss: 0.01833595521748066\n",
      "Epoch 4, Loss: 0.07287289947271347\n",
      "Epoch 1, Loss: 0.08372703194618225\n",
      "Epoch 3, Loss: 0.26772165298461914\n",
      "Epoch 2, Loss: 0.02780766598880291\n",
      "Epoch 3, Loss: 0.05060592293739319\n",
      "Epoch 5, Loss: 0.06307711452245712\n",
      "Epoch 3, Loss: 0.07946523278951645\n",
      "Epoch 1, Loss: 1.42156982421875\n",
      "Epoch 3, Loss: 0.35447484254837036\n",
      "Epoch 4, Loss: 0.21216478943824768\n",
      "Epoch 3, Loss: 0.0819164589047432\n",
      "Epoch 3, Loss: 0.10458429902791977\n",
      "Epoch 4, Loss: 0.4240057170391083\n",
      "Epoch 6, Loss: 0.11005546897649765\n",
      "Epoch 2, Loss: 0.30437496304512024\n",
      "Epoch 3, Loss: 0.24657979607582092\n",
      "Epoch 2, Loss: 0.4917300343513489\n",
      "Epoch 2, Loss: 0.31167981028556824\n",
      "Epoch 4, Loss: 0.47604721784591675\n",
      "Epoch 5, Loss: 0.07142431288957596\n",
      "Epoch 4, Loss: 0.35888078808784485\n",
      "Epoch 4, Loss: 0.05673839896917343\n",
      "Epoch 5, Loss: 0.6595776081085205\n",
      "Epoch 4, Loss: 0.4328630864620209\n",
      "Epoch 2, Loss: 0.10494223982095718\n",
      "Epoch 3, Loss: 0.25747087597846985\n",
      "Epoch 7, Loss: 0.08351132273674011\n",
      "Epoch 6, Loss: 0.018253818154335022\n",
      "Epoch 4, Loss: 0.21448667347431183\n",
      "Epoch 3, Loss: 0.07432269304990768\n",
      "Epoch 6, Loss: 0.6045243144035339\n",
      "Epoch 5, Loss: 0.6622470021247864\n",
      "Epoch 5, Loss: 0.16746732592582703\n",
      "Epoch 5, Loss: 0.06779207289218903\n",
      "Epoch 3, Loss: 0.06691128015518188\n",
      "Epoch 8, Loss: 0.029726959764957428\n",
      "Epoch 5, Loss: 0.5898052453994751\n",
      "Epoch 3, Loss: 0.2398277074098587\n",
      "Epoch 7, Loss: 0.05582167208194733\n",
      "Epoch 4, Loss: 0.5757590532302856\n",
      "Epoch 7, Loss: 0.408946692943573\n",
      "Epoch 5, Loss: 0.07955697178840637\n",
      "Epoch 6, Loss: 0.5512773394584656\n",
      "Epoch 9, Loss: 0.014230627566576004\n",
      "Epoch 4, Loss: 0.02806040458381176\n",
      "Epoch 6, Loss: 0.03638705238699913\n",
      "Epoch 6, Loss: 0.018474390730261803\n",
      "Epoch 8, Loss: 0.10124485194683075\n",
      "Epoch 4, Loss: 0.15494072437286377\n",
      "Epoch 4, Loss: 0.527177631855011\n",
      "Epoch 8, Loss: 0.2063482105731964\n",
      "Epoch 6, Loss: 0.5001270174980164\n",
      "Epoch 10, Loss: 0.03992758318781853\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0004751520709183149, num_heads=4, num_layers=2; total time=   0.9s\n",
      "Epoch 5, Loss: 0.5859838724136353\n",
      "Epoch 6, Loss: 0.012834649533033371\n",
      "Epoch 7, Loss: 0.33259761333465576\n",
      "Epoch 7, Loss: 0.029351895675063133\n",
      "Epoch 9, Loss: 0.09759692847728729\n",
      "Epoch 7, Loss: 0.030160032212734222\n",
      "Epoch 9, Loss: 0.06709996610879898\n",
      "Epoch 5, Loss: 0.11881454288959503\n",
      "Epoch 7, Loss: 0.305824339389801\n",
      "Epoch 5, Loss: 0.4341679513454437\n",
      "Epoch 5, Loss: 0.25241607427597046\n",
      "Epoch 8, Loss: 0.14443658292293549\n",
      "Epoch 6, Loss: 0.39854323863983154\n",
      "Epoch 7, Loss: 0.0367363803088665\n",
      "Epoch 10, Loss: 0.05655927583575249\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0004751520709183149, num_heads=4, num_layers=2; total time=   1.1s\n",
      "Epoch 10, Loss: 0.017771776765584946\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0004751520709183149, num_heads=4, num_layers=2; total time=   1.1s\n",
      "Epoch 8, Loss: 0.03405822068452835\n",
      "Epoch 8, Loss: 0.09453119337558746\n",
      "Epoch 6, Loss: 0.10530813783407211\n",
      "Epoch 8, Loss: 0.1353655457496643\n",
      "Epoch 9, Loss: 0.046451885253190994\n",
      "Epoch 6, Loss: 0.147257000207901\n",
      "Epoch 6, Loss: 0.20388561487197876\n",
      "Epoch 8, Loss: 0.08743604272603989\n",
      "Epoch 9, Loss: 0.012773774564266205\n",
      "Epoch 9, Loss: 0.04510669410228729\n",
      "Epoch 10, Loss: 0.04066501930356026\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0004751520709183149, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 7, Loss: 0.19668146967887878\n",
      "Epoch 9, Loss: 0.14259839057922363\n",
      "Epoch 7, Loss: 0.035301003605127335\n",
      "Epoch 10, Loss: 0.008274970576167107\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0004751520709183149, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 7, Loss: 0.03675145283341408\n",
      "Epoch 7, Loss: 0.044898469001054764\n",
      "Epoch 10, Loss: 0.04016391560435295\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0004751520709183149, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 9, Loss: 0.10281748324632645\n",
      "Epoch 10, Loss: 0.1397450566291809\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0004751520709183149, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 8, Loss: 0.0740327313542366\n",
      "Epoch 8, Loss: 0.03163902088999748\n",
      "Epoch 8, Loss: 0.012625431641936302\n",
      "Epoch 10, Loss: 0.07730735838413239\n",
      "Epoch 8, Loss: 0.006008611060678959\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0004751520709183149, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 9, Loss: 0.04514327272772789\n",
      "Epoch 9, Loss: 0.08789211511611938\n",
      "Epoch 9, Loss: 0.06937011331319809\n",
      "Epoch 9, Loss: 0.03186695650219917\n",
      "Epoch 10, Loss: 0.0800415500998497\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0004751520709183149, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 10, Loss: 0.11527656763792038\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0004751520709183149, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.0583503432571888\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0004751520709183149, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.13741987943649292\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0004751520709183149, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.21001370251178741\n",
      "Epoch 1, Loss: 0.2788096070289612\n",
      "Epoch 1, Loss: 0.17368027567863464\n",
      "Epoch 1, Loss: 0.29132622480392456\n",
      "Epoch 1, Loss: 0.8173019289970398\n",
      "Epoch 2, Loss: 0.18812352418899536\n",
      "Epoch 1, Loss: 0.13306032121181488\n",
      "Epoch 2, Loss: 0.2064528614282608\n",
      "Epoch 2, Loss: 0.11904234439134598\n",
      "Epoch 1, Loss: 0.10849522799253464\n",
      "Epoch 1, Loss: 0.1914149969816208\n",
      "Epoch 2, Loss: 0.2272881418466568\n",
      "Epoch 2, Loss: 0.6674858927726746\n",
      "Epoch 3, Loss: 0.16982413828372955\n",
      "Epoch 3, Loss: 0.14447593688964844\n",
      "Epoch 2, Loss: 0.12025701254606247\n",
      "Epoch 3, Loss: 0.07987857609987259\n",
      "Epoch 1, Loss: 0.6029716730117798\n",
      "Epoch 2, Loss: 0.06113726273179054\n",
      "Epoch 3, Loss: 0.18621601164340973\n",
      "Epoch 1, Loss: 0.29705241322517395\n",
      "Epoch 4, Loss: 0.16033446788787842\n",
      "Epoch 2, Loss: 0.15397390723228455\n",
      "Epoch 3, Loss: 0.5287126302719116\n",
      "Epoch 1, Loss: 0.3738246262073517\n",
      "Epoch 4, Loss: 0.09670062363147736\n",
      "Epoch 3, Loss: 0.11201926320791245\n",
      "Epoch 1, Loss: 0.7446215748786926\n",
      "Epoch 4, Loss: 0.1614716351032257\n",
      "Epoch 4, Loss: 0.04803698882460594\n",
      "Epoch 5, Loss: 0.1518016755580902\n",
      "Epoch 2, Loss: 0.47351932525634766\n",
      "Epoch 3, Loss: 0.030467912554740906\n",
      "Epoch 5, Loss: 0.06570743024349213\n",
      "Epoch 4, Loss: 0.4190380275249481\n",
      "Epoch 4, Loss: 0.10216064751148224\n",
      "Epoch 2, Loss: 0.23577247560024261\n",
      "Epoch 3, Loss: 0.1278991997241974\n",
      "Epoch 5, Loss: 0.14893066883087158\n",
      "Epoch 2, Loss: 0.28150883316993713\n",
      "Epoch 6, Loss: 0.14177916944026947\n",
      "Epoch 5, Loss: 0.030454576015472412\n",
      "Epoch 6, Loss: 0.04719388112425804\n",
      "Epoch 4, Loss: 0.01745668426156044\n",
      "Epoch 3, Loss: 0.37307822704315186\n",
      "Epoch 2, Loss: 0.6074874401092529\n",
      "Epoch 5, Loss: 0.3223421573638916\n",
      "Epoch 5, Loss: 0.09515514224767685\n",
      "Epoch 4, Loss: 0.11568723618984222\n",
      "Epoch 6, Loss: 0.14407815039157867\n",
      "Epoch 3, Loss: 0.18457409739494324\n",
      "Epoch 7, Loss: 0.13183754682540894\n",
      "Epoch 6, Loss: 0.0225059911608696\n",
      "Epoch 7, Loss: 0.04049336910247803\n",
      "Epoch 3, Loss: 0.2042044848203659\n",
      "Epoch 8, Loss: 0.11854401230812073\n",
      "Epoch 4, Loss: 0.28583574295043945\n",
      "Epoch 5, Loss: 0.016400430351495743\n",
      "Epoch 7, Loss: 0.14281828701496124\n",
      "Epoch 6, Loss: 0.2446788251399994\n",
      "Epoch 8, Loss: 0.04062052071094513\n",
      "Epoch 3, Loss: 0.47957172989845276\n",
      "Epoch 6, Loss: 0.08669255673885345\n",
      "Epoch 5, Loss: 0.11045118421316147\n",
      "Epoch 7, Loss: 0.02272673323750496\n",
      "Epoch 8, Loss: 0.14218172430992126\n",
      "Epoch 9, Loss: 0.11035890132188797\n",
      "Epoch 9, Loss: 0.049151983112096786\n",
      "Epoch 4, Loss: 0.1455695778131485\n",
      "Epoch 4, Loss: 0.1410442441701889\n",
      "Epoch 6, Loss: 0.023156827315688133\n",
      "Epoch 7, Loss: 0.17853790521621704\n",
      "Epoch 5, Loss: 0.22099272906780243\n",
      "Epoch 7, Loss: 0.07791588455438614\n",
      "Epoch 8, Loss: 0.026753442361950874\n",
      "Epoch 4, Loss: 0.3747049570083618\n",
      "Epoch 9, Loss: 0.13708719611167908\n",
      "Epoch 10, Loss: 0.10111799091100693\n",
      "Epoch 10, Loss: 0.05635976046323776\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.38910138501053426, feed_forward_dim=1024, head_dim=8, lr=5.006728171377132e-05, num_heads=2, num_layers=1; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.38910138501053426, feed_forward_dim=1024, head_dim=8, lr=5.006728171377132e-05, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 6, Loss: 0.11319339275360107\n",
      "Epoch 8, Loss: 0.132864311337471\n",
      "Epoch 8, Loss: 0.07188352197408676\n",
      "Epoch 9, Loss: 0.032746363431215286\n",
      "Epoch 5, Loss: 0.11570149660110474\n",
      "Epoch 10, Loss: 0.12954452633857727\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.38910138501053426, feed_forward_dim=1024, head_dim=8, lr=5.006728171377132e-05, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 7, Loss: 0.031245676800608635\n",
      "Epoch 6, Loss: 0.17412440478801727\n",
      "Epoch 5, Loss: 0.09345776587724686\n",
      "Epoch 7, Loss: 0.10798127949237823\n",
      "Epoch 5, Loss: 0.28783300518989563\n",
      "Epoch 10, Loss: 0.03712296858429909\n",
      "Epoch 9, Loss: 0.066844642162323\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.38910138501053426, feed_forward_dim=1024, head_dim=8, lr=5.006728171377132e-05, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 9, Loss: 0.0988994762301445\n",
      "Epoch 8, Loss: 0.034508977085351944\n",
      "Epoch 6, Loss: 0.09385640919208527\n",
      "Epoch 8, Loss: 0.10682563483715057\n",
      "Epoch 6, Loss: 0.05995415523648262\n",
      "Epoch 7, Loss: 0.14371249079704285\n",
      "Epoch 6, Loss: 0.2175179272890091\n",
      "Epoch 10, Loss: 0.05943939834833145\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.38910138501053426, feed_forward_dim=1024, head_dim=8, lr=5.006728171377132e-05, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.08078241348266602\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.38910138501053426, feed_forward_dim=1024, head_dim=8, lr=5.006728171377132e-05, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 7, Loss: 0.08255009353160858\n",
      "Epoch 9, Loss: 0.033041179180145264\n",
      "Epoch 9, Loss: 0.09856336563825607\n",
      "Epoch 7, Loss: 0.03885946050286293\n",
      "Epoch 8, Loss: 0.12549729645252228\n",
      "Epoch 7, Loss: 0.16673141717910767\n",
      "Epoch 10, Loss: 0.027734333649277687\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.38910138501053426, feed_forward_dim=1024, head_dim=8, lr=5.006728171377132e-05, num_heads=2, num_layers=1; total time=   1.6s\n",
      "Epoch 8, Loss: 0.0745706856250763\n",
      "Epoch 10, Loss: 0.09127708524465561\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.38910138501053426, feed_forward_dim=1024, head_dim=8, lr=5.006728171377132e-05, num_heads=2, num_layers=1; total time=   1.6s\n",
      "Epoch 8, Loss: 0.03087661974132061\n",
      "Epoch 9, Loss: 0.11813672631978989\n",
      "Epoch 8, Loss: 0.12960995733737946\n",
      "Epoch 9, Loss: 0.0733741968870163\n",
      "Epoch 9, Loss: 0.030641812831163406\n",
      "Epoch 10, Loss: 0.11913780868053436\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.38910138501053426, feed_forward_dim=1024, head_dim=8, lr=5.006728171377132e-05, num_heads=2, num_layers=1; total time=   1.7s\n",
      "Epoch 9, Loss: 0.1100970134139061\n",
      "Epoch 10, Loss: 0.07632629573345184\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.38910138501053426, feed_forward_dim=1024, head_dim=8, lr=5.006728171377132e-05, num_heads=2, num_layers=1; total time=   1.7s\n",
      "Epoch 10, Loss: 0.03598795458674431\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.38910138501053426, feed_forward_dim=1024, head_dim=8, lr=5.006728171377132e-05, num_heads=2, num_layers=1; total time=   1.7s\n",
      "Epoch 10, Loss: 0.10102580487728119\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.38910138501053426, feed_forward_dim=1024, head_dim=8, lr=5.006728171377132e-05, num_heads=2, num_layers=1; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.1824905127286911\n",
      "Epoch 1, Loss: 0.14269916713237762\n",
      "Epoch 1, Loss: 0.18014340102672577\n",
      "Epoch 1, Loss: 0.18418991565704346\n",
      "Epoch 1, Loss: 0.04976179450750351\n",
      "Epoch 1, Loss: 0.6289463043212891\n",
      "Epoch 2, Loss: 0.08116966485977173\n",
      "Epoch 1, Loss: 0.9140689969062805\n",
      "Epoch 2, Loss: 0.1377081573009491\n",
      "Epoch 2, Loss: 0.05809323489665985\n",
      "Epoch 1, Loss: 2.050244092941284\n",
      "Epoch 1, Loss: 0.17672693729400635\n",
      "Epoch 2, Loss: 0.11798075586557388\n",
      "Epoch 3, Loss: 0.037198733538389206\n",
      "Epoch 2, Loss: 0.0401613749563694\n",
      "Epoch 1, Loss: 0.0873521938920021\n",
      "Epoch 3, Loss: 0.024710072204470634\n",
      "Epoch 2, Loss: 0.6722990274429321\n",
      "Epoch 2, Loss: 0.43839576840400696\n",
      "Epoch 1, Loss: 0.09517677128314972\n",
      "Epoch 3, Loss: 0.1289910078048706\n",
      "Epoch 4, Loss: 0.03007500432431698\n",
      "Epoch 4, Loss: 0.027873165905475616\n",
      "Epoch 2, Loss: 1.644043207168579\n",
      "Epoch 1, Loss: 0.09437239170074463\n",
      "Epoch 2, Loss: 0.13241106271743774\n",
      "Epoch 3, Loss: 0.037124358117580414\n",
      "Epoch 3, Loss: 0.08901645243167877\n",
      "Epoch 5, Loss: 0.05029979720711708\n",
      "Epoch 3, Loss: 0.28521010279655457\n",
      "Epoch 4, Loss: 0.12059709429740906\n",
      "Epoch 3, Loss: 0.4799100160598755\n",
      "Epoch 2, Loss: 0.07448408007621765\n",
      "Epoch 3, Loss: 1.2773112058639526\n",
      "Epoch 5, Loss: 0.042913082987070084\n",
      "Epoch 2, Loss: 0.03637339919805527\n",
      "Epoch 6, Loss: 0.06284379214048386\n",
      "Epoch 2, Loss: 0.06966152042150497\n",
      "Epoch 4, Loss: 0.02751990035176277\n",
      "Epoch 4, Loss: 0.08530516177415848\n",
      "Epoch 5, Loss: 0.10811363905668259\n",
      "Epoch 4, Loss: 0.17330211400985718\n",
      "Epoch 4, Loss: 0.3189069628715515\n",
      "Epoch 3, Loss: 0.110563725233078\n",
      "Epoch 7, Loss: 0.06735420972108841\n",
      "Epoch 3, Loss: 0.0620860792696476\n",
      "Epoch 6, Loss: 0.05227974057197571\n",
      "Epoch 4, Loss: 0.9616920948028564\n",
      "Epoch 5, Loss: 0.024109357967972755\n",
      "Epoch 5, Loss: 0.09011134505271912\n",
      "Epoch 5, Loss: 0.09828059375286102\n",
      "Epoch 6, Loss: 0.09049428254365921\n",
      "Epoch 3, Loss: 0.017020361497998238\n",
      "Epoch 4, Loss: 0.10239718854427338\n",
      "Epoch 7, Loss: 0.04925438389182091\n",
      "Epoch 5, Loss: 0.20504987239837646\n",
      "Epoch 8, Loss: 0.05576429143548012\n",
      "Epoch 3, Loss: 0.05928998813033104\n",
      "Epoch 6, Loss: 0.021351618692278862\n",
      "Epoch 6, Loss: 0.08739083260297775\n",
      "Epoch 4, Loss: 0.04960497096180916\n",
      "Epoch 5, Loss: 0.6930103898048401\n",
      "Epoch 4, Loss: 0.024931717664003372\n",
      "Epoch 7, Loss: 0.07572342455387115\n",
      "Epoch 8, Loss: 0.03885065019130707\n",
      "Epoch 9, Loss: 0.0385652557015419\n",
      "Epoch 6, Loss: 0.05576672777533531\n",
      "Epoch 5, Loss: 0.09976840019226074\n",
      "Epoch 6, Loss: 0.12999273836612701\n",
      "Epoch 7, Loss: 0.08298707008361816\n",
      "Epoch 7, Loss: 0.019025569781661034\n",
      "Epoch 5, Loss: 0.039691463112831116\n",
      "Epoch 8, Loss: 0.06597965210676193\n",
      "Epoch 10, Loss: 0.02419956959784031\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3756444580691032, feed_forward_dim=128, head_dim=32, lr=8.28271787769839e-05, num_heads=4, num_layers=3; total time=   1.0s\n",
      "Epoch 4, Loss: 0.05368161201477051\n",
      "Epoch 9, Loss: 0.026210520416498184\n",
      "Epoch 6, Loss: 0.46470436453819275\n",
      "Epoch 5, Loss: 0.03638717532157898\n",
      "Epoch 7, Loss: 0.08938112109899521\n",
      "Epoch 9, Loss: 0.059468306601047516\n",
      "Epoch 6, Loss: 0.09323446452617645\n",
      "Epoch 7, Loss: 0.042899709194898605\n",
      "Epoch 8, Loss: 0.07071901857852936\n",
      "Epoch 8, Loss: 0.014914823696017265\n",
      "Epoch 10, Loss: 0.017020877450704575\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3756444580691032, feed_forward_dim=128, head_dim=32, lr=8.28271787769839e-05, num_heads=4, num_layers=3; total time=   1.1s\n",
      "Epoch 10, Loss: 0.053369440138339996\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3756444580691032, feed_forward_dim=128, head_dim=32, lr=8.28271787769839e-05, num_heads=4, num_layers=3; total time=   1.1s\n",
      "Epoch 5, Loss: 0.043248433619737625\n",
      "Epoch 9, Loss: 0.05688111484050751\n",
      "Epoch 8, Loss: 0.07324636727571487\n",
      "Epoch 6, Loss: 0.032193250954151154\n",
      "Epoch 7, Loss: 0.28818848729133606\n",
      "Epoch 8, Loss: 0.05154973641037941\n",
      "Epoch 6, Loss: 0.037504397332668304\n",
      "Epoch 7, Loss: 0.08381369709968567\n",
      "Epoch 9, Loss: 0.012554087676107883\n",
      "Epoch 10, Loss: 0.043892648071050644\n",
      "Epoch 9, Loss: 0.07178203761577606\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3756444580691032, feed_forward_dim=128, head_dim=32, lr=8.28271787769839e-05, num_heads=4, num_layers=3; total time=   1.2s\n",
      "Epoch 9, Loss: 0.07865164428949356\n",
      "Epoch 6, Loss: 0.032937098294496536\n",
      "Epoch 7, Loss: 0.02505764178931713\n",
      "Epoch 10, Loss: 0.011730493046343327\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3756444580691032, feed_forward_dim=128, head_dim=32, lr=8.28271787769839e-05, num_heads=4, num_layers=3; total time=   1.3s\n",
      "Epoch 7, Loss: 0.03178016096353531\n",
      "Epoch 8, Loss: 0.15769962966442108\n",
      "Epoch 10, Loss: 0.0911397784948349\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3756444580691032, feed_forward_dim=128, head_dim=32, lr=8.28271787769839e-05, num_heads=4, num_layers=3; total time=   1.3s\n",
      "Epoch 10, Loss: 0.09534551948308945\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3756444580691032, feed_forward_dim=128, head_dim=32, lr=8.28271787769839e-05, num_heads=4, num_layers=3; total time=   1.3s\n",
      "Epoch 8, Loss: 0.07202482223510742\n",
      "Epoch 8, Loss: 0.018384788185358047\n",
      "Epoch 7, Loss: 0.024090223014354706\n",
      "Epoch 8, Loss: 0.022000622004270554\n",
      "Epoch 9, Loss: 0.06972639262676239\n",
      "Epoch 9, Loss: 0.059353478252887726\n",
      "Epoch 9, Loss: 0.014707970432937145\n",
      "Epoch 8, Loss: 0.018600065261125565\n",
      "Epoch 9, Loss: 0.014873803593218327\n",
      "Epoch 10, Loss: 0.02316361293196678\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3756444580691032, feed_forward_dim=128, head_dim=32, lr=8.28271787769839e-05, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Epoch 10, Loss: 0.05129177123308182\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3756444580691032, feed_forward_dim=128, head_dim=32, lr=8.28271787769839e-05, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Epoch 10, Loss: 0.012137685902416706\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3756444580691032, feed_forward_dim=128, head_dim=32, lr=8.28271787769839e-05, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.015900610014796257\n",
      "Epoch 10, Loss: 0.011989807710051537\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3756444580691032, feed_forward_dim=128, head_dim=32, lr=8.28271787769839e-05, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.013004539534449577\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3756444580691032, feed_forward_dim=128, head_dim=32, lr=8.28271787769839e-05, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.29721885919570923\n",
      "Epoch 1, Loss: 0.21775130927562714\n",
      "Epoch 1, Loss: 0.06086855009198189\n",
      "Epoch 1, Loss: 0.4501560926437378\n",
      "Epoch 2, Loss: 0.21527116000652313\n",
      "Epoch 1, Loss: 0.24678295850753784\n",
      "Epoch 1, Loss: 1.1353237628936768\n",
      "Epoch 1, Loss: 0.37576520442962646\n",
      "Epoch 2, Loss: 0.17109769582748413\n",
      "Epoch 3, Loss: 0.15126284956932068\n",
      "Epoch 1, Loss: 1.569760799407959\n",
      "Epoch 2, Loss: 0.3449622690677643\n",
      "Epoch 2, Loss: 0.053712256252765656\n",
      "Epoch 3, Loss: 0.14480245113372803\n",
      "Epoch 2, Loss: 0.19452232122421265\n",
      "Epoch 1, Loss: 0.49855297803878784\n",
      "Epoch 2, Loss: 0.9837212562561035\n",
      "Epoch 2, Loss: 0.27175840735435486\n",
      "Epoch 4, Loss: 0.10478441417217255\n",
      "Epoch 3, Loss: 0.2538837492465973\n",
      "Epoch 1, Loss: 0.19716966152191162\n",
      "Epoch 1, Loss: 0.04057896137237549\n",
      "Epoch 3, Loss: 0.04983536899089813\n",
      "Epoch 2, Loss: 1.3997716903686523\n",
      "Epoch 5, Loss: 0.0668097659945488\n",
      "Epoch 1, Loss: 0.11332591623067856\n",
      "Epoch 4, Loss: 0.1237034946680069\n",
      "Epoch 3, Loss: 0.16777700185775757\n",
      "Epoch 2, Loss: 0.4166046977043152\n",
      "Epoch 3, Loss: 0.8483355045318604\n",
      "Epoch 4, Loss: 0.18108154833316803\n",
      "Epoch 3, Loss: 0.18752476572990417\n",
      "Epoch 4, Loss: 0.04557061567902565\n",
      "Epoch 6, Loss: 0.04244823753833771\n",
      "Epoch 2, Loss: 0.1461278349161148\n",
      "Epoch 2, Loss: 0.01515938900411129\n",
      "Epoch 5, Loss: 0.11244576424360275\n",
      "Epoch 3, Loss: 1.2265028953552246\n",
      "Epoch 4, Loss: 0.14599645137786865\n",
      "Epoch 7, Loss: 0.030852170661091805\n",
      "Epoch 5, Loss: 0.1267220675945282\n",
      "Epoch 2, Loss: 0.10050316154956818\n",
      "Epoch 5, Loss: 0.03963517025113106\n",
      "Epoch 4, Loss: 0.7272080183029175\n",
      "Epoch 4, Loss: 0.12213515490293503\n",
      "Epoch 3, Loss: 0.3413003087043762\n",
      "Epoch 8, Loss: 0.029899120330810547\n",
      "Epoch 6, Loss: 0.11207897216081619\n",
      "Epoch 5, Loss: 0.13717809319496155\n",
      "Epoch 4, Loss: 1.0721698999404907\n",
      "Epoch 3, Loss: 0.006699609104543924\n",
      "Epoch 3, Loss: 0.11221874505281448\n",
      "Epoch 6, Loss: 0.0369061604142189\n",
      "Epoch 6, Loss: 0.08620738983154297\n",
      "Epoch 5, Loss: 0.610762357711792\n",
      "Epoch 3, Loss: 0.08893247693777084\n",
      "Epoch 7, Loss: 0.10921148955821991\n",
      "Epoch 6, Loss: 0.13300956785678864\n",
      "Epoch 5, Loss: 0.07727154344320297\n",
      "Epoch 9, Loss: 0.034011147916316986\n",
      "Epoch 4, Loss: 0.2799997925758362\n",
      "Epoch 7, Loss: 0.05990361049771309\n",
      "Epoch 7, Loss: 0.032117802649736404\n",
      "Epoch 10, Loss: 0.0394255667924881\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=4, num_layers=3; total time=   1.0s\n",
      "Epoch 8, Loss: 0.10664086043834686\n",
      "Epoch 6, Loss: 0.5070480108261108\n",
      "Epoch 4, Loss: 0.01027971412986517\n",
      "Epoch 5, Loss: 0.9286074042320251\n",
      "Epoch 4, Loss: 0.09579537808895111\n",
      "Epoch 7, Loss: 0.1307883858680725\n",
      "Epoch 8, Loss: 0.04739939793944359\n",
      "Epoch 4, Loss: 0.07813909649848938\n",
      "Epoch 6, Loss: 0.04833485931158066\n",
      "Epoch 5, Loss: 0.2336292713880539\n",
      "Epoch 8, Loss: 0.027999788522720337\n",
      "Epoch 9, Loss: 0.10197467356920242\n",
      "Epoch 7, Loss: 0.4108462333679199\n",
      "Epoch 9, Loss: 0.046425711363554\n",
      "Epoch 8, Loss: 0.12602055072784424\n",
      "Epoch 6, Loss: 0.7903704047203064\n",
      "Epoch 9, Loss: 0.02494433894753456\n",
      "Epoch 5, Loss: 0.06979413330554962\n",
      "Epoch 5, Loss: 0.08981695026159286\n",
      "Epoch 10, Loss: 0.09091563522815704\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=4, num_layers=3; total time=   1.2s\n",
      "Epoch 8, Loss: 0.331169992685318\n",
      "Epoch 10, Loss: 0.05213477090001106\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=4, num_layers=3; total time=   1.2s\n",
      "Epoch 5, Loss: 0.015983188524842262\n",
      "Epoch 7, Loss: 0.035725515335798264\n",
      "Epoch 6, Loss: 0.20055361092090607\n",
      "Epoch 9, Loss: 0.119923897087574\n",
      "Epoch 10, Loss: 0.02174188196659088\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=4, num_layers=3; total time=   1.2s\n",
      "Epoch 7, Loss: 0.6715142130851746\n",
      "Epoch 6, Loss: 0.059226635843515396\n",
      "Epoch 8, Loss: 0.036718759685754776\n",
      "Epoch 9, Loss: 0.26073965430259705\n",
      "Epoch 7, Loss: 0.17889833450317383\n",
      "Epoch 6, Loss: 0.018345477059483528\n",
      "Epoch 6, Loss: 0.09152250736951828\n",
      "Epoch 10, Loss: 0.11011854559183121\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=4, num_layers=3; total time=   1.3s\n",
      "Epoch 10, Loss: 0.19829674065113068\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.04272571951150894\n",
      "Epoch 8, Loss: 0.5606271624565125\n",
      "Epoch 8, Loss: 0.16555418074131012\n",
      "Epoch 7, Loss: 0.05167943239212036\n",
      "Epoch 7, Loss: 0.014660564251244068\n",
      "Epoch 7, Loss: 0.09131923317909241\n",
      "Epoch 10, Loss: 0.05405879020690918\n",
      "Epoch 9, Loss: 0.461553692817688\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.16129514575004578\n",
      "Epoch 8, Loss: 0.01081665139645338\n",
      "Epoch 8, Loss: 0.046631962060928345\n",
      "Epoch 8, Loss: 0.0897943452000618\n",
      "Epoch 10, Loss: 0.37120112776756287\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.15726995468139648\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 9, Loss: 0.007089980412274599\n",
      "Epoch 9, Loss: 0.08728872984647751\n",
      "Epoch 9, Loss: 0.03966192901134491\n",
      "Epoch 10, Loss: 0.0065482486970722675\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=4, num_layers=3; total time=   1.6s\n",
      "Epoch 10, Loss: 0.07806120067834854\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=4, num_layers=3; total time=   1.6s\n",
      "Epoch 10, Loss: 0.033583931624889374\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=4, num_layers=3; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 2.2321534156799316\n",
      "Epoch 1, Loss: 1.218916654586792\n",
      "Epoch 1, Loss: 0.4633628726005554\n",
      "Epoch 2, Loss: 1.9859508275985718\n",
      "Epoch 1, Loss: 1.0655438899993896\n",
      "Epoch 1, Loss: 0.40830326080322266\n",
      "Epoch 1, Loss: 1.1273735761642456\n",
      "Epoch 2, Loss: 1.057641625404358\n",
      "Epoch 2, Loss: 0.3653133511543274\n",
      "Epoch 2, Loss: 0.8587430119514465\n",
      "Epoch 1, Loss: 0.7329184412956238\n",
      "Epoch 3, Loss: 1.7382868528366089\n",
      "Epoch 1, Loss: 0.9742587208747864\n",
      "Epoch 2, Loss: 0.31509819626808167\n",
      "Epoch 1, Loss: 0.5754402875900269\n",
      "Epoch 2, Loss: 0.9590991139411926\n",
      "Epoch 3, Loss: 0.9134498834609985\n",
      "Epoch 3, Loss: 0.28224247694015503\n",
      "Epoch 4, Loss: 1.5173176527023315\n",
      "Epoch 2, Loss: 0.600907027721405\n",
      "Epoch 3, Loss: 0.6722867488861084\n",
      "Epoch 1, Loss: 0.9635052680969238\n",
      "Epoch 1, Loss: 0.9012451767921448\n",
      "Epoch 4, Loss: 0.21695393323898315\n",
      "Epoch 1, Loss: 2.1619386672973633\n",
      "Epoch 2, Loss: 0.8168928623199463\n",
      "Epoch 4, Loss: 0.7806486487388611\n",
      "Epoch 3, Loss: 0.24084311723709106\n",
      "Epoch 3, Loss: 0.792161762714386\n",
      "Epoch 5, Loss: 1.3138538599014282\n",
      "Epoch 4, Loss: 0.5127704739570618\n",
      "Epoch 2, Loss: 0.45149579644203186\n",
      "Epoch 3, Loss: 0.4838773012161255\n",
      "Epoch 5, Loss: 0.17164704203605652\n",
      "Epoch 5, Loss: 0.6558624505996704\n",
      "Epoch 2, Loss: 0.8148813843727112\n",
      "Epoch 6, Loss: 1.120939016342163\n",
      "Epoch 3, Loss: 0.6722524166107178\n",
      "Epoch 4, Loss: 0.17894700169563293\n",
      "Epoch 2, Loss: 0.6977114081382751\n",
      "Epoch 2, Loss: 1.9288859367370605\n",
      "Epoch 4, Loss: 0.6485362648963928\n",
      "Epoch 5, Loss: 0.3802715241909027\n",
      "Epoch 6, Loss: 0.5434918403625488\n",
      "Epoch 6, Loss: 0.13553765416145325\n",
      "Epoch 3, Loss: 0.3497118651866913\n",
      "Epoch 7, Loss: 0.956968367099762\n",
      "Epoch 4, Loss: 0.3780980408191681\n",
      "Epoch 5, Loss: 0.1367931216955185\n",
      "Epoch 3, Loss: 0.6633332967758179\n",
      "Epoch 7, Loss: 0.4458845853805542\n",
      "Epoch 7, Loss: 0.11572407186031342\n",
      "Epoch 3, Loss: 0.5189744234085083Epoch 4, Loss: 0.5421304702758789\n",
      "\n",
      "Epoch 5, Loss: 0.5191988348960876\n",
      "Epoch 8, Loss: 0.8058527708053589\n",
      "Epoch 6, Loss: 0.2677401602268219\n",
      "Epoch 3, Loss: 1.70368492603302\n",
      "Epoch 5, Loss: 0.2914029359817505\n",
      "Epoch 8, Loss: 0.3559759855270386\n",
      "Epoch 6, Loss: 0.10522489994764328\n",
      "Epoch 4, Loss: 0.26084667444229126\n",
      "Epoch 9, Loss: 0.6650214195251465\n",
      "Epoch 6, Loss: 0.4081540107727051\n",
      "Epoch 8, Loss: 0.1089942455291748\n",
      "Epoch 7, Loss: 0.17927613854408264\n",
      "Epoch 4, Loss: 0.5377267003059387\n",
      "Epoch 5, Loss: 0.43404898047447205\n",
      "Epoch 9, Loss: 0.282067209482193\n",
      "Epoch 4, Loss: 0.3725036084651947\n",
      "Epoch 10, Loss: 0.5513753890991211\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.26531459095842913, feed_forward_dim=128, head_dim=8, lr=5.050673503847966e-05, num_heads=2, num_layers=1; total time=   1.1s\n",
      "Epoch 7, Loss: 0.0887480080127716\n",
      "Epoch 9, Loss: 0.10791858285665512\n",
      "Epoch 5, Loss: 0.1850525587797165\n",
      "Epoch 6, Loss: 0.21518824994564056\n",
      "Epoch 7, Loss: 0.31279683113098145\n",
      "Epoch 4, Loss: 1.4943948984146118\n",
      "Epoch 10, Loss: 0.2180856168270111\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.26531459095842913, feed_forward_dim=128, head_dim=8, lr=5.050673503847966e-05, num_heads=2, num_layers=1; total time=   1.1s\n",
      "Epoch 8, Loss: 0.11335346102714539\n",
      "Epoch 5, Loss: 0.42051446437835693\n",
      "Epoch 10, Loss: 0.11016395688056946\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.26531459095842913, feed_forward_dim=128, head_dim=8, lr=5.050673503847966e-05, num_heads=2, num_layers=1; total time=   1.1s\n",
      "Epoch 8, Loss: 0.08239984512329102\n",
      "Epoch 6, Loss: 0.345401793718338\n",
      "Epoch 8, Loss: 0.23270216584205627\n",
      "Epoch 6, Loss: 0.12490241974592209\n",
      "Epoch 5, Loss: 0.24877451360225677\n",
      "Epoch 7, Loss: 0.1601821631193161\n",
      "Epoch 9, Loss: 0.06615220755338669\n",
      "Epoch 7, Loss: 0.26620617508888245\n",
      "Epoch 9, Loss: 0.08294608443975449\n",
      "Epoch 5, Loss: 1.3037737607955933\n",
      "Epoch 6, Loss: 0.3262530267238617\n",
      "Epoch 9, Loss: 0.1681305468082428\n",
      "Epoch 7, Loss: 0.08049237728118896\n",
      "Epoch 10, Loss: 0.03987816721200943\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.26531459095842913, feed_forward_dim=128, head_dim=8, lr=5.050673503847966e-05, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 10, Loss: 0.08943039923906326\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.26531459095842913, feed_forward_dim=128, head_dim=8, lr=5.050673503847966e-05, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 6, Loss: 0.15486256778240204\n",
      "Epoch 8, Loss: 0.11263632029294968\n",
      "Epoch 8, Loss: 0.2106686234474182\n",
      "Epoch 7, Loss: 0.24603743851184845\n",
      "Epoch 6, Loss: 1.1236705780029297\n",
      "Epoch 10, Loss: 0.11997255682945251\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.26531459095842913, feed_forward_dim=128, head_dim=8, lr=5.050673503847966e-05, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 8, Loss: 0.04789834842085838\n",
      "Epoch 9, Loss: 0.07857399433851242\n",
      "Epoch 7, Loss: 0.0881064161658287\n",
      "Epoch 9, Loss: 0.1690520942211151\n",
      "Epoch 8, Loss: 0.17730273306369781\n",
      "Epoch 9, Loss: 0.030559994280338287\n",
      "Epoch 10, Loss: 0.055580079555511475\n",
      "Epoch 7, Loss: 0.9623799920082092\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.26531459095842913, feed_forward_dim=128, head_dim=8, lr=5.050673503847966e-05, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 8, Loss: 0.0426311232149601\n",
      "Epoch 9, Loss: 0.12410545349121094\n",
      "Epoch 10, Loss: 0.13893121480941772\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.26531459095842913, feed_forward_dim=128, head_dim=8, lr=5.050673503847966e-05, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.021523738279938698\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.26531459095842913, feed_forward_dim=128, head_dim=8, lr=5.050673503847966e-05, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 8, Loss: 0.8120748400688171\n",
      "Epoch 10, Loss: 0.08425728231668472\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.26531459095842913, feed_forward_dim=128, head_dim=8, lr=5.050673503847966e-05, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 9, Loss: 0.022184448316693306\n",
      "Epoch 9, Loss: 0.6787253022193909\n",
      "Epoch 10, Loss: 0.016946766525506973\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.26531459095842913, feed_forward_dim=128, head_dim=8, lr=5.050673503847966e-05, num_heads=2, num_layers=1; total time=   1.6s\n",
      "Epoch 10, Loss: 0.5578874349594116\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.26531459095842913, feed_forward_dim=128, head_dim=8, lr=5.050673503847966e-05, num_heads=2, num_layers=1; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 1.058298945426941\n",
      "Epoch 1, Loss: 0.6399039030075073\n",
      "Epoch 1, Loss: 0.062474191188812256\n",
      "Epoch 1, Loss: 0.6733869314193726\n",
      "Epoch 1, Loss: 0.5500783324241638\n",
      "Epoch 2, Loss: 0.1258985698223114\n",
      "Epoch 1, Loss: 0.15588243305683136\n",
      "Epoch 2, Loss: 0.1496165245771408\n",
      "Epoch 1, Loss: 0.4899328947067261\n",
      "Epoch 2, Loss: 0.026582319289445877\n",
      "Epoch 2, Loss: 0.7667409181594849\n",
      "Epoch 3, Loss: 0.37924665212631226\n",
      "Epoch 2, Loss: 0.08200207352638245\n",
      "Epoch 1, Loss: 0.1844826638698578\n",
      "Epoch 2, Loss: 0.31206125020980835\n",
      "Epoch 1, Loss: 0.06364733725786209\n",
      "Epoch 3, Loss: 0.3211420774459839\n",
      "Epoch 3, Loss: 0.07769176363945007\n",
      "Epoch 2, Loss: 0.1035279706120491\n",
      "Epoch 3, Loss: 0.31654617190361023\n",
      "Epoch 4, Loss: 0.4662473499774933\n",
      "Epoch 4, Loss: 0.26614585518836975\n",
      "Epoch 3, Loss: 0.3257349729537964\n",
      "Epoch 2, Loss: 0.3227122724056244\n",
      "Epoch 3, Loss: 0.11620961129665375\n",
      "Epoch 4, Loss: 0.16002148389816284\n",
      "Epoch 5, Loss: 0.29181617498397827\n",
      "Epoch 2, Loss: 0.48366329073905945\n",
      "Epoch 4, Loss: 0.2670673131942749\n",
      "Epoch 3, Loss: 0.30426108837127686\n",
      "Epoch 5, Loss: 0.11272629350423813\n",
      "Epoch 1, Loss: 0.12211410701274872\n",
      "Epoch 5, Loss: 0.34992098808288574\n",
      "Epoch 1, Loss: 0.1640041321516037\n",
      "Epoch 4, Loss: 0.179153710603714\n",
      "Epoch 6, Loss: 0.10554404556751251\n",
      "Epoch 1, Loss: 0.022790301591157913\n",
      "Epoch 4, Loss: 0.05162936821579933\n",
      "Epoch 3, Loss: 0.13734254240989685\n",
      "Epoch 6, Loss: 0.031885355710983276\n",
      "Epoch 5, Loss: 0.08680089563131332\n",
      "Epoch 3, Loss: 0.06767132878303528\n",
      "Epoch 4, Loss: 0.21319150924682617\n",
      "Epoch 6, Loss: 0.23305536806583405\n",
      "Epoch 7, Loss: 0.03477881848812103\n",
      "Epoch 5, Loss: 0.024689890444278717\n",
      "Epoch 2, Loss: 0.4851788580417633\n",
      "Epoch 7, Loss: 0.05499016493558884\n",
      "Epoch 2, Loss: 0.5967771410942078\n",
      "Epoch 5, Loss: 0.12411554157733917\n",
      "Epoch 2, Loss: 0.3310098946094513\n",
      "Epoch 6, Loss: 0.010889865458011627\n",
      "Epoch 8, Loss: 0.06545843183994293\n",
      "Epoch 4, Loss: 0.03334759920835495\n",
      "Epoch 7, Loss: 0.06349153816699982\n",
      "Epoch 4, Loss: 0.09141971915960312\n",
      "Epoch 8, Loss: 0.10650376230478287\n",
      "Epoch 6, Loss: 0.020998328924179077\n",
      "Epoch 5, Loss: 0.07549172639846802\n",
      "Epoch 9, Loss: 0.1295008361339569\n",
      "Epoch 6, Loss: 0.10981598496437073\n",
      "Epoch 7, Loss: 0.03512192144989967\n",
      "Epoch 3, Loss: 0.14189176261425018\n",
      "Epoch 3, Loss: 0.047977086156606674\n",
      "Epoch 9, Loss: 0.11017487198114395\n",
      "Epoch 8, Loss: 0.010912828147411346\n",
      "Epoch 5, Loss: 0.09929518401622772\n",
      "Epoch 10, Loss: 0.15267646312713623\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.000504033049365802, num_heads=8, num_layers=2; total time=   1.1s\n",
      "Epoch 3, Loss: 0.008063595741987228\n",
      "Epoch 7, Loss: 0.08982102572917938\n",
      "Epoch 5, Loss: 0.22017820179462433\n",
      "Epoch 7, Loss: 0.04112187772989273\n",
      "Epoch 6, Loss: 0.04410242661833763\n",
      "Epoch 8, Loss: 0.08339002728462219\n",
      "Epoch 10, Loss: 0.07092670351266861\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.000504033049365802, num_heads=8, num_layers=2; total time=   1.1s\n",
      "Epoch 4, Loss: 0.08181071281433105\n",
      "Epoch 4, Loss: 0.13171765208244324\n",
      "Epoch 9, Loss: 0.06491068005561829\n",
      "Epoch 8, Loss: 0.12314580380916595\n",
      "Epoch 6, Loss: 0.11566527187824249\n",
      "Epoch 4, Loss: 0.1571802943944931\n",
      "Epoch 7, Loss: 0.09113802015781403\n",
      "Epoch 8, Loss: 0.01621384546160698\n",
      "Epoch 6, Loss: 0.1471627801656723\n",
      "Epoch 9, Loss: 0.09953416883945465\n",
      "Epoch 10, Loss: 0.12550365924835205\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.000504033049365802, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 5, Loss: 0.24001270532608032\n",
      "Epoch 7, Loss: 0.05445215478539467\n",
      "Epoch 9, Loss: 0.09227962791919708\n",
      "Epoch 5, Loss: 0.2204466164112091\n",
      "Epoch 5, Loss: 0.17874373495578766\n",
      "Epoch 8, Loss: 0.12259960174560547\n",
      "Epoch 7, Loss: 0.033561162650585175\n",
      "Epoch 9, Loss: 0.03991520032286644\n",
      "Epoch 10, Loss: 0.07342232018709183\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.000504033049365802, num_heads=8, num_layers=2; total time=   1.4s\n",
      "Epoch 10, Loss: 0.04290685057640076\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.000504033049365802, num_heads=8, num_layers=2; total time=   1.4s\n",
      "Epoch 6, Loss: 0.1845349222421646\n",
      "Epoch 8, Loss: 0.010068570263683796\n",
      "Epoch 6, Loss: 0.10227706283330917\n",
      "Epoch 10, Loss: 0.06061647832393646\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.000504033049365802, num_heads=8, num_layers=2; total time=   1.4s\n",
      "Epoch 6, Loss: 0.0654461681842804\n",
      "Epoch 8, Loss: 0.00990327075123787\n",
      "Epoch 9, Loss: 0.02457279898226261\n",
      "Epoch 7, Loss: 0.05607474967837334\n",
      "Epoch 7, Loss: 0.012513513676822186\n",
      "Epoch 9, Loss: 0.10526252537965775\n",
      "Epoch 7, Loss: 0.0052604940719902515\n",
      "Epoch 9, Loss: 0.05866437405347824\n",
      "Epoch 10, Loss: 0.055132441222667694\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.000504033049365802, num_heads=8, num_layers=2; total time=   1.5s\n",
      "Epoch 8, Loss: 0.01659853383898735\n",
      "Epoch 8, Loss: 0.03354454040527344\n",
      "Epoch 10, Loss: 0.059451792389154434\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.000504033049365802, num_heads=8, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.09527610242366791\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.000504033049365802, num_heads=8, num_layers=2; total time=   1.6s\n",
      "Epoch 8, Loss: 0.036027777940034866\n",
      "Epoch 9, Loss: 0.06491886079311371\n",
      "Epoch 9, Loss: 0.08733461797237396\n",
      "Epoch 9, Loss: 0.08077261596918106\n",
      "Epoch 10, Loss: 0.10713949054479599\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.000504033049365802, num_heads=8, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.09451398253440857\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.000504033049365802, num_heads=8, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.0808422788977623\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.000504033049365802, num_heads=8, num_layers=2; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 1.0556787252426147\n",
      "Epoch 1, Loss: 0.5961531400680542\n",
      "Epoch 1, Loss: 0.07384845614433289\n",
      "Epoch 1, Loss: 0.24139496684074402\n",
      "Epoch 1, Loss: 1.141672968864441\n",
      "Epoch 1, Loss: 0.08805355429649353\n",
      "Epoch 1, Loss: 0.7353518605232239\n",
      "Epoch 2, Loss: 0.0238699521869421\n",
      "Epoch 1, Loss: 0.9506058692932129\n",
      "Epoch 2, Loss: 0.07315310835838318\n",
      "Epoch 1, Loss: 2.519174575805664\n",
      "Epoch 2, Loss: 0.5843998193740845\n",
      "Epoch 2, Loss: 0.42248979210853577\n",
      "Epoch 3, Loss: 0.3547036051750183\n",
      "Epoch 2, Loss: 0.5374204516410828\n",
      "Epoch 2, Loss: 0.1635703146457672\n",
      "Epoch 1, Loss: 0.02173527702689171\n",
      "Epoch 3, Loss: 0.3409145176410675\n",
      "Epoch 2, Loss: 0.10653010755777359\n",
      "Epoch 2, Loss: 0.059096600860357285\n",
      "Epoch 1, Loss: 0.38671910762786865\n",
      "Epoch 3, Loss: 0.1000726968050003\n",
      "Epoch 3, Loss: 0.16788001358509064\n",
      "Epoch 1, Loss: 0.8162927627563477\n",
      "Epoch 4, Loss: 0.4359801411628723\n",
      "Epoch 3, Loss: 0.048852063715457916\n",
      "Epoch 2, Loss: 0.4674864411354065\n",
      "Epoch 4, Loss: 0.2665534019470215\n",
      "Epoch 3, Loss: 0.4056464433670044\n",
      "Epoch 5, Loss: 0.2517193555831909\n",
      "Epoch 2, Loss: 0.9103289842605591\n",
      "Epoch 4, Loss: 0.06280278414487839\n",
      "Epoch 3, Loss: 0.3950296938419342\n",
      "Epoch 3, Loss: 0.3882351815700531\n",
      "Epoch 4, Loss: 0.07508570700883865\n",
      "Epoch 5, Loss: 0.09220343083143234\n",
      "Epoch 4, Loss: 0.1946587711572647\n",
      "Epoch 2, Loss: 0.3496224880218506\n",
      "Epoch 2, Loss: 0.09080886095762253\n",
      "Epoch 6, Loss: 0.07151123881340027\n",
      "Epoch 4, Loss: 0.30388331413269043\n",
      "Epoch 5, Loss: 0.2383895218372345\n",
      "Epoch 3, Loss: 0.07844049483537674\n",
      "Epoch 4, Loss: 0.4226073622703552\n",
      "Epoch 6, Loss: 0.025524543598294258\n",
      "Epoch 5, Loss: 0.15067461133003235\n",
      "Epoch 4, Loss: 0.4805855453014374\n",
      "Epoch 3, Loss: 0.08285565674304962\n",
      "Epoch 7, Loss: 0.013011191971600056\n",
      "Epoch 5, Loss: 0.10599835962057114\n",
      "Epoch 3, Loss: 0.28935742378234863\n",
      "Epoch 5, Loss: 0.2717352509498596\n",
      "Epoch 6, Loss: 0.17975665628910065\n",
      "Epoch 3, Loss: 0.3868393301963806\n",
      "Epoch 7, Loss: 0.06737414002418518\n",
      "Epoch 8, Loss: 0.05340162664651871\n",
      "Epoch 6, Loss: 0.1471972018480301\n",
      "Epoch 4, Loss: 0.47782644629478455\n",
      "Epoch 5, Loss: 0.23591496050357819\n",
      "Epoch 5, Loss: 0.2907911539077759\n",
      "Epoch 9, Loss: 0.1138835996389389\n",
      "Epoch 6, Loss: 0.03681357577443123\n",
      "Epoch 8, Loss: 0.12419920414686203\n",
      "Epoch 4, Loss: 0.1765291839838028\n",
      "Epoch 7, Loss: 0.053627368062734604\n",
      "Epoch 4, Loss: 0.06747932732105255\n",
      "Epoch 4, Loss: 0.36421462893486023\n",
      "Epoch 7, Loss: 0.06597305834293365\n",
      "Epoch 6, Loss: 0.1294185221195221\n",
      "Epoch 6, Loss: 0.07779933512210846\n",
      "Epoch 9, Loss: 0.12725108861923218\n",
      "Epoch 5, Loss: 0.6696745753288269\n",
      "Epoch 10, Loss: 0.14071257412433624\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.000539050091682291, num_heads=4, num_layers=2; total time=   1.1s\n",
      "Epoch 6, Loss: 0.09701430052518845\n",
      "Epoch 7, Loss: 0.09369008988142014\n",
      "Epoch 8, Loss: 0.010278926230967045\n",
      "Epoch 8, Loss: 0.02019030973315239\n",
      "Epoch 5, Loss: 0.4007762372493744\n",
      "Epoch 10, Loss: 0.08067389577627182\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.000539050091682291, num_heads=4, num_layers=2; total time=   1.1s\n",
      "Epoch 8, Loss: 0.14819438755512238\n",
      "Epoch 5, Loss: 0.045787230134010315\n",
      "Epoch 7, Loss: 0.02271922305226326\n",
      "Epoch 5, Loss: 0.17013536393642426\n",
      "Epoch 6, Loss: 0.562110185623169\n",
      "Epoch 7, Loss: 0.04051098972558975\n",
      "Epoch 9, Loss: 0.0494961179792881\n",
      "Epoch 7, Loss: 0.0330631248652935\n",
      "Epoch 9, Loss: 0.03764593228697777\n",
      "Epoch 6, Loss: 0.269397109746933\n",
      "Epoch 8, Loss: 0.03991911560297012\n",
      "Epoch 9, Loss: 0.13282106816768646\n",
      "Epoch 10, Loss: 0.09344041347503662\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.000539050091682291, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 6, Loss: 0.12147372961044312\n",
      "Epoch 6, Loss: 0.04989320784807205\n",
      "Epoch 7, Loss: 0.3444750905036926\n",
      "Epoch 10, Loss: 0.07046042382717133\n",
      "Epoch 8, Loss: 0.08070118725299835\n",
      "Epoch 8, Loss: 0.0961197093129158\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.000539050091682291, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 7, Loss: 0.07372201234102249\n",
      "Epoch 9, Loss: 0.10154567658901215\n",
      "Epoch 10, Loss: 0.07081625610589981\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.000539050091682291, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 9, Loss: 0.15402443706989288\n",
      "Epoch 7, Loss: 0.1278614103794098\n",
      "Epoch 7, Loss: 0.05470341816544533\n",
      "Epoch 8, Loss: 0.14707009494304657\n",
      "Epoch 9, Loss: 0.14985787868499756\n",
      "Epoch 10, Loss: 0.1175718754529953\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.000539050091682291, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.1791774034500122\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.000539050091682291, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 8, Loss: 0.005471077281981707\n",
      "Epoch 8, Loss: 0.06370382010936737\n",
      "Epoch 10, Loss: 0.15393173694610596\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.000539050091682291, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 9, Loss: 0.03912683203816414\n",
      "Epoch 8, Loss: 0.11656630039215088\n",
      "Epoch 9, Loss: 0.05450800806283951\n",
      "Epoch 9, Loss: 0.01198200136423111\n",
      "Epoch 9, Loss: 0.1495567113161087\n",
      "Epoch 10, Loss: 0.025617634877562523\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.000539050091682291, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.1222705990076065\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.000539050091682291, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.013455616310238838\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.000539050091682291, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.12803982198238373\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.000539050091682291, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.5135693550109863\n",
      "Epoch 1, Loss: 2.217912197113037\n",
      "Epoch 2, Loss: 0.09797996282577515\n",
      "Epoch 1, Loss: 0.3011412024497986\n",
      "Epoch 1, Loss: 0.27555471658706665\n",
      "Epoch 1, Loss: 1.087715744972229\n",
      "Epoch 1, Loss: 0.3826368749141693\n",
      "Epoch 2, Loss: 0.48364993929862976\n",
      "Epoch 1, Loss: 1.5853512287139893\n",
      "Epoch 2, Loss: 0.5066314339637756\n",
      "Epoch 3, Loss: 0.32102179527282715\n",
      "Epoch 2, Loss: 0.0375477597117424\n",
      "Epoch 2, Loss: 0.2547994554042816\n",
      "Epoch 1, Loss: 1.5497652292251587\n",
      "Epoch 2, Loss: 0.45174896717071533\n",
      "Epoch 3, Loss: 0.10610026866197586\n",
      "Epoch 1, Loss: 1.5771366357803345\n",
      "Epoch 1, Loss: 0.23737511038780212\n",
      "Epoch 3, Loss: 0.24102020263671875\n",
      "Epoch 1, Loss: 0.03881454840302467\n",
      "Epoch 4, Loss: 0.17244426906108856\n",
      "Epoch 3, Loss: 0.21280206739902496\n",
      "Epoch 2, Loss: 0.12838900089263916\n",
      "Epoch 3, Loss: 0.22681951522827148\n",
      "Epoch 4, Loss: 0.4132840931415558\n",
      "Epoch 3, Loss: 0.24843773245811462\n",
      "Epoch 1, Loss: 0.6505658030509949\n",
      "Epoch 2, Loss: 0.17756636440753937\n",
      "Epoch 5, Loss: 0.03410195931792259\n",
      "Epoch 2, Loss: 0.2392820566892624\n",
      "Epoch 4, Loss: 0.08291511982679367\n",
      "Epoch 2, Loss: 0.7184903621673584\n",
      "Epoch 4, Loss: 0.4252026081085205\n",
      "Epoch 5, Loss: 0.5791123509407043\n",
      "Epoch 2, Loss: 0.3146527409553528\n",
      "Epoch 4, Loss: 0.047348421066999435\n",
      "Epoch 6, Loss: 0.043318118900060654\n",
      "Epoch 3, Loss: 0.26509717106819153\n",
      "Epoch 4, Loss: 0.10626779496669769\n",
      "Epoch 2, Loss: 0.036776334047317505\n",
      "Epoch 3, Loss: 0.3459275960922241\n",
      "Epoch 5, Loss: 0.15778158605098724\n",
      "Epoch 7, Loss: 0.1037704348564148\n",
      "Epoch 6, Loss: 0.5022952556610107\n",
      "Epoch 5, Loss: 0.3407483696937561\n",
      "Epoch 3, Loss: 0.4462333023548126\n",
      "Epoch 5, Loss: 0.12385231256484985\n",
      "Epoch 3, Loss: 0.06431911140680313\n",
      "Epoch 3, Loss: 0.1654706448316574\n",
      "Epoch 5, Loss: 0.05703990161418915\n",
      "Epoch 4, Loss: 0.5471956133842468\n",
      "Epoch 6, Loss: 0.15967945754528046\n",
      "Epoch 8, Loss: 0.12165622413158417\n",
      "Epoch 7, Loss: 0.3176629841327667\n",
      "Epoch 4, Loss: 0.5739446878433228\n",
      "Epoch 6, Loss: 0.17167751491069794\n",
      "Epoch 6, Loss: 0.1784096509218216\n",
      "Epoch 3, Loss: 0.2995588183403015\n",
      "Epoch 4, Loss: 0.5956355929374695\n",
      "Epoch 7, Loss: 0.07879096269607544\n",
      "Epoch 9, Loss: 0.08246087282896042\n",
      "Epoch 6, Loss: 0.09174391627311707\n",
      "Epoch 8, Loss: 0.15211960673332214\n",
      "Epoch 5, Loss: 0.4872935712337494\n",
      "Epoch 4, Loss: 0.15109393000602722\n",
      "Epoch 7, Loss: 0.11566215753555298\n",
      "Epoch 4, Loss: 0.017200157046318054\n",
      "Epoch 7, Loss: 0.04919777438044548\n",
      "Epoch 5, Loss: 0.4777679145336151\n",
      "Epoch 8, Loss: 0.02416681870818138\n",
      "Epoch 10, Loss: 0.03361247852444649\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=0.0005434201317464343, num_heads=8, num_layers=4; total time=   1.2s\n",
      "Epoch 7, Loss: 0.097529336810112\n",
      "Epoch 9, Loss: 0.05400225147604942\n",
      "Epoch 4, Loss: 0.2883344292640686\n",
      "Epoch 8, Loss: 0.03708833083510399\n",
      "Epoch 6, Loss: 0.290434867143631\n",
      "Epoch 5, Loss: 0.44570815563201904\n",
      "Epoch 9, Loss: 0.03942086920142174\n",
      "Epoch 8, Loss: 0.019635185599327087\n",
      "Epoch 5, Loss: 0.33204588294029236\n",
      "Epoch 6, Loss: 0.27383312582969666\n",
      "Epoch 5, Loss: 0.08133076876401901\n",
      "Epoch 8, Loss: 0.05748293176293373\n",
      "Epoch 10, Loss: 0.03588441386818886\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=0.0005434201317464343, num_heads=8, num_layers=4; total time=   1.3s\n",
      "Epoch 9, Loss: 0.020689571276307106\n",
      "Epoch 10, Loss: 0.07529277354478836\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=0.0005434201317464343, num_heads=8, num_layers=4; total time=   1.3s\n",
      "Epoch 7, Loss: 0.11681042611598969\n",
      "Epoch 5, Loss: 0.12549489736557007\n",
      "Epoch 9, Loss: 0.057482268661260605\n",
      "Epoch 7, Loss: 0.1113065555691719\n",
      "Epoch 6, Loss: 0.22687171399593353\n",
      "Epoch 10, Loss: 0.052615195512771606\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=0.0005434201317464343, num_heads=8, num_layers=4; total time=   1.3s\n",
      "Epoch 6, Loss: 0.23167100548744202\n",
      "Epoch 9, Loss: 0.01898590289056301\n",
      "Epoch 6, Loss: 0.12450975179672241\n",
      "Epoch 10, Loss: 0.10949388146400452\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=0.0005434201317464343, num_heads=8, num_layers=4; total time=   1.4s\n",
      "Epoch 8, Loss: 0.0368705615401268\n",
      "Epoch 8, Loss: 0.05047949403524399\n",
      "Epoch 7, Loss: 0.0855126604437828\n",
      "Epoch 7, Loss: 0.06785319000482559\n",
      "Epoch 6, Loss: 0.02339792251586914\n",
      "Epoch 10, Loss: 0.017635459080338478\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=0.0005434201317464343, num_heads=8, num_layers=4; total time=   1.5s\n",
      "Epoch 7, Loss: 0.0635535717010498\n",
      "Epoch 9, Loss: 0.043696243315935135\n",
      "Epoch 9, Loss: 0.07369308918714523\n",
      "Epoch 8, Loss: 0.05209115892648697\n",
      "Epoch 8, Loss: 0.0067474087700247765\n",
      "Epoch 8, Loss: 0.008265884593129158\n",
      "Epoch 7, Loss: 0.0355600081384182\n",
      "Epoch 10, Loss: 0.0922762006521225\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=0.0005434201317464343, num_heads=8, num_layers=4; total time=   1.6s\n",
      "Epoch 10, Loss: 0.12746675312519073\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=0.0005434201317464343, num_heads=8, num_layers=4; total time=   1.6s\n",
      "Epoch 9, Loss: 0.057900674641132355\n",
      "Epoch 9, Loss: 0.020379213616251945\n",
      "Epoch 9, Loss: 0.09177395701408386\n",
      "Epoch 8, Loss: 0.09570597857236862\n",
      "Epoch 10, Loss: 0.1233290433883667\n",
      "Epoch 10, Loss: 0.05977243185043335\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=0.0005434201317464343, num_heads=8, num_layers=4; total time=   1.7s\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=0.0005434201317464343, num_heads=8, num_layers=4; total time=   1.7s\n",
      "Epoch 10, Loss: 0.1420227736234665\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=0.0005434201317464343, num_heads=8, num_layers=4; total time=   1.7s\n",
      "Epoch 9, Loss: 0.12679654359817505\n",
      "Epoch 10, Loss: 0.10447988659143448\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=0.0005434201317464343, num_heads=8, num_layers=4; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.08612065017223358\n",
      "Epoch 1, Loss: 0.06979545205831528\n",
      "Epoch 1, Loss: 1.247334599494934\n",
      "Epoch 1, Loss: 1.1877015829086304\n",
      "Epoch 1, Loss: 0.1884366273880005\n",
      "Epoch 2, Loss: 0.07387717068195343\n",
      "Epoch 1, Loss: 0.04312639310956001\n",
      "Epoch 3, Loss: 0.0585797019302845\n",
      "Epoch 2, Loss: 0.022953052073717117\n",
      "Epoch 2, Loss: 0.9092676043510437\n",
      "Epoch 1, Loss: 4.231753349304199\n",
      "Epoch 1, Loss: 0.4367320239543915\n",
      "Epoch 2, Loss: 0.07293613255023956\n",
      "Epoch 4, Loss: 0.045353781431913376\n",
      "Epoch 2, Loss: 0.02525058574974537\n",
      "Epoch 2, Loss: 0.8448845744132996\n",
      "Epoch 3, Loss: 0.03464585170149803\n",
      "Epoch 3, Loss: 0.6258884072303772\n",
      "Epoch 1, Loss: 0.5075504183769226\n",
      "Epoch 1, Loss: 1.6162456274032593\n",
      "Epoch 2, Loss: 3.576173782348633\n",
      "Epoch 1, Loss: 0.5963571071624756\n",
      "Epoch 5, Loss: 0.036573901772499084\n",
      "Epoch 1, Loss: 0.37367942929267883\n",
      "Epoch 3, Loss: 0.031029200181365013\n",
      "Epoch 2, Loss: 0.27562764286994934\n",
      "Epoch 4, Loss: 0.04132545739412308\n",
      "Epoch 3, Loss: 0.5721610188484192\n",
      "Epoch 3, Loss: 0.015285150147974491\n",
      "Epoch 4, Loss: 0.4090360701084137\n",
      "Epoch 6, Loss: 0.029709357768297195\n",
      "Epoch 3, Loss: 2.974801778793335\n",
      "Epoch 2, Loss: 0.3284527063369751\n",
      "Epoch 3, Loss: 0.16779890656471252\n",
      "Epoch 5, Loss: 0.029664721339941025\n",
      "Epoch 4, Loss: 0.02148481272161007\n",
      "Epoch 2, Loss: 0.3391697406768799\n",
      "Epoch 5, Loss: 0.25138166546821594\n",
      "Epoch 2, Loss: 0.24189068377017975\n",
      "Epoch 7, Loss: 0.02172025851905346\n",
      "Epoch 2, Loss: 1.205588698387146\n",
      "Epoch 4, Loss: 0.3691539168357849\n",
      "Epoch 4, Loss: 0.009917514398694038\n",
      "Epoch 6, Loss: 0.016328100115060806\n",
      "Epoch 4, Loss: 2.4161148071289062\n",
      "Epoch 8, Loss: 0.016661956906318665\n",
      "Epoch 4, Loss: 0.11194068193435669\n",
      "Epoch 5, Loss: 0.011623626574873924\n",
      "Epoch 6, Loss: 0.1557142585515976\n",
      "Epoch 3, Loss: 0.17166568338871002\n",
      "Epoch 5, Loss: 0.03286942467093468\n",
      "Epoch 3, Loss: 0.20666863024234772\n",
      "Epoch 5, Loss: 0.2281986027956009\n",
      "Epoch 3, Loss: 0.8741440176963806\n",
      "Epoch 3, Loss: 0.16366639733314514\n",
      "Epoch 7, Loss: 0.012268167920410633\n",
      "Epoch 5, Loss: 1.9105193614959717\n",
      "Epoch 9, Loss: 0.013820438645780087\n",
      "Epoch 6, Loss: 0.009893982671201229\n",
      "Epoch 6, Loss: 0.05433647334575653\n",
      "Epoch 7, Loss: 0.10682904720306396\n",
      "Epoch 6, Loss: 0.1466151773929596\n",
      "Epoch 8, Loss: 0.016432443633675575\n",
      "Epoch 4, Loss: 0.13189728558063507\n",
      "Epoch 4, Loss: 0.08677493035793304\n",
      "Epoch 4, Loss: 0.6053237915039062\n",
      "Epoch 5, Loss: 0.09761992841959\n",
      "Epoch 6, Loss: 1.4624477624893188\n",
      "Epoch 10, Loss: 0.012092006392776966\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.26988047446482083, feed_forward_dim=128, head_dim=8, lr=0.00010677102568205735, num_heads=2, num_layers=1; total time=   0.9s\n",
      "Epoch 4, Loss: 0.1251646727323532\n",
      "Epoch 7, Loss: 0.11606397479772568\n",
      "Epoch 7, Loss: 0.012361754663288593\n",
      "Epoch 7, Loss: 0.055688753724098206\n",
      "Epoch 8, Loss: 0.09258894622325897\n",
      "Epoch 9, Loss: 0.01920945942401886\n",
      "Epoch 6, Loss: 0.11058017611503601\n",
      "Epoch 8, Loss: 0.11549942195415497\n",
      "Epoch 5, Loss: 0.4130662679672241\n",
      "Epoch 5, Loss: 0.09930268675088882\n",
      "Epoch 7, Loss: 1.076611042022705\n",
      "Epoch 8, Loss: 0.04465717077255249\n",
      "Epoch 8, Loss: 0.011275430209934711\n",
      "Epoch 9, Loss: 0.10663192719221115\n",
      "Epoch 5, Loss: 0.12517492473125458\n",
      "Epoch 10, Loss: 0.01797902211546898\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.26988047446482083, feed_forward_dim=128, head_dim=8, lr=0.00010677102568205735, num_heads=2, num_layers=1; total time=   1.1s\n",
      "Epoch 9, Loss: 0.1397966593503952\n",
      "Epoch 5, Loss: 0.06939487159252167\n",
      "Epoch 9, Loss: 0.028939174488186836\n",
      "Epoch 9, Loss: 0.00800189096480608\n",
      "Epoch 8, Loss: 0.7628428339958191\n",
      "Epoch 10, Loss: 0.12922228872776031\n",
      "Epoch 6, Loss: 0.28741371631622314\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.26988047446482083, feed_forward_dim=128, head_dim=8, lr=0.00010677102568205735, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 6, Loss: 0.09826559573411942\n",
      "Epoch 7, Loss: 0.12993159890174866\n",
      "Epoch 10, Loss: 0.16893357038497925\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.26988047446482083, feed_forward_dim=128, head_dim=8, lr=0.00010677102568205735, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 10, Loss: 0.014101961627602577\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.26988047446482083, feed_forward_dim=128, head_dim=8, lr=0.00010677102568205735, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 6, Loss: 0.1348838061094284\n",
      "Epoch 6, Loss: 0.09163205325603485\n",
      "Epoch 10, Loss: 0.005538982804864645\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.26988047446482083, feed_forward_dim=128, head_dim=8, lr=0.00010677102568205735, num_heads=2, num_layers=1; total time=   1.2s\n",
      "Epoch 9, Loss: 0.5122271180152893\n",
      "Epoch 7, Loss: 0.2195054292678833\n",
      "Epoch 8, Loss: 0.1433868557214737\n",
      "Epoch 7, Loss: 0.11206669360399246\n",
      "Epoch 7, Loss: 0.1240074411034584\n",
      "Epoch 7, Loss: 0.14222298562526703\n",
      "Epoch 9, Loss: 0.14408616721630096\n",
      "Epoch 8, Loss: 0.19500844180583954\n",
      "Epoch 10, Loss: 0.3300965428352356\n",
      "Epoch 8, Loss: 0.129757821559906\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.26988047446482083, feed_forward_dim=128, head_dim=8, lr=0.00010677102568205735, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 8, Loss: 0.13751772046089172\n",
      "Epoch 8, Loss: 0.1453663557767868\n",
      "Epoch 10, Loss: 0.1323627084493637\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.26988047446482083, feed_forward_dim=128, head_dim=8, lr=0.00010677102568205735, num_heads=2, num_layers=1; total time=   1.3s\n",
      "Epoch 9, Loss: 0.20101621747016907\n",
      "Epoch 9, Loss: 0.13940434157848358\n",
      "Epoch 9, Loss: 0.12238544970750809\n",
      "Epoch 9, Loss: 0.14598435163497925\n",
      "Epoch 10, Loss: 0.21571974456310272\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.26988047446482083, feed_forward_dim=128, head_dim=8, lr=0.00010677102568205735, num_heads=2, num_layers=1; total time=   1.4s\n",
      "Epoch 10, Loss: 0.1407208889722824\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.26988047446482083, feed_forward_dim=128, head_dim=8, lr=0.00010677102568205735, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.10222741961479187\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.26988047446482083, feed_forward_dim=128, head_dim=8, lr=0.00010677102568205735, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.12913043797016144\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.26988047446482083, feed_forward_dim=128, head_dim=8, lr=0.00010677102568205735, num_heads=2, num_layers=1; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.12128538638353348\n",
      "Epoch 1, Loss: 1.2249482870101929\n",
      "Epoch 1, Loss: 0.5427750945091248\n",
      "Epoch 1, Loss: 0.9032917022705078\n",
      "Epoch 1, Loss: 0.4352237284183502\n",
      "Epoch 1, Loss: 0.12276851385831833\n",
      "Epoch 2, Loss: 0.10728736221790314\n",
      "Epoch 1, Loss: 0.024251103401184082\n",
      "Epoch 1, Loss: 1.0983740091323853\n",
      "Epoch 2, Loss: 0.8214547038078308\n",
      "Epoch 2, Loss: 0.5179505348205566\n",
      "Epoch 2, Loss: 0.26295608282089233\n",
      "Epoch 1, Loss: 0.8358703851699829\n",
      "Epoch 2, Loss: 0.04671432822942734\n",
      "Epoch 1, Loss: 0.10679497569799423\n",
      "Epoch 3, Loss: 0.07236731052398682\n",
      "Epoch 2, Loss: 0.2031022608280182\n",
      "Epoch 1, Loss: 0.03587930276989937\n",
      "Epoch 2, Loss: 0.6092450618743896\n",
      "Epoch 1, Loss: 0.10875850915908813\n",
      "Epoch 2, Loss: 0.012896195985376835\n",
      "Epoch 3, Loss: 0.1322747766971588\n",
      "Epoch 3, Loss: 0.5102644562721252\n",
      "Epoch 3, Loss: 0.2441544234752655\n",
      "Epoch 4, Loss: 0.06356657296419144\n",
      "Epoch 2, Loss: 0.4704386591911316\n",
      "Epoch 4, Loss: 0.10952115803956985\n",
      "Epoch 3, Loss: 0.06928171962499619\n",
      "Epoch 3, Loss: 0.11573219299316406\n",
      "Epoch 2, Loss: 0.04245634377002716\n",
      "Epoch 2, Loss: 0.0414118729531765\n",
      "Epoch 4, Loss: 0.2769562005996704\n",
      "Epoch 3, Loss: 0.011394730769097805\n",
      "Epoch 2, Loss: 0.09516897797584534\n",
      "Epoch 4, Loss: 0.09155551344156265\n",
      "Epoch 3, Loss: 0.2708895802497864\n",
      "Epoch 5, Loss: 0.05102047696709633\n",
      "Epoch 5, Loss: 0.13943330943584442\n",
      "Epoch 4, Loss: 0.12304911762475967\n",
      "Epoch 5, Loss: 0.13259251415729523\n",
      "Epoch 5, Loss: 0.03910880535840988\n",
      "Epoch 4, Loss: 0.003972677513957024\n",
      "Epoch 6, Loss: 0.03655509278178215\n",
      "Epoch 3, Loss: 0.2149747610092163\n",
      "Epoch 4, Loss: 0.08137716352939606\n",
      "Epoch 4, Loss: 0.07068406790494919\n",
      "Epoch 3, Loss: 0.026738254353404045\n",
      "Epoch 6, Loss: 0.15670330822467804\n",
      "Epoch 6, Loss: 0.059749968349933624\n",
      "Epoch 3, Loss: 0.049764107912778854\n",
      "Epoch 3, Loss: 0.07741231471300125\n",
      "Epoch 5, Loss: 0.15065564215183258\n",
      "Epoch 5, Loss: 0.02522263303399086\n",
      "Epoch 7, Loss: 0.027786994352936745\n",
      "Epoch 5, Loss: 0.0453130342066288\n",
      "Epoch 7, Loss: 0.04709385335445404\n",
      "Epoch 6, Loss: 0.0623471662402153\n",
      "Epoch 4, Loss: 0.072697214782238\n",
      "Epoch 5, Loss: 0.007214427459985018\n",
      "Epoch 7, Loss: 0.14426518976688385\n",
      "Epoch 8, Loss: 0.027003560215234756\n",
      "Epoch 4, Loss: 0.01306500006467104\n",
      "Epoch 6, Loss: 0.023817013949155807\n",
      "Epoch 4, Loss: 0.047463297843933105\n",
      "Epoch 4, Loss: 0.05344613268971443\n",
      "Epoch 8, Loss: 0.0766436830163002\n",
      "Epoch 6, Loss: 0.06872347742319107\n",
      "Epoch 7, Loss: 0.11672165244817734\n",
      "Epoch 8, Loss: 0.11005660891532898\n",
      "Epoch 6, Loss: 0.15257401764392853\n",
      "Epoch 9, Loss: 0.023341001942753792\n",
      "Epoch 6, Loss: 0.005079615395516157\n",
      "Epoch 5, Loss: 0.026523688808083534\n",
      "Epoch 9, Loss: 0.11810281127691269\n",
      "Epoch 5, Loss: 0.018400728702545166\n",
      "Epoch 9, Loss: 0.07163015007972717\n",
      "Epoch 10, Loss: 0.020445169880986214\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00015551204262935256, num_heads=4, num_layers=3; total time=   1.1s\n",
      "Epoch 8, Loss: 0.16547852754592896\n",
      "Epoch 7, Loss: 0.14654792845249176\n",
      "Epoch 7, Loss: 0.021644746884703636\n",
      "Epoch 5, Loss: 0.04137352481484413\n",
      "Epoch 5, Loss: 0.037487294524908066\n",
      "Epoch 10, Loss: 0.15897682309150696\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00015551204262935256, num_heads=4, num_layers=3; total time=   1.1s\n",
      "Epoch 7, Loss: 0.12806573510169983\n",
      "Epoch 7, Loss: 0.005593573674559593\n",
      "Epoch 10, Loss: 0.03899562731385231\n",
      "Epoch 6, Loss: 0.05052414536476135\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00015551204262935256, num_heads=4, num_layers=3; total time=   1.2s\n",
      "Epoch 8, Loss: 0.028166791424155235\n",
      "Epoch 9, Loss: 0.19120581448078156\n",
      "Epoch 6, Loss: 0.02098693512380123\n",
      "Epoch 8, Loss: 0.20518235862255096\n",
      "Epoch 6, Loss: 0.017911508679389954\n",
      "Epoch 6, Loss: 0.039699383080005646\n",
      "Epoch 8, Loss: 0.08973902463912964\n",
      "Epoch 8, Loss: 0.007811489049345255\n",
      "Epoch 9, Loss: 0.02948545478284359\n",
      "Epoch 7, Loss: 0.10459665209054947\n",
      "Epoch 10, Loss: 0.18626724183559418\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00015551204262935256, num_heads=4, num_layers=3; total time=   1.3s\n",
      "Epoch 9, Loss: 0.22187112271785736\n",
      "Epoch 7, Loss: 0.012372986413538456\n",
      "Epoch 7, Loss: 0.01054459623992443\n",
      "Epoch 10, Loss: 0.023820964619517326\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00015551204262935256, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Epoch 7, Loss: 0.026838133111596107\n",
      "Epoch 9, Loss: 0.055333059281110764\n",
      "Epoch 8, Loss: 0.1502366065979004\n",
      "Epoch 10, Loss: 0.20451587438583374\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00015551204262935256, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.005956022068858147\n",
      "Epoch 8, Loss: 0.015421495772898197\n",
      "Epoch 10, Loss: 0.03537406027317047\n",
      "Epoch 8, Loss: 0.008916416205465794\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00015551204262935256, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 8, Loss: 0.014297437854111195\n",
      "Epoch 9, Loss: 0.17345452308654785\n",
      "Epoch 10, Loss: 0.005786816123872995\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00015551204262935256, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 9, Loss: 0.012360826134681702\n",
      "Epoch 9, Loss: 0.020482171326875687\n",
      "Epoch 10, Loss: 0.16444845497608185\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00015551204262935256, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 9, Loss: 0.011624923907220364\n",
      "Epoch 10, Loss: 0.018646731972694397\n",
      "Epoch 10, Loss: 0.015305598266422749\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00015551204262935256, num_heads=4, num_layers=3; total time=   1.6s\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00015551204262935256, num_heads=4, num_layers=3; total time=   1.6s\n",
      "Epoch 10, Loss: 0.014135674573481083\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00015551204262935256, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.03517104685306549\n",
      "Epoch 1, Loss: 0.3456411063671112\n",
      "Epoch 1, Loss: 1.1211748123168945\n",
      "Epoch 1, Loss: 0.09580951929092407\n",
      "Epoch 2, Loss: 0.030014079064130783\n",
      "Epoch 1, Loss: 0.970217764377594\n",
      "Epoch 1, Loss: 0.7488290667533875\n",
      "Epoch 1, Loss: 0.8957380056381226\n",
      "Epoch 2, Loss: 0.11447792500257492\n",
      "Epoch 1, Loss: 0.1224694475531578\n",
      "Epoch 2, Loss: 0.6206969022750854\n",
      "Epoch 1, Loss: 0.08697453141212463\n",
      "Epoch 2, Loss: 0.0494832806289196\n",
      "Epoch 1, Loss: 0.7965679168701172\n",
      "Epoch 3, Loss: 0.02635965496301651\n",
      "Epoch 3, Loss: 0.09099660068750381\n",
      "Epoch 2, Loss: 0.48564016819000244\n",
      "Epoch 1, Loss: 1.8791427612304688\n",
      "Epoch 2, Loss: 0.483044296503067\n",
      "Epoch 2, Loss: 0.32233068346977234\n",
      "Epoch 1, Loss: 0.40351229906082153\n",
      "Epoch 3, Loss: 0.28266218304634094\n",
      "Epoch 4, Loss: 0.14192232489585876\n",
      "Epoch 2, Loss: 0.07993023842573166\n",
      "Epoch 4, Loss: 0.013276022858917713\n",
      "Epoch 3, Loss: 0.06632941216230392\n",
      "Epoch 2, Loss: 0.0331936776638031\n",
      "Epoch 2, Loss: 0.44620537757873535\n",
      "Epoch 3, Loss: 0.1944868117570877\n",
      "Epoch 3, Loss: 0.20672912895679474\n",
      "Epoch 5, Loss: 0.012087413109838963\n",
      "Epoch 3, Loss: 0.1052108034491539\n",
      "Epoch 4, Loss: 0.08649427443742752\n",
      "Epoch 5, Loss: 0.14206135272979736\n",
      "Epoch 4, Loss: 0.05361922085285187\n",
      "Epoch 2, Loss: 1.1734532117843628\n",
      "Epoch 2, Loss: 0.15733489394187927\n",
      "Epoch 3, Loss: 0.09303251653909683\n",
      "Epoch 3, Loss: 0.05245855078101158\n",
      "Epoch 6, Loss: 0.10085228830575943\n",
      "Epoch 5, Loss: 0.017596233636140823\n",
      "Epoch 6, Loss: 0.01553392130881548\n",
      "Epoch 4, Loss: 0.06479683518409729\n",
      "Epoch 3, Loss: 0.21170099079608917\n",
      "Epoch 4, Loss: 0.06381949037313461\n",
      "Epoch 5, Loss: 0.031495410948991776\n",
      "Epoch 4, Loss: 0.05794937163591385\n",
      "Epoch 7, Loss: 0.05277075245976448\n",
      "Epoch 6, Loss: 0.035005152225494385\n",
      "Epoch 7, Loss: 0.011623344384133816\n",
      "Epoch 4, Loss: 0.05375907942652702\n",
      "Epoch 3, Loss: 0.6404435634613037\n",
      "Epoch 4, Loss: 0.07608752697706223\n",
      "Epoch 6, Loss: 0.02384309656918049\n",
      "Epoch 5, Loss: 0.06563355773687363\n",
      "Epoch 5, Loss: 0.12373948842287064\n",
      "Epoch 3, Loss: 0.05559483915567398\n",
      "Epoch 5, Loss: 0.017382187768816948\n",
      "Epoch 4, Loss: 0.08137264102697372\n",
      "Epoch 8, Loss: 0.007589833810925484\n",
      "Epoch 7, Loss: 0.09796802699565887\n",
      "Epoch 8, Loss: 0.0229034461081028\n",
      "Epoch 5, Loss: 0.03386502340435982\n",
      "Epoch 7, Loss: 0.029827114194631577\n",
      "Epoch 6, Loss: 0.13023406267166138\n",
      "Epoch 6, Loss: 0.18985411524772644\n",
      "Epoch 4, Loss: 0.2832549810409546\n",
      "Epoch 8, Loss: 0.16099022328853607\n",
      "Epoch 6, Loss: 0.04473251849412918\n",
      "Epoch 9, Loss: 0.007539626210927963\n",
      "Epoch 5, Loss: 0.0553630106151104\n",
      "Epoch 9, Loss: 0.022236377000808716\n",
      "Epoch 4, Loss: 0.062352504581213\n",
      "Epoch 5, Loss: 0.04203689843416214\n",
      "Epoch 8, Loss: 0.031130146235227585\n",
      "Epoch 7, Loss: 0.20012985169887543\n",
      "Epoch 7, Loss: 0.21656788885593414\n",
      "Epoch 9, Loss: 0.19554339349269867\n",
      "Epoch 10, Loss: 0.011045647785067558\n",
      "Epoch 10, Loss: 0.03797531872987747\n",
      "Epoch 6, Loss: 0.020797744393348694\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.36642101422557405, feed_forward_dim=128, head_dim=8, lr=0.000154173852647622, num_heads=2, num_layers=3; total time=   1.2s\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.36642101422557405, feed_forward_dim=128, head_dim=8, lr=0.000154173852647622, num_heads=2, num_layers=3; total time=   1.1s\n",
      "Epoch 6, Loss: 0.04589541256427765\n",
      "Epoch 7, Loss: 0.10060004144906998\n",
      "Epoch 5, Loss: 0.09722734987735748\n",
      "Epoch 9, Loss: 0.02222275547683239\n",
      "Epoch 5, Loss: 0.1078198030591011\n",
      "Epoch 8, Loss: 0.22695906460285187\n",
      "Epoch 6, Loss: 0.06211181730031967\n",
      "Epoch 8, Loss: 0.18953777849674225\n",
      "Epoch 10, Loss: 0.19730161130428314\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.36642101422557405, feed_forward_dim=128, head_dim=8, lr=0.000154173852647622, num_heads=2, num_layers=3; total time=   1.3s\n",
      "Epoch 7, Loss: 0.02099301852285862\n",
      "Epoch 8, Loss: 0.14659838378429413\n",
      "Epoch 10, Loss: 0.012798203155398369\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.36642101422557405, feed_forward_dim=128, head_dim=8, lr=0.000154173852647622, num_heads=2, num_layers=3; total time=   1.3s\n",
      "Epoch 7, Loss: 0.04717560112476349\n",
      "Epoch 9, Loss: 0.13937877118587494\n",
      "Epoch 6, Loss: 0.13154228031635284\n",
      "Epoch 9, Loss: 0.221892848610878\n",
      "Epoch 8, Loss: 0.027019690722227097\n",
      "Epoch 6, Loss: 0.052050232887268066\n",
      "Epoch 7, Loss: 0.10669831186532974\n",
      "Epoch 9, Loss: 0.1720278263092041\n",
      "Epoch 10, Loss: 0.08602220565080643\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.36642101422557405, feed_forward_dim=128, head_dim=8, lr=0.000154173852647622, num_heads=2, num_layers=3; total time=   1.4s\n",
      "Epoch 8, Loss: 0.04383530467748642\n",
      "Epoch 9, Loss: 0.026135588064789772\n",
      "Epoch 8, Loss: 0.1473386585712433\n",
      "Epoch 10, Loss: 0.18492960929870605\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.36642101422557405, feed_forward_dim=128, head_dim=8, lr=0.000154173852647622, num_heads=2, num_layers=3; total time=   1.5s\n",
      "Epoch 7, Loss: 0.11809593439102173\n",
      "Epoch 10, Loss: 0.1714278757572174\n",
      "Epoch 7, Loss: 0.10113032907247543\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.36642101422557405, feed_forward_dim=128, head_dim=8, lr=0.000154173852647622, num_heads=2, num_layers=3; total time=   1.4s\n",
      "Epoch 10, Loss: 0.01857660710811615\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.36642101422557405, feed_forward_dim=128, head_dim=8, lr=0.000154173852647622, num_heads=2, num_layers=3; total time=   1.5s\n",
      "Epoch 9, Loss: 0.034331925213336945\n",
      "Epoch 9, Loss: 0.1641179621219635\n",
      "Epoch 8, Loss: 0.18688207864761353\n",
      "Epoch 8, Loss: 0.08497331291437149\n",
      "Epoch 10, Loss: 0.024925952777266502\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.36642101422557405, feed_forward_dim=128, head_dim=8, lr=0.000154173852647622, num_heads=2, num_layers=3; total time=   1.6s\n",
      "Epoch 10, Loss: 0.1564701497554779\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.36642101422557405, feed_forward_dim=128, head_dim=8, lr=0.000154173852647622, num_heads=2, num_layers=3; total time=   1.6s\n",
      "Epoch 9, Loss: 0.26660090684890747\n",
      "Epoch 9, Loss: 0.04822339490056038\n",
      "Epoch 10, Loss: 0.3083454668521881\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.36642101422557405, feed_forward_dim=128, head_dim=8, lr=0.000154173852647622, num_heads=2, num_layers=3; total time=   1.7s\n",
      "Epoch 10, Loss: 0.02273789420723915\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.36642101422557405, feed_forward_dim=128, head_dim=8, lr=0.000154173852647622, num_heads=2, num_layers=3; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 1.0071653127670288\n",
      "Epoch 1, Loss: 0.5671564340591431\n",
      "Epoch 1, Loss: 4.357979774475098\n",
      "Epoch 1, Loss: 0.1801050454378128\n",
      "Epoch 2, Loss: 0.10577961802482605\n",
      "Epoch 1, Loss: 0.09207935631275177\n",
      "Epoch 2, Loss: 0.23008278012275696\n",
      "Epoch 1, Loss: 0.06237863749265671\n",
      "Epoch 3, Loss: 0.4183894097805023\n",
      "Epoch 1, Loss: 0.08082607388496399\n",
      "Epoch 2, Loss: 0.9384955167770386\n",
      "Epoch 1, Loss: 0.11548635363578796\n",
      "Epoch 2, Loss: 0.307971715927124\n",
      "Epoch 3, Loss: 0.3707122802734375\n",
      "Epoch 2, Loss: 0.6943355798721313\n",
      "Epoch 1, Loss: 0.23072005808353424\n",
      "Epoch 1, Loss: 3.0422616004943848\n",
      "Epoch 2, Loss: 0.8594010472297668\n",
      "Epoch 4, Loss: 0.433077871799469\n",
      "Epoch 1, Loss: 0.7470424175262451\n",
      "Epoch 2, Loss: 0.7698323726654053\n",
      "Epoch 1, Loss: 0.3427192270755768\n",
      "Epoch 4, Loss: 0.16967764496803284\n",
      "Epoch 2, Loss: 0.5477526187896729\n",
      "Epoch 5, Loss: 0.23661793768405914\n",
      "Epoch 3, Loss: 0.16365115344524384\n",
      "Epoch 3, Loss: 0.03531765937805176\n",
      "Epoch 3, Loss: 0.015082140453159809\n",
      "Epoch 3, Loss: 0.12110036611557007\n",
      "Epoch 2, Loss: 0.46584656834602356\n",
      "Epoch 6, Loss: 0.0677490159869194\n",
      "Epoch 2, Loss: 0.5609196424484253\n",
      "Epoch 5, Loss: 0.035658616572618484\n",
      "Epoch 4, Loss: 0.02704397775232792\n",
      "Epoch 2, Loss: 0.2399034947156906\n",
      "Epoch 4, Loss: 0.5831955075263977\n",
      "Epoch 4, Loss: 0.21740248799324036\n",
      "Epoch 3, Loss: 0.13086462020874023\n",
      "Epoch 2, Loss: 0.5876732468605042\n",
      "Epoch 4, Loss: 0.13227251172065735\n",
      "Epoch 3, Loss: 0.05532097816467285\n",
      "Epoch 7, Loss: 0.029178034514188766\n",
      "Epoch 5, Loss: 0.9681512713432312\n",
      "Epoch 3, Loss: 0.22849038243293762\n",
      "Epoch 6, Loss: 0.06071167066693306\n",
      "Epoch 3, Loss: 0.37136876583099365\n",
      "Epoch 5, Loss: 0.07106903195381165\n",
      "Epoch 5, Loss: 0.3333739936351776\n",
      "Epoch 5, Loss: 0.35431337356567383\n",
      "Epoch 4, Loss: 0.06576263904571533\n",
      "Epoch 8, Loss: 0.08600747585296631\n",
      "Epoch 4, Loss: 0.21058723330497742\n",
      "Epoch 3, Loss: 0.2846251130104065\n",
      "Epoch 6, Loss: 0.11432760953903198\n",
      "Epoch 3, Loss: 0.4586556553840637\n",
      "Epoch 7, Loss: 0.12035522609949112\n",
      "Epoch 6, Loss: 0.8823564052581787\n",
      "Epoch 6, Loss: 0.26978930830955505\n",
      "Epoch 6, Loss: 0.18032218515872955\n",
      "Epoch 5, Loss: 0.28982648253440857\n",
      "Epoch 4, Loss: 0.825614333152771\n",
      "Epoch 9, Loss: 0.14450885355472565\n",
      "Epoch 4, Loss: 0.022429384291172028\n",
      "Epoch 7, Loss: 0.06932486593723297\n",
      "Epoch 5, Loss: 0.26713064312934875\n",
      "Epoch 8, Loss: 0.1160924881696701\n",
      "Epoch 7, Loss: 0.5786874890327454\n",
      "Epoch 4, Loss: 0.06409506499767303\n",
      "Epoch 4, Loss: 0.25250256061553955\n",
      "Epoch 7, Loss: 0.033751338720321655\n",
      "Epoch 8, Loss: 0.015103207901120186\n",
      "Epoch 7, Loss: 0.09847254306077957\n",
      "Epoch 10, Loss: 0.1487702876329422\n",
      "Epoch 6, Loss: 0.24342721700668335\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3936184082509223, feed_forward_dim=128, head_dim=16, lr=0.000619446092294134, num_heads=8, num_layers=1; total time=   1.1s\n",
      "Epoch 6, Loss: 0.12114064395427704\n",
      "Epoch 5, Loss: 0.7925413250923157\n",
      "Epoch 9, Loss: 0.05828119069337845\n",
      "Epoch 8, Loss: 0.2787640392780304\n",
      "Epoch 5, Loss: 0.15254375338554382\n",
      "Epoch 8, Loss: 0.02027738094329834\n",
      "Epoch 9, Loss: 0.011213371530175209\n",
      "Epoch 10, Loss: 0.014794527553021908\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3936184082509223, feed_forward_dim=128, head_dim=16, lr=0.000619446092294134, num_heads=8, num_layers=1; total time=   1.2s\n",
      "Epoch 7, Loss: 0.026853663846850395\n",
      "Epoch 7, Loss: 0.08931955695152283\n",
      "Epoch 5, Loss: 0.07135795056819916\n",
      "Epoch 5, Loss: 0.1432139128446579\n",
      "Epoch 6, Loss: 0.507685661315918\n",
      "Epoch 8, Loss: 0.021091878414154053\n",
      "Epoch 9, Loss: 0.08649973571300507\n",
      "Epoch 10, Loss: 0.039193857461214066\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3936184082509223, feed_forward_dim=128, head_dim=16, lr=0.000619446092294134, num_heads=8, num_layers=1; total time=   1.2s\n",
      "Epoch 6, Loss: 0.20777827501296997\n",
      "Epoch 8, Loss: 0.011984975077211857\n",
      "Epoch 9, Loss: 0.08806726336479187\n",
      "Epoch 8, Loss: 0.045531488955020905\n",
      "Epoch 6, Loss: 0.20308370888233185\n",
      "Epoch 7, Loss: 0.23067177832126617\n",
      "Epoch 6, Loss: 0.06021130084991455\n",
      "Epoch 9, Loss: 0.05395513400435448\n",
      "Epoch 10, Loss: 0.018593749031424522\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3936184082509223, feed_forward_dim=128, head_dim=16, lr=0.000619446092294134, num_heads=8, num_layers=1; total time=   1.3s\n",
      "Epoch 7, Loss: 0.10655231773853302\n",
      "Epoch 9, Loss: 0.03836735710501671\n",
      "Epoch 10, Loss: 0.136069193482399\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3936184082509223, feed_forward_dim=128, head_dim=16, lr=0.000619446092294134, num_heads=8, num_layers=1; total time=   1.4s\n",
      "Epoch 9, Loss: 0.10415715724229813\n",
      "Epoch 10, Loss: 0.11628707498311996\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3936184082509223, feed_forward_dim=128, head_dim=16, lr=0.000619446092294134, num_heads=8, num_layers=1; total time=   1.4s\n",
      "Epoch 8, Loss: 0.07127542793750763\n",
      "Epoch 7, Loss: 0.12736061215400696\n",
      "Epoch 8, Loss: 0.02012994885444641\n",
      "Epoch 7, Loss: 0.13108707964420319\n",
      "Epoch 10, Loss: 0.11889265477657318\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3936184082509223, feed_forward_dim=128, head_dim=16, lr=0.000619446092294134, num_heads=8, num_layers=1; total time=   1.4s\n",
      "Epoch 10, Loss: 0.0975484848022461\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3936184082509223, feed_forward_dim=128, head_dim=16, lr=0.000619446092294134, num_heads=8, num_layers=1; total time=   1.4s\n",
      "Epoch 9, Loss: 0.03821861743927002\n",
      "Epoch 8, Loss: 0.03899877890944481\n",
      "Epoch 9, Loss: 0.02479589730501175\n",
      "Epoch 8, Loss: 0.15511716902256012\n",
      "Epoch 10, Loss: 0.084312804043293\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3936184082509223, feed_forward_dim=128, head_dim=16, lr=0.000619446092294134, num_heads=8, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.07549167424440384\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3936184082509223, feed_forward_dim=128, head_dim=16, lr=0.000619446092294134, num_heads=8, num_layers=1; total time=   1.5s\n",
      "Epoch 9, Loss: 0.020853498950600624\n",
      "Epoch 9, Loss: 0.11267515271902084\n",
      "Epoch 10, Loss: 0.057513777166604996\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3936184082509223, feed_forward_dim=128, head_dim=16, lr=0.000619446092294134, num_heads=8, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.049659986048936844\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3936184082509223, feed_forward_dim=128, head_dim=16, lr=0.000619446092294134, num_heads=8, num_layers=1; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.716446042060852\n",
      "Epoch 1, Loss: 2.0218966007232666\n",
      "Epoch 1, Loss: 0.027972130104899406\n",
      "Epoch 1, Loss: 0.4718930125236511\n",
      "Epoch 1, Loss: 1.957049012184143\n",
      "Epoch 1, Loss: 0.1390322893857956\n",
      "Epoch 2, Loss: 0.07592331618070602\n",
      "Epoch 2, Loss: 0.064963199198246\n",
      "Epoch 2, Loss: 0.40043526887893677\n",
      "Epoch 1, Loss: 0.13892672955989838\n",
      "Epoch 1, Loss: 0.8347063660621643\n",
      "Epoch 3, Loss: 0.3087165355682373\n",
      "Epoch 2, Loss: 0.1162085086107254\n",
      "Epoch 2, Loss: 0.28301581740379333\n",
      "Epoch 2, Loss: 0.30892643332481384\n",
      "Epoch 1, Loss: 0.4218209683895111\n",
      "Epoch 3, Loss: 0.17119628190994263\n",
      "Epoch 1, Loss: 0.024612190201878548\n",
      "Epoch 3, Loss: 0.035364504903554916\n",
      "Epoch 4, Loss: 0.3396662473678589\n",
      "Epoch 2, Loss: 0.37532126903533936\n",
      "Epoch 1, Loss: 0.4946672022342682\n",
      "Epoch 2, Loss: 0.06071089580655098\n",
      "Epoch 3, Loss: 0.32020658254623413\n",
      "Epoch 3, Loss: 0.10694126039743423\n",
      "Epoch 1, Loss: 0.41492709517478943\n",
      "Epoch 4, Loss: 0.036140721291303635\n",
      "Epoch 3, Loss: 0.3658131957054138\n",
      "Epoch 5, Loss: 0.19668851792812347\n",
      "Epoch 4, Loss: 0.26926514506340027\n",
      "Epoch 2, Loss: 0.32573196291923523\n",
      "Epoch 2, Loss: 0.39449143409729004\n",
      "Epoch 4, Loss: 0.15471844375133514\n",
      "Epoch 3, Loss: 0.3511725962162018\n",
      "Epoch 3, Loss: 0.11854693293571472\n",
      "Epoch 5, Loss: 0.031807128340005875\n",
      "Epoch 4, Loss: 0.6809800863265991\n",
      "Epoch 2, Loss: 0.14166899025440216\n",
      "Epoch 5, Loss: 0.46542665362358093\n",
      "Epoch 4, Loss: 0.05831490084528923\n",
      "Epoch 6, Loss: 0.06993620097637177\n",
      "Epoch 2, Loss: 0.13795290887355804\n",
      "Epoch 3, Loss: 0.29213669896125793\n",
      "Epoch 5, Loss: 0.01781393401324749\n",
      "Epoch 6, Loss: 0.08182522654533386\n",
      "Epoch 4, Loss: 0.047905083745718\n",
      "Epoch 3, Loss: 0.01688932441174984\n",
      "Epoch 5, Loss: 0.6128827333450317\n",
      "Epoch 6, Loss: 0.466829776763916\n",
      "Epoch 4, Loss: 0.36215609312057495\n",
      "Epoch 7, Loss: 0.0354769192636013\n",
      "Epoch 3, Loss: 0.3017546236515045\n",
      "Epoch 7, Loss: 0.04018358513712883\n",
      "Epoch 5, Loss: 0.11998993903398514\n",
      "Epoch 6, Loss: 0.044655799865722656\n",
      "Epoch 5, Loss: 0.14123812317848206\n",
      "Epoch 4, Loss: 0.08754070103168488\n",
      "Epoch 6, Loss: 0.37070074677467346\n",
      "Epoch 7, Loss: 0.35525408387184143\n",
      "Epoch 8, Loss: 0.07369730621576309\n",
      "Epoch 3, Loss: 0.2790810465812683\n",
      "Epoch 4, Loss: 0.14612418413162231\n",
      "Epoch 5, Loss: 0.17427945137023926\n",
      "Epoch 8, Loss: 0.20724859833717346\n",
      "Epoch 9, Loss: 0.12082815170288086\n",
      "Epoch 4, Loss: 0.16910363733768463\n",
      "Epoch 6, Loss: 0.09561304748058319\n",
      "Epoch 7, Loss: 0.15862834453582764\n",
      "Epoch 8, Loss: 0.0046689375303685665\n",
      "Epoch 7, Loss: 0.1168651208281517\n",
      "Epoch 5, Loss: 0.048809342086315155\n",
      "Epoch 6, Loss: 0.13112770020961761\n",
      "Epoch 9, Loss: 0.026514096185564995\n",
      "Epoch 8, Loss: 0.11994270980358124\n",
      "Epoch 7, Loss: 0.03590155392885208\n",
      "Epoch 5, Loss: 0.21746021509170532\n",
      "Epoch 6, Loss: 0.0404113233089447\n",
      "Epoch 10, Loss: 0.12574179470539093\n",
      "Epoch 8, Loss: 0.06594762951135635\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0005023753054673823, num_heads=2, num_layers=3; total time=   1.5s\n",
      "Epoch 5, Loss: 0.04397888854146004\n",
      "Epoch 9, Loss: 0.09038008004426956\n",
      "Epoch 4, Loss: 0.13018877804279327\n",
      "Epoch 6, Loss: 0.11150099337100983\n",
      "Epoch 9, Loss: 0.06367889791727066\n",
      "Epoch 7, Loss: 0.05627308413386345\n",
      "Epoch 10, Loss: 0.04647039622068405\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0005023753054673823, num_heads=2, num_layers=3; total time=   1.6s\n",
      "Epoch 10, Loss: 0.03015470877289772\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0005023753054673823, num_heads=2, num_layers=3; total time=   1.6s\n",
      "Epoch 8, Loss: 0.022303389385342598\n",
      "Epoch 7, Loss: 0.025766711682081223\n",
      "Epoch 9, Loss: 0.07711181044578552\n",
      "Epoch 6, Loss: 0.1131468117237091\n",
      "Epoch 7, Loss: 0.1190035343170166\n",
      "Epoch 5, Loss: 0.0378517284989357\n",
      "Epoch 6, Loss: 0.045120399445295334\n",
      "Epoch 8, Loss: 0.018677283078432083\n",
      "Epoch 10, Loss: 0.016056114807724953\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0005023753054673823, num_heads=2, num_layers=3; total time=   1.7s\n",
      "Epoch 9, Loss: 0.04541322961449623\n",
      "Epoch 10, Loss: 0.13731630146503448\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0005023753054673823, num_heads=2, num_layers=3; total time=   1.7s\n",
      "Epoch 8, Loss: 0.08309736847877502\n",
      "Epoch 8, Loss: 0.0598175972700119\n",
      "Epoch 9, Loss: 0.041486408561468124\n",
      "Epoch 7, Loss: 0.020344046875834465\n",
      "Epoch 6, Loss: 0.07393000274896622\n",
      "Epoch 7, Loss: 0.09352800250053406\n",
      "Epoch 10, Loss: 0.05619960278272629\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0005023753054673823, num_heads=2, num_layers=3; total time=   1.8s\n",
      "Epoch 9, Loss: 0.013693390414118767\n",
      "Epoch 9, Loss: 0.1262856125831604\n",
      "Epoch 10, Loss: 0.07159716635942459\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0005023753054673823, num_heads=2, num_layers=3; total time=   1.8s\n",
      "Epoch 7, Loss: 0.1171390637755394\n",
      "Epoch 8, Loss: 0.09976635128259659\n",
      "Epoch 8, Loss: 0.017476411536335945\n",
      "Epoch 10, Loss: 0.1185331866145134\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0005023753054673823, num_heads=2, num_layers=3; total time=   1.9s\n",
      "Epoch 10, Loss: 0.018849577754735947\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0005023753054673823, num_heads=2, num_layers=3; total time=   1.9s\n",
      "Epoch 8, Loss: 0.10267579555511475\n",
      "Epoch 9, Loss: 0.060409631580114365\n",
      "Epoch 9, Loss: 0.06676092743873596\n",
      "Epoch 10, Loss: 0.017835406586527824\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0005023753054673823, num_heads=2, num_layers=3; total time=   2.0s\n",
      "Epoch 10, Loss: 0.09473852813243866\n",
      "Epoch 9, Loss: 0.05349065735936165\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0005023753054673823, num_heads=2, num_layers=3; total time=   2.0s\n",
      "Epoch 10, Loss: 0.02100680023431778\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0005023753054673823, num_heads=2, num_layers=3; total time=   2.0s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 1.5505602359771729\n",
      "Epoch 1, Loss: 0.7829482555389404\n",
      "Epoch 1, Loss: 0.48456138372421265\n",
      "Epoch 1, Loss: 0.07652224600315094\n",
      "Epoch 1, Loss: 0.27855944633483887\n",
      "Epoch 1, Loss: 0.07195109128952026\n",
      "Epoch 1, Loss: 0.3634755313396454\n",
      "Epoch 2, Loss: 0.12940222024917603\n",
      "Epoch 2, Loss: 0.25908729434013367\n",
      "Epoch 2, Loss: 0.129815936088562\n",
      "Epoch 2, Loss: 0.38639193773269653\n",
      "Epoch 2, Loss: 0.6446426510810852\n",
      "Epoch 1, Loss: 0.9646937251091003\n",
      "Epoch 3, Loss: 0.3114818036556244\n",
      "Epoch 2, Loss: 0.1076832264661789\n",
      "Epoch 1, Loss: 0.3727489411830902\n",
      "Epoch 3, Loss: 0.4278556704521179\n",
      "Epoch 2, Loss: 0.2520386576652527\n",
      "Epoch 1, Loss: 0.5198050737380981\n",
      "Epoch 1, Loss: 0.6581103801727295\n",
      "Epoch 3, Loss: 0.3054981827735901\n",
      "Epoch 4, Loss: 0.33536913990974426\n",
      "Epoch 3, Loss: 0.077207550406456\n",
      "Epoch 3, Loss: 0.07006808370351791\n",
      "Epoch 1, Loss: 0.42664390802383423\n",
      "Epoch 3, Loss: 0.2747396230697632\n",
      "Epoch 3, Loss: 0.1956864446401596\n",
      "Epoch 4, Loss: 0.6167301535606384\n",
      "Epoch 2, Loss: 0.04369030147790909\n",
      "Epoch 2, Loss: 0.05815333127975464\n",
      "Epoch 2, Loss: 0.28880226612091064\n",
      "Epoch 4, Loss: 0.22095811367034912\n",
      "Epoch 5, Loss: 0.1922665536403656\n",
      "Epoch 4, Loss: 0.07862365990877151\n",
      "Epoch 2, Loss: 0.1868204027414322\n",
      "Epoch 5, Loss: 0.474893182516098\n",
      "Epoch 4, Loss: 0.1201353594660759\n",
      "Epoch 3, Loss: 0.2966781556606293\n",
      "Epoch 4, Loss: 0.07801000028848648\n",
      "Epoch 4, Loss: 0.09320161491632462\n",
      "Epoch 2, Loss: 0.4491349160671234\n",
      "Epoch 5, Loss: 0.17175155878067017\n",
      "Epoch 3, Loss: 0.26438456773757935\n",
      "Epoch 5, Loss: 0.08494987338781357\n",
      "Epoch 3, Loss: 0.31075799465179443\n",
      "Epoch 6, Loss: 0.25254592299461365\n",
      "Epoch 6, Loss: 0.0641995519399643\n",
      "Epoch 3, Loss: 0.40888193249702454\n",
      "Epoch 5, Loss: 0.2928677797317505\n",
      "Epoch 5, Loss: 0.042004719376564026\n",
      "Epoch 4, Loss: 0.43915650248527527\n",
      "Epoch 5, Loss: 0.030589986592531204\n",
      "Epoch 6, Loss: 0.04551432281732559\n",
      "Epoch 6, Loss: 0.12244856357574463\n",
      "Epoch 7, Loss: 0.025498738512396812\n",
      "Epoch 7, Loss: 0.09977370500564575\n",
      "Epoch 4, Loss: 0.21311242878437042\n",
      "Epoch 4, Loss: 0.10386483371257782\n",
      "Epoch 6, Loss: 0.19175685942173004\n",
      "Epoch 3, Loss: 0.19458073377609253\n",
      "Epoch 4, Loss: 0.21999622881412506\n",
      "Epoch 8, Loss: 0.059599462896585464\n",
      "Epoch 6, Loss: 0.11807817220687866\n",
      "Epoch 7, Loss: 0.08986629545688629\n",
      "Epoch 8, Loss: 0.07212527841329575\n",
      "Epoch 6, Loss: 0.05697504058480263\n",
      "Epoch 7, Loss: 0.034885063767433167\n",
      "Epoch 5, Loss: 0.3256315588951111\n",
      "Epoch 9, Loss: 0.10272005945444107\n",
      "Epoch 5, Loss: 0.0544782355427742\n",
      "Epoch 7, Loss: 0.04769843816757202\n",
      "Epoch 8, Loss: 0.12353193759918213\n",
      "Epoch 5, Loss: 0.06888729333877563\n",
      "Epoch 7, Loss: 0.12985050678253174\n",
      "Epoch 9, Loss: 0.1269473135471344\n",
      "Epoch 5, Loss: 0.0553637258708477\n",
      "Epoch 8, Loss: 0.014837674796581268\n",
      "Epoch 7, Loss: 0.08821951597929001\n",
      "Epoch 10, Loss: 0.1128140315413475\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005004359742853257, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 4, Loss: 0.09005787968635559\n",
      "Epoch 6, Loss: 0.1499370038509369\n",
      "Epoch 8, Loss: 0.011089225299656391\n",
      "Epoch 10, Loss: 0.18045219779014587\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005004359742853257, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 9, Loss: 0.10342981666326523\n",
      "Epoch 8, Loss: 0.06555892527103424\n",
      "Epoch 9, Loss: 0.05021742358803749\n",
      "Epoch 6, Loss: 0.02259599231183529\n",
      "Epoch 8, Loss: 0.0717410072684288\n",
      "Epoch 6, Loss: 0.06305869668722153\n",
      "Epoch 6, Loss: 0.11395632475614548\n",
      "Epoch 5, Loss: 0.14026902616024017\n",
      "Epoch 7, Loss: 0.039541617035865784\n",
      "Epoch 10, Loss: 0.053865693509578705\n",
      "Epoch 9, Loss: 0.07002107053995132\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005004359742853257, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 0.013662486337125301\n",
      "Epoch 10, Loss: 0.07918206602334976\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005004359742853257, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 7, Loss: 0.08526353538036346\n",
      "Epoch 9, Loss: 0.035046253353357315\n",
      "Epoch 7, Loss: 0.13111858069896698\n",
      "Epoch 10, Loss: 0.12027877569198608\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005004359742853257, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 7, Loss: 0.1115158274769783\n",
      "Epoch 10, Loss: 0.017985453829169273\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005004359742853257, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 8, Loss: 0.03183208405971527\n",
      "Epoch 10, Loss: 0.0153341731056571\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005004359742853257, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 8, Loss: 0.1281111091375351\n",
      "Epoch 6, Loss: 0.10559529066085815\n",
      "Epoch 8, Loss: 0.05959480628371239\n",
      "Epoch 8, Loss: 0.14166724681854248\n",
      "Epoch 9, Loss: 0.08857543766498566\n",
      "Epoch 9, Loss: 0.11063466221094131\n",
      "Epoch 7, Loss: 0.031865958124399185\n",
      "Epoch 9, Loss: 0.021608585491776466\n",
      "Epoch 9, Loss: 0.08812874555587769\n",
      "Epoch 10, Loss: 0.14196613430976868\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005004359742853257, num_heads=4, num_layers=2; total time=   1.8s\n",
      "Epoch 10, Loss: 0.058778226375579834\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005004359742853257, num_heads=4, num_layers=2; total time=   1.7s\n",
      "Epoch 8, Loss: 0.018116727471351624\n",
      "Epoch 10, Loss: 0.02750776894390583\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005004359742853257, num_heads=4, num_layers=2; total time=   1.8s\n",
      "Epoch 10, Loss: 0.030728695914149284\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005004359742853257, num_heads=4, num_layers=2; total time=   1.7s\n",
      "Epoch 9, Loss: 0.05257930979132652\n",
      "Epoch 10, Loss: 0.0645783320069313\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005004359742853257, num_heads=4, num_layers=2; total time=   1.8s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.1645253449678421\n",
      "Epoch 1, Loss: 0.5525537729263306\n",
      "Epoch 1, Loss: 0.3760960102081299\n",
      "Epoch 1, Loss: 0.27108848094940186\n",
      "Epoch 2, Loss: 0.33709025382995605\n",
      "Epoch 1, Loss: 1.8167680501937866\n",
      "Epoch 1, Loss: 1.6580911874771118\n",
      "Epoch 2, Loss: 0.34476974606513977\n",
      "Epoch 3, Loss: 0.1337757259607315\n",
      "Epoch 2, Loss: 0.5137840509414673\n",
      "Epoch 1, Loss: 0.2515151798725128\n",
      "Epoch 2, Loss: 0.05058656260371208\n",
      "Epoch 1, Loss: 0.06891297549009323\n",
      "Epoch 2, Loss: 0.16759507358074188\n",
      "Epoch 1, Loss: 0.16610087454319\n",
      "Epoch 4, Loss: 0.042833294719457626\n",
      "Epoch 2, Loss: 0.23801970481872559\n",
      "Epoch 3, Loss: 0.19361822307109833\n",
      "Epoch 1, Loss: 0.08468712121248245\n",
      "Epoch 3, Loss: 0.32536831498146057\n",
      "Epoch 1, Loss: 1.1336084604263306\n",
      "Epoch 3, Loss: 0.2489791363477707\n",
      "Epoch 2, Loss: 0.24374811351299286\n",
      "Epoch 5, Loss: 0.11899218708276749\n",
      "Epoch 1, Loss: 0.0801827684044838\n",
      "Epoch 3, Loss: 0.17548368871212006\n",
      "Epoch 2, Loss: 0.12769104540348053\n",
      "Epoch 4, Loss: 0.06470953673124313\n",
      "Epoch 3, Loss: 0.25630372762680054\n",
      "Epoch 2, Loss: 0.3571467697620392\n",
      "Epoch 4, Loss: 0.23624135553836823\n",
      "Epoch 2, Loss: 0.38730597496032715\n",
      "Epoch 6, Loss: 0.11895519495010376\n",
      "Epoch 4, Loss: 0.06937738507986069\n",
      "Epoch 2, Loss: 0.10180547833442688\n",
      "Epoch 3, Loss: 0.1780613660812378\n",
      "Epoch 3, Loss: 0.09034345299005508\n",
      "Epoch 5, Loss: 0.06561935693025589\n",
      "Epoch 5, Loss: 0.1443111002445221\n",
      "Epoch 4, Loss: 0.5433570742607117\n",
      "Epoch 7, Loss: 0.04911297559738159\n",
      "Epoch 2, Loss: 0.4867062568664551\n",
      "Epoch 5, Loss: 0.09567432850599289\n",
      "Epoch 4, Loss: 0.5662394762039185\n",
      "Epoch 3, Loss: 0.06167085841298103\n",
      "Epoch 3, Loss: 0.13504955172538757\n",
      "Epoch 3, Loss: 0.3240770101547241\n",
      "Epoch 4, Loss: 0.03433992341160774\n",
      "Epoch 6, Loss: 0.1655094474554062\n",
      "Epoch 8, Loss: 0.014381888322532177\n",
      "Epoch 6, Loss: 0.019232505932450294\n",
      "Epoch 4, Loss: 0.09048951417207718\n",
      "Epoch 6, Loss: 0.1202237531542778\n",
      "Epoch 5, Loss: 0.5489814877510071\n",
      "Epoch 5, Loss: 0.5322864055633545\n",
      "Epoch 3, Loss: 0.08569800853729248\n",
      "Epoch 9, Loss: 0.03731510788202286\n",
      "Epoch 5, Loss: 0.06196930631995201\n",
      "Epoch 4, Loss: 0.03732111304998398\n",
      "Epoch 4, Loss: 0.11074843257665634\n",
      "Epoch 7, Loss: 0.07731013745069504\n",
      "Epoch 7, Loss: 0.07163793593645096\n",
      "Epoch 6, Loss: 0.361849844455719\n",
      "Epoch 10, Loss: 0.06364144384860992\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0005071812971667298, num_heads=4, num_layers=2; total time=   0.9s\n",
      "Epoch 4, Loss: 0.48313742876052856\n",
      "Epoch 7, Loss: 0.07744108885526657\n",
      "Epoch 6, Loss: 0.3227887749671936\n",
      "Epoch 5, Loss: 0.011201492510735989\n",
      "Epoch 8, Loss: 0.1285560131072998\n",
      "Epoch 4, Loss: 0.05038445070385933\n",
      "Epoch 6, Loss: 0.11271198838949203\n",
      "Epoch 8, Loss: 0.013067326508462429\n",
      "Epoch 8, Loss: 0.026257134974002838\n",
      "Epoch 5, Loss: 0.12288288027048111\n",
      "Epoch 5, Loss: 0.18486467003822327\n",
      "Epoch 7, Loss: 0.15283973515033722\n",
      "Epoch 7, Loss: 0.12963446974754333\n",
      "Epoch 9, Loss: 0.11342515796422958\n",
      "Epoch 5, Loss: 0.35858380794525146\n",
      "Epoch 6, Loss: 0.0440421886742115\n",
      "Epoch 9, Loss: 0.03640420362353325\n",
      "Epoch 7, Loss: 0.08194132149219513\n",
      "Epoch 5, Loss: 0.1923595815896988\n",
      "Epoch 9, Loss: 0.020763486623764038\n",
      "Epoch 8, Loss: 0.031874120235443115\n",
      "Epoch 10, Loss: 0.06557146459817886\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0005071812971667298, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 6, Loss: 0.12474630028009415\n",
      "Epoch 6, Loss: 0.08849555253982544\n",
      "Epoch 8, Loss: 0.043422631919384\n",
      "Epoch 10, Loss: 0.07556691765785217\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0005071812971667298, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 7, Loss: 0.0615062415599823\n",
      "Epoch 9, Loss: 0.01371712051331997\n",
      "Epoch 8, Loss: 0.025421565398573875\n",
      "Epoch 10, Loss: 0.044786788523197174\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0005071812971667298, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 6, Loss: 0.17277830839157104\n",
      "Epoch 6, Loss: 0.15743550658226013\n",
      "Epoch 7, Loss: 0.0185285285115242\n",
      "Epoch 7, Loss: 0.049047715961933136\n",
      "Epoch 9, Loss: 0.060672610998153687\n",
      "Epoch 10, Loss: 0.06429387629032135\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0005071812971667298, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 8, Loss: 0.020639099180698395\n",
      "Epoch 7, Loss: 0.05811980739235878\n",
      "Epoch 9, Loss: 0.01290963590145111\n",
      "Epoch 10, Loss: 0.127196803689003\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0005071812971667298, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 8, Loss: 0.010226231068372726\n",
      "Epoch 7, Loss: 0.051349326968193054\n",
      "Epoch 8, Loss: 0.03235549479722977\n",
      "Epoch 9, Loss: 0.009265399537980556\n",
      "Epoch 10, Loss: 0.04105199873447418\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0005071812971667298, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 8, Loss: 0.05156543850898743\n",
      "Epoch 9, Loss: 0.03354278579354286\n",
      "Epoch 9, Loss: 0.07288891822099686\n",
      "Epoch 8, Loss: 0.006761061493307352\n",
      "Epoch 10, Loss: 0.03151273727416992\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0005071812971667298, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.06488893181085587\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0005071812971667298, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 9, Loss: 0.10208447277545929\n",
      "Epoch 10, Loss: 0.07842764258384705\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0005071812971667298, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 9, Loss: 0.03704449161887169\n",
      "Epoch 10, Loss: 0.1494644582271576\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0005071812971667298, num_heads=4, num_layers=2; total time=   1.7s\n",
      "Epoch 10, Loss: 0.07947137206792831\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=8, lr=0.0005071812971667298, num_heads=4, num_layers=2; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.7118233442306519\n",
      "Epoch 1, Loss: 0.17512840032577515\n",
      "Epoch 1, Loss: 1.3597791194915771\n",
      "Epoch 1, Loss: 0.23677776753902435\n",
      "Epoch 1, Loss: 0.4969080686569214\n",
      "Epoch 1, Loss: 0.06022263318300247\n",
      "Epoch 2, Loss: 0.0565556064248085\n",
      "Epoch 1, Loss: 0.2912747859954834\n",
      "Epoch 2, Loss: 0.265208899974823\n",
      "Epoch 1, Loss: 0.4267593026161194\n",
      "Epoch 2, Loss: 0.1518515944480896\n",
      "Epoch 2, Loss: 0.05080915987491608\n",
      "Epoch 2, Loss: 0.5655065774917603\n",
      "Epoch 3, Loss: 0.13971474766731262\n",
      "Epoch 2, Loss: 0.7113697528839111\n",
      "Epoch 1, Loss: 0.15193025767803192\n",
      "Epoch 2, Loss: 0.18325895071029663\n",
      "Epoch 3, Loss: 0.3932499587535858\n",
      "Epoch 3, Loss: 0.16495679318904877\n",
      "Epoch 1, Loss: 0.2379796802997589\n",
      "Epoch 3, Loss: 0.4013911187648773\n",
      "Epoch 2, Loss: 0.1567320078611374\n",
      "Epoch 4, Loss: 0.016849972307682037\n",
      "Epoch 4, Loss: 0.3072755038738251\n",
      "Epoch 3, Loss: 0.30255839228630066\n",
      "Epoch 1, Loss: 0.34799715876579285\n",
      "Epoch 3, Loss: 0.06860820949077606\n",
      "Epoch 4, Loss: 0.057425662875175476\n",
      "Epoch 3, Loss: 0.19458810985088348\n",
      "Epoch 2, Loss: 0.2944257855415344\n",
      "Epoch 1, Loss: 0.18875963985919952\n",
      "Epoch 3, Loss: 0.29606062173843384\n",
      "Epoch 5, Loss: 0.06836926937103271\n",
      "Epoch 5, Loss: 0.09672655910253525\n",
      "Epoch 4, Loss: 0.5621601343154907\n",
      "Epoch 4, Loss: 0.1506401002407074\n",
      "Epoch 4, Loss: 0.1071363016963005\n",
      "Epoch 4, Loss: 0.0521761029958725\n",
      "Epoch 2, Loss: 0.12546750903129578\n",
      "Epoch 5, Loss: 0.024638677015900612\n",
      "Epoch 2, Loss: 0.1844322681427002\n",
      "Epoch 6, Loss: 0.01471981406211853\n",
      "Epoch 6, Loss: 0.10355811566114426\n",
      "Epoch 4, Loss: 0.15825647115707397\n",
      "Epoch 2, Loss: 0.4128760099411011\n",
      "Epoch 3, Loss: 0.13232789933681488\n",
      "Epoch 5, Loss: 0.36185982823371887\n",
      "Epoch 7, Loss: 0.06870945543050766\n",
      "Epoch 6, Loss: 0.06354956328868866\n",
      "Epoch 5, Loss: 0.14812703430652618\n",
      "Epoch 5, Loss: 0.3325606882572174\n",
      "Epoch 7, Loss: 0.0588713176548481\n",
      "Epoch 5, Loss: 0.04076838493347168\n",
      "Epoch 3, Loss: 0.2590270936489105\n",
      "Epoch 5, Loss: 0.040169525891542435\n",
      "Epoch 3, Loss: 0.1793287843465805\n",
      "Epoch 8, Loss: 0.13661141693592072\n",
      "Epoch 6, Loss: 0.1267131119966507\n",
      "Epoch 3, Loss: 0.10988038033246994\n",
      "Epoch 4, Loss: 0.015758972615003586\n",
      "Epoch 7, Loss: 0.0706099420785904\n",
      "Epoch 8, Loss: 0.011329416185617447\n",
      "Epoch 6, Loss: 0.1679728627204895\n",
      "Epoch 6, Loss: 0.2168189138174057\n",
      "Epoch 4, Loss: 0.09521766006946564\n",
      "Epoch 9, Loss: 0.14480052888393402\n",
      "Epoch 6, Loss: 0.04677186533808708\n",
      "Epoch 6, Loss: 0.09119405597448349\n",
      "Epoch 7, Loss: 0.025390969589352608\n",
      "Epoch 8, Loss: 0.03743210807442665\n",
      "Epoch 4, Loss: 0.05233759060502052\n",
      "Epoch 5, Loss: 0.08399967849254608\n",
      "Epoch 9, Loss: 0.012895332649350166\n",
      "Epoch 4, Loss: 0.09377327561378479\n",
      "Epoch 7, Loss: 0.09237145632505417\n",
      "Epoch 8, Loss: 0.05978095531463623\n",
      "Epoch 7, Loss: 0.05353575199842453\n",
      "Epoch 10, Loss: 0.09622938930988312\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.0005091629692197746, num_heads=4, num_layers=3; total time=   1.1s\n",
      "Epoch 7, Loss: 0.10007420927286148\n",
      "Epoch 7, Loss: 0.08828243613243103\n",
      "Epoch 9, Loss: 0.009719153866171837\n",
      "Epoch 5, Loss: 0.024221686646342278\n",
      "Epoch 9, Loss: 0.1424970030784607\n",
      "Epoch 5, Loss: 0.011123226955533028\n",
      "Epoch 10, Loss: 0.03974616527557373\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.0005091629692197746, num_heads=4, num_layers=3; total time=   1.1s\n",
      "Epoch 8, Loss: 0.02555193565785885\n",
      "Epoch 6, Loss: 0.11524216085672379\n",
      "Epoch 5, Loss: 0.1730259209871292\n",
      "Epoch 8, Loss: 0.008701681159436703\n",
      "Epoch 8, Loss: 0.04087027162313461\n",
      "Epoch 10, Loss: 0.1894829422235489\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.0005091629692197746, num_heads=4, num_layers=3; total time=   1.2s\n",
      "Epoch 10, Loss: 0.013880828395485878\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.0005091629692197746, num_heads=4, num_layers=3; total time=   1.2s\n",
      "Epoch 8, Loss: 0.10411781072616577\n",
      "Epoch 6, Loss: 0.0802341103553772\n",
      "Epoch 9, Loss: 0.02515432797372341\n",
      "Epoch 9, Loss: 0.0682411640882492\n",
      "Epoch 7, Loss: 0.06034242361783981\n",
      "Epoch 6, Loss: 0.0592457540333271\n",
      "Epoch 6, Loss: 0.11568973958492279\n",
      "Epoch 9, Loss: 0.060789573937654495\n",
      "Epoch 10, Loss: 0.05899983271956444\n",
      "Epoch 10, Loss: 0.1273014098405838\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.0005091629692197746, num_heads=4, num_layers=3; total time=   1.3s\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.0005091629692197746, num_heads=4, num_layers=3; total time=   1.3s\n",
      "Epoch 9, Loss: 0.010987695306539536\n",
      "Epoch 7, Loss: 0.11574678122997284\n",
      "Epoch 7, Loss: 0.08213763684034348\n",
      "Epoch 8, Loss: 0.011441384442150593\n",
      "Epoch 7, Loss: 0.03322913497686386\n",
      "Epoch 10, Loss: 0.017263391986489296\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.0005091629692197746, num_heads=4, num_layers=3; total time=   1.3s\n",
      "Epoch 8, Loss: 0.07957316935062408\n",
      "Epoch 8, Loss: 0.054583337157964706\n",
      "Epoch 10, Loss: 0.023470180109143257\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.0005091629692197746, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.01623268611729145\n",
      "Epoch 8, Loss: 0.02174381911754608\n",
      "Epoch 9, Loss: 0.016212640330195427\n",
      "Epoch 10, Loss: 0.045850373804569244\n",
      "Epoch 9, Loss: 0.024398786947131157\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.0005091629692197746, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.057509180158376694\n",
      "Epoch 10, Loss: 0.006002293899655342\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.0005091629692197746, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.008425471372902393\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.0005091629692197746, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.07470611482858658\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.0005091629692197746, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 1.7386388778686523\n",
      "Epoch 1, Loss: 0.8128591775894165\n",
      "Epoch 2, Loss: 0.24650543928146362\n",
      "Epoch 1, Loss: 0.33700424432754517\n",
      "Epoch 1, Loss: 0.11586663872003555\n",
      "Epoch 1, Loss: 0.8081262111663818\n",
      "Epoch 1, Loss: 0.11630166321992874\n",
      "Epoch 3, Loss: 0.6941569447517395\n",
      "Epoch 2, Loss: 0.35251355171203613\n",
      "Epoch 1, Loss: 0.0554095022380352\n",
      "Epoch 1, Loss: 3.2491378784179688\n",
      "Epoch 2, Loss: 0.34908169507980347\n",
      "Epoch 2, Loss: 1.049521803855896\n",
      "Epoch 1, Loss: 0.007966273464262486\n",
      "Epoch 2, Loss: 0.9590743184089661\n",
      "Epoch 1, Loss: 0.6311182975769043\n",
      "Epoch 4, Loss: 0.5560252666473389\n",
      "Epoch 2, Loss: 0.7200660109519958\n",
      "Epoch 3, Loss: 0.4558961093425751\n",
      "Epoch 1, Loss: 0.15136678516864777\n",
      "Epoch 1, Loss: 0.8782709240913391\n",
      "Epoch 2, Loss: 1.524476170539856\n",
      "Epoch 3, Loss: 0.371314138174057\n",
      "Epoch 3, Loss: 0.469163179397583\n",
      "Epoch 5, Loss: 0.24102988839149475\n",
      "Epoch 2, Loss: 2.3355374336242676\n",
      "Epoch 3, Loss: 0.03955212980508804\n",
      "Epoch 2, Loss: 0.09522915631532669\n",
      "Epoch 4, Loss: 0.1790846437215805\n",
      "Epoch 3, Loss: 0.17564061284065247\n",
      "Epoch 2, Loss: 0.6950854063034058\n",
      "Epoch 6, Loss: 0.07003001868724823\n",
      "Epoch 4, Loss: 0.1902368664741516\n",
      "Epoch 4, Loss: 0.020818382501602173\n",
      "Epoch 3, Loss: 0.18655939400196075\n",
      "Epoch 4, Loss: 0.3998134434223175\n",
      "Epoch 5, Loss: 0.03334331139922142\n",
      "Epoch 2, Loss: 1.2065616846084595\n",
      "Epoch 2, Loss: 0.29308077692985535\n",
      "Epoch 3, Loss: 0.8211364150047302\n",
      "Epoch 3, Loss: 0.18878720700740814\n",
      "Epoch 4, Loss: 0.042245812714099884\n",
      "Epoch 7, Loss: 0.0830022394657135\n",
      "Epoch 5, Loss: 0.21136321127414703\n",
      "Epoch 5, Loss: 0.039176829159259796\n",
      "Epoch 3, Loss: 0.4869803488254547\n",
      "Epoch 6, Loss: 0.07378681749105453\n",
      "Epoch 4, Loss: 0.19198809564113617\n",
      "Epoch 8, Loss: 0.164609894156456\n",
      "Epoch 5, Loss: 0.4142722487449646\n",
      "Epoch 3, Loss: 0.16002953052520752\n",
      "Epoch 4, Loss: 1.0993019342422485\n",
      "Epoch 6, Loss: 0.08368851989507675\n",
      "Epoch 5, Loss: 0.22976846992969513\n",
      "Epoch 4, Loss: 0.41288745403289795\n",
      "Epoch 6, Loss: 0.31528228521347046\n",
      "Epoch 7, Loss: 0.14180666208267212\n",
      "Epoch 3, Loss: 0.5181276202201843\n",
      "Epoch 9, Loss: 0.20488180220127106\n",
      "Epoch 5, Loss: 0.5122687816619873\n",
      "Epoch 4, Loss: 0.09206444770097733\n",
      "Epoch 6, Loss: 0.1382579207420349\n",
      "Epoch 6, Loss: 0.22263099253177643\n",
      "Epoch 7, Loss: 0.15743191540241241\n",
      "Epoch 10, Loss: 0.17261755466461182\n",
      "Epoch 7, Loss: 0.2006027102470398\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3522573717978259, feed_forward_dim=256, head_dim=16, lr=0.0008539167280668204, num_heads=2, num_layers=3; total time=   1.1s\n",
      "Epoch 5, Loss: 0.7296300530433655\n",
      "Epoch 4, Loss: 0.18060052394866943\n",
      "Epoch 8, Loss: 0.13528262078762054\n",
      "Epoch 7, Loss: 0.01534019410610199\n",
      "Epoch 6, Loss: 0.38044479489326477\n",
      "Epoch 5, Loss: 0.06630349904298782\n",
      "Epoch 5, Loss: 0.8723090291023254\n",
      "Epoch 4, Loss: 0.283462256193161\n",
      "Epoch 9, Loss: 0.07515809684991837\n",
      "Epoch 8, Loss: 0.14664605259895325\n",
      "Epoch 8, Loss: 0.059956952929496765\n",
      "Epoch 7, Loss: 0.09608148038387299\n",
      "Epoch 6, Loss: 0.298490047454834\n",
      "Epoch 8, Loss: 0.07076357305049896\n",
      "Epoch 5, Loss: 0.4308376908302307\n",
      "Epoch 6, Loss: 0.6587648987770081\n",
      "Epoch 7, Loss: 0.14515994489192963\n",
      "Epoch 10, Loss: 0.021296856924891472\n",
      "Epoch 5, Loss: 0.08227257430553436\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3522573717978259, feed_forward_dim=256, head_dim=16, lr=0.0008539167280668204, num_heads=2, num_layers=3; total time=   1.3s\n",
      "Epoch 9, Loss: 0.008782890625298023\n",
      "Epoch 9, Loss: 0.08031060546636581\n",
      "Epoch 6, Loss: 0.19684571027755737\n",
      "Epoch 8, Loss: 0.01996663585305214\n",
      "Epoch 7, Loss: 0.06692935526371002\n",
      "Epoch 9, Loss: 0.15280239284038544\n",
      "Epoch 8, Loss: 0.02607075683772564\n",
      "Epoch 10, Loss: 0.024530895054340363\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3522573717978259, feed_forward_dim=256, head_dim=16, lr=0.0008539167280668204, num_heads=2, num_layers=3; total time=   1.4s\n",
      "Epoch 6, Loss: 0.32203227281570435\n",
      "Epoch 10, Loss: 0.04557151719927788\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3522573717978259, feed_forward_dim=256, head_dim=16, lr=0.0008539167280668204, num_heads=2, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.03207334876060486\n",
      "Epoch 7, Loss: 0.21756573021411896\n",
      "Epoch 7, Loss: 0.27457258105278015\n",
      "Epoch 8, Loss: 0.05132821202278137\n",
      "Epoch 10, Loss: 0.16874416172504425\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3522573717978259, feed_forward_dim=256, head_dim=16, lr=0.0008539167280668204, num_heads=2, num_layers=3; total time=   1.5s\n",
      "Epoch 6, Loss: 0.06898721307516098\n",
      "Epoch 9, Loss: 0.03995070233941078\n",
      "Epoch 10, Loss: 0.07836103439331055\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3522573717978259, feed_forward_dim=256, head_dim=16, lr=0.0008539167280668204, num_heads=2, num_layers=3; total time=   1.5s\n",
      "Epoch 8, Loss: 0.13465259969234467\n",
      "Epoch 9, Loss: 0.1546032875776291\n",
      "Epoch 8, Loss: 0.041244275867938995\n",
      "Epoch 10, Loss: 0.10740887373685837\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3522573717978259, feed_forward_dim=256, head_dim=16, lr=0.0008539167280668204, num_heads=2, num_layers=3; total time=   1.5s\n",
      "Epoch 7, Loss: 0.12041524797677994\n",
      "Epoch 9, Loss: 0.04448410123586655\n",
      "Epoch 10, Loss: 0.2541506588459015\n",
      "Epoch 7, Loss: 0.14558742940425873\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3522573717978259, feed_forward_dim=256, head_dim=16, lr=0.0008539167280668204, num_heads=2, num_layers=3; total time=   1.6s\n",
      "Epoch 9, Loss: 0.020484991371631622\n",
      "Epoch 8, Loss: 0.023706510663032532\n",
      "Epoch 10, Loss: 0.017743634060025215\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3522573717978259, feed_forward_dim=256, head_dim=16, lr=0.0008539167280668204, num_heads=2, num_layers=3; total time=   1.6s\n",
      "Epoch 10, Loss: 0.1184217557311058\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3522573717978259, feed_forward_dim=256, head_dim=16, lr=0.0008539167280668204, num_heads=2, num_layers=3; total time=   1.7s\n",
      "Epoch 8, Loss: 0.17204052209854126\n",
      "Epoch 9, Loss: 0.05502237379550934\n",
      "Epoch 9, Loss: 0.12932869791984558\n",
      "Epoch 10, Loss: 0.12720054388046265\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3522573717978259, feed_forward_dim=256, head_dim=16, lr=0.0008539167280668204, num_heads=2, num_layers=3; total time=   1.8s\n",
      "Epoch 10, Loss: 0.06256668269634247\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.3522573717978259, feed_forward_dim=256, head_dim=16, lr=0.0008539167280668204, num_heads=2, num_layers=3; total time=   1.8s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.23495307564735413\n",
      "Epoch 1, Loss: 1.3109605312347412\n",
      "Epoch 1, Loss: 0.18956707417964935\n",
      "Epoch 1, Loss: 0.6445907354354858\n",
      "Epoch 2, Loss: 0.6418641209602356\n",
      "Epoch 1, Loss: 0.42575913667678833\n",
      "Epoch 1, Loss: 1.1535978317260742\n",
      "Epoch 2, Loss: 0.13015566766262054\n",
      "Epoch 2, Loss: 0.8738847970962524\n",
      "Epoch 3, Loss: 0.2402658611536026\n",
      "Epoch 2, Loss: 0.25750792026519775\n",
      "Epoch 1, Loss: 0.11810259521007538\n",
      "Epoch 1, Loss: 0.19379274547100067\n",
      "Epoch 1, Loss: 0.11164209991693497\n",
      "Epoch 2, Loss: 0.3847084939479828\n",
      "Epoch 3, Loss: 0.6456277966499329\n",
      "Epoch 4, Loss: 0.017348017543554306\n",
      "Epoch 2, Loss: 0.043084342032670975\n",
      "Epoch 3, Loss: 0.23511579632759094\n",
      "Epoch 3, Loss: 0.3982325792312622\n",
      "Epoch 2, Loss: 1.2706525325775146\n",
      "Epoch 2, Loss: 0.7849865555763245\n",
      "Epoch 1, Loss: 0.702759325504303\n",
      "Epoch 5, Loss: 0.13719011843204498\n",
      "Epoch 1, Loss: 0.07122047245502472\n",
      "Epoch 4, Loss: 0.47904911637306213\n",
      "Epoch 1, Loss: 0.27556586265563965\n",
      "Epoch 3, Loss: 0.32245489954948425\n",
      "Epoch 2, Loss: 0.9485044479370117\n",
      "Epoch 4, Loss: 0.058306992053985596\n",
      "Epoch 3, Loss: 0.4841564893722534\n",
      "Epoch 4, Loss: 0.14484967291355133\n",
      "Epoch 6, Loss: 0.21181078255176544\n",
      "Epoch 2, Loss: 0.20193082094192505\n",
      "Epoch 5, Loss: 0.15166075527668\n",
      "Epoch 3, Loss: 0.17578981816768646\n",
      "Epoch 3, Loss: 0.22038540244102478\n",
      "Epoch 5, Loss: 0.269732803106308\n",
      "Epoch 2, Loss: 1.0688471794128418\n",
      "Epoch 4, Loss: 0.050902821123600006\n",
      "Epoch 4, Loss: 0.46475958824157715\n",
      "Epoch 7, Loss: 0.13756801187992096\n",
      "Epoch 3, Loss: 0.12726497650146484\n",
      "Epoch 2, Loss: 0.4623681604862213\n",
      "Epoch 5, Loss: 0.01740901917219162\n",
      "Epoch 6, Loss: 0.0229556392878294\n",
      "Epoch 6, Loss: 0.28088417649269104\n",
      "Epoch 5, Loss: 0.21339824795722961\n",
      "Epoch 4, Loss: 0.05457441136240959\n",
      "Epoch 8, Loss: 0.04078059270977974\n",
      "Epoch 3, Loss: 0.4385555386543274\n",
      "Epoch 5, Loss: 0.032632745802402496\n",
      "Epoch 3, Loss: 0.15666194260120392\n",
      "Epoch 4, Loss: 0.12517160177230835\n",
      "Epoch 7, Loss: 0.08911188691854477\n",
      "Epoch 4, Loss: 0.13001881539821625\n",
      "Epoch 7, Loss: 0.1309322863817215\n",
      "Epoch 6, Loss: 0.07402482628822327\n",
      "Epoch 9, Loss: 0.013903914019465446\n",
      "Epoch 3, Loss: 0.22278417646884918\n",
      "Epoch 6, Loss: 0.04612593352794647\n",
      "Epoch 8, Loss: 0.18791763484477997\n",
      "Epoch 5, Loss: 0.2641161382198334\n",
      "Epoch 4, Loss: 0.10832911729812622\n",
      "Epoch 6, Loss: 0.13940607011318207\n",
      "Epoch 10, Loss: 0.04556987062096596\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3352997717478835, feed_forward_dim=128, head_dim=16, lr=0.0007413676050228495, num_heads=4, num_layers=2; total time=   1.0s\n",
      "Epoch 5, Loss: 0.424320787191391\n",
      "Epoch 8, Loss: 0.03352673724293709\n",
      "Epoch 5, Loss: 0.3667615056037903\n",
      "Epoch 4, Loss: 0.23349210619926453\n",
      "Epoch 7, Loss: 0.14257246255874634\n",
      "Epoch 9, Loss: 0.20970551669597626\n",
      "Epoch 7, Loss: 0.039627186954021454\n",
      "Epoch 5, Loss: 0.3829135596752167\n",
      "Epoch 9, Loss: 0.04456470534205437\n",
      "Epoch 6, Loss: 0.2664566934108734\n",
      "Epoch 7, Loss: 0.15613645315170288\n",
      "Epoch 10, Loss: 0.15205954015254974\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3352997717478835, feed_forward_dim=128, head_dim=16, lr=0.0007413676050228495, num_heads=4, num_layers=2; total time=   1.1s\n",
      "Epoch 6, Loss: 0.3838883638381958\n",
      "Epoch 4, Loss: 0.03416597470641136\n",
      "Epoch 6, Loss: 0.29195526242256165\n",
      "Epoch 8, Loss: 0.1278347223997116\n",
      "Epoch 5, Loss: 0.0454443097114563\n",
      "Epoch 10, Loss: 0.10533767938613892\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3352997717478835, feed_forward_dim=128, head_dim=16, lr=0.0007413676050228495, num_heads=4, num_layers=2; total time=   1.1s\n",
      "Epoch 8, Loss: 0.11894387751817703\n",
      "Epoch 7, Loss: 0.11941009014844894\n",
      "Epoch 6, Loss: 0.29554277658462524\n",
      "Epoch 7, Loss: 0.17840000987052917\n",
      "Epoch 8, Loss: 0.08859732002019882\n",
      "Epoch 9, Loss: 0.061673905700445175\n",
      "Epoch 5, Loss: 0.09953320771455765\n",
      "Epoch 7, Loss: 0.1063949465751648\n",
      "Epoch 6, Loss: 0.03941234201192856\n",
      "Epoch 8, Loss: 0.03470603749155998\n",
      "Epoch 9, Loss: 0.17724837362766266\n",
      "Epoch 8, Loss: 0.026152312755584717\n",
      "Epoch 10, Loss: 0.013011153787374496\n",
      "Epoch 7, Loss: 0.09860557317733765\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3352997717478835, feed_forward_dim=128, head_dim=16, lr=0.0007413676050228495, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 9, Loss: 0.021327698603272438\n",
      "Epoch 8, Loss: 0.01320701465010643\n",
      "Epoch 6, Loss: 0.15926486253738403\n",
      "Epoch 9, Loss: 0.02431018091738224\n",
      "Epoch 7, Loss: 0.12021699547767639\n",
      "Epoch 10, Loss: 0.011307456530630589\n",
      "Epoch 9, Loss: 0.04038950428366661\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3352997717478835, feed_forward_dim=128, head_dim=16, lr=0.0007413676050228495, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 10, Loss: 0.17312656342983246\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3352997717478835, feed_forward_dim=128, head_dim=16, lr=0.0007413676050228495, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 8, Loss: 0.00973791629076004\n",
      "Epoch 10, Loss: 0.09652362763881683\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3352997717478835, feed_forward_dim=128, head_dim=16, lr=0.0007413676050228495, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 0.04553353413939476\n",
      "Epoch 7, Loss: 0.10421206057071686\n",
      "Epoch 10, Loss: 0.09849648177623749\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3352997717478835, feed_forward_dim=128, head_dim=16, lr=0.0007413676050228495, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 8, Loss: 0.14519526064395905\n",
      "Epoch 9, Loss: 0.04663696140050888\n",
      "Epoch 10, Loss: 0.11885330080986023\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3352997717478835, feed_forward_dim=128, head_dim=16, lr=0.0007413676050228495, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 8, Loss: 0.0303921140730381\n",
      "Epoch 10, Loss: 0.11666494607925415\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3352997717478835, feed_forward_dim=128, head_dim=16, lr=0.0007413676050228495, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 9, Loss: 0.09845487028360367\n",
      "Epoch 9, Loss: 0.013875767588615417\n",
      "Epoch 10, Loss: 0.036966633051633835\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3352997717478835, feed_forward_dim=128, head_dim=16, lr=0.0007413676050228495, num_heads=4, num_layers=2; total time=   1.7s\n",
      "Epoch 10, Loss: 0.043942585587501526\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.3352997717478835, feed_forward_dim=128, head_dim=16, lr=0.0007413676050228495, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.28728312253952026\n",
      "Epoch 1, Loss: 0.4496358036994934\n",
      "Epoch 1, Loss: 0.38955339789390564\n",
      "Epoch 2, Loss: 0.1412992924451828\n",
      "Epoch 1, Loss: 0.6225137710571289\n",
      "Epoch 1, Loss: 0.12949898838996887\n",
      "Epoch 1, Loss: 0.10036610066890717\n",
      "Epoch 2, Loss: 0.12233353406190872\n",
      "Epoch 1, Loss: 0.29787638783454895\n",
      "Epoch 2, Loss: 0.26498663425445557\n",
      "Epoch 3, Loss: 0.19069823622703552\n",
      "Epoch 1, Loss: 0.9127432703971863\n",
      "Epoch 2, Loss: 0.048865512013435364\n",
      "Epoch 2, Loss: 0.29213979840278625\n",
      "Epoch 3, Loss: 0.3191121816635132\n",
      "Epoch 2, Loss: 0.4736196994781494\n",
      "Epoch 4, Loss: 0.08063133805990219\n",
      "Epoch 2, Loss: 0.11472131311893463\n",
      "Epoch 1, Loss: 2.3268537521362305\n",
      "Epoch 3, Loss: 0.2864096760749817\n",
      "Epoch 3, Loss: 0.35517480969429016\n",
      "Epoch 2, Loss: 0.22199301421642303\n",
      "Epoch 4, Loss: 0.16086874902248383\n",
      "Epoch 5, Loss: 0.018528273329138756\n",
      "Epoch 3, Loss: 0.11246130615472794\n",
      "Epoch 4, Loss: 0.12286244332790375\n",
      "Epoch 3, Loss: 0.09440778940916061\n",
      "Epoch 3, Loss: 0.22197021543979645\n",
      "Epoch 2, Loss: 0.5284326672554016\n",
      "Epoch 4, Loss: 0.27332884073257446\n",
      "Epoch 6, Loss: 0.04929717257618904\n",
      "Epoch 5, Loss: 0.023484667763113976\n",
      "Epoch 3, Loss: 0.40856099128723145\n",
      "Epoch 5, Loss: 0.056883472949266434\n",
      "Epoch 1, Loss: 0.11566974967718124\n",
      "Epoch 1, Loss: 0.873574435710907\n",
      "Epoch 1, Loss: 1.2882708311080933\n",
      "Epoch 4, Loss: 0.014780981466174126\n",
      "Epoch 6, Loss: 0.05337754637002945\n",
      "Epoch 4, Loss: 0.0862555280327797\n",
      "Epoch 7, Loss: 0.07717540115118027\n",
      "Epoch 4, Loss: 0.1106545627117157\n",
      "Epoch 5, Loss: 0.08007366955280304\n",
      "Epoch 3, Loss: 0.10468407720327377\n",
      "Epoch 6, Loss: 0.10359735041856766\n",
      "Epoch 5, Loss: 0.09752833098173141\n",
      "Epoch 8, Loss: 0.05688844621181488\n",
      "Epoch 2, Loss: 0.029289625585079193\n",
      "Epoch 7, Loss: 0.12427100539207458\n",
      "Epoch 2, Loss: 0.26314541697502136\n",
      "Epoch 4, Loss: 0.3996838927268982\n",
      "Epoch 6, Loss: 0.014664358459413052\n",
      "Epoch 2, Loss: 0.21454598009586334\n",
      "Epoch 5, Loss: 0.007313445210456848\n",
      "Epoch 8, Loss: 0.12790685892105103\n",
      "Epoch 4, Loss: 0.3568747341632843\n",
      "Epoch 9, Loss: 0.022408757358789444\n",
      "Epoch 7, Loss: 0.12572933733463287\n",
      "Epoch 6, Loss: 0.11395425349473953\n",
      "Epoch 5, Loss: 0.22060894966125488\n",
      "Epoch 5, Loss: 0.23285531997680664\n",
      "Epoch 3, Loss: 0.29890963435173035\n",
      "Epoch 7, Loss: 0.07433561980724335\n",
      "Epoch 9, Loss: 0.0706266239285469\n",
      "Epoch 3, Loss: 0.09464515000581741\n",
      "Epoch 10, Loss: 0.012234386056661606\n",
      "Epoch 3, Loss: 0.17913836240768433\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17394194330862195, feed_forward_dim=128, head_dim=16, lr=0.00047327111139548473, num_heads=4, num_layers=2; total time=   1.1s\n",
      "Epoch 8, Loss: 0.07885540276765823\n",
      "Epoch 6, Loss: 0.16076286137104034\n",
      "Epoch 7, Loss: 0.05532388761639595\n",
      "Epoch 6, Loss: 0.04552688077092171\n",
      "Epoch 5, Loss: 0.5533788204193115\n",
      "Epoch 10, Loss: 0.020214006304740906\n",
      "Epoch 6, Loss: 0.09781740605831146\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17394194330862195, feed_forward_dim=128, head_dim=16, lr=0.00047327111139548473, num_heads=4, num_layers=2; total time=   1.1s\n",
      "Epoch 8, Loss: 0.1404542475938797\n",
      "Epoch 4, Loss: 0.38271501660346985\n",
      "Epoch 8, Loss: 0.011706189252436161\n",
      "Epoch 9, Loss: 0.02640606462955475\n",
      "Epoch 7, Loss: 0.05736927315592766\n",
      "Epoch 4, Loss: 0.0172322615981102\n",
      "Epoch 7, Loss: 0.09574772417545319\n",
      "Epoch 6, Loss: 0.5301109552383423\n",
      "Epoch 7, Loss: 0.06304376572370529\n",
      "Epoch 4, Loss: 0.42737022042274475\n",
      "Epoch 10, Loss: 0.015291113406419754\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17394194330862195, feed_forward_dim=128, head_dim=16, lr=0.00047327111139548473, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 9, Loss: 0.1344207376241684\n",
      "Epoch 9, Loss: 0.019939355552196503\n",
      "Epoch 5, Loss: 0.22733673453330994\n",
      "Epoch 5, Loss: 0.09037645906209946\n",
      "Epoch 7, Loss: 0.39136695861816406\n",
      "Epoch 8, Loss: 0.08172737061977386\n",
      "Epoch 8, Loss: 0.025283457711338997\n",
      "Epoch 8, Loss: 0.09799081832170486\n",
      "Epoch 5, Loss: 0.42088866233825684\n",
      "Epoch 10, Loss: 0.04714871570467949\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17394194330862195, feed_forward_dim=128, head_dim=16, lr=0.00047327111139548473, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 10, Loss: 0.07837778329849243\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17394194330862195, feed_forward_dim=128, head_dim=16, lr=0.00047327111139548473, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 6, Loss: 0.09529999643564224\n",
      "Epoch 9, Loss: 0.06211861968040466\n",
      "Epoch 9, Loss: 0.03592376783490181\n",
      "Epoch 8, Loss: 0.23286305367946625\n",
      "Epoch 9, Loss: 0.1339605152606964\n",
      "Epoch 6, Loss: 0.06419431418180466\n",
      "Epoch 6, Loss: 0.25705721974372864\n",
      "Epoch 10, Loss: 0.09566589444875717\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17394194330862195, feed_forward_dim=128, head_dim=16, lr=0.00047327111139548473, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 0.11161773651838303\n",
      "Epoch 7, Loss: 0.034568872302770615\n",
      "Epoch 10, Loss: 0.1304670125246048\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17394194330862195, feed_forward_dim=128, head_dim=16, lr=0.00047327111139548473, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 10, Loss: 0.00716064078733325\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17394194330862195, feed_forward_dim=128, head_dim=16, lr=0.00047327111139548473, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 7, Loss: 0.009183160960674286\n",
      "Epoch 7, Loss: 0.0996333658695221\n",
      "Epoch 10, Loss: 0.055074676871299744\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17394194330862195, feed_forward_dim=128, head_dim=16, lr=0.00047327111139548473, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 8, Loss: 0.0051700156182050705\n",
      "Epoch 8, Loss: 0.04964527487754822\n",
      "Epoch 8, Loss: 0.02659841813147068\n",
      "Epoch 9, Loss: 0.027838287875056267\n",
      "Epoch 9, Loss: 0.11118615418672562\n",
      "Epoch 9, Loss: 0.03950292989611626\n",
      "Epoch 10, Loss: 0.05361923575401306\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17394194330862195, feed_forward_dim=128, head_dim=16, lr=0.00047327111139548473, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.1353568285703659\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17394194330862195, feed_forward_dim=128, head_dim=16, lr=0.00047327111139548473, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.09138372540473938\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.17394194330862195, feed_forward_dim=128, head_dim=16, lr=0.00047327111139548473, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.34407615661621094\n",
      "Epoch 1, Loss: 0.616724967956543\n",
      "Epoch 1, Loss: 0.36897504329681396\n",
      "Epoch 2, Loss: 0.3834863603115082\n",
      "Epoch 1, Loss: 0.14700505137443542\n",
      "Epoch 1, Loss: 0.0614607036113739\n",
      "Epoch 1, Loss: 1.8934921026229858\n",
      "Epoch 2, Loss: 0.1285129189491272\n",
      "Epoch 1, Loss: 0.8509033918380737\n",
      "Epoch 2, Loss: 0.1678663194179535\n",
      "Epoch 1, Loss: 1.5585038661956787\n",
      "Epoch 3, Loss: 0.2204378992319107\n",
      "Epoch 2, Loss: 0.4330277740955353\n",
      "Epoch 2, Loss: 0.6988518834114075\n",
      "Epoch 3, Loss: 0.3235597312450409\n",
      "Epoch 1, Loss: 0.36815744638442993\n",
      "Epoch 3, Loss: 0.27427878975868225\n",
      "Epoch 1, Loss: 0.6494846940040588\n",
      "Epoch 2, Loss: 0.22188304364681244\n",
      "Epoch 2, Loss: 0.09188000857830048\n",
      "Epoch 2, Loss: 0.04235110059380531\n",
      "Epoch 3, Loss: 0.12035694718360901\n",
      "Epoch 1, Loss: 0.16766370832920074\n",
      "Epoch 4, Loss: 0.07092870026826859\n",
      "Epoch 4, Loss: 0.26438984274864197\n",
      "Epoch 3, Loss: 0.07500200718641281\n",
      "Epoch 1, Loss: 0.8555644154548645\n",
      "Epoch 4, Loss: 0.09133332222700119\n",
      "Epoch 5, Loss: 0.10386703163385391\n",
      "Epoch 3, Loss: 0.32101544737815857\n",
      "Epoch 3, Loss: 0.36390581727027893\n",
      "Epoch 2, Loss: 0.3448011577129364\n",
      "Epoch 4, Loss: 0.04657050594687462\n",
      "Epoch 5, Loss: 0.10258601605892181\n",
      "Epoch 2, Loss: 0.2314222753047943\n",
      "Epoch 3, Loss: 0.10217027366161346\n",
      "Epoch 4, Loss: 0.18058998882770538\n",
      "Epoch 5, Loss: 0.016205068677663803\n",
      "Epoch 6, Loss: 0.13411089777946472\n",
      "Epoch 2, Loss: 0.2808721959590912\n",
      "Epoch 2, Loss: 0.17382916808128357\n",
      "Epoch 5, Loss: 0.1680520921945572\n",
      "Epoch 6, Loss: 0.024282466620206833\n",
      "Epoch 4, Loss: 0.6048070192337036\n",
      "Epoch 4, Loss: 0.3777898848056793\n",
      "Epoch 6, Loss: 0.08104546368122101\n",
      "Epoch 5, Loss: 0.339754581451416\n",
      "Epoch 7, Loss: 0.07810559868812561\n",
      "Epoch 3, Loss: 0.43558570742607117\n",
      "Epoch 4, Loss: 0.4560422897338867\n",
      "Epoch 7, Loss: 0.05245338752865791\n",
      "Epoch 3, Loss: 0.261762797832489\n",
      "Epoch 3, Loss: 0.1411881148815155\n",
      "Epoch 5, Loss: 0.17024357616901398\n",
      "Epoch 6, Loss: 0.13774952292442322\n",
      "Epoch 3, Loss: 0.42174217104911804\n",
      "Epoch 5, Loss: 0.4824214577674866\n",
      "Epoch 7, Loss: 0.12275608628988266\n",
      "Epoch 8, Loss: 0.023649223148822784\n",
      "Epoch 6, Loss: 0.21055668592453003\n",
      "Epoch 8, Loss: 0.10521946847438812\n",
      "Epoch 9, Loss: 0.028637617826461792\n",
      "Epoch 5, Loss: 0.5387316346168518\n",
      "Epoch 8, Loss: 0.08759111911058426\n",
      "Epoch 7, Loss: 0.05728410929441452\n",
      "Epoch 4, Loss: 0.053847797214984894\n",
      "Epoch 7, Loss: 0.0471249558031559\n",
      "Epoch 4, Loss: 0.03283475711941719\n",
      "Epoch 6, Loss: 0.03294669836759567\n",
      "Epoch 9, Loss: 0.11289956420660019\n",
      "Epoch 4, Loss: 0.20376884937286377\n",
      "Epoch 6, Loss: 0.2378838211297989\n",
      "Epoch 4, Loss: 0.3479599058628082\n",
      "Epoch 10, Loss: 0.05933497101068497\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.26193316259050015, feed_forward_dim=256, head_dim=8, lr=0.0005343230249406909, num_heads=4, num_layers=3; total time=   1.0s\n",
      "Epoch 6, Loss: 0.39603114128112793\n",
      "Epoch 9, Loss: 0.028841130435466766\n",
      "Epoch 8, Loss: 0.020929859951138496\n",
      "Epoch 8, Loss: 0.012144332751631737\n",
      "Epoch 5, Loss: 0.03514932096004486\n",
      "Epoch 10, Loss: 0.07111000269651413\n",
      "Epoch 7, Loss: 0.029415341094136238\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.26193316259050015, feed_forward_dim=256, head_dim=8, lr=0.0005343230249406909, num_heads=4, num_layers=3; total time=   1.1s\n",
      "Epoch 5, Loss: 0.08815999329090118\n",
      "Epoch 5, Loss: 0.06635025888681412\n",
      "Epoch 7, Loss: 0.06497667729854584\n",
      "Epoch 10, Loss: 0.0072977179661393166\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.26193316259050015, feed_forward_dim=256, head_dim=8, lr=0.0005343230249406909, num_heads=4, num_layers=3; total time=   1.1s\n",
      "Epoch 9, Loss: 0.042955432087183\n",
      "Epoch 7, Loss: 0.21538859605789185\n",
      "Epoch 9, Loss: 0.07779400050640106\n",
      "Epoch 8, Loss: 0.09372472763061523\n",
      "Epoch 5, Loss: 0.14749376475811005\n",
      "Epoch 6, Loss: 0.1196364164352417\n",
      "Epoch 8, Loss: 0.02482498623430729\n",
      "Epoch 6, Loss: 0.11586999893188477\n",
      "Epoch 10, Loss: 0.12948250770568848\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.26193316259050015, feed_forward_dim=256, head_dim=8, lr=0.0005343230249406909, num_heads=4, num_layers=3; total time=   1.2s\n",
      "Epoch 10, Loss: 0.07460078597068787\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.26193316259050015, feed_forward_dim=256, head_dim=8, lr=0.0005343230249406909, num_heads=4, num_layers=3; total time=   1.2s\n",
      "Epoch 6, Loss: 0.10206154733896255\n",
      "Epoch 8, Loss: 0.07860998064279556\n",
      "Epoch 9, Loss: 0.13469769060611725\n",
      "Epoch 7, Loss: 0.1265173852443695\n",
      "Epoch 9, Loss: 0.07872583717107773\n",
      "Epoch 10, Loss: 0.12108413130044937\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.26193316259050015, feed_forward_dim=256, head_dim=8, lr=0.0005343230249406909, num_heads=4, num_layers=3; total time=   1.2s\n",
      "Epoch 6, Loss: 0.050249628722667694\n",
      "Epoch 7, Loss: 0.06237626075744629\n",
      "Epoch 9, Loss: 0.027933016419410706\n",
      "Epoch 7, Loss: 0.16484178602695465\n",
      "Epoch 8, Loss: 0.0637432411313057\n",
      "Epoch 10, Loss: 0.14742818474769592\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.26193316259050015, feed_forward_dim=256, head_dim=8, lr=0.0005343230249406909, num_heads=4, num_layers=3; total time=   1.3s\n",
      "Epoch 10, Loss: 0.046201493591070175\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.26193316259050015, feed_forward_dim=256, head_dim=8, lr=0.0005343230249406909, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Epoch 7, Loss: 0.07352042943239212\n",
      "Epoch 8, Loss: 0.1395225077867508\n",
      "Epoch 9, Loss: 0.013917949981987476\n",
      "Epoch 8, Loss: 0.015413324348628521\n",
      "Epoch 9, Loss: 0.06776309013366699\n",
      "Epoch 8, Loss: 0.12831060588359833\n",
      "Epoch 10, Loss: 0.019603176042437553\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.26193316259050015, feed_forward_dim=256, head_dim=8, lr=0.0005343230249406909, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.020108725875616074\n",
      "Epoch 10, Loss: 0.019454386085271835\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.26193316259050015, feed_forward_dim=256, head_dim=8, lr=0.0005343230249406909, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 9, Loss: 0.13860130310058594\n",
      "Epoch 10, Loss: 0.046722669154405594\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.26193316259050015, feed_forward_dim=256, head_dim=8, lr=0.0005343230249406909, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.09802954643964767\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.26193316259050015, feed_forward_dim=256, head_dim=8, lr=0.0005343230249406909, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.17042213678359985\n",
      "Epoch 1, Loss: 1.9638713598251343\n",
      "Epoch 1, Loss: 0.47464388608932495\n",
      "Epoch 1, Loss: 1.287916898727417\n",
      "Epoch 1, Loss: 0.1482340693473816\n",
      "Epoch 1, Loss: 0.40205928683280945\n",
      "Epoch 2, Loss: 0.38348886370658875\n",
      "Epoch 1, Loss: 0.7853454947471619\n",
      "Epoch 2, Loss: 0.1429198682308197\n",
      "Epoch 1, Loss: 0.29442253708839417\n",
      "Epoch 1, Loss: 0.027286158874630928\n",
      "Epoch 2, Loss: 0.09039053320884705\n",
      "Epoch 2, Loss: 0.2703690230846405\n",
      "Epoch 3, Loss: 0.14825500547885895\n",
      "Epoch 2, Loss: 0.08624555170536041\n",
      "Epoch 1, Loss: 1.0260523557662964\n",
      "Epoch 2, Loss: 0.11285192519426346\n",
      "Epoch 3, Loss: 0.28502312302589417\n",
      "Epoch 1, Loss: 0.18970483541488647\n",
      "Epoch 2, Loss: 0.01638997159898281\n",
      "Epoch 2, Loss: 0.32975539565086365\n",
      "Epoch 1, Loss: 0.5617524981498718\n",
      "Epoch 3, Loss: 0.290246844291687\n",
      "Epoch 4, Loss: 0.016257742419838905\n",
      "Epoch 3, Loss: 0.256171852350235\n",
      "Epoch 3, Loss: 0.1260620802640915\n",
      "Epoch 2, Loss: 0.4368515908718109\n",
      "Epoch 4, Loss: 0.6706355810165405\n",
      "Epoch 3, Loss: 0.20007525384426117\n",
      "Epoch 5, Loss: 0.11479172110557556\n",
      "Epoch 2, Loss: 0.07441066950559616\n",
      "Epoch 2, Loss: 0.4133267402648926\n",
      "Epoch 4, Loss: 0.20751619338989258\n",
      "Epoch 5, Loss: 0.612667441368103\n",
      "Epoch 3, Loss: 0.3643946051597595\n",
      "Epoch 2, Loss: 0.06390857696533203\n",
      "Epoch 4, Loss: 0.44555965065956116\n",
      "Epoch 3, Loss: 0.2027716487646103\n",
      "Epoch 4, Loss: 0.16725090146064758\n",
      "Epoch 4, Loss: 0.0059263259172439575\n",
      "Epoch 6, Loss: 0.1434338092803955\n",
      "Epoch 6, Loss: 0.3654768764972687\n",
      "Epoch 5, Loss: 0.07013709098100662\n",
      "Epoch 3, Loss: 0.044166211038827896\n",
      "Epoch 4, Loss: 0.35917752981185913\n",
      "Epoch 5, Loss: 0.4263564348220825\n",
      "Epoch 3, Loss: 0.31495150923728943\n",
      "Epoch 5, Loss: 0.041991833597421646\n",
      "Epoch 7, Loss: 0.07251808792352676\n",
      "Epoch 3, Loss: 0.05601454898715019\n",
      "Epoch 6, Loss: 0.027840059250593185\n",
      "Epoch 4, Loss: 0.058236561715602875\n",
      "Epoch 7, Loss: 0.13665536046028137\n",
      "Epoch 5, Loss: 0.07412237673997879\n",
      "Epoch 3, Loss: 0.2990061938762665\n",
      "Epoch 8, Loss: 0.013608144596219063\n",
      "Epoch 6, Loss: 0.2667034864425659\n",
      "Epoch 4, Loss: 0.10272548347711563\n",
      "Epoch 5, Loss: 0.14988237619400024\n",
      "Epoch 7, Loss: 0.07521115243434906\n",
      "Epoch 8, Loss: 0.028035206720232964\n",
      "Epoch 6, Loss: 0.019838901236653328\n",
      "Epoch 5, Loss: 0.0932130217552185\n",
      "Epoch 4, Loss: 0.12778079509735107\n",
      "Epoch 6, Loss: 0.11240091919898987\n",
      "Epoch 4, Loss: 0.42185238003730774\n",
      "Epoch 9, Loss: 0.018770931288599968\n",
      "Epoch 7, Loss: 0.11094574630260468\n",
      "Epoch 8, Loss: 0.11619433760643005\n",
      "Epoch 6, Loss: 0.022656651213765144\n",
      "Epoch 9, Loss: 0.038955207914114\n",
      "Epoch 4, Loss: 0.23091274499893188\n",
      "Epoch 10, Loss: 0.05430535972118378\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005322971413060712, num_heads=2, num_layers=2; total time=   1.2s\n",
      "Epoch 5, Loss: 0.21149149537086487\n",
      "Epoch 7, Loss: 0.07295757532119751\n",
      "Epoch 6, Loss: 0.1347232609987259\n",
      "Epoch 9, Loss: 0.1011032909154892\n",
      "Epoch 5, Loss: 0.16835971176624298\n",
      "Epoch 5, Loss: 0.27574682235717773\n",
      "Epoch 10, Loss: 0.10855086147785187\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005322971413060712, num_heads=2, num_layers=2; total time=   1.2s\n",
      "Epoch 7, Loss: 0.06164352223277092\n",
      "Epoch 8, Loss: 0.030800746753811836\n",
      "Epoch 7, Loss: 0.03244945406913757\n",
      "Epoch 5, Loss: 0.0744130089879036\n",
      "Epoch 6, Loss: 0.1253117471933365\n",
      "Epoch 10, Loss: 0.05692344158887863\n",
      "Epoch 8, Loss: 0.10247015953063965\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005322971413060712, num_heads=2, num_layers=2; total time=   1.2s\n",
      "Epoch 8, Loss: 0.009426955133676529\n",
      "Epoch 6, Loss: 0.10485690087080002\n",
      "Epoch 9, Loss: 0.0341838039457798\n",
      "Epoch 7, Loss: 0.09099680185317993\n",
      "Epoch 6, Loss: 0.0600476935505867\n",
      "Epoch 9, Loss: 0.07768712937831879\n",
      "Epoch 8, Loss: 0.10236282646656036\n",
      "Epoch 6, Loss: 0.020169371739029884\n",
      "Epoch 9, Loss: 0.011201711371541023\n",
      "Epoch 7, Loss: 0.02453865483403206\n",
      "Epoch 10, Loss: 0.03401881828904152\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005322971413060712, num_heads=2, num_layers=2; total time=   1.4s\n",
      "Epoch 8, Loss: 0.03524358570575714\n",
      "Epoch 7, Loss: 0.027687231078743935\n",
      "Epoch 10, Loss: 0.08344907313585281\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005322971413060712, num_heads=2, num_layers=2; total time=   1.4s\n",
      "Epoch 7, Loss: 0.007083276752382517\n",
      "Epoch 9, Loss: 0.1482952982187271\n",
      "Epoch 10, Loss: 0.041320350021123886\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005322971413060712, num_heads=2, num_layers=2; total time=   1.4s\n",
      "Epoch 7, Loss: 0.06452560424804688\n",
      "Epoch 9, Loss: 0.01930723339319229\n",
      "Epoch 8, Loss: 0.011295199394226074\n",
      "Epoch 8, Loss: 0.04280569776892662\n",
      "Epoch 10, Loss: 0.13319595158100128\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005322971413060712, num_heads=2, num_layers=2; total time=   1.5s\n",
      "Epoch 8, Loss: 0.0471433661878109\n",
      "Epoch 8, Loss: 0.11183265596628189\n",
      "Epoch 9, Loss: 0.051728755235672\n",
      "Epoch 9, Loss: 0.09562242776155472\n",
      "Epoch 10, Loss: 0.044992461800575256\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005322971413060712, num_heads=2, num_layers=2; total time=   1.6s\n",
      "Epoch 9, Loss: 0.08379849791526794\n",
      "Epoch 9, Loss: 0.10918005555868149\n",
      "Epoch 10, Loss: 0.08208189159631729\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005322971413060712, num_heads=2, num_layers=2; total time=   1.7s\n",
      "Epoch 10, Loss: 0.12682323157787323\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005322971413060712, num_heads=2, num_layers=2; total time=   1.7s\n",
      "Epoch 10, Loss: 0.067623570561409\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005322971413060712, num_heads=2, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.06863591820001602\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005322971413060712, num_heads=2, num_layers=2; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.35397273302078247\n",
      "Epoch 1, Loss: 0.5999643802642822\n",
      "Epoch 1, Loss: 2.9379324913024902\n",
      "Epoch 2, Loss: 0.10100769996643066\n",
      "Epoch 2, Loss: 0.1377246081829071\n",
      "Epoch 1, Loss: 0.036442745476961136\n",
      "Epoch 1, Loss: 0.7812928557395935\n",
      "Epoch 1, Loss: 0.16781356930732727\n",
      "Epoch 1, Loss: 0.21703962981700897\n",
      "Epoch 1, Loss: 2.2222189903259277\n",
      "Epoch 3, Loss: 0.24515517055988312\n",
      "Epoch 1, Loss: 0.1544685810804367\n",
      "Epoch 1, Loss: 0.660504162311554\n",
      "Epoch 2, Loss: 0.014695029705762863\n",
      "Epoch 2, Loss: 0.9596359729766846\n",
      "Epoch 3, Loss: 0.2986501157283783\n",
      "Epoch 2, Loss: 0.27040666341781616\n",
      "Epoch 1, Loss: 1.5812649726867676\n",
      "Epoch 2, Loss: 0.26686379313468933\n",
      "Epoch 2, Loss: 0.1738532930612564\n",
      "Epoch 1, Loss: 0.09535399079322815\n",
      "Epoch 2, Loss: 0.4599556028842926\n",
      "Epoch 4, Loss: 0.10748160630464554\n",
      "Epoch 3, Loss: 0.3201163709163666\n",
      "Epoch 3, Loss: 0.1028582900762558\n",
      "Epoch 2, Loss: 0.06744382530450821\n",
      "Epoch 4, Loss: 0.29488760232925415\n",
      "Epoch 2, Loss: 0.2803593873977661\n",
      "Epoch 3, Loss: 0.011609802953898907\n",
      "Epoch 5, Loss: 0.021454473957419395\n",
      "Epoch 3, Loss: 0.12831111252307892\n",
      "Epoch 2, Loss: 0.17325405776500702\n",
      "Epoch 3, Loss: 0.03900817409157753\n",
      "Epoch 4, Loss: 0.1512957662343979\n",
      "Epoch 3, Loss: 0.17086340487003326\n",
      "Epoch 4, Loss: 0.3538362681865692\n",
      "Epoch 2, Loss: 0.23236994445323944\n",
      "Epoch 5, Loss: 0.1528775990009308\n",
      "Epoch 3, Loss: 0.3769526481628418\n",
      "Epoch 4, Loss: 0.1358739286661148\n",
      "Epoch 3, Loss: 0.12120407074689865\n",
      "Epoch 4, Loss: 0.047422438859939575\n",
      "Epoch 6, Loss: 0.052541304379701614\n",
      "Epoch 5, Loss: 0.16599564254283905\n",
      "Epoch 5, Loss: 0.4719437062740326\n",
      "Epoch 4, Loss: 0.3690296411514282\n",
      "Epoch 3, Loss: 0.16320592164993286\n",
      "Epoch 4, Loss: 0.029351074248552322\n",
      "Epoch 7, Loss: 0.09662254899740219\n",
      "Epoch 6, Loss: 0.05418074131011963\n",
      "Epoch 5, Loss: 0.09879610687494278\n",
      "Epoch 4, Loss: 0.30257564783096313\n",
      "Epoch 5, Loss: 0.14426149427890778\n",
      "Epoch 3, Loss: 0.08155921846628189\n",
      "Epoch 6, Loss: 0.02383159101009369\n",
      "Epoch 4, Loss: 0.033914290368556976\n",
      "Epoch 6, Loss: 0.609514057636261\n",
      "Epoch 5, Loss: 0.022511716932058334\n",
      "Epoch 8, Loss: 0.07821566611528397\n",
      "Epoch 7, Loss: 0.050546687096357346\n",
      "Epoch 5, Loss: 0.5863775014877319\n",
      "Epoch 4, Loss: 0.49106308817863464\n",
      "Epoch 7, Loss: 0.5452442169189453\n",
      "Epoch 7, Loss: 0.015125741250813007\n",
      "Epoch 6, Loss: 0.04691603034734726\n",
      "Epoch 9, Loss: 0.029849853366613388\n",
      "Epoch 6, Loss: 0.09783883392810822\n",
      "Epoch 5, Loss: 0.10846416652202606\n",
      "Epoch 8, Loss: 0.09533999860286713\n",
      "Epoch 4, Loss: 0.014244411140680313\n",
      "Epoch 6, Loss: 0.5481587648391724\n",
      "Epoch 5, Loss: 0.09803959727287292\n",
      "Epoch 8, Loss: 0.3839998245239258\n",
      "Epoch 6, Loss: 0.08404462039470673\n",
      "Epoch 10, Loss: 0.007337914314121008\n",
      "Epoch 8, Loss: 0.08292998373508453\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0004635816735124662, num_heads=4, num_layers=2; total time=   1.1s\n",
      "Epoch 7, Loss: 0.0072781965136528015\n",
      "Epoch 9, Loss: 0.12028682231903076\n",
      "Epoch 6, Loss: 0.03362628072500229\n",
      "Epoch 7, Loss: 0.042792122811079025\n",
      "Epoch 9, Loss: 0.21335534751415253\n",
      "Epoch 5, Loss: 0.5155766606330872\n",
      "Epoch 5, Loss: 0.08110319823026657\n",
      "Epoch 10, Loss: 0.10496324300765991\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0004635816735124662, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 6, Loss: 0.10413549095392227\n",
      "Epoch 7, Loss: 0.08132841438055038\n",
      "Epoch 7, Loss: 0.3687300384044647\n",
      "Epoch 8, Loss: 0.044896744191646576\n",
      "Epoch 9, Loss: 0.13538026809692383\n",
      "Epoch 10, Loss: 0.09525780379772186\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0004635816735124662, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 7, Loss: 0.08558611571788788\n",
      "Epoch 8, Loss: 0.015785373747348785\n",
      "Epoch 9, Loss: 0.07839318364858627\n",
      "Epoch 6, Loss: 0.34271153807640076\n",
      "Epoch 8, Loss: 0.03125375509262085\n",
      "Epoch 6, Loss: 0.08711978793144226\n",
      "Epoch 7, Loss: 0.048132166266441345\n",
      "Epoch 10, Loss: 0.12988141179084778\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0004635816735124662, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 8, Loss: 0.1954951286315918\n",
      "Epoch 10, Loss: 0.06190221384167671\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0004635816735124662, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 9, Loss: 0.031657662242650986\n",
      "Epoch 8, Loss: 0.1469927728176117\n",
      "Epoch 7, Loss: 0.14914865791797638\n",
      "Epoch 8, Loss: 0.012834925204515457\n",
      "Epoch 7, Loss: 0.03539639338850975\n",
      "Epoch 9, Loss: 0.003184688976034522\n",
      "Epoch 9, Loss: 0.07258682698011398\n",
      "Epoch 10, Loss: 0.05216047540307045\n",
      "Epoch 9, Loss: 0.14745394885540009\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0004635816735124662, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 8, Loss: 0.04099220409989357\n",
      "Epoch 9, Loss: 0.030730044469237328\n",
      "Epoch 8, Loss: 0.005933340173214674\n",
      "Epoch 10, Loss: 0.029960718005895615\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0004635816735124662, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.017183886840939522\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0004635816735124662, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.09821734577417374\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0004635816735124662, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 0.034155409783124924\n",
      "Epoch 10, Loss: 0.055388301610946655\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0004635816735124662, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 0.021522382274270058\n",
      "Epoch 10, Loss: 0.08811639994382858\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0004635816735124662, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.044385023415088654\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0004635816735124662, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.19005827605724335\n",
      "Epoch 1, Loss: 0.8096258044242859\n",
      "Epoch 2, Loss: 0.3120945394039154\n",
      "Epoch 2, Loss: 0.01941392756998539\n",
      "Epoch 1, Loss: 0.16340012848377228\n",
      "Epoch 1, Loss: 2.651015281677246\n",
      "Epoch 3, Loss: 0.12175682932138443\n",
      "Epoch 1, Loss: 1.0757278203964233\n",
      "Epoch 1, Loss: 0.10143521428108215\n",
      "Epoch 3, Loss: 0.2692520320415497\n",
      "Epoch 1, Loss: 0.560175895690918\n",
      "Epoch 2, Loss: 0.3553760349750519\n",
      "Epoch 2, Loss: 0.7818445563316345\n",
      "Epoch 1, Loss: 0.4276978671550751\n",
      "Epoch 4, Loss: 0.03820425271987915\n",
      "Epoch 2, Loss: 0.08451900631189346\n",
      "Epoch 2, Loss: 0.4073372483253479\n",
      "Epoch 1, Loss: 0.26126742362976074\n",
      "Epoch 4, Loss: 0.3588346838951111\n",
      "Epoch 3, Loss: 0.10773986577987671\n",
      "Epoch 1, Loss: 1.842143177986145\n",
      "Epoch 1, Loss: 0.05362524837255478\n",
      "Epoch 3, Loss: 0.13236308097839355\n",
      "Epoch 1, Loss: 0.17443011701107025\n",
      "Epoch 2, Loss: 0.045214761048555374\n",
      "Epoch 2, Loss: 0.05767867714166641\n",
      "Epoch 5, Loss: 0.09711550921201706\n",
      "Epoch 3, Loss: 0.1157693937420845\n",
      "Epoch 5, Loss: 0.20948883891105652\n",
      "Epoch 4, Loss: 0.043257828801870346\n",
      "Epoch 3, Loss: 0.05852754786610603\n",
      "Epoch 2, Loss: 0.1348048895597458\n",
      "Epoch 6, Loss: 0.10084611177444458\n",
      "Epoch 4, Loss: 0.24491232633590698\n",
      "Epoch 2, Loss: 0.42512351274490356\n",
      "Epoch 2, Loss: 0.32256320118904114\n",
      "Epoch 2, Loss: 0.09699871391057968\n",
      "Epoch 3, Loss: 0.2539334297180176\n",
      "Epoch 6, Loss: 0.06077937036752701\n",
      "Epoch 3, Loss: 0.26985347270965576\n",
      "Epoch 4, Loss: 0.3501087725162506\n",
      "Epoch 5, Loss: 0.13239794969558716\n",
      "Epoch 4, Loss: 0.12344945222139359\n",
      "Epoch 7, Loss: 0.041429564356803894\n",
      "Epoch 5, Loss: 0.5044492483139038\n",
      "Epoch 3, Loss: 0.2013205587863922\n",
      "Epoch 6, Loss: 0.11335043609142303\n",
      "Epoch 5, Loss: 0.34852394461631775\n",
      "Epoch 8, Loss: 0.008999708108603954\n",
      "Epoch 7, Loss: 0.011479441076517105\n",
      "Epoch 4, Loss: 0.2754893898963928\n",
      "Epoch 3, Loss: 0.057802751660346985\n",
      "Epoch 4, Loss: 0.18397840857505798\n",
      "Epoch 6, Loss: 0.5693051218986511\n",
      "Epoch 3, Loss: 0.04928789660334587\n",
      "Epoch 3, Loss: 0.10711713135242462\n",
      "Epoch 5, Loss: 0.1989995837211609\n",
      "Epoch 4, Loss: 0.06600282341241837\n",
      "Epoch 7, Loss: 0.03654196485877037\n",
      "Epoch 6, Loss: 0.209920734167099\n",
      "Epoch 7, Loss: 0.4764383137226105\n",
      "Epoch 9, Loss: 0.028694545850157738\n",
      "Epoch 8, Loss: 0.0477818101644516\n",
      "Epoch 5, Loss: 0.13567249476909637\n",
      "Epoch 5, Loss: 0.0534629225730896\n",
      "Epoch 4, Loss: 0.09767714887857437\n",
      "Epoch 4, Loss: 0.39702078700065613\n",
      "Epoch 8, Loss: 0.32103002071380615\n",
      "Epoch 10, Loss: 0.05414752662181854\n",
      "Epoch 6, Loss: 0.10726585239171982\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3592088280370018, feed_forward_dim=512, head_dim=16, lr=0.00046329688759691234, num_heads=4, num_layers=1; total time=   1.0s\n",
      "Epoch 8, Loss: 0.012469647452235222\n",
      "Epoch 4, Loss: 0.027661127969622612\n",
      "Epoch 5, Loss: 0.009340284392237663\n",
      "Epoch 6, Loss: 0.03577433526515961\n",
      "Epoch 9, Loss: 0.10397879779338837\n",
      "Epoch 7, Loss: 0.07677911967039108\n",
      "Epoch 9, Loss: 0.17490646243095398\n",
      "Epoch 6, Loss: 0.018632922321558\n",
      "Epoch 7, Loss: 0.02123727649450302\n",
      "Epoch 9, Loss: 0.04708577319979668\n",
      "Epoch 10, Loss: 0.1282186359167099\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3592088280370018, feed_forward_dim=512, head_dim=16, lr=0.00046329688759691234, num_heads=4, num_layers=1; total time=   1.1s\n",
      "Epoch 5, Loss: 0.20903687179088593\n",
      "Epoch 5, Loss: 0.03847750648856163\n",
      "Epoch 6, Loss: 0.05883612856268883\n",
      "Epoch 8, Loss: 0.014780765399336815\n",
      "Epoch 10, Loss: 0.07461610436439514\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3592088280370018, feed_forward_dim=512, head_dim=16, lr=0.00046329688759691234, num_heads=4, num_layers=1; total time=   1.1s\n",
      "Epoch 7, Loss: 0.030007638037204742\n",
      "Epoch 5, Loss: 0.5332251191139221\n",
      "Epoch 10, Loss: 0.07140745967626572\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3592088280370018, feed_forward_dim=512, head_dim=16, lr=0.00046329688759691234, num_heads=4, num_layers=1; total time=   1.1s\n",
      "Epoch 8, Loss: 0.024238046258687973\n",
      "Epoch 7, Loss: 0.060600124299526215\n",
      "Epoch 6, Loss: 0.14202648401260376\n",
      "Epoch 6, Loss: 0.039492323994636536\n",
      "Epoch 9, Loss: 0.027725979685783386\n",
      "Epoch 7, Loss: 0.09085068106651306\n",
      "Epoch 8, Loss: 0.07827820628881454\n",
      "Epoch 6, Loss: 0.4226623773574829\n",
      "Epoch 9, Loss: 0.07197313755750656\n",
      "Epoch 10, Loss: 0.07754696905612946\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3592088280370018, feed_forward_dim=512, head_dim=16, lr=0.00046329688759691234, num_heads=4, num_layers=1; total time=   1.3s\n",
      "Epoch 8, Loss: 0.0962519720196724\n",
      "Epoch 7, Loss: 0.04090483486652374\n",
      "Epoch 8, Loss: 0.0637371838092804\n",
      "Epoch 9, Loss: 0.11242268979549408\n",
      "Epoch 7, Loss: 0.011904196813702583\n",
      "Epoch 7, Loss: 0.23585626482963562\n",
      "Epoch 9, Loss: 0.08537523448467255\n",
      "Epoch 10, Loss: 0.08569487929344177\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3592088280370018, feed_forward_dim=512, head_dim=16, lr=0.00046329688759691234, num_heads=4, num_layers=1; total time=   1.4s\n",
      "Epoch 10, Loss: 0.10004567354917526\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3592088280370018, feed_forward_dim=512, head_dim=16, lr=0.00046329688759691234, num_heads=4, num_layers=1; total time=   1.4s\n",
      "Epoch 9, Loss: 0.019002104178071022\n",
      "Epoch 8, Loss: 0.01651611551642418\n",
      "Epoch 8, Loss: 0.028465064242482185\n",
      "Epoch 8, Loss: 0.08672115951776505\n",
      "Epoch 10, Loss: 0.047205328941345215\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3592088280370018, feed_forward_dim=512, head_dim=16, lr=0.00046329688759691234, num_heads=4, num_layers=1; total time=   1.4s\n",
      "Epoch 10, Loss: 0.003991779405623674\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3592088280370018, feed_forward_dim=512, head_dim=16, lr=0.00046329688759691234, num_heads=4, num_layers=1; total time=   1.4s\n",
      "Epoch 9, Loss: 0.058970049023628235\n",
      "Epoch 9, Loss: 0.033728018403053284\n",
      "Epoch 9, Loss: 0.020435167476534843\n",
      "Epoch 10, Loss: 0.09447655081748962\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3592088280370018, feed_forward_dim=512, head_dim=16, lr=0.00046329688759691234, num_heads=4, num_layers=1; total time=   1.6s\n",
      "Epoch 10, Loss: 0.01637435145676136\n",
      "Epoch 10, Loss: 0.030108775943517685\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3592088280370018, feed_forward_dim=512, head_dim=16, lr=0.00046329688759691234, num_heads=4, num_layers=1; total time=   1.5s\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.3592088280370018, feed_forward_dim=512, head_dim=16, lr=0.00046329688759691234, num_heads=4, num_layers=1; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.14950640499591827\n",
      "Epoch 1, Loss: 2.390763759613037\n",
      "Epoch 1, Loss: 0.16947568953037262\n",
      "Epoch 2, Loss: 0.34804800152778625\n",
      "Epoch 1, Loss: 0.5097506642341614\n",
      "Epoch 1, Loss: 0.14403125643730164\n",
      "Epoch 1, Loss: 0.19827106595039368\n",
      "Epoch 2, Loss: 0.5129790306091309\n",
      "Epoch 2, Loss: 0.3767201006412506\n",
      "Epoch 1, Loss: 0.9607246518135071\n",
      "Epoch 1, Loss: 0.38443100452423096\n",
      "Epoch 1, Loss: 3.396791696548462\n",
      "Epoch 3, Loss: 0.09899729490280151\n",
      "Epoch 2, Loss: 0.18226172029972076\n",
      "Epoch 2, Loss: 0.40288060903549194\n",
      "Epoch 1, Loss: 0.331962525844574\n",
      "Epoch 3, Loss: 0.12691207230091095\n",
      "Epoch 3, Loss: 0.2034071832895279\n",
      "Epoch 2, Loss: 0.06982768326997757\n",
      "Epoch 1, Loss: 0.06223442777991295\n",
      "Epoch 2, Loss: 0.4823608696460724\n",
      "Epoch 1, Loss: 0.27208325266838074\n",
      "Epoch 4, Loss: 0.10064244270324707\n",
      "Epoch 3, Loss: 0.09824683517217636\n",
      "Epoch 3, Loss: 0.39305731654167175\n",
      "Epoch 4, Loss: 0.03660958260297775\n",
      "Epoch 4, Loss: 0.5996281504631042\n",
      "Epoch 2, Loss: 0.03604794293642044\n",
      "Epoch 2, Loss: 1.1726374626159668\n",
      "Epoch 5, Loss: 0.1639402061700821\n",
      "Epoch 3, Loss: 0.23177485167980194\n",
      "Epoch 2, Loss: 0.2762918174266815\n",
      "Epoch 3, Loss: 0.16632765531539917\n",
      "Epoch 4, Loss: 0.02204410545527935\n",
      "Epoch 5, Loss: 0.7250515818595886\n",
      "Epoch 2, Loss: 0.4397793710231781\n",
      "Epoch 5, Loss: 0.13631388545036316\n",
      "Epoch 4, Loss: 0.1469264030456543\n",
      "Epoch 6, Loss: 0.10359680652618408\n",
      "Epoch 4, Loss: 0.4065870940685272\n",
      "Epoch 3, Loss: 0.21475976705551147\n",
      "Epoch 2, Loss: 0.2384714037179947\n",
      "Epoch 6, Loss: 0.5790646076202393\n",
      "Epoch 3, Loss: 0.19991590082645416\n",
      "Epoch 5, Loss: 0.052263230085372925\n",
      "Epoch 6, Loss: 0.12352195382118225\n",
      "Epoch 4, Loss: 0.08340991288423538\n",
      "Epoch 5, Loss: 0.08636631816625595\n",
      "Epoch 3, Loss: 0.0641130730509758\n",
      "Epoch 7, Loss: 0.035202305763959885\n",
      "Epoch 3, Loss: 0.21006251871585846\n",
      "Epoch 7, Loss: 0.3378244936466217\n",
      "Epoch 6, Loss: 0.06851617991924286\n",
      "Epoch 5, Loss: 0.3379639685153961\n",
      "Epoch 4, Loss: 0.176005020737648\n",
      "Epoch 8, Loss: 0.029185805469751358\n",
      "Epoch 7, Loss: 0.03883318975567818\n",
      "Epoch 5, Loss: 0.20269538462162018\n",
      "Epoch 6, Loss: 0.1733855903148651\n",
      "Epoch 3, Loss: 0.05963510647416115\n",
      "Epoch 8, Loss: 0.1475701630115509\n",
      "Epoch 4, Loss: 0.28005191683769226\n",
      "Epoch 4, Loss: 0.08741001039743423\n",
      "Epoch 9, Loss: 0.05943993106484413\n",
      "Epoch 4, Loss: 0.10325565934181213\n",
      "Epoch 8, Loss: 0.007071046158671379\n",
      "Epoch 7, Loss: 0.03457818180322647\n",
      "Epoch 6, Loss: 0.1838168203830719\n",
      "Epoch 5, Loss: 0.05869238078594208\n",
      "Epoch 9, Loss: 0.061477042734622955\n",
      "Epoch 5, Loss: 0.6552053093910217\n",
      "Epoch 7, Loss: 0.1794496774673462\n",
      "Epoch 6, Loss: 0.17557568848133087\n",
      "Epoch 10, Loss: 0.06871568411588669\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21664254248384412, feed_forward_dim=128, head_dim=32, lr=0.0004643443591714636, num_heads=4, num_layers=2; total time=   1.0s\n",
      "Epoch 4, Loss: 0.08421667665243149\n",
      "Epoch 9, Loss: 0.041488274931907654\n",
      "Epoch 8, Loss: 0.00712121045216918\n",
      "Epoch 5, Loss: 0.21255962550640106\n",
      "Epoch 5, Loss: 0.07977312058210373\n",
      "Epoch 10, Loss: 0.07101240754127502\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21664254248384412, feed_forward_dim=128, head_dim=32, lr=0.0004643443591714636, num_heads=4, num_layers=2; total time=   1.1s\n",
      "Epoch 6, Loss: 0.01423309464007616\n",
      "Epoch 7, Loss: 0.06547861546278\n",
      "Epoch 10, Loss: 0.06881976127624512\n",
      "Epoch 7, Loss: 0.07091846317052841\n",
      "Epoch 8, Loss: 0.09609056264162064\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21664254248384412, feed_forward_dim=128, head_dim=32, lr=0.0004643443591714636, num_heads=4, num_layers=2; total time=   1.1s\n",
      "Epoch 9, Loss: 0.01867903210222721\n",
      "Epoch 6, Loss: 0.7667763233184814\n",
      "Epoch 6, Loss: 0.1544017344713211\n",
      "Epoch 9, Loss: 0.032893866300582886\n",
      "Epoch 5, Loss: 0.0618804432451725\n",
      "Epoch 7, Loss: 0.04632403701543808\n",
      "Epoch 8, Loss: 0.027370430529117584\n",
      "Epoch 6, Loss: 0.10310768336057663\n",
      "Epoch 10, Loss: 0.03777576610445976\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21664254248384412, feed_forward_dim=128, head_dim=32, lr=0.0004643443591714636, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 8, Loss: 0.032082848250865936\n",
      "Epoch 7, Loss: 0.6522443294525146\n",
      "Epoch 10, Loss: 0.03732675686478615\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21664254248384412, feed_forward_dim=128, head_dim=32, lr=0.0004643443591714636, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 7, Loss: 0.052215319126844406\n",
      "Epoch 9, Loss: 0.06173191964626312\n",
      "Epoch 9, Loss: 0.06881734728813171\n",
      "Epoch 6, Loss: 0.010902485810220242\n",
      "Epoch 8, Loss: 0.08749517053365707\n",
      "Epoch 8, Loss: 0.4397834241390228\n",
      "Epoch 10, Loss: 0.09320647269487381\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21664254248384412, feed_forward_dim=128, head_dim=32, lr=0.0004643443591714636, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 8, Loss: 0.018175212666392326\n",
      "Epoch 7, Loss: 0.07611653953790665\n",
      "Epoch 10, Loss: 0.12470303475856781\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21664254248384412, feed_forward_dim=128, head_dim=32, lr=0.0004643443591714636, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 9, Loss: 0.0852711871266365\n",
      "Epoch 7, Loss: 0.024403026327490807\n",
      "Epoch 9, Loss: 0.2441702038049698\n",
      "Epoch 9, Loss: 0.05502662807703018\n",
      "Epoch 10, Loss: 0.05417679622769356\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21664254248384412, feed_forward_dim=128, head_dim=32, lr=0.0004643443591714636, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 8, Loss: 0.048815857619047165\n",
      "Epoch 10, Loss: 0.11577360332012177\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21664254248384412, feed_forward_dim=128, head_dim=32, lr=0.0004643443591714636, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 8, Loss: 0.028944743797183037\n",
      "Epoch 10, Loss: 0.09402456134557724\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21664254248384412, feed_forward_dim=128, head_dim=32, lr=0.0004643443591714636, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 0.03673677518963814\n",
      "Epoch 9, Loss: 0.016399327665567398\n",
      "Epoch 10, Loss: 0.03586368262767792\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21664254248384412, feed_forward_dim=128, head_dim=32, lr=0.0004643443591714636, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.017642764374613762\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.21664254248384412, feed_forward_dim=128, head_dim=32, lr=0.0004643443591714636, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.2927839756011963\n",
      "Epoch 1, Loss: 0.07676085829734802\n",
      "Epoch 1, Loss: 0.4793500006198883\n",
      "Epoch 1, Loss: 0.053304627537727356\n",
      "Epoch 1, Loss: 0.36265939474105835\n",
      "Epoch 1, Loss: 0.2769126892089844\n",
      "Epoch 2, Loss: 0.13336828351020813\n",
      "Epoch 1, Loss: 2.426132917404175\n",
      "Epoch 2, Loss: 0.16230332851409912\n",
      "Epoch 2, Loss: 0.3367138206958771\n",
      "Epoch 2, Loss: 0.2950102686882019\n",
      "Epoch 1, Loss: 0.07578190416097641\n",
      "Epoch 1, Loss: 0.10627172142267227\n",
      "Epoch 1, Loss: 0.332427054643631\n",
      "Epoch 2, Loss: 0.31416207551956177\n",
      "Epoch 3, Loss: 0.22084495425224304\n",
      "Epoch 2, Loss: 0.2182045876979828\n",
      "Epoch 2, Loss: 0.3876717984676361\n",
      "Epoch 3, Loss: 0.024162637069821358\n",
      "Epoch 1, Loss: 0.5448247194290161\n",
      "Epoch 3, Loss: 0.284170538187027\n",
      "Epoch 3, Loss: 0.012470638379454613\n",
      "Epoch 4, Loss: 0.08034705370664597\n",
      "Epoch 2, Loss: 0.5254588723182678\n",
      "Epoch 1, Loss: 1.8498162031173706\n",
      "Epoch 3, Loss: 0.21539616584777832\n",
      "Epoch 2, Loss: 0.2104215919971466\n",
      "Epoch 3, Loss: 0.2128225564956665\n",
      "Epoch 4, Loss: 0.17783495783805847\n",
      "Epoch 2, Loss: 0.05362100899219513\n",
      "Epoch 5, Loss: 0.010342396795749664\n",
      "Epoch 3, Loss: 0.09219400584697723\n",
      "Epoch 4, Loss: 0.16784530878067017\n",
      "Epoch 4, Loss: 0.17193645238876343\n",
      "Epoch 4, Loss: 0.05111639201641083\n",
      "Epoch 2, Loss: 0.04225544258952141\n",
      "Epoch 6, Loss: 0.056917157024145126\n",
      "Epoch 5, Loss: 0.1614692211151123\n",
      "Epoch 3, Loss: 0.05298769846558571\n",
      "Epoch 2, Loss: 0.4508541524410248\n",
      "Epoch 4, Loss: 0.06480202078819275\n",
      "Epoch 3, Loss: 0.08466417342424393\n",
      "Epoch 5, Loss: 0.15344266593456268\n",
      "Epoch 4, Loss: 0.5489789843559265\n",
      "Epoch 3, Loss: 0.21671922504901886\n",
      "Epoch 5, Loss: 0.045421238988637924\n",
      "Epoch 7, Loss: 0.09712575376033783\n",
      "Epoch 5, Loss: 0.062452927231788635\n",
      "Epoch 6, Loss: 0.038429562002420425\n",
      "Epoch 5, Loss: 0.036797359585762024\n",
      "Epoch 6, Loss: 0.03976621851325035\n",
      "Epoch 4, Loss: 0.03075406141579151\n",
      "Epoch 4, Loss: 0.16720172762870789\n",
      "Epoch 3, Loss: 0.15333394706249237\n",
      "Epoch 3, Loss: 0.3248719573020935\n",
      "Epoch 5, Loss: 0.7255032062530518\n",
      "Epoch 8, Loss: 0.07282299548387527\n",
      "Epoch 4, Loss: 0.13609528541564941\n",
      "Epoch 6, Loss: 0.03998338058590889\n",
      "Epoch 7, Loss: 0.011609995737671852\n",
      "Epoch 9, Loss: 0.02458089590072632\n",
      "Epoch 6, Loss: 0.10860875993967056\n",
      "Epoch 6, Loss: 0.09327378869056702\n",
      "Epoch 7, Loss: 0.0126411821693182\n",
      "Epoch 7, Loss: 0.09006140381097794\n",
      "Epoch 5, Loss: 0.08246883749961853\n",
      "Epoch 6, Loss: 0.5842218995094299\n",
      "Epoch 5, Loss: 0.271231085062027\n",
      "Epoch 5, Loss: 0.030457379296422005\n",
      "Epoch 4, Loss: 0.41352054476737976\n",
      "Epoch 8, Loss: 0.060949794948101044\n",
      "Epoch 10, Loss: 0.00501348078250885\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00046202286676105163, num_heads=4, num_layers=4; total time=   1.0s\n",
      "Epoch 4, Loss: 0.2480170577764511\n",
      "Epoch 8, Loss: 0.060089290142059326\n",
      "Epoch 7, Loss: 0.06955521553754807\n",
      "Epoch 7, Loss: 0.3409945070743561\n",
      "Epoch 7, Loss: 0.09945093840360641\n",
      "Epoch 6, Loss: 0.1659073680639267\n",
      "Epoch 8, Loss: 0.0982859879732132\n",
      "Epoch 9, Loss: 0.08739912509918213\n",
      "Epoch 6, Loss: 0.020222779363393784\n",
      "Epoch 9, Loss: 0.08985115587711334\n",
      "Epoch 8, Loss: 0.01933302916586399\n",
      "Epoch 6, Loss: 0.07509308308362961\n",
      "Epoch 5, Loss: 0.06898000091314316\n",
      "Epoch 5, Loss: 0.5495610237121582\n",
      "Epoch 8, Loss: 0.13120976090431213\n",
      "Epoch 9, Loss: 0.058587297797203064\n",
      "Epoch 8, Loss: 0.051812052726745605\n",
      "Epoch 10, Loss: 0.061633460223674774\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00046202286676105163, num_heads=4, num_layers=4; total time=   1.2s\n",
      "Epoch 10, Loss: 0.0605953224003315\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00046202286676105163, num_heads=4, num_layers=4; total time=   1.2s\n",
      "Epoch 7, Loss: 0.04628841578960419\n",
      "Epoch 7, Loss: 0.06361956894397736\n",
      "Epoch 9, Loss: 0.027207113802433014\n",
      "Epoch 6, Loss: 0.010433361865580082\n",
      "Epoch 10, Loss: 0.019751569256186485\n",
      "Epoch 9, Loss: 0.014971911907196045\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00046202286676105163, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 9, Loss: 0.029609428718686104\n",
      "Epoch 6, Loss: 0.4630172550678253\n",
      "Epoch 7, Loss: 0.028339777141809464\n",
      "Epoch 10, Loss: 0.060983382165431976\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00046202286676105163, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 8, Loss: 0.023409662768244743\n",
      "Epoch 8, Loss: 0.08623918145895004\n",
      "Epoch 7, Loss: 0.06992220878601074\n",
      "Epoch 10, Loss: 0.027931034564971924\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00046202286676105163, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 10, Loss: 0.01844601146876812\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00046202286676105163, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 8, Loss: 0.010167763568460941\n",
      "Epoch 9, Loss: 0.0723380371928215\n",
      "Epoch 7, Loss: 0.2831180989742279\n",
      "Epoch 9, Loss: 0.06487911194562912\n",
      "Epoch 8, Loss: 0.13011913001537323\n",
      "Epoch 9, Loss: 0.029115619137883186\n",
      "Epoch 10, Loss: 0.11305855214595795\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00046202286676105163, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 10, Loss: 0.02746880240738392\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00046202286676105163, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 8, Loss: 0.13039880990982056\n",
      "Epoch 9, Loss: 0.11941730976104736\n",
      "Epoch 10, Loss: 0.044204723089933395\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00046202286676105163, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Epoch 9, Loss: 0.05344855785369873\n",
      "Epoch 10, Loss: 0.06560276448726654\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00046202286676105163, num_heads=4, num_layers=4; total time=   1.6s\n",
      "Epoch 10, Loss: 0.05039333924651146\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00046202286676105163, num_heads=4, num_layers=4; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.3937753736972809\n",
      "Epoch 1, Loss: 0.038925062865018845\n",
      "Epoch 1, Loss: 0.04676274582743645\n",
      "Epoch 2, Loss: 0.16942261159420013\n",
      "Epoch 1, Loss: 0.8932451009750366\n",
      "Epoch 1, Loss: 0.9707483649253845\n",
      "Epoch 2, Loss: 0.4518984854221344\n",
      "Epoch 1, Loss: 1.1977578401565552\n",
      "Epoch 1, Loss: 0.27652373909950256\n",
      "Epoch 2, Loss: 0.5468790531158447\n",
      "Epoch 3, Loss: 0.25675708055496216\n",
      "Epoch 1, Loss: 0.38753166794776917\n",
      "Epoch 2, Loss: 0.11406444758176804\n",
      "Epoch 3, Loss: 0.0501193068921566\n",
      "Epoch 2, Loss: 0.15724052488803864\n",
      "Epoch 2, Loss: 0.1872333586215973\n",
      "Epoch 3, Loss: 0.07134988158941269\n",
      "Epoch 2, Loss: 0.21919870376586914\n",
      "Epoch 4, Loss: 0.15277066826820374\n",
      "Epoch 1, Loss: 0.12439799308776855\n",
      "Epoch 1, Loss: 0.26404091715812683\n",
      "Epoch 2, Loss: 0.05061441659927368\n",
      "Epoch 4, Loss: 0.08227749913930893\n",
      "Epoch 3, Loss: 0.34464597702026367\n",
      "Epoch 1, Loss: 0.5475617051124573\n",
      "Epoch 5, Loss: 0.05737677961587906\n",
      "Epoch 4, Loss: 0.09129570424556732\n",
      "Epoch 1, Loss: 0.1255933791399002\n",
      "Epoch 3, Loss: 0.2694425582885742\n",
      "Epoch 3, Loss: 0.1803169697523117\n",
      "Epoch 3, Loss: 0.07222237437963486\n",
      "Epoch 2, Loss: 0.29255038499832153\n",
      "Epoch 5, Loss: 0.2100362628698349\n",
      "Epoch 6, Loss: 0.05853081867098808\n",
      "Epoch 4, Loss: 0.39810097217559814\n",
      "Epoch 5, Loss: 0.24239104986190796\n",
      "Epoch 4, Loss: 0.4054538905620575\n",
      "Epoch 2, Loss: 0.14577876031398773\n",
      "Epoch 3, Loss: 0.23191742599010468\n",
      "Epoch 2, Loss: 0.32209351658821106\n",
      "Epoch 4, Loss: 0.06484878063201904\n",
      "Epoch 7, Loss: 0.09430402517318726\n",
      "Epoch 4, Loss: 0.31316807866096497\n",
      "Epoch 6, Loss: 0.14422833919525146\n",
      "Epoch 2, Loss: 0.18677932024002075\n",
      "Epoch 3, Loss: 0.09334214776754379\n",
      "Epoch 5, Loss: 0.239088237285614\n",
      "Epoch 5, Loss: 0.34054556488990784\n",
      "Epoch 6, Loss: 0.16821523010730743\n",
      "Epoch 8, Loss: 0.09258580207824707\n",
      "Epoch 3, Loss: 0.1850113421678543\n",
      "Epoch 4, Loss: 0.18047387897968292\n",
      "Epoch 7, Loss: 0.03789651021361351\n",
      "Epoch 3, Loss: 0.36500614881515503\n",
      "Epoch 5, Loss: 0.3788864016532898\n",
      "Epoch 5, Loss: 0.055830590426921844\n",
      "Epoch 6, Loss: 0.20675675570964813\n",
      "Epoch 6, Loss: 0.08885389566421509\n",
      "Epoch 7, Loss: 0.0421573705971241\n",
      "Epoch 4, Loss: 0.01919935643672943\n",
      "Epoch 3, Loss: 0.08524984121322632\n",
      "Epoch 9, Loss: 0.05229086056351662\n",
      "Epoch 8, Loss: 0.006212083622813225\n",
      "Epoch 6, Loss: 0.0813329741358757\n",
      "Epoch 8, Loss: 0.010166251100599766\n",
      "Epoch 5, Loss: 0.06335990875959396\n",
      "Epoch 7, Loss: 0.04001956060528755\n",
      "Epoch 7, Loss: 0.10048031061887741\n",
      "Epoch 6, Loss: 0.2900167405605316\n",
      "Epoch 4, Loss: 0.10150106996297836\n",
      "Epoch 10, Loss: 0.018561016768217087\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.000465460125668301, num_heads=4, num_layers=3; total time=   1.2s\n",
      "Epoch 4, Loss: 0.17844945192337036\n",
      "Epoch 9, Loss: 0.04562044516205788\n",
      "Epoch 5, Loss: 0.09640312194824219\n",
      "Epoch 4, Loss: 0.041777659207582474\n",
      "Epoch 9, Loss: 0.05754099041223526\n",
      "Epoch 7, Loss: 0.06060992553830147\n",
      "Epoch 8, Loss: 0.077279232442379\n",
      "Epoch 8, Loss: 0.06583497673273087\n",
      "Epoch 7, Loss: 0.15669170022010803\n",
      "Epoch 10, Loss: 0.08347521722316742\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.000465460125668301, num_heads=4, num_layers=3; total time=   1.3s\n",
      "Epoch 6, Loss: 0.0234223622828722\n",
      "Epoch 5, Loss: 0.047128867357969284\n",
      "Epoch 5, Loss: 0.062063515186309814\n",
      "Epoch 10, Loss: 0.10178307443857193\n",
      "Epoch 6, Loss: 0.10433191061019897\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.000465460125668301, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.1270270049571991\n",
      "Epoch 9, Loss: 0.0850890502333641\n",
      "Epoch 5, Loss: 0.07432994991540909\n",
      "Epoch 8, Loss: 0.05752775818109512\n",
      "Epoch 8, Loss: 0.02160240150988102\n",
      "Epoch 7, Loss: 0.05829400569200516\n",
      "Epoch 6, Loss: 0.0552225261926651\n",
      "Epoch 7, Loss: 0.04327523335814476\n",
      "Epoch 10, Loss: 0.13908986747264862\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.000465460125668301, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.1182636246085167\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.000465460125668301, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 6, Loss: 0.08144192397594452\n",
      "Epoch 9, Loss: 0.017737766727805138\n",
      "Epoch 9, Loss: 0.011349854990839958\n",
      "Epoch 8, Loss: 0.09644392132759094\n",
      "Epoch 8, Loss: 0.007696165703237057\n",
      "Epoch 7, Loss: 0.07307283580303192\n",
      "Epoch 6, Loss: 0.0660756528377533\n",
      "Epoch 10, Loss: 0.03145245462656021\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.000465460125668301, num_heads=4, num_layers=3; total time=   1.6s\n",
      "Epoch 7, Loss: 0.11895015090703964\n",
      "Epoch 10, Loss: 0.03097984567284584\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.000465460125668301, num_heads=4, num_layers=3; total time=   1.6s\n",
      "Epoch 9, Loss: 0.025755995884537697\n",
      "Epoch 9, Loss: 0.09033834934234619\n",
      "Epoch 8, Loss: 0.058057352900505066\n",
      "Epoch 8, Loss: 0.09535865485668182\n",
      "Epoch 7, Loss: 0.02779347077012062\n",
      "Epoch 10, Loss: 0.05501289665699005\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.000465460125668301, num_heads=4, num_layers=3; total time=   1.7s\n",
      "Epoch 10, Loss: 0.05360082536935806\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.000465460125668301, num_heads=4, num_layers=3; total time=   1.6s\n",
      "Epoch 9, Loss: 0.028041601181030273\n",
      "Epoch 9, Loss: 0.04312553256750107\n",
      "Epoch 8, Loss: 0.014645184390246868\n",
      "Epoch 10, Loss: 0.014884303323924541\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.000465460125668301, num_heads=4, num_layers=3; total time=   1.7s\n",
      "Epoch 10, Loss: 0.016507450491189957\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.000465460125668301, num_heads=4, num_layers=3; total time=   1.8s\n",
      "Epoch 9, Loss: 0.02979923225939274\n",
      "Epoch 10, Loss: 0.035546354949474335\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.000465460125668301, num_heads=4, num_layers=3; total time=   1.9s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.7065619230270386\n",
      "Epoch 1, Loss: 0.3094770610332489\n",
      "Epoch 1, Loss: 0.22797845304012299\n",
      "Epoch 1, Loss: 0.06598533689975739\n",
      "Epoch 1, Loss: 0.5974084138870239\n",
      "Epoch 1, Loss: 1.729172706604004\n",
      "Epoch 2, Loss: 0.07065929472446442\n",
      "Epoch 2, Loss: 0.37069717049598694\n",
      "Epoch 2, Loss: 0.09784338623285294\n",
      "Epoch 1, Loss: 0.33708345890045166\n",
      "Epoch 2, Loss: 0.029205424711108208\n",
      "Epoch 1, Loss: 1.5262750387191772\n",
      "Epoch 2, Loss: 0.27878573536872864\n",
      "Epoch 3, Loss: 0.37543368339538574\n",
      "Epoch 3, Loss: 0.17855751514434814\n",
      "Epoch 1, Loss: 0.2710357904434204\n",
      "Epoch 2, Loss: 0.3706977963447571\n",
      "Epoch 3, Loss: 0.21458949148654938\n",
      "Epoch 1, Loss: 0.795414388179779\n",
      "Epoch 3, Loss: 0.060957472771406174\n",
      "Epoch 3, Loss: 0.3137683868408203\n",
      "Epoch 1, Loss: 1.3378185033798218Epoch 1, Loss: 0.7130211591720581\n",
      "\n",
      "Epoch 2, Loss: 0.11504118889570236\n",
      "Epoch 4, Loss: 0.31589680910110474\n",
      "Epoch 2, Loss: 0.2732861340045929\n",
      "Epoch 4, Loss: 0.04219510033726692\n",
      "Epoch 3, Loss: 0.26677098870277405\n",
      "Epoch 4, Loss: 0.11453863233327866\n",
      "Epoch 2, Loss: 0.09100176393985748\n",
      "Epoch 4, Loss: 0.03346985951066017\n",
      "Epoch 4, Loss: 0.2971472442150116\n",
      "Epoch 5, Loss: 0.11046809703111649\n",
      "Epoch 2, Loss: 0.21041300892829895\n",
      "Epoch 3, Loss: 0.23078152537345886\n",
      "Epoch 2, Loss: 0.19738906621932983\n",
      "Epoch 3, Loss: 0.06311298906803131\n",
      "Epoch 5, Loss: 0.03379044309258461\n",
      "Epoch 2, Loss: 0.151993528008461\n",
      "Epoch 5, Loss: 0.12268421798944473\n",
      "Epoch 5, Loss: 0.11839006096124649\n",
      "Epoch 5, Loss: 0.12657125294208527\n",
      "Epoch 4, Loss: 0.514714777469635\n",
      "Epoch 6, Loss: 0.014868592843413353\n",
      "Epoch 3, Loss: 0.20401839911937714\n",
      "Epoch 4, Loss: 0.10635557025671005\n",
      "Epoch 3, Loss: 0.20100137591362\n",
      "Epoch 3, Loss: 0.32026854157447815\n",
      "Epoch 6, Loss: 0.017010165378451347\n",
      "Epoch 6, Loss: 0.09355734288692474\n",
      "Epoch 6, Loss: 0.05155303329229355\n",
      "Epoch 6, Loss: 0.1485632210969925\n",
      "Epoch 4, Loss: 0.33763352036476135\n",
      "Epoch 5, Loss: 0.5214748382568359\n",
      "Epoch 7, Loss: 0.06196514889597893\n",
      "Epoch 3, Loss: 0.3443031907081604\n",
      "Epoch 4, Loss: 0.08977746218442917\n",
      "Epoch 8, Loss: 0.13721196353435516\n",
      "Epoch 7, Loss: 0.08875294774770737\n",
      "Epoch 5, Loss: 0.022682616487145424\n",
      "Epoch 7, Loss: 0.027961404994130135\n",
      "Epoch 5, Loss: 0.46761733293533325\n",
      "Epoch 4, Loss: 0.44164228439331055\n",
      "Epoch 7, Loss: 0.07963618636131287\n",
      "Epoch 6, Loss: 0.37110549211502075\n",
      "Epoch 7, Loss: 0.032286565750837326\n",
      "Epoch 4, Loss: 0.34944218397140503\n",
      "Epoch 8, Loss: 0.08172109723091125\n",
      "Epoch 9, Loss: 0.14467091858386993\n",
      "Epoch 4, Loss: 0.3267921209335327\n",
      "Epoch 8, Loss: 0.010069995187222958\n",
      "Epoch 5, Loss: 0.013318918645381927\n",
      "Epoch 8, Loss: 0.0187419131398201\n",
      "Epoch 6, Loss: 0.04771774634718895\n",
      "Epoch 7, Loss: 0.19795586168766022\n",
      "Epoch 5, Loss: 0.4454347789287567\n",
      "Epoch 6, Loss: 0.3949633538722992\n",
      "Epoch 8, Loss: 0.10263072699308395\n",
      "Epoch 10, Loss: 0.09093116968870163\n",
      "Epoch 9, Loss: 0.03979652374982834\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00045602354658840605, num_heads=4, num_layers=3; total time=   1.3s\n",
      "Epoch 9, Loss: 0.037834733724594116\n",
      "Epoch 9, Loss: 0.023953920230269432\n",
      "Epoch 5, Loss: 0.22270895540714264\n",
      "Epoch 8, Loss: 0.08357714116573334\n",
      "Epoch 5, Loss: 0.17478984594345093\n",
      "Epoch 7, Loss: 0.09317264705896378\n",
      "Epoch 10, Loss: 0.015078717842698097\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00045602354658840605, num_heads=4, num_layers=3; total time=   1.3s\n",
      "Epoch 6, Loss: 0.0440833643078804\n",
      "Epoch 10, Loss: 0.061654798686504364\n",
      "Epoch 9, Loss: 0.13344094157218933\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00045602354658840605, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Epoch 10, Loss: 0.060930803418159485\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00045602354658840605, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Epoch 7, Loss: 0.23403896391391754\n",
      "Epoch 9, Loss: 0.04403601586818695\n",
      "Epoch 6, Loss: 0.3003235161304474\n",
      "Epoch 8, Loss: 0.07869503647089005\n",
      "Epoch 6, Loss: 0.09915357083082199\n",
      "Epoch 7, Loss: 0.09029725939035416\n",
      "Epoch 10, Loss: 0.10583913326263428\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00045602354658840605, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 8, Loss: 0.09624289721250534\n",
      "Epoch 10, Loss: 0.06188188120722771\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00045602354658840605, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 6, Loss: 0.0645315870642662\n",
      "Epoch 7, Loss: 0.1513785421848297\n",
      "Epoch 9, Loss: 0.03630434721708298\n",
      "Epoch 7, Loss: 0.05628081038594246\n",
      "Epoch 8, Loss: 0.0770290419459343\n",
      "Epoch 9, Loss: 0.023637112230062485\n",
      "Epoch 7, Loss: 0.05076747387647629\n",
      "Epoch 8, Loss: 0.05929320678114891\n",
      "Epoch 10, Loss: 0.007617806550115347\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00045602354658840605, num_heads=4, num_layers=3; total time=   1.6s\n",
      "Epoch 8, Loss: 0.076905757188797\n",
      "Epoch 9, Loss: 0.035186585038900375\n",
      "Epoch 10, Loss: 0.01895224116742611\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00045602354658840605, num_heads=4, num_layers=3; total time=   1.6s\n",
      "Epoch 8, Loss: 0.09400087594985962\n",
      "Epoch 9, Loss: 0.04594291001558304\n",
      "Epoch 9, Loss: 0.11124730110168457\n",
      "Epoch 10, Loss: 0.008931603282690048\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00045602354658840605, num_heads=4, num_layers=3; total time=   1.7s\n",
      "Epoch 9, Loss: 0.12149322032928467\n",
      "Epoch 10, Loss: 0.08019626140594482\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00045602354658840605, num_heads=4, num_layers=3; total time=   1.7s\n",
      "Epoch 10, Loss: 0.11464964598417282\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00045602354658840605, num_heads=4, num_layers=3; total time=   1.8s\n",
      "Epoch 10, Loss: 0.10335870832204819\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00045602354658840605, num_heads=4, num_layers=3; total time=   1.8s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.7307337522506714\n",
      "Epoch 1, Loss: 1.5268394947052002\n",
      "Epoch 1, Loss: 0.20525895059108734\n",
      "Epoch 1, Loss: 0.2825049161911011\n",
      "Epoch 1, Loss: 0.22809651494026184\n",
      "Epoch 1, Loss: 0.0860561728477478\n",
      "Epoch 1, Loss: 0.1896069198846817\n",
      "Epoch 1, Loss: 0.07222484052181244\n",
      "Epoch 2, Loss: 0.35849279165267944\n",
      "Epoch 2, Loss: 0.1318308562040329\n",
      "Epoch 1, Loss: 0.26324114203453064\n",
      "Epoch 1, Loss: 0.6011580228805542\n",
      "Epoch 2, Loss: 0.2804185152053833\n",
      "Epoch 1, Loss: 0.0969344899058342\n",
      "Epoch 2, Loss: 0.1837787628173828\n",
      "Epoch 2, Loss: 0.4010893404483795\n",
      "Epoch 2, Loss: 0.46989065408706665\n",
      "Epoch 3, Loss: 0.05755294859409332\n",
      "Epoch 2, Loss: 0.15414956212043762\n",
      "Epoch 3, Loss: 0.3588559329509735\n",
      "Epoch 2, Loss: 0.14845511317253113\n",
      "Epoch 1, Loss: 1.1566154956817627\n",
      "Epoch 3, Loss: 0.17956222593784332\n",
      "Epoch 3, Loss: 0.16271845996379852\n",
      "Epoch 2, Loss: 0.11552811414003372\n",
      "Epoch 3, Loss: 0.17069144546985626\n",
      "Epoch 4, Loss: 0.24083104729652405\n",
      "Epoch 2, Loss: 0.036088697612285614\n",
      "Epoch 3, Loss: 0.1025407537817955\n",
      "Epoch 2, Loss: 0.3637198805809021\n",
      "Epoch 4, Loss: 0.04847944155335426\n",
      "Epoch 4, Loss: 0.3522481620311737\n",
      "Epoch 4, Loss: 0.03841468691825867\n",
      "Epoch 3, Loss: 0.12302996963262558\n",
      "Epoch 5, Loss: 0.3999063968658447\n",
      "Epoch 3, Loss: 0.015353322960436344\n",
      "Epoch 4, Loss: 0.026235399767756462\n",
      "Epoch 2, Loss: 0.08377384394407272\n",
      "Epoch 5, Loss: 0.08284705132246017\n",
      "Epoch 3, Loss: 0.1980300098657608\n",
      "Epoch 3, Loss: 0.2934715151786804\n",
      "Epoch 4, Loss: 0.030289798974990845\n",
      "Epoch 6, Loss: 0.3763901889324188\n",
      "Epoch 5, Loss: 0.10600166767835617\n",
      "Epoch 4, Loss: 0.08753610402345657\n",
      "Epoch 5, Loss: 0.1899619847536087\n",
      "Epoch 4, Loss: 0.012289905920624733\n",
      "Epoch 6, Loss: 0.11352889239788055\n",
      "Epoch 3, Loss: 0.07000213861465454\n",
      "Epoch 5, Loss: 0.021550167351961136\n",
      "Epoch 7, Loss: 0.25984084606170654\n",
      "Epoch 6, Loss: 0.11805867403745651\n",
      "Epoch 4, Loss: 0.08298905193805695\n",
      "Epoch 3, Loss: 0.47741004824638367\n",
      "Epoch 5, Loss: 0.18117326498031616\n",
      "Epoch 6, Loss: 0.06964512169361115\n",
      "Epoch 5, Loss: 0.03399601951241493\n",
      "Epoch 7, Loss: 0.06187015399336815\n",
      "Epoch 5, Loss: 0.05775082856416702\n",
      "Epoch 6, Loss: 0.08432453870773315\n",
      "Epoch 4, Loss: 0.27504387497901917\n",
      "Epoch 8, Loss: 0.13779456913471222\n",
      "Epoch 4, Loss: 0.06786344945430756\n",
      "Epoch 7, Loss: 0.055490925908088684\n",
      "Epoch 5, Loss: 0.018960287794470787\n",
      "Epoch 7, Loss: 0.08561515063047409\n",
      "Epoch 8, Loss: 0.012711954303085804\n",
      "Epoch 6, Loss: 0.009150507859885693\n",
      "Epoch 6, Loss: 0.15858158469200134\n",
      "Epoch 7, Loss: 0.05685333535075188\n",
      "Epoch 6, Loss: 0.07833781838417053\n",
      "Epoch 9, Loss: 0.052419230341911316\n",
      "Epoch 4, Loss: 0.5174526572227478\n",
      "Epoch 5, Loss: 0.11220012605190277\n",
      "Epoch 8, Loss: 0.011739958077669144\n",
      "Epoch 8, Loss: 0.04071684554219246\n",
      "Epoch 5, Loss: 0.15243147313594818\n",
      "Epoch 8, Loss: 0.1050887256860733\n",
      "Epoch 9, Loss: 0.021743008866906166\n",
      "Epoch 10, Loss: 0.02313852310180664\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.0004757108642710107, num_heads=4, num_layers=4; total time=   1.2s\n",
      "Epoch 7, Loss: 0.021005801856517792\n",
      "Epoch 6, Loss: 0.05175947770476341\n",
      "Epoch 7, Loss: 0.0525892898440361\n",
      "Epoch 5, Loss: 0.25672614574432373\n",
      "Epoch 7, Loss: 0.06097211316227913\n",
      "Epoch 9, Loss: 0.03169892728328705\n",
      "Epoch 10, Loss: 0.05406861752271652\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.0004757108642710107, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 6, Loss: 0.020579000934958458\n",
      "Epoch 9, Loss: 0.0075874291360378265\n",
      "Epoch 9, Loss: 0.14106597006320953\n",
      "Epoch 6, Loss: 0.10287094116210938\n",
      "Epoch 8, Loss: 0.046973686665296555\n",
      "Epoch 10, Loss: 0.06548576802015305\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.0004757108642710107, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 8, Loss: 0.004201402887701988\n",
      "Epoch 8, Loss: 0.02113090455532074\n",
      "Epoch 10, Loss: 0.01525123231112957\n",
      "Epoch 7, Loss: 0.08719945698976517\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.0004757108642710107, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 6, Loss: 0.05811557546257973\n",
      "Epoch 10, Loss: 0.12457149475812912\n",
      "Epoch 7, Loss: 0.04160358011722565\n",
      "Epoch 9, Loss: 0.03622087836265564\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.0004757108642710107, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 9, Loss: 0.03599105402827263\n",
      "Epoch 7, Loss: 0.026904532685875893\n",
      "Epoch 9, Loss: 0.006467471830546856\n",
      "Epoch 8, Loss: 0.06485170125961304\n",
      "Epoch 8, Loss: 0.0999017059803009\n",
      "Epoch 10, Loss: 0.01224076934158802\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.0004757108642710107, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Epoch 7, Loss: 0.032784752547740936\n",
      "Epoch 10, Loss: 0.07794199883937836\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.0004757108642710107, num_heads=4, num_layers=4; total time=   1.6s\n",
      "Epoch 10, Loss: 0.02421792596578598\n",
      "Epoch 8, Loss: 0.00978336576372385\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.0004757108642710107, num_heads=4, num_layers=4; total time=   1.6s\n",
      "Epoch 9, Loss: 0.024052372202277184\n",
      "Epoch 9, Loss: 0.12388748675584793\n",
      "Epoch 8, Loss: 0.1103719174861908\n",
      "Epoch 9, Loss: 0.045245032757520676\n",
      "Epoch 10, Loss: 0.008080330677330494\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.0004757108642710107, num_heads=4, num_layers=4; total time=   1.7s\n",
      "Epoch 10, Loss: 0.0939125120639801\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.0004757108642710107, num_heads=4, num_layers=4; total time=   1.7s\n",
      "Epoch 9, Loss: 0.17830108106136322\n",
      "Epoch 10, Loss: 0.06926035135984421\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.0004757108642710107, num_heads=4, num_layers=4; total time=   1.7s\n",
      "Epoch 10, Loss: 0.17353244125843048\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.0004757108642710107, num_heads=4, num_layers=4; total time=   1.8s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.5198483467102051\n",
      "Epoch 1, Loss: 0.13319522142410278\n",
      "Epoch 1, Loss: 0.6690025329589844\n",
      "Epoch 1, Loss: 0.23516489565372467\n",
      "Epoch 1, Loss: 1.030842900276184\n",
      "Epoch 2, Loss: 0.1597255915403366\n",
      "Epoch 1, Loss: 0.13486196100711823\n",
      "Epoch 2, Loss: 0.4520275294780731\n",
      "Epoch 1, Loss: 0.0507584773004055\n",
      "Epoch 2, Loss: 0.009865366853773594\n",
      "Epoch 1, Loss: 0.8162209391593933\n",
      "Epoch 2, Loss: 0.19019943475723267\n",
      "Epoch 2, Loss: 0.43555161356925964\n",
      "Epoch 3, Loss: 0.3378874957561493\n",
      "Epoch 1, Loss: 0.9251464605331421\n",
      "Epoch 1, Loss: 3.2156729698181152\n",
      "Epoch 2, Loss: 0.4627395570278168\n",
      "Epoch 3, Loss: 0.08716971427202225\n",
      "Epoch 3, Loss: 0.4751305878162384\n",
      "Epoch 3, Loss: 0.2706921398639679\n",
      "Epoch 4, Loss: 0.18954899907112122\n",
      "Epoch 1, Loss: 1.1400017738342285\n",
      "Epoch 2, Loss: 0.0740995705127716\n",
      "Epoch 3, Loss: 0.16964338719844818\n",
      "Epoch 2, Loss: 0.4804452359676361\n",
      "Epoch 4, Loss: 0.09042266011238098\n",
      "Epoch 5, Loss: 0.03712894767522812\n",
      "Epoch 1, Loss: 1.1346631050109863\n",
      "Epoch 4, Loss: 0.313576340675354\n",
      "Epoch 4, Loss: 0.45057451725006104\n",
      "Epoch 2, Loss: 0.044431593269109726\n",
      "Epoch 2, Loss: 0.9373438954353333\n",
      "Epoch 4, Loss: 0.044566620141267776\n",
      "Epoch 3, Loss: 0.07856182754039764\n",
      "Epoch 3, Loss: 0.276353657245636\n",
      "Epoch 3, Loss: 0.04315989464521408\n",
      "Epoch 5, Loss: 0.19962644577026367\n",
      "Epoch 6, Loss: 0.042700767517089844\n",
      "Epoch 2, Loss: 0.19182099401950836\n",
      "Epoch 5, Loss: 0.16348755359649658\n",
      "Epoch 5, Loss: 0.2392755001783371\n",
      "Epoch 5, Loss: 0.12444049119949341\n",
      "Epoch 6, Loss: 0.12375283986330032\n",
      "Epoch 4, Loss: 0.17960061132907867\n",
      "Epoch 2, Loss: 0.06322043389081955\n",
      "Epoch 4, Loss: 0.3727338910102844\n",
      "Epoch 4, Loss: 0.12064921855926514\n",
      "Epoch 3, Loss: 0.05584994703531265\n",
      "Epoch 3, Loss: 0.34089401364326477\n",
      "Epoch 7, Loss: 0.030303524807095528\n",
      "Epoch 7, Loss: 0.11560516804456711\n",
      "Epoch 6, Loss: 0.03811023384332657\n",
      "Epoch 6, Loss: 0.13937632739543915\n",
      "Epoch 6, Loss: 0.0864269807934761\n",
      "Epoch 3, Loss: 0.3453654944896698\n",
      "Epoch 5, Loss: 0.23416779935359955\n",
      "Epoch 3, Loss: 0.5311460494995117\n",
      "Epoch 5, Loss: 0.23011445999145508\n",
      "Epoch 8, Loss: 0.1304503083229065\n",
      "Epoch 5, Loss: 0.24496731162071228\n",
      "Epoch 8, Loss: 0.018330752849578857\n",
      "Epoch 4, Loss: 0.2056196928024292\n",
      "Epoch 7, Loss: 0.016319623216986656\n",
      "Epoch 4, Loss: 0.41766899824142456\n",
      "Epoch 7, Loss: 0.07259643822908401\n",
      "Epoch 7, Loss: 0.06750990450382233\n",
      "Epoch 6, Loss: 0.11667173355817795\n",
      "Epoch 9, Loss: 0.06197228655219078\n",
      "Epoch 4, Loss: 0.4632323384284973\n",
      "Epoch 9, Loss: 0.08159121870994568\n",
      "Epoch 6, Loss: 0.09866021573543549\n",
      "Epoch 8, Loss: 0.06522625684738159\n",
      "Epoch 5, Loss: 0.2511148154735565\n",
      "Epoch 6, Loss: 0.14345642924308777\n",
      "Epoch 4, Loss: 0.5256518721580505\n",
      "Epoch 8, Loss: 0.13230161368846893\n",
      "Epoch 5, Loss: 0.5311964750289917\n",
      "Epoch 8, Loss: 0.012437507510185242\n",
      "Epoch 7, Loss: 0.03341575711965561\n",
      "Epoch 10, Loss: 0.026158951222896576\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005317118272498465, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 10, Loss: 0.08449333161115646\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005317118272498465, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 9, Loss: 0.11299066245555878\n",
      "Epoch 5, Loss: 0.33530041575431824\n",
      "Epoch 9, Loss: 0.02341930754482746\n",
      "Epoch 7, Loss: 0.03572772070765495\n",
      "Epoch 7, Loss: 0.03584904968738556\n",
      "Epoch 9, Loss: 0.17219747602939606\n",
      "Epoch 6, Loss: 0.09076802432537079\n",
      "Epoch 5, Loss: 0.24056443572044373\n",
      "Epoch 8, Loss: 0.051920294761657715\n",
      "Epoch 10, Loss: 0.11684772372245789\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005317118272498465, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 6, Loss: 0.6126135587692261\n",
      "Epoch 10, Loss: 0.06068553403019905\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005317118272498465, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 10, Loss: 0.1503230184316635\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005317118272498465, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 8, Loss: 0.05892277881503105\n",
      "Epoch 6, Loss: 0.15870286524295807\n",
      "Epoch 8, Loss: 0.009235541336238384\n",
      "Epoch 7, Loss: 0.03209798410534859\n",
      "Epoch 9, Loss: 0.09963613003492355\n",
      "Epoch 6, Loss: 0.04706607386469841\n",
      "Epoch 9, Loss: 0.11166258901357651\n",
      "Epoch 7, Loss: 0.5040414333343506\n",
      "Epoch 7, Loss: 0.06024027243256569\n",
      "Epoch 9, Loss: 0.05108802020549774\n",
      "Epoch 8, Loss: 0.0647445023059845\n",
      "Epoch 10, Loss: 0.10530220717191696\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005317118272498465, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 7, Loss: 0.04250221326947212\n",
      "Epoch 10, Loss: 0.13165594637393951\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005317118272498465, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.09061408042907715\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005317118272498465, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 8, Loss: 0.05958797037601471\n",
      "Epoch 8, Loss: 0.3258823752403259\n",
      "Epoch 9, Loss: 0.12296060472726822\n",
      "Epoch 9, Loss: 0.16593313217163086\n",
      "Epoch 8, Loss: 0.13767093420028687\n",
      "Epoch 9, Loss: 0.1046055257320404\n",
      "Epoch 10, Loss: 0.14962759613990784\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005317118272498465, num_heads=4, num_layers=2; total time=   1.7s\n",
      "Epoch 10, Loss: 0.06402359157800674\n",
      "Epoch 9, Loss: 0.20084765553474426\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005317118272498465, num_heads=4, num_layers=2; total time=   1.7s\n",
      "Epoch 10, Loss: 0.13734424114227295\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005317118272498465, num_heads=4, num_layers=2; total time=   1.7s\n",
      "Epoch 10, Loss: 0.1875987946987152\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005317118272498465, num_heads=4, num_layers=2; total time=   1.8s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 1.0337646007537842\n",
      "Epoch 1, Loss: 0.7049862146377563\n",
      "Epoch 1, Loss: 1.281891107559204\n",
      "Epoch 1, Loss: 0.9058313369750977\n",
      "Epoch 1, Loss: 0.06253023445606232\n",
      "Epoch 1, Loss: 2.024948835372925\n",
      "Epoch 2, Loss: 0.23304924368858337\n",
      "Epoch 2, Loss: 0.048292193561792374\n",
      "Epoch 1, Loss: 0.6478932499885559\n",
      "Epoch 1, Loss: 1.9667835235595703\n",
      "Epoch 2, Loss: 0.13259397447109222\n",
      "Epoch 2, Loss: 0.27543020248413086\n",
      "Epoch 2, Loss: 0.1814797818660736\n",
      "Epoch 2, Loss: 0.7172271013259888\n",
      "Epoch 3, Loss: 0.14822901785373688\n",
      "Epoch 3, Loss: 0.11051971465349197\n",
      "Epoch 1, Loss: 0.5122795104980469\n",
      "Epoch 2, Loss: 0.09873811900615692\n",
      "Epoch 1, Loss: 1.697608470916748\n",
      "Epoch 3, Loss: 0.07549510151147842\n",
      "Epoch 4, Loss: 0.33834725618362427\n",
      "Epoch 2, Loss: 0.9613275527954102\n",
      "Epoch 1, Loss: 0.10102403163909912\n",
      "Epoch 3, Loss: 0.06144287437200546\n",
      "Epoch 3, Loss: 0.04522378370165825\n",
      "Epoch 4, Loss: 0.2756021320819855\n",
      "Epoch 3, Loss: 0.10727722942829132\n",
      "Epoch 1, Loss: 1.2087498903274536\n",
      "Epoch 2, Loss: 0.021574320271611214\n",
      "Epoch 4, Loss: 0.3325826823711395\n",
      "Epoch 3, Loss: 0.3422834575176239\n",
      "Epoch 3, Loss: 0.23658379912376404\n",
      "Epoch 5, Loss: 0.3772473633289337\n",
      "Epoch 4, Loss: 0.23717354238033295\n",
      "Epoch 2, Loss: 0.60546875\n",
      "Epoch 5, Loss: 0.24195459485054016\n",
      "Epoch 4, Loss: 0.04847190901637077\n",
      "Epoch 2, Loss: 0.2097385674715042\n",
      "Epoch 6, Loss: 0.27573761343955994\n",
      "Epoch 5, Loss: 0.41171056032180786\n",
      "Epoch 4, Loss: 0.037082694470882416\n",
      "Epoch 3, Loss: 0.12140811234712601\n",
      "Epoch 2, Loss: 0.23551850020885468\n",
      "Epoch 5, Loss: 0.1193973496556282\n",
      "Epoch 4, Loss: 0.0888342633843422\n",
      "Epoch 6, Loss: 0.12613603472709656\n",
      "Epoch 5, Loss: 0.2982899844646454\n",
      "Epoch 4, Loss: 0.31042101979255676\n",
      "Epoch 7, Loss: 0.14098842442035675\n",
      "Epoch 6, Loss: 0.3170357644557953\n",
      "Epoch 3, Loss: 0.09586846828460693\n",
      "Epoch 3, Loss: 0.07243760675191879\n",
      "Epoch 7, Loss: 0.034211691468954086\n",
      "Epoch 6, Loss: 0.08432497829198837\n",
      "Epoch 3, Loss: 0.058625735342502594\n",
      "Epoch 5, Loss: 0.2109808325767517\n",
      "Epoch 5, Loss: 0.10092291980981827\n",
      "Epoch 7, Loss: 0.16872823238372803\n",
      "Epoch 8, Loss: 0.05352538079023361\n",
      "Epoch 6, Loss: 0.23498307168483734\n",
      "Epoch 5, Loss: 0.21925033628940582\n",
      "Epoch 8, Loss: 0.008897494524717331\n",
      "Epoch 4, Loss: 0.23173683881759644\n",
      "Epoch 4, Loss: 0.06616044044494629\n",
      "Epoch 7, Loss: 0.020990515127778053\n",
      "Epoch 6, Loss: 0.35958021879196167\n",
      "Epoch 6, Loss: 0.22019143402576447\n",
      "Epoch 9, Loss: 0.03651193529367447\n",
      "Epoch 7, Loss: 0.13431812822818756\n",
      "Epoch 8, Loss: 0.050401072949171066\n",
      "Epoch 4, Loss: 0.012895594350993633\n",
      "Epoch 9, Loss: 0.03927868232131004\n",
      "Epoch 6, Loss: 0.09495669603347778\n",
      "Epoch 4, Loss: 0.29751139879226685\n",
      "Epoch 10, Loss: 0.06624683737754822\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00035777300738632574, num_heads=4, num_layers=3; total time=   1.1s\n",
      "Epoch 8, Loss: 0.011493435129523277\n",
      "Epoch 5, Loss: 0.2457418143749237\n",
      "Epoch 5, Loss: 0.17664112150669098\n",
      "Epoch 9, Loss: 0.005784698761999607\n",
      "Epoch 10, Loss: 0.08058787137269974\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00035777300738632574, num_heads=4, num_layers=3; total time=   1.1s\n",
      "Epoch 8, Loss: 0.05316632613539696\n",
      "Epoch 7, Loss: 0.3175007998943329\n",
      "Epoch 7, Loss: 0.39569830894470215\n",
      "Epoch 7, Loss: 0.033034540712833405\n",
      "Epoch 5, Loss: 0.3985261023044586\n",
      "Epoch 10, Loss: 0.025845946744084358\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00035777300738632574, num_heads=4, num_layers=3; total time=   1.2s\n",
      "Epoch 9, Loss: 0.020879052579402924\n",
      "Epoch 9, Loss: 0.043229132890701294\n",
      "Epoch 5, Loss: 0.07825153321027756\n",
      "Epoch 6, Loss: 0.36962610483169556\n",
      "Epoch 8, Loss: 0.3474145829677582\n",
      "Epoch 6, Loss: 0.07651324570178986\n",
      "Epoch 8, Loss: 0.3472222089767456\n",
      "Epoch 8, Loss: 0.04805538058280945\n",
      "Epoch 6, Loss: 0.30886033177375793\n",
      "Epoch 10, Loss: 0.031575288623571396\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00035777300738632574, num_heads=4, num_layers=3; total time=   1.2s\n",
      "Epoch 10, Loss: 0.060077015310525894\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00035777300738632574, num_heads=4, num_layers=3; total time=   1.3s\n",
      "Epoch 6, Loss: 0.08193618804216385\n",
      "Epoch 9, Loss: 0.25424060225486755\n",
      "Epoch 7, Loss: 0.37364712357521057\n",
      "Epoch 9, Loss: 0.31885963678359985\n",
      "Epoch 9, Loss: 0.09130430966615677\n",
      "Epoch 7, Loss: 0.014646471478044987\n",
      "Epoch 7, Loss: 0.16013118624687195\n",
      "Epoch 10, Loss: 0.15734466910362244\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00035777300738632574, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Epoch 8, Loss: 0.29838502407073975\n",
      "Epoch 10, Loss: 0.1095028966665268\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00035777300738632574, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Epoch 10, Loss: 0.2540483772754669\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00035777300738632574, num_heads=4, num_layers=3; total time=   1.3s\n",
      "Epoch 7, Loss: 0.029176311567425728\n",
      "Epoch 8, Loss: 0.0164936576038599\n",
      "Epoch 8, Loss: 0.05057213827967644\n",
      "Epoch 9, Loss: 0.1917746514081955\n",
      "Epoch 9, Loss: 0.05542544648051262\n",
      "Epoch 8, Loss: 0.007322308607399464\n",
      "Epoch 9, Loss: 0.013937180861830711\n",
      "Epoch 10, Loss: 0.09723788499832153\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00035777300738632574, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.08426126092672348\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00035777300738632574, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 9, Loss: 0.031117837876081467\n",
      "Epoch 10, Loss: 0.03643926605582237\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00035777300738632574, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.05000556260347366\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00035777300738632574, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 1.3560512065887451\n",
      "Epoch 1, Loss: 0.07085464149713516\n",
      "Epoch 1, Loss: 0.12867581844329834\n",
      "Epoch 1, Loss: 0.7477192282676697\n",
      "Epoch 1, Loss: 0.23338738083839417\n",
      "Epoch 1, Loss: 0.29155486822128296\n",
      "Epoch 2, Loss: 0.8403006196022034\n",
      "Epoch 2, Loss: 0.0509040541946888\n",
      "Epoch 1, Loss: 2.5975637435913086\n",
      "Epoch 2, Loss: 0.09415259212255478\n",
      "Epoch 2, Loss: 0.042612042278051376\n",
      "Epoch 1, Loss: 0.19287827610969543\n",
      "Epoch 3, Loss: 0.4448396861553192\n",
      "Epoch 2, Loss: 0.43033939599990845\n",
      "Epoch 2, Loss: 0.10979204624891281\n",
      "Epoch 3, Loss: 0.0351438969373703\n",
      "Epoch 1, Loss: 0.11260463297367096\n",
      "Epoch 1, Loss: 0.035021450370550156\n",
      "Epoch 3, Loss: 0.0715252086520195\n",
      "Epoch 4, Loss: 0.1947559416294098\n",
      "Epoch 3, Loss: 0.03862568363547325\n",
      "Epoch 1, Loss: 0.5047441124916077\n",
      "Epoch 2, Loss: 1.8484089374542236\n",
      "Epoch 2, Loss: 0.04663321375846863\n",
      "Epoch 1, Loss: 0.3352867364883423\n",
      "Epoch 3, Loss: 0.03635885566473007\n",
      "Epoch 3, Loss: 0.21676257252693176\n",
      "Epoch 5, Loss: 0.06601433455944061\n",
      "Epoch 4, Loss: 0.024265579879283905\n",
      "Epoch 2, Loss: 0.04015444219112396\n",
      "Epoch 2, Loss: 0.06959177553653717\n",
      "Epoch 4, Loss: 0.06092219427227974\n",
      "Epoch 4, Loss: 0.09677133709192276\n",
      "Epoch 6, Loss: 0.04369986802339554\n",
      "Epoch 4, Loss: 0.11580648273229599\n",
      "Epoch 2, Loss: 0.22568213939666748\n",
      "Epoch 3, Loss: 1.2357393503189087\n",
      "Epoch 5, Loss: 0.016702374443411827\n",
      "Epoch 4, Loss: 0.0438418984413147\n",
      "Epoch 2, Loss: 0.10775540769100189\n",
      "Epoch 3, Loss: 0.05119730159640312\n",
      "Epoch 5, Loss: 0.05893537774682045\n",
      "Epoch 7, Loss: 0.08682699501514435\n",
      "Epoch 5, Loss: 0.09837555140256882\n",
      "Epoch 5, Loss: 0.10703925043344498\n",
      "Epoch 3, Loss: 0.07268144190311432\n",
      "Epoch 3, Loss: 0.019693337380886078\n",
      "Epoch 3, Loss: 0.08124040812253952\n",
      "Epoch 6, Loss: 0.01166567113250494\n",
      "Epoch 4, Loss: 0.7659043669700623\n",
      "Epoch 5, Loss: 0.07562516629695892\n",
      "Epoch 6, Loss: 0.039797812700271606\n",
      "Epoch 6, Loss: 0.1339401751756668\n",
      "Epoch 8, Loss: 0.15555906295776367\n",
      "Epoch 3, Loss: 0.014356209896504879\n",
      "Epoch 4, Loss: 0.09098222106695175\n",
      "Epoch 7, Loss: 0.008626867085695267\n",
      "Epoch 6, Loss: 0.0877448320388794\n",
      "Epoch 4, Loss: 0.017574548721313477\n",
      "Epoch 4, Loss: 0.0675414428114891\n",
      "Epoch 7, Loss: 0.02116413414478302\n",
      "Epoch 9, Loss: 0.21101276576519012\n",
      "Epoch 4, Loss: 0.03635512664914131\n",
      "Epoch 7, Loss: 0.1730695366859436\n",
      "Epoch 6, Loss: 0.09275811165571213\n",
      "Epoch 5, Loss: 0.4230774939060211\n",
      "Epoch 8, Loss: 0.010122480802237988\n",
      "Epoch 5, Loss: 0.08658847212791443\n",
      "Epoch 7, Loss: 0.06000128760933876\n",
      "Epoch 4, Loss: 0.027755821123719215\n",
      "Epoch 10, Loss: 0.24228113889694214\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.00013847726866053763, num_heads=4, num_layers=3; total time=   1.0s\n",
      "Epoch 8, Loss: 0.013412415981292725\n",
      "Epoch 6, Loss: 0.2053035944700241\n",
      "Epoch 5, Loss: 0.019337091594934464\n",
      "Epoch 8, Loss: 0.19632552564144135\n",
      "Epoch 9, Loss: 0.01002922747284174\n",
      "Epoch 8, Loss: 0.03626423701643944\n",
      "Epoch 6, Loss: 0.054058246314525604\n",
      "Epoch 9, Loss: 0.016237959265708923\n",
      "Epoch 7, Loss: 0.08529238402843475\n",
      "Epoch 5, Loss: 0.04546888917684555\n",
      "Epoch 5, Loss: 0.07413769513368607\n",
      "Epoch 5, Loss: 0.07843783497810364\n",
      "Epoch 10, Loss: 0.011109245009720325\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.00013847726866053763, num_heads=4, num_layers=3; total time=   1.1s\n",
      "Epoch 9, Loss: 0.1911035180091858\n",
      "Epoch 7, Loss: 0.09262613207101822\n",
      "Epoch 9, Loss: 0.026525042951107025\n",
      "Epoch 10, Loss: 0.021546997129917145\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.00013847726866053763, num_heads=4, num_layers=3; total time=   1.2s\n",
      "Epoch 7, Loss: 0.024177301675081253\n",
      "Epoch 8, Loss: 0.06348538398742676\n",
      "Epoch 6, Loss: 0.013126463629305363\n",
      "Epoch 10, Loss: 0.028976595029234886\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.00013847726866053763, num_heads=4, num_layers=3; total time=   1.2s\n",
      "Epoch 10, Loss: 0.16534143686294556\n",
      "Epoch 8, Loss: 0.06971699744462967\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.00013847726866053763, num_heads=4, num_layers=3; total time=   1.2s\n",
      "Epoch 6, Loss: 0.10641558468341827\n",
      "Epoch 6, Loss: 0.03721792623400688\n",
      "Epoch 6, Loss: 0.12538832426071167\n",
      "Epoch 9, Loss: 0.037724532186985016\n",
      "Epoch 8, Loss: 0.015132260508835316\n",
      "Epoch 7, Loss: 0.008193755522370338\n",
      "Epoch 9, Loss: 0.10297638177871704\n",
      "Epoch 7, Loss: 0.03818543627858162\n",
      "Epoch 7, Loss: 0.15049433708190918\n",
      "Epoch 10, Loss: 0.017440691590309143\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.00013847726866053763, num_heads=4, num_layers=3; total time=   1.3s\n",
      "Epoch 9, Loss: 0.024646224454045296\n",
      "Epoch 7, Loss: 0.09768447279930115\n",
      "Epoch 10, Loss: 0.16235986351966858\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.00013847726866053763, num_heads=4, num_layers=3; total time=   1.3s\n",
      "Epoch 8, Loss: 0.011043914593756199\n",
      "Epoch 8, Loss: 0.03628190979361534\n",
      "Epoch 8, Loss: 0.14179617166519165\n",
      "Epoch 10, Loss: 0.03723965957760811\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.00013847726866053763, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.013491787947714329\n",
      "Epoch 8, Loss: 0.06847191601991653\n",
      "Epoch 9, Loss: 0.028923312202095985\n",
      "Epoch 9, Loss: 0.11130916327238083\n",
      "Epoch 10, Loss: 0.01105553936213255\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.00013847726866053763, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.01879284717142582\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.00013847726866053763, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 9, Loss: 0.0355873741209507\n",
      "Epoch 10, Loss: 0.07317176461219788\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.00013847726866053763, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.014068719930946827\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.00013847726866053763, num_heads=4, num_layers=3; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.09008095413446426\n",
      "Epoch 1, Loss: 2.241933584213257\n",
      "Epoch 2, Loss: 0.6583633422851562\n",
      "Epoch 1, Loss: 0.11349661648273468\n",
      "Epoch 1, Loss: 1.3027864694595337\n",
      "Epoch 1, Loss: 0.7419024109840393\n",
      "Epoch 2, Loss: 0.5872234106063843\n",
      "Epoch 1, Loss: 0.5834540128707886\n",
      "Epoch 1, Loss: 0.10173091292381287\n",
      "Epoch 2, Loss: 0.6775462627410889\n",
      "Epoch 3, Loss: 0.8368552923202515\n",
      "Epoch 3, Loss: 0.10785628855228424\n",
      "Epoch 2, Loss: 1.3644226789474487\n",
      "Epoch 1, Loss: 0.7542120814323425\n",
      "Epoch 2, Loss: 2.3042590618133545\n",
      "Epoch 1, Loss: 1.0802465677261353\n",
      "Epoch 2, Loss: 1.7887325286865234\n",
      "Epoch 2, Loss: 2.4907524585723877\n",
      "Epoch 3, Loss: 0.7672417759895325\n",
      "Epoch 4, Loss: 0.35371133685112\n",
      "Epoch 4, Loss: 0.34110575914382935\n",
      "Epoch 3, Loss: 0.6631532907485962\n",
      "Epoch 3, Loss: 0.4082258939743042\n",
      "Epoch 2, Loss: 1.7345285415649414\n",
      "Epoch 4, Loss: 0.26743581891059875\n",
      "Epoch 5, Loss: 0.08228417485952377\n",
      "Epoch 2, Loss: 1.1686949729919434\n",
      "Epoch 3, Loss: 0.5924001336097717\n",
      "Epoch 5, Loss: 0.11360681056976318\n",
      "Epoch 3, Loss: 0.4387202560901642\n",
      "Epoch 4, Loss: 0.12307693809270859\n",
      "Epoch 1, Loss: 0.2633665204048157\n",
      "Epoch 4, Loss: 0.07472136616706848\n",
      "Epoch 5, Loss: 0.03241562470793724\n",
      "Epoch 6, Loss: 0.07909214496612549\n",
      "Epoch 3, Loss: 0.8401538729667664\n",
      "Epoch 1, Loss: 1.0844669342041016\n",
      "Epoch 6, Loss: 0.009157093241810799\n",
      "Epoch 1, Loss: 1.1665534973144531\n",
      "Epoch 4, Loss: 0.02501414529979229\n",
      "Epoch 6, Loss: 0.0903700739145279\n",
      "Epoch 3, Loss: 0.705069363117218\n",
      "Epoch 5, Loss: 0.1280980110168457\n",
      "Epoch 4, Loss: 0.1050272062420845\n",
      "Epoch 7, Loss: 0.07654760032892227\n",
      "Epoch 5, Loss: 0.5875027179718018\n",
      "Epoch 7, Loss: 0.16515053808689117\n",
      "Epoch 2, Loss: 1.596214771270752\n",
      "Epoch 4, Loss: 0.1165296882390976\n",
      "Epoch 2, Loss: 0.819451630115509\n",
      "Epoch 8, Loss: 0.13158759474754333\n",
      "Epoch 5, Loss: 0.25415128469467163\n",
      "Epoch 7, Loss: 0.20650050044059753\n",
      "Epoch 6, Loss: 0.3133218586444855\n",
      "Epoch 2, Loss: 0.6829013824462891\n",
      "Epoch 5, Loss: 0.5501411557197571\n",
      "Epoch 4, Loss: 0.12375201284885406\n",
      "Epoch 8, Loss: 0.2045585811138153\n",
      "Epoch 3, Loss: 0.4464450180530548\n",
      "Epoch 9, Loss: 0.10552854835987091\n",
      "Epoch 8, Loss: 0.2291933298110962\n",
      "Epoch 6, Loss: 0.5165481567382812\n",
      "Epoch 6, Loss: 0.4380943179130554\n",
      "Epoch 5, Loss: 0.126022607088089\n",
      "Epoch 7, Loss: 0.3258619010448456\n",
      "Epoch 3, Loss: 0.6760987639427185\n",
      "Epoch 9, Loss: 0.1762063056230545\n",
      "Epoch 3, Loss: 0.593163251876831\n",
      "Epoch 6, Loss: 0.5189513564109802\n",
      "Epoch 10, Loss: 0.04937799274921417\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.11811368131275798, feed_forward_dim=256, head_dim=32, lr=0.0012147829999088595, num_heads=4, num_layers=3; total time=   1.2s\n",
      "Epoch 9, Loss: 0.1643368899822235\n",
      "Epoch 5, Loss: 0.06454231590032578\n",
      "Epoch 8, Loss: 0.21236853301525116\n",
      "Epoch 7, Loss: 0.23433661460876465\n",
      "Epoch 4, Loss: 0.02199299819767475\n",
      "Epoch 7, Loss: 0.3560149371623993\n",
      "Epoch 6, Loss: 0.339715838432312\n",
      "Epoch 10, Loss: 0.11706169694662094\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.11811368131275798, feed_forward_dim=256, head_dim=32, lr=0.0012147829999088595, num_heads=4, num_layers=3; total time=   1.3s\n",
      "Epoch 4, Loss: 0.17737537622451782\n",
      "Epoch 9, Loss: 0.08857174962759018\n",
      "Epoch 4, Loss: 0.13672387599945068\n",
      "Epoch 7, Loss: 0.25700828433036804\n",
      "Epoch 10, Loss: 0.07698822021484375\n",
      "Epoch 6, Loss: 0.22896936535835266\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.11811368131275798, feed_forward_dim=256, head_dim=32, lr=0.0012147829999088595, num_heads=4, num_layers=3; total time=   1.3s\n",
      "Epoch 8, Loss: 0.052010852843523026\n",
      "Epoch 8, Loss: 0.17266662418842316\n",
      "Epoch 10, Loss: 0.03369377925992012\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.11811368131275798, feed_forward_dim=256, head_dim=32, lr=0.0012147829999088595, num_heads=4, num_layers=3; total time=   1.3s\n",
      "Epoch 7, Loss: 0.368820458650589\n",
      "Epoch 5, Loss: 0.21421967446804047\n",
      "Epoch 8, Loss: 0.06665157526731491\n",
      "Epoch 5, Loss: 0.04347807168960571\n",
      "Epoch 5, Loss: 0.04204796627163887\n",
      "Epoch 9, Loss: 0.044011883437633514\n",
      "Epoch 9, Loss: 0.030072031542658806\n",
      "Epoch 7, Loss: 0.2772426903247833\n",
      "Epoch 8, Loss: 0.24027091264724731\n",
      "Epoch 9, Loss: 0.028385233134031296\n",
      "Epoch 6, Loss: 0.3397875428199768\n",
      "Epoch 10, Loss: 0.09799329936504364\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.11811368131275798, feed_forward_dim=256, head_dim=32, lr=0.0012147829999088595, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.02530660107731819\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.11811368131275798, feed_forward_dim=256, head_dim=32, lr=0.0012147829999088595, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 6, Loss: 0.17557640373706818\n",
      "Epoch 6, Loss: 0.16624222695827484\n",
      "Epoch 10, Loss: 0.08805935084819794\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.11811368131275798, feed_forward_dim=256, head_dim=32, lr=0.0012147829999088595, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 8, Loss: 0.1880657821893692\n",
      "Epoch 7, Loss: 0.24698300659656525\n",
      "Epoch 9, Loss: 0.09893738478422165\n",
      "Epoch 7, Loss: 0.24184256792068481\n",
      "Epoch 9, Loss: 0.0760810524225235\n",
      "Epoch 7, Loss: 0.2560308873653412\n",
      "Epoch 10, Loss: 0.039875153452157974\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.11811368131275798, feed_forward_dim=256, head_dim=32, lr=0.0012147829999088595, num_heads=4, num_layers=3; total time=   1.6s\n",
      "Epoch 8, Loss: 0.10711677372455597\n",
      "Epoch 10, Loss: 0.022074157372117043\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.11811368131275798, feed_forward_dim=256, head_dim=32, lr=0.0012147829999088595, num_heads=4, num_layers=3; total time=   1.6s\n",
      "Epoch 8, Loss: 0.1904418021440506\n",
      "Epoch 9, Loss: 0.03212584927678108\n",
      "Epoch 8, Loss: 0.21970655024051666\n",
      "Epoch 10, Loss: 0.041222795844078064\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.11811368131275798, feed_forward_dim=256, head_dim=32, lr=0.0012147829999088595, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 9, Loss: 0.12674613296985626\n",
      "Epoch 9, Loss: 0.09672215580940247\n",
      "Epoch 10, Loss: 0.05060865357518196\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.11811368131275798, feed_forward_dim=256, head_dim=32, lr=0.0012147829999088595, num_heads=4, num_layers=3; total time=   1.6s\n",
      "Epoch 10, Loss: 0.03412972390651703\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.11811368131275798, feed_forward_dim=256, head_dim=32, lr=0.0012147829999088595, num_heads=4, num_layers=3; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.16893437504768372\n",
      "Epoch 1, Loss: 0.18781085312366486\n",
      "Epoch 2, Loss: 0.07149241864681244\n",
      "Epoch 1, Loss: 0.3405211269855499\n",
      "Epoch 1, Loss: 1.2572083473205566\n",
      "Epoch 2, Loss: 0.09404256939888\n",
      "Epoch 1, Loss: 0.34287720918655396\n",
      "Epoch 3, Loss: 0.044297266751527786\n",
      "Epoch 1, Loss: 0.06939058005809784\n",
      "Epoch 1, Loss: 0.2115814983844757\n",
      "Epoch 2, Loss: 0.19148999452590942\n",
      "Epoch 1, Loss: 2.660396099090576\n",
      "Epoch 3, Loss: 0.08856800943613052\n",
      "Epoch 2, Loss: 0.8575714230537415\n",
      "Epoch 4, Loss: 0.05581660196185112\n",
      "Epoch 2, Loss: 0.1566891223192215\n",
      "Epoch 1, Loss: 0.14245720207691193\n",
      "Epoch 1, Loss: 0.10699564963579178\n",
      "Epoch 3, Loss: 0.11517231166362762\n",
      "Epoch 5, Loss: 0.07147619873285294\n",
      "Epoch 1, Loss: 0.17085811495780945\n",
      "Epoch 2, Loss: 0.06977171450853348\n",
      "Epoch 3, Loss: 0.5500897169113159\n",
      "Epoch 4, Loss: 0.09593372046947479\n",
      "Epoch 2, Loss: 0.06930925697088242\n",
      "Epoch 2, Loss: 1.9816479682922363\n",
      "Epoch 4, Loss: 0.09930035471916199\n",
      "Epoch 1, Loss: 0.7528508305549622\n",
      "Epoch 3, Loss: 0.0701606497168541\n",
      "Epoch 6, Loss: 0.07144680619239807\n",
      "Epoch 2, Loss: 0.06849727779626846\n",
      "Epoch 4, Loss: 0.3085131347179413\n",
      "Epoch 5, Loss: 0.08368925750255585\n",
      "Epoch 2, Loss: 0.08678466081619263\n",
      "Epoch 3, Loss: 0.04642486944794655\n",
      "Epoch 5, Loss: 0.11328375339508057\n",
      "Epoch 2, Loss: 0.06261471658945084\n",
      "Epoch 3, Loss: 0.02989227883517742\n",
      "Epoch 7, Loss: 0.05685058981180191\n",
      "Epoch 4, Loss: 0.06900055706501007\n",
      "Epoch 3, Loss: 1.4059408903121948\n",
      "Epoch 2, Loss: 0.4334867000579834\n",
      "Epoch 6, Loss: 0.058175522834062576\n",
      "Epoch 5, Loss: 0.14608269929885864\n",
      "Epoch 3, Loss: 0.06487283110618591\n",
      "Epoch 6, Loss: 0.12606827914714813\n",
      "Epoch 4, Loss: 0.03460213541984558\n",
      "Epoch 8, Loss: 0.04060842841863632\n",
      "Epoch 4, Loss: 0.9314447045326233\n",
      "Epoch 5, Loss: 0.10399150848388672\n",
      "Epoch 3, Loss: 0.052106887102127075\n",
      "Epoch 4, Loss: 0.0588587261736393\n",
      "Epoch 3, Loss: 0.06452324986457825\n",
      "Epoch 6, Loss: 0.05917423963546753\n",
      "Epoch 9, Loss: 0.025326509028673172\n",
      "Epoch 7, Loss: 0.12098683416843414\n",
      "Epoch 7, Loss: 0.03694697842001915\n",
      "Epoch 3, Loss: 0.20921722054481506\n",
      "Epoch 5, Loss: 0.032220374792814255\n",
      "Epoch 4, Loss: 0.07670767605304718\n",
      "Epoch 5, Loss: 0.5649752020835876\n",
      "Epoch 6, Loss: 0.12543605268001556\n",
      "Epoch 8, Loss: 0.10492543131113052\n",
      "Epoch 8, Loss: 0.02733513154089451\n",
      "Epoch 4, Loss: 0.05204937979578972\n",
      "Epoch 7, Loss: 0.032608598470687866\n",
      "Epoch 10, Loss: 0.02053840644657612\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.00013123930152861293, num_heads=4, num_layers=2; total time=   1.0s\n",
      "Epoch 5, Loss: 0.08464125543832779\n",
      "Epoch 4, Loss: 0.07849760353565216\n",
      "Epoch 6, Loss: 0.02483893558382988\n",
      "Epoch 9, Loss: 0.029412057250738144\n",
      "Epoch 9, Loss: 0.08087445795536041\n",
      "Epoch 6, Loss: 0.29926827549934387\n",
      "Epoch 7, Loss: 0.1229841336607933\n",
      "Epoch 5, Loss: 0.06696052104234695\n",
      "Epoch 5, Loss: 0.03859100118279457\n",
      "Epoch 6, Loss: 0.08103837072849274\n",
      "Epoch 5, Loss: 0.08278147876262665\n",
      "Epoch 8, Loss: 0.048843249678611755\n",
      "Epoch 4, Loss: 0.08492453396320343\n",
      "Epoch 7, Loss: 0.015825027599930763\n",
      "Epoch 10, Loss: 0.032796137034893036\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.00013123930152861293, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 10, Loss: 0.05886948108673096\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.00013123930152861293, num_heads=4, num_layers=2; total time=   1.1s\n",
      "Epoch 8, Loss: 0.09907381981611252\n",
      "Epoch 7, Loss: 0.13079500198364258\n",
      "Epoch 9, Loss: 0.09125161170959473\n",
      "Epoch 7, Loss: 0.054648466408252716\n",
      "Epoch 8, Loss: 0.012112169526517391\n",
      "Epoch 6, Loss: 0.06065049394965172\n",
      "Epoch 6, Loss: 0.04465796798467636\n",
      "Epoch 6, Loss: 0.028191884979605675\n",
      "Epoch 9, Loss: 0.06914312392473221\n",
      "Epoch 10, Loss: 0.13533508777618408\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.00013123930152861293, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 8, Loss: 0.04330669343471527\n",
      "Epoch 5, Loss: 0.04251573607325554\n",
      "Epoch 8, Loss: 0.030489550903439522\n",
      "Epoch 9, Loss: 0.011142618022859097\n",
      "Epoch 7, Loss: 0.029064856469631195\n",
      "Epoch 10, Loss: 0.04587073624134064\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.00013123930152861293, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 7, Loss: 0.0379914864897728\n",
      "Epoch 7, Loss: 0.020993903279304504\n",
      "Epoch 9, Loss: 0.02255149371922016\n",
      "Epoch 9, Loss: 0.01798049733042717\n",
      "Epoch 6, Loss: 0.05611267313361168\n",
      "Epoch 10, Loss: 0.009876488707959652\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.00013123930152861293, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 8, Loss: 0.021662311628460884\n",
      "Epoch 8, Loss: 0.015871388837695122\n",
      "Epoch 8, Loss: 0.02404876798391342\n",
      "Epoch 10, Loss: 0.04893946647644043\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.00013123930152861293, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 10, Loss: 0.018275117501616478\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.00013123930152861293, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 7, Loss: 0.09677208960056305\n",
      "Epoch 9, Loss: 0.02325163222849369\n",
      "Epoch 9, Loss: 0.011244208551943302\n",
      "Epoch 9, Loss: 0.024231722578406334\n",
      "Epoch 8, Loss: 0.1350075602531433\n",
      "Epoch 10, Loss: 0.026256566867232323\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.00013123930152861293, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.009104565717279911\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.00013123930152861293, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.030066076666116714\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.00013123930152861293, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 9, Loss: 0.15529446303844452\n",
      "Epoch 10, Loss: 0.15275782346725464\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=0.00013123930152861293, num_heads=4, num_layers=2; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 2.988740921020508\n",
      "Epoch 1, Loss: 0.6551485657691956\n",
      "Epoch 2, Loss: 2.2896363735198975\n",
      "Epoch 1, Loss: 2.067030191421509\n",
      "Epoch 1, Loss: 0.5694672465324402\n",
      "Epoch 1, Loss: 0.037190962582826614\n",
      "Epoch 3, Loss: 1.6675022840499878\n",
      "Epoch 1, Loss: 0.09179804474115372\n",
      "Epoch 2, Loss: 0.4227955937385559\n",
      "Epoch 1, Loss: 0.08083323389291763\n",
      "Epoch 1, Loss: 0.07568272948265076\n",
      "Epoch 1, Loss: 0.3611709475517273\n",
      "Epoch 2, Loss: 0.2942744493484497\n",
      "Epoch 1, Loss: 0.5973891019821167\n",
      "Epoch 4, Loss: 1.168454647064209\n",
      "Epoch 2, Loss: 1.5098422765731812\n",
      "Epoch 2, Loss: 0.038963835686445236\n",
      "Epoch 3, Loss: 0.25905516743659973\n",
      "Epoch 2, Loss: 0.04822106286883354\n",
      "Epoch 3, Loss: 1.0356507301330566\n",
      "Epoch 1, Loss: 1.1959460973739624\n",
      "Epoch 3, Loss: 0.1412511169910431\n",
      "Epoch 5, Loss: 0.7778107523918152\n",
      "Epoch 1, Loss: 0.19609928131103516\n",
      "Epoch 4, Loss: 0.1657290756702423\n",
      "Epoch 2, Loss: 0.061736393719911575\n",
      "Epoch 2, Loss: 0.0481155663728714\n",
      "Epoch 2, Loss: 0.19385775923728943\n",
      "Epoch 2, Loss: 0.3365870714187622\n",
      "Epoch 3, Loss: 0.03072972223162651\n",
      "Epoch 4, Loss: 0.6564295291900635\n",
      "Epoch 4, Loss: 0.09043261408805847\n",
      "Epoch 6, Loss: 0.48271942138671875\n",
      "Epoch 5, Loss: 0.1342875212430954\n",
      "Epoch 2, Loss: 0.7770923972129822\n",
      "Epoch 3, Loss: 0.059018366038799286\n",
      "Epoch 4, Loss: 0.021404262632131577\n",
      "Epoch 3, Loss: 0.05500683933496475\n",
      "Epoch 2, Loss: 0.06733501702547073\n",
      "Epoch 3, Loss: 0.044058915227651596\n",
      "Epoch 3, Loss: 0.11594830453395844\n",
      "Epoch 7, Loss: 0.2907690107822418\n",
      "Epoch 5, Loss: 0.379177987575531\n",
      "Epoch 5, Loss: 0.10877028107643127\n",
      "Epoch 6, Loss: 0.13794764876365662\n",
      "Epoch 4, Loss: 0.05374293774366379\n",
      "Epoch 3, Loss: 0.17368084192276\n",
      "Epoch 8, Loss: 0.18778784573078156\n",
      "Epoch 5, Loss: 0.024277351796627045\n",
      "Epoch 6, Loss: 0.19283239543437958\n",
      "Epoch 3, Loss: 0.4531116783618927\n",
      "Epoch 6, Loss: 0.14484526216983795\n",
      "Epoch 4, Loss: 0.031636226922273636\n",
      "Epoch 3, Loss: 0.019968384876847267\n",
      "Epoch 4, Loss: 0.10925227403640747\n",
      "Epoch 4, Loss: 0.036770299077034\n",
      "Epoch 9, Loss: 0.1526593714952469\n",
      "Epoch 7, Loss: 0.1552238166332245\n",
      "Epoch 5, Loss: 0.03634900227189064\n",
      "Epoch 7, Loss: 0.09665883332490921\n",
      "Epoch 4, Loss: 0.10586682707071304\n",
      "Epoch 6, Loss: 0.02183755487203598\n",
      "Epoch 7, Loss: 0.1616055816411972\n",
      "Epoch 5, Loss: 0.02086680941283703\n",
      "Epoch 10, Loss: 0.16390416026115417\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.0001341561914727442, num_heads=8, num_layers=2; total time=   1.0s\n",
      "Epoch 8, Loss: 0.17455555498600006\n",
      "Epoch 5, Loss: 0.022155961021780968\n",
      "Epoch 4, Loss: 0.23135529458522797\n",
      "Epoch 5, Loss: 0.13274720311164856\n",
      "Epoch 8, Loss: 0.06750869005918503\n",
      "Epoch 4, Loss: 0.029274607077240944\n",
      "Epoch 6, Loss: 0.023590559139847755\n",
      "Epoch 7, Loss: 0.01777316816151142\n",
      "Epoch 6, Loss: 0.012746685184538364\n",
      "Epoch 8, Loss: 0.1523328572511673\n",
      "Epoch 9, Loss: 0.1737777590751648\n",
      "Epoch 5, Loss: 0.10376852005720139\n",
      "Epoch 6, Loss: 0.020308762788772583\n",
      "Epoch 9, Loss: 0.09061697870492935\n",
      "Epoch 10, Loss: 0.16031122207641602\n",
      "Epoch 6, Loss: 0.15214349329471588\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.0001341561914727442, num_heads=8, num_layers=2; total time=   1.2s\n",
      "Epoch 7, Loss: 0.008023529313504696\n",
      "Epoch 5, Loss: 0.09847113490104675\n",
      "Epoch 7, Loss: 0.021420719102025032\n",
      "Epoch 8, Loss: 0.014789712615311146\n",
      "Epoch 9, Loss: 0.12514138221740723\n",
      "Epoch 5, Loss: 0.05299665778875351\n",
      "Epoch 10, Loss: 0.13994300365447998\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.0001341561914727442, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 6, Loss: 0.13240885734558105\n",
      "Epoch 7, Loss: 0.02225523442029953\n",
      "Epoch 8, Loss: 0.005705927964299917\n",
      "Epoch 7, Loss: 0.1458938866853714\n",
      "Epoch 10, Loss: 0.08617318421602249\n",
      "Epoch 6, Loss: 0.04400438815355301\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.0001341561914727442, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 9, Loss: 0.016726378351449966\n",
      "Epoch 8, Loss: 0.024537257850170135\n",
      "Epoch 6, Loss: 0.062352586537599564\n",
      "Epoch 9, Loss: 0.004599247593432665\n",
      "Epoch 8, Loss: 0.017825813964009285\n",
      "Epoch 8, Loss: 0.12504149973392487\n",
      "Epoch 10, Loss: 0.019045831635594368\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.0001341561914727442, num_heads=8, num_layers=2; total time=   1.4s\n",
      "Epoch 7, Loss: 0.16182711720466614\n",
      "Epoch 9, Loss: 0.02195301093161106\n",
      "Epoch 10, Loss: 0.00523882731795311\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.0001341561914727442, num_heads=8, num_layers=2; total time=   1.4s\n",
      "Epoch 7, Loss: 0.04795069247484207\n",
      "Epoch 9, Loss: 0.010022359900176525\n",
      "Epoch 9, Loss: 0.09886722266674042\n",
      "Epoch 8, Loss: 0.17270363867282867\n",
      "Epoch 7, Loss: 0.052371084690093994\n",
      "Epoch 10, Loss: 0.016189852729439735\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.0001341561914727442, num_heads=8, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.007823871448636055\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.0001341561914727442, num_heads=8, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.07623398303985596\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.0001341561914727442, num_heads=8, num_layers=2; total time=   1.5s\n",
      "Epoch 8, Loss: 0.08566600829362869\n",
      "Epoch 9, Loss: 0.16275346279144287\n",
      "Epoch 8, Loss: 0.032590217888355255\n",
      "Epoch 9, Loss: 0.13523483276367188\n",
      "Epoch 10, Loss: 0.13951298594474792\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.0001341561914727442, num_heads=8, num_layers=2; total time=   1.7s\n",
      "Epoch 10, Loss: 0.17086143791675568\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.0001341561914727442, num_heads=8, num_layers=2; total time=   1.6s\n",
      "Epoch 9, Loss: 0.01473306119441986\n",
      "Epoch 10, Loss: 0.004966398701071739\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.0001341561914727442, num_heads=8, num_layers=2; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 4.185734272003174\n",
      "Epoch 1, Loss: 0.8583325743675232\n",
      "Epoch 1, Loss: 1.214573621749878\n",
      "Epoch 1, Loss: 1.5084819793701172\n",
      "Epoch 1, Loss: 1.3934893608093262\n",
      "Epoch 2, Loss: 0.24519291520118713\n",
      "Epoch 1, Loss: 0.49787119030952454\n",
      "Epoch 1, Loss: 0.05636516585946083\n",
      "Epoch 1, Loss: 0.37551140785217285\n",
      "Epoch 2, Loss: 1.7969281673431396\n",
      "Epoch 1, Loss: 0.023861736059188843\n",
      "Epoch 3, Loss: 1.1953994035720825\n",
      "Epoch 2, Loss: 1.090090036392212\n",
      "Epoch 2, Loss: 1.03511381149292\n",
      "Epoch 2, Loss: 1.7734613418579102\n",
      "Epoch 1, Loss: 0.13587649166584015\n",
      "Epoch 2, Loss: 2.5721940994262695\n",
      "Epoch 3, Loss: 0.8360844850540161\n",
      "Epoch 3, Loss: 0.8180148005485535\n",
      "Epoch 1, Loss: 0.33915308117866516\n",
      "Epoch 2, Loss: 0.9312797784805298\n",
      "Epoch 4, Loss: 0.8026981353759766\n",
      "Epoch 2, Loss: 1.8492169380187988\n",
      "Epoch 3, Loss: 1.0392649173736572\n",
      "Epoch 1, Loss: 0.8456259369850159\n",
      "Epoch 2, Loss: 3.3153293132781982\n",
      "Epoch 3, Loss: 0.8605154156684875\n",
      "Epoch 4, Loss: 0.20539183914661407\n",
      "Epoch 4, Loss: 0.09603428840637207\n",
      "Epoch 2, Loss: 3.195687770843506\n",
      "Epoch 5, Loss: 0.24945420026779175\n",
      "Epoch 3, Loss: 0.01745789498090744\n",
      "Epoch 4, Loss: 0.17019560933113098\n",
      "Epoch 2, Loss: 2.6040923595428467\n",
      "Epoch 3, Loss: 0.489074170589447\n",
      "Epoch 5, Loss: 0.1762823909521103\n",
      "Epoch 6, Loss: 0.04616279527544975\n",
      "Epoch 5, Loss: 0.06604038178920746\n",
      "Epoch 2, Loss: 2.864773988723755\n",
      "Epoch 4, Loss: 0.23992209136486053\n",
      "Epoch 3, Loss: 0.4167257845401764\n",
      "Epoch 3, Loss: 0.4730958044528961\n",
      "Epoch 4, Loss: 0.8609689474105835\n",
      "Epoch 5, Loss: 0.08683878928422928\n",
      "Epoch 3, Loss: 0.595066249370575\n",
      "Epoch 6, Loss: 0.38767704367637634\n",
      "Epoch 4, Loss: 0.08752606809139252\n",
      "Epoch 3, Loss: 0.7890139222145081\n",
      "Epoch 5, Loss: 0.04351591318845749\n",
      "Epoch 7, Loss: 0.11888639628887177\n",
      "Epoch 6, Loss: 0.22283786535263062\n",
      "Epoch 3, Loss: 0.9479117393493652\n",
      "Epoch 4, Loss: 0.03663884475827217\n",
      "Epoch 6, Loss: 0.313326358795166\n",
      "Epoch 7, Loss: 0.36000412702560425\n",
      "Epoch 4, Loss: 0.16751016676425934\n",
      "Epoch 4, Loss: 0.24732454121112823\n",
      "Epoch 5, Loss: 0.7863149046897888\n",
      "Epoch 7, Loss: 0.3172447681427002\n",
      "Epoch 8, Loss: 0.24922491610050201\n",
      "Epoch 8, Loss: 0.1965930461883545\n",
      "Epoch 6, Loss: 0.16173259913921356\n",
      "Epoch 7, Loss: 0.39353951811790466\n",
      "Epoch 5, Loss: 0.2889808416366577\n",
      "Epoch 5, Loss: 0.08284159004688263\n",
      "Epoch 4, Loss: 0.024815671145915985\n",
      "Epoch 4, Loss: 0.060321737080812454\n",
      "Epoch 9, Loss: 0.2961539626121521\n",
      "Epoch 9, Loss: 0.06179485097527504\n",
      "Epoch 8, Loss: 0.25849097967147827\n",
      "Epoch 8, Loss: 0.2840433418750763\n",
      "Epoch 7, Loss: 0.2809637188911438\n",
      "Epoch 6, Loss: 0.3082258105278015\n",
      "Epoch 5, Loss: 0.8227542042732239\n",
      "Epoch 6, Loss: 0.3723635673522949\n",
      "Epoch 10, Loss: 0.24725352227687836\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.319173844205769, feed_forward_dim=1024, head_dim=8, lr=0.0012495365072118468, num_heads=4, num_layers=3; total time=   1.0s\n",
      "Epoch 5, Loss: 0.7727692127227783\n",
      "Epoch 6, Loss: 0.2027290165424347\n",
      "Epoch 9, Loss: 0.1403408944606781\n",
      "Epoch 10, Loss: 0.03240581229329109\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.319173844205769, feed_forward_dim=1024, head_dim=8, lr=0.0012495365072118468, num_heads=4, num_layers=3; total time=   1.1s\n",
      "Epoch 9, Loss: 0.11937723308801651\n",
      "Epoch 8, Loss: 0.27200937271118164\n",
      "Epoch 5, Loss: 0.29948949813842773\n",
      "Epoch 7, Loss: 0.0400252528488636\n",
      "Epoch 5, Loss: 0.37566906213760376\n",
      "Epoch 10, Loss: 0.05684942007064819\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.319173844205769, feed_forward_dim=1024, head_dim=8, lr=0.0012495365072118468, num_heads=4, num_layers=3; total time=   1.1s\n",
      "Epoch 7, Loss: 0.22755298018455505\n",
      "Epoch 7, Loss: 0.2333390712738037\n",
      "Epoch 6, Loss: 0.6618527770042419\n",
      "Epoch 10, Loss: 0.032257914543151855\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.319173844205769, feed_forward_dim=1024, head_dim=8, lr=0.0012495365072118468, num_heads=4, num_layers=3; total time=   1.2s\n",
      "Epoch 6, Loss: 0.682280957698822\n",
      "Epoch 8, Loss: 0.04935265704989433\n",
      "Epoch 9, Loss: 0.17594845592975616\n",
      "Epoch 6, Loss: 0.5249176621437073\n",
      "Epoch 8, Loss: 0.15967963635921478\n",
      "Epoch 6, Loss: 0.5822438597679138\n",
      "Epoch 8, Loss: 0.07406896352767944\n",
      "Epoch 9, Loss: 0.16788454353809357\n",
      "Epoch 7, Loss: 0.2898256182670593\n",
      "Epoch 7, Loss: 0.3169979155063629\n",
      "Epoch 10, Loss: 0.08088003098964691\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.319173844205769, feed_forward_dim=1024, head_dim=8, lr=0.0012495365072118468, num_heads=4, num_layers=3; total time=   1.3s\n",
      "Epoch 7, Loss: 0.4253722131252289\n",
      "Epoch 9, Loss: 0.07966941595077515\n",
      "Epoch 10, Loss: 0.24945983290672302\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.319173844205769, feed_forward_dim=1024, head_dim=8, lr=0.0012495365072118468, num_heads=4, num_layers=3; total time=   1.3s\n",
      "Epoch 9, Loss: 0.021428938955068588\n",
      "Epoch 7, Loss: 0.42769160866737366\n",
      "Epoch 8, Loss: 0.06507553905248642\n",
      "Epoch 8, Loss: 0.08018980175256729\n",
      "Epoch 10, Loss: 0.035864345729351044\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.319173844205769, feed_forward_dim=1024, head_dim=8, lr=0.0012495365072118468, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Epoch 8, Loss: 0.19821015000343323\n",
      "Epoch 10, Loss: 0.07407863438129425\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.319173844205769, feed_forward_dim=1024, head_dim=8, lr=0.0012495365072118468, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.04526996240019798\n",
      "Epoch 8, Loss: 0.17968404293060303\n",
      "Epoch 9, Loss: 0.025882817804813385\n",
      "Epoch 9, Loss: 0.04461250454187393\n",
      "Epoch 10, Loss: 0.13155895471572876\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.319173844205769, feed_forward_dim=1024, head_dim=8, lr=0.0012495365072118468, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.0880330428481102\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.319173844205769, feed_forward_dim=1024, head_dim=8, lr=0.0012495365072118468, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 9, Loss: 0.0425092913210392\n",
      "Epoch 10, Loss: 0.025806263089179993\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.319173844205769, feed_forward_dim=1024, head_dim=8, lr=0.0012495365072118468, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.04453650861978531\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.319173844205769, feed_forward_dim=1024, head_dim=8, lr=0.0012495365072118468, num_heads=4, num_layers=3; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.42947643995285034\n",
      "Epoch 1, Loss: 1.5222702026367188\n",
      "Epoch 1, Loss: 0.23127105832099915\n",
      "Epoch 1, Loss: 0.15259794890880585\n",
      "Epoch 1, Loss: 0.0576188825070858\n",
      "Epoch 2, Loss: 0.23143000900745392\n",
      "Epoch 1, Loss: 0.014008993282914162\n",
      "Epoch 2, Loss: 1.0546863079071045\n",
      "Epoch 2, Loss: 0.09943028539419174\n",
      "Epoch 1, Loss: 0.24368642270565033\n",
      "Epoch 3, Loss: 0.1006879061460495\n",
      "Epoch 2, Loss: 0.04670597240328789\n",
      "Epoch 1, Loss: 2.8981776237487793\n",
      "Epoch 3, Loss: 0.6717122793197632\n",
      "Epoch 2, Loss: 0.010256814770400524\n",
      "Epoch 1, Loss: 2.8038604259490967\n",
      "Epoch 2, Loss: 0.03513680398464203\n",
      "Epoch 1, Loss: 0.039841972291469574\n",
      "Epoch 4, Loss: 0.03164798393845558\n",
      "Epoch 3, Loss: 0.05587843433022499\n",
      "Epoch 3, Loss: 0.0383431538939476\n",
      "Epoch 1, Loss: 0.30662691593170166\n",
      "Epoch 2, Loss: 0.08363981544971466\n",
      "Epoch 4, Loss: 0.38427484035491943\n",
      "Epoch 2, Loss: 2.1784839630126953\n",
      "Epoch 1, Loss: 1.4869275093078613\n",
      "Epoch 3, Loss: 0.024513091892004013\n",
      "Epoch 2, Loss: 2.0470809936523438\n",
      "Epoch 5, Loss: 0.01504320465028286\n",
      "Epoch 3, Loss: 0.011357415467500687\n",
      "Epoch 2, Loss: 0.038613155484199524\n",
      "Epoch 4, Loss: 0.06588491797447205\n",
      "Epoch 4, Loss: 0.06838908046483994\n",
      "Epoch 3, Loss: 0.024263422936201096\n",
      "Epoch 5, Loss: 0.18371102213859558\n",
      "Epoch 6, Loss: 0.03190196305513382\n",
      "Epoch 2, Loss: 0.1694491058588028\n",
      "Epoch 3, Loss: 1.5580230951309204\n",
      "Epoch 4, Loss: 0.032296210527420044\n",
      "Epoch 5, Loss: 0.07188772410154343\n",
      "Epoch 2, Loss: 0.9851651787757874\n",
      "Epoch 3, Loss: 1.4123156070709229\n",
      "Epoch 6, Loss: 0.06776122003793716\n",
      "Epoch 5, Loss: 0.09010767936706543\n",
      "Epoch 4, Loss: 0.011145664379000664\n",
      "Epoch 4, Loss: 0.04526684433221817\n",
      "Epoch 7, Loss: 0.05931081622838974\n",
      "Epoch 3, Loss: 0.027184078469872475\n",
      "Epoch 5, Loss: 0.023022696375846863\n",
      "Epoch 8, Loss: 0.08206100016832352\n",
      "Epoch 6, Loss: 0.09122248739004135\n",
      "Epoch 6, Loss: 0.05256544053554535\n",
      "Epoch 7, Loss: 0.028875771909952164\n",
      "Epoch 4, Loss: 1.0360386371612549\n",
      "Epoch 5, Loss: 0.021773971617221832\n",
      "Epoch 3, Loss: 0.5904127359390259\n",
      "Epoch 3, Loss: 0.10924376547336578\n",
      "Epoch 4, Loss: 0.9094250202178955\n",
      "Epoch 5, Loss: 0.0779556855559349\n",
      "Epoch 8, Loss: 0.04731687530875206\n",
      "Epoch 6, Loss: 0.009659353643655777\n",
      "Epoch 9, Loss: 0.09325573593378067\n",
      "Epoch 7, Loss: 0.07093854993581772\n",
      "Epoch 7, Loss: 0.029702262952923775\n",
      "Epoch 4, Loss: 0.016103103756904602\n",
      "Epoch 5, Loss: 0.6420304179191589\n",
      "Epoch 6, Loss: 0.015110229142010212\n",
      "Epoch 9, Loss: 0.09891355782747269\n",
      "Epoch 10, Loss: 0.085553377866745\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13615368997251726, feed_forward_dim=1024, head_dim=32, lr=0.00013082234118212257, num_heads=8, num_layers=3; total time=   1.1s\n",
      "Epoch 8, Loss: 0.017474181950092316\n",
      "Epoch 4, Loss: 0.11101438850164413\n",
      "Epoch 4, Loss: 0.31317147612571716\n",
      "Epoch 6, Loss: 0.0897587463259697\n",
      "Epoch 8, Loss: 0.048725925385951996\n",
      "Epoch 7, Loss: 0.006142075639218092\n",
      "Epoch 5, Loss: 0.5243625640869141\n",
      "Epoch 5, Loss: 0.016367238014936447\n",
      "Epoch 7, Loss: 0.007966066710650921\n",
      "Epoch 10, Loss: 0.1611243039369583\n",
      "Epoch 6, Loss: 0.35702162981033325\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13615368997251726, feed_forward_dim=1024, head_dim=32, lr=0.00013082234118212257, num_heads=8, num_layers=3; total time=   1.2s\n",
      "Epoch 9, Loss: 0.016774585470557213\n",
      "Epoch 5, Loss: 0.12704043090343475\n",
      "Epoch 8, Loss: 0.011141468770802021\n",
      "Epoch 9, Loss: 0.029599877074360847Epoch 5, Loss: 0.1470986008644104\n",
      "\n",
      "Epoch 6, Loss: 0.2583157420158386\n",
      "Epoch 8, Loss: 0.00876423716545105\n",
      "Epoch 10, Loss: 0.02489645592868328\n",
      "Epoch 7, Loss: 0.07512928545475006\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13615368997251726, feed_forward_dim=1024, head_dim=32, lr=0.00013082234118212257, num_heads=8, num_layers=3; total time=   1.2s\n",
      "Epoch 7, Loss: 0.1854165643453598\n",
      "Epoch 6, Loss: 0.014655613340437412\n",
      "Epoch 9, Loss: 0.01690428890287876\n",
      "Epoch 10, Loss: 0.020386366173624992\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13615368997251726, feed_forward_dim=1024, head_dim=32, lr=0.00013082234118212257, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 7, Loss: 0.09569462388753891\n",
      "Epoch 9, Loss: 0.01378528494387865\n",
      "Epoch 6, Loss: 0.0817406103014946\n",
      "Epoch 8, Loss: 0.04963773116469383\n",
      "Epoch 6, Loss: 0.1286885142326355\n",
      "Epoch 7, Loss: 0.009315616451203823\n",
      "Epoch 10, Loss: 0.016006818041205406\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13615368997251726, feed_forward_dim=1024, head_dim=32, lr=0.00013082234118212257, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 8, Loss: 0.1101875752210617\n",
      "Epoch 8, Loss: 0.02335944026708603\n",
      "Epoch 10, Loss: 0.013011560775339603\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13615368997251726, feed_forward_dim=1024, head_dim=32, lr=0.00013082234118212257, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 7, Loss: 0.08912942558526993\n",
      "Epoch 7, Loss: 0.11113696545362473\n",
      "Epoch 8, Loss: 0.005947773810476065\n",
      "Epoch 9, Loss: 0.11345405131578445\n",
      "Epoch 9, Loss: 0.02799188904464245\n",
      "Epoch 9, Loss: 0.015452426858246326\n",
      "Epoch 10, Loss: 0.16123627126216888\n",
      "Epoch 8, Loss: 0.08811964094638824\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13615368997251726, feed_forward_dim=1024, head_dim=32, lr=0.00013082234118212257, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 9, Loss: 0.008392052724957466\n",
      "Epoch 8, Loss: 0.141256183385849\n",
      "Epoch 10, Loss: 0.01644236594438553\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13615368997251726, feed_forward_dim=1024, head_dim=32, lr=0.00013082234118212257, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.0524018369615078\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13615368997251726, feed_forward_dim=1024, head_dim=32, lr=0.00013082234118212257, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 9, Loss: 0.06286625564098358\n",
      "Epoch 10, Loss: 0.009111795574426651\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13615368997251726, feed_forward_dim=1024, head_dim=32, lr=0.00013082234118212257, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 9, Loss: 0.19838133454322815\n",
      "Epoch 10, Loss: 0.047357603907585144\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13615368997251726, feed_forward_dim=1024, head_dim=32, lr=0.00013082234118212257, num_heads=8, num_layers=3; total time=   1.6s\n",
      "Epoch 10, Loss: 0.24175263941287994\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13615368997251726, feed_forward_dim=1024, head_dim=32, lr=0.00013082234118212257, num_heads=8, num_layers=3; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.3452930152416229\n",
      "Epoch 1, Loss: 1.4881786108016968\n",
      "Epoch 1, Loss: 1.1059402227401733\n",
      "Epoch 1, Loss: 0.23653213679790497\n",
      "Epoch 1, Loss: 0.32008814811706543\n",
      "Epoch 2, Loss: 0.12795855104923248\n",
      "Epoch 2, Loss: 0.28623875975608826\n",
      "Epoch 1, Loss: 0.11943967640399933\n",
      "Epoch 2, Loss: 0.11381196230649948\n",
      "Epoch 2, Loss: 0.2559007406234741\n",
      "Epoch 1, Loss: 0.1584901064634323\n",
      "Epoch 3, Loss: 0.2656717598438263\n",
      "Epoch 3, Loss: 0.5071688294410706\n",
      "Epoch 1, Loss: 0.16102451086044312\n",
      "Epoch 2, Loss: 0.3417823910713196\n",
      "Epoch 3, Loss: 0.6010140180587769\n",
      "Epoch 2, Loss: 0.5935992002487183\n",
      "Epoch 3, Loss: 0.17335198819637299\n",
      "Epoch 1, Loss: 0.3506883680820465\n",
      "Epoch 4, Loss: 0.4889690577983856\n",
      "Epoch 2, Loss: 0.4757227301597595\n",
      "Epoch 1, Loss: 0.8907812237739563\n",
      "Epoch 4, Loss: 0.04635600000619888\n",
      "Epoch 3, Loss: 0.2626774311065674\n",
      "Epoch 2, Loss: 0.5015481114387512\n",
      "Epoch 1, Loss: 0.5967622995376587\n",
      "Epoch 3, Loss: 0.09827300161123276\n",
      "Epoch 4, Loss: 0.6496880650520325\n",
      "Epoch 1, Loss: 0.25926631689071655\n",
      "Epoch 4, Loss: 0.022386537864804268\n",
      "Epoch 5, Loss: 0.2179240882396698\n",
      "Epoch 5, Loss: 0.03794970363378525\n",
      "Epoch 2, Loss: 0.500983715057373\n",
      "Epoch 2, Loss: 0.2384704202413559\n",
      "Epoch 4, Loss: 0.10144826024770737\n",
      "Epoch 3, Loss: 0.1540146917104721\n",
      "Epoch 5, Loss: 0.343808650970459\n",
      "Epoch 3, Loss: 0.14214490354061127\n",
      "Epoch 4, Loss: 0.0713440477848053\n",
      "Epoch 2, Loss: 0.3984964191913605\n",
      "Epoch 6, Loss: 0.1303284764289856\n",
      "Epoch 5, Loss: 0.05646514147520065\n",
      "Epoch 6, Loss: 0.04974208027124405\n",
      "Epoch 2, Loss: 0.3632994592189789\n",
      "Epoch 3, Loss: 0.24522244930267334\n",
      "Epoch 5, Loss: 0.23958605527877808\n",
      "Epoch 5, Loss: 0.06908398866653442Epoch 4, Loss: 0.06249871850013733\n",
      "\n",
      "Epoch 6, Loss: 0.11082863807678223\n",
      "Epoch 7, Loss: 0.1336383819580078\n",
      "Epoch 3, Loss: 0.5085523724555969\n",
      "Epoch 4, Loss: 0.02973928675055504\n",
      "Epoch 6, Loss: 0.11616819351911545\n",
      "Epoch 7, Loss: 0.05869146063923836\n",
      "Epoch 3, Loss: 0.060654304921627045\n",
      "Epoch 7, Loss: 0.06138424202799797\n",
      "Epoch 8, Loss: 0.06360624730587006\n",
      "Epoch 3, Loss: 0.37681177258491516\n",
      "Epoch 4, Loss: 0.0419517382979393\n",
      "Epoch 6, Loss: 0.166141539812088\n",
      "Epoch 6, Loss: 0.13768810033798218\n",
      "Epoch 5, Loss: 0.17932040989398956\n",
      "Epoch 8, Loss: 0.14909853041172028\n",
      "Epoch 7, Loss: 0.0899544432759285\n",
      "Epoch 8, Loss: 0.13040931522846222\n",
      "Epoch 9, Loss: 0.01222032867372036\n",
      "Epoch 4, Loss: 0.2927067279815674\n",
      "Epoch 7, Loss: 0.0435575433075428\n",
      "Epoch 5, Loss: 0.16212664544582367\n",
      "Epoch 6, Loss: 0.15939465165138245\n",
      "Epoch 4, Loss: 0.16046911478042603\n",
      "Epoch 10, Loss: 0.01942954584956169\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.0005576211880461871, num_heads=4, num_layers=2; total time=   1.1s\n",
      "Epoch 7, Loss: 0.12057214975357056\n",
      "Epoch 8, Loss: 0.03273959457874298\n",
      "Epoch 4, Loss: 0.178812637925148\n",
      "Epoch 5, Loss: 0.14233584702014923\n",
      "Epoch 9, Loss: 0.20124498009681702\n",
      "Epoch 9, Loss: 0.18593858182430267\n",
      "Epoch 8, Loss: 0.009886016137897968\n",
      "Epoch 7, Loss: 0.06219739466905594\n",
      "Epoch 5, Loss: 0.07296445220708847\n",
      "Epoch 10, Loss: 0.1494707465171814\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.0005576211880461871, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 9, Loss: 0.011637134477496147\n",
      "Epoch 10, Loss: 0.21530383825302124\n",
      "Epoch 8, Loss: 0.05342479050159454\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.0005576211880461871, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 6, Loss: 0.16885656118392944\n",
      "Epoch 5, Loss: 0.08735041320323944\n",
      "Epoch 6, Loss: 0.19186915457248688\n",
      "Epoch 5, Loss: 0.12226215749979019\n",
      "Epoch 9, Loss: 0.05969535559415817\n",
      "Epoch 8, Loss: 0.016816895455121994\n",
      "Epoch 9, Loss: 0.01898767054080963\n",
      "Epoch 10, Loss: 0.034505490213632584\n",
      "Epoch 6, Loss: 0.05037229508161545\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.0005576211880461871, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 7, Loss: 0.07345479726791382\n",
      "Epoch 6, Loss: 0.11918382346630096\n",
      "Epoch 9, Loss: 0.04118728265166283\n",
      "Epoch 10, Loss: 0.037048082798719406\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.0005576211880461871, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 10, Loss: 0.1025964617729187\n",
      "Epoch 7, Loss: 0.10559600591659546\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.0005576211880461871, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 6, Loss: 0.020790880545973778\n",
      "Epoch 7, Loss: 0.12767857313156128\n",
      "Epoch 8, Loss: 0.01275383960455656\n",
      "Epoch 10, Loss: 0.07869880646467209\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.0005576211880461871, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 7, Loss: 0.14339758455753326\n",
      "Epoch 8, Loss: 0.022040434181690216\n",
      "Epoch 9, Loss: 0.027805538848042488\n",
      "Epoch 8, Loss: 0.16218408942222595\n",
      "Epoch 7, Loss: 0.028521670028567314\n",
      "Epoch 8, Loss: 0.10454111546278\n",
      "Epoch 10, Loss: 0.07057619839906693\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.0005576211880461871, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 9, Loss: 0.11863033473491669\n",
      "Epoch 9, Loss: 0.028527667745947838\n",
      "Epoch 8, Loss: 0.07341641932725906\n",
      "Epoch 9, Loss: 0.048527851700782776\n",
      "Epoch 10, Loss: 0.05192837491631508\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.0005576211880461871, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.0797041654586792\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.0005576211880461871, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 0.06708988547325134\n",
      "Epoch 10, Loss: 0.02488134801387787\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.0005576211880461871, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.02807602658867836\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.0005576211880461871, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.09884754568338394\n",
      "Epoch 1, Loss: 0.2279653251171112\n",
      "Epoch 1, Loss: 0.07274118810892105\n",
      "Epoch 1, Loss: 0.7093049883842468\n",
      "Epoch 1, Loss: 0.07124895602464676\n",
      "Epoch 2, Loss: 0.0873386338353157\n",
      "Epoch 1, Loss: 0.9204849004745483\n",
      "Epoch 2, Loss: 0.03706063702702522\n",
      "Epoch 2, Loss: 0.15790137648582458\n",
      "Epoch 3, Loss: 0.07234534621238708\n",
      "Epoch 2, Loss: 0.102904312312603\n",
      "Epoch 1, Loss: 0.37306278944015503\n",
      "Epoch 2, Loss: 0.1356787532567978\n",
      "Epoch 1, Loss: 0.486493855714798\n",
      "Epoch 4, Loss: 0.012925677932798862\n",
      "Epoch 3, Loss: 0.12522266805171967\n",
      "Epoch 2, Loss: 0.2512453496456146\n",
      "Epoch 3, Loss: 0.05610654875636101\n",
      "Epoch 1, Loss: 0.16348989307880402\n",
      "Epoch 1, Loss: 0.05994834750890732\n",
      "Epoch 3, Loss: 0.028775742277503014\n",
      "Epoch 2, Loss: 0.08765538781881332\n",
      "Epoch 3, Loss: 0.05524689331650734\n",
      "Epoch 1, Loss: 0.1733187884092331\n",
      "Epoch 1, Loss: 0.12056638300418854\n",
      "Epoch 2, Loss: 0.15406593680381775\n",
      "Epoch 3, Loss: 0.11206989735364914\n",
      "Epoch 4, Loss: 0.11931789666414261\n",
      "Epoch 5, Loss: 0.019204190000891685\n",
      "Epoch 2, Loss: 0.03612843528389931\n",
      "Epoch 4, Loss: 0.17351794242858887\n",
      "Epoch 4, Loss: 0.06453008949756622\n",
      "Epoch 2, Loss: 0.13329729437828064\n",
      "Epoch 3, Loss: 0.16708824038505554\n",
      "Epoch 4, Loss: 0.01960749737918377\n",
      "Epoch 5, Loss: 0.056046344339847565\n",
      "Epoch 6, Loss: 0.0400373749434948\n",
      "Epoch 3, Loss: 0.139238178730011\n",
      "Epoch 3, Loss: 0.11481943726539612\n",
      "Epoch 4, Loss: 0.2428113967180252\n",
      "Epoch 2, Loss: 0.07695826888084412\n",
      "Epoch 5, Loss: 0.05769595876336098\n",
      "Epoch 5, Loss: 0.24947121739387512\n",
      "Epoch 2, Loss: 0.04050673544406891\n",
      "Epoch 7, Loss: 0.02984798513352871\n",
      "Epoch 3, Loss: 0.049339812248945236\n",
      "Epoch 6, Loss: 0.014297529123723507\n",
      "Epoch 5, Loss: 0.03966768458485603\n",
      "Epoch 4, Loss: 0.20164817571640015\n",
      "Epoch 4, Loss: 0.2073485255241394\n",
      "Epoch 4, Loss: 0.05818114057183266\n",
      "Epoch 6, Loss: 0.21898281574249268\n",
      "Epoch 8, Loss: 0.0089033842086792\n",
      "Epoch 6, Loss: 0.019865797832608223\n",
      "Epoch 5, Loss: 0.32387280464172363\n",
      "Epoch 3, Loss: 0.09067250788211823\n",
      "Epoch 3, Loss: 0.10275870561599731\n",
      "Epoch 6, Loss: 0.04258246347308159\n",
      "Epoch 4, Loss: 0.0153535520657897\n",
      "Epoch 7, Loss: 0.02422318421304226\n",
      "Epoch 9, Loss: 0.007192007265985012\n",
      "Epoch 7, Loss: 0.14181962609291077\n",
      "Epoch 5, Loss: 0.13886243104934692\n",
      "Epoch 5, Loss: 0.008847824297845364\n",
      "Epoch 7, Loss: 0.013546613045036793\n",
      "Epoch 6, Loss: 0.2793492078781128\n",
      "Epoch 10, Loss: 0.02088608220219612\n",
      "Epoch 5, Loss: 0.19901730120182037\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.34361434274641606, feed_forward_dim=128, head_dim=32, lr=0.0002866108366765471, num_heads=4, num_layers=1; total time=   1.0s\n",
      "Epoch 8, Loss: 0.05213668569922447\n",
      "Epoch 7, Loss: 0.01906050741672516\n",
      "Epoch 8, Loss: 0.06816416233778\n",
      "Epoch 5, Loss: 0.057936880737543106\n",
      "Epoch 6, Loss: 0.0682201012969017\n",
      "Epoch 4, Loss: 0.039786484092473984\n",
      "Epoch 4, Loss: 0.0849207416176796\n",
      "Epoch 8, Loss: 0.03733166307210922\n",
      "Epoch 7, Loss: 0.18311922252178192\n",
      "Epoch 6, Loss: 0.02180204726755619\n",
      "Epoch 8, Loss: 0.007391295861452818\n",
      "Epoch 9, Loss: 0.05940975993871689\n",
      "Epoch 9, Loss: 0.027496472001075745\n",
      "Epoch 7, Loss: 0.04091433435678482\n",
      "Epoch 9, Loss: 0.037843797355890274\n",
      "Epoch 6, Loss: 0.13614074885845184\n",
      "Epoch 8, Loss: 0.09043146669864655\n",
      "Epoch 6, Loss: 0.054679401218891144\n",
      "Epoch 7, Loss: 0.04876420274376869\n",
      "Epoch 10, Loss: 0.024192651733756065\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.34361434274641606, feed_forward_dim=128, head_dim=32, lr=0.0002866108366765471, num_heads=4, num_layers=1; total time=   1.1s\n",
      "Epoch 10, Loss: 0.03893586993217468\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.34361434274641606, feed_forward_dim=128, head_dim=32, lr=0.0002866108366765471, num_heads=4, num_layers=1; total time=   1.2s\n",
      "Epoch 9, Loss: 0.0158639345318079\n",
      "Epoch 5, Loss: 0.02060087025165558\n",
      "Epoch 10, Loss: 0.018606388941407204\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.34361434274641606, feed_forward_dim=128, head_dim=32, lr=0.0002866108366765471, num_heads=4, num_layers=1; total time=   1.2s\n",
      "Epoch 8, Loss: 0.05913565307855606\n",
      "Epoch 5, Loss: 0.03161485493183136\n",
      "Epoch 7, Loss: 0.07550302892923355\n",
      "Epoch 10, Loss: 0.023472467437386513\n",
      "Epoch 9, Loss: 0.040693122893571854\n",
      "Epoch 8, Loss: 0.044006116688251495\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.34361434274641606, feed_forward_dim=128, head_dim=32, lr=0.0002866108366765471, num_heads=4, num_layers=1; total time=   1.2s\n",
      "Epoch 7, Loss: 0.02156146802008152\n",
      "Epoch 6, Loss: 0.0375564806163311\n",
      "Epoch 9, Loss: 0.08247697353363037\n",
      "Epoch 8, Loss: 0.047229282557964325\n",
      "Epoch 10, Loss: 0.03627030551433563\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.34361434274641606, feed_forward_dim=128, head_dim=32, lr=0.0002866108366765471, num_heads=4, num_layers=1; total time=   1.3s\n",
      "Epoch 6, Loss: 0.012353109195828438\n",
      "Epoch 9, Loss: 0.019650891423225403\n",
      "Epoch 8, Loss: 0.010320513509213924\n",
      "Epoch 10, Loss: 0.07943755388259888\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.34361434274641606, feed_forward_dim=128, head_dim=32, lr=0.0002866108366765471, num_heads=4, num_layers=1; total time=   1.3s\n",
      "Epoch 7, Loss: 0.041255924850702286\n",
      "Epoch 9, Loss: 0.051023826003074646\n",
      "Epoch 7, Loss: 0.02854074537754059\n",
      "Epoch 10, Loss: 0.004454376641660929\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.34361434274641606, feed_forward_dim=128, head_dim=32, lr=0.0002866108366765471, num_heads=4, num_layers=1; total time=   1.3s\n",
      "Epoch 9, Loss: 0.026155078783631325\n",
      "Epoch 8, Loss: 0.022270627319812775\n",
      "Epoch 10, Loss: 0.06814692169427872\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.34361434274641606, feed_forward_dim=128, head_dim=32, lr=0.0002866108366765471, num_heads=4, num_layers=1; total time=   1.4s\n",
      "Epoch 8, Loss: 0.04182977229356766\n",
      "Epoch 10, Loss: 0.03800176456570625\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.34361434274641606, feed_forward_dim=128, head_dim=32, lr=0.0002866108366765471, num_heads=4, num_layers=1; total time=   1.4s\n",
      "Epoch 9, Loss: 0.009728307835757732\n",
      "Epoch 9, Loss: 0.03564664348959923\n",
      "Epoch 10, Loss: 0.016803313046693802\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.34361434274641606, feed_forward_dim=128, head_dim=32, lr=0.0002866108366765471, num_heads=4, num_layers=1; total time=   1.5s\n",
      "Epoch 10, Loss: 0.015583285130560398\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.34361434274641606, feed_forward_dim=128, head_dim=32, lr=0.0002866108366765471, num_heads=4, num_layers=1; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.10953852534294128\n",
      "Epoch 1, Loss: 0.06765823066234589\n",
      "Epoch 1, Loss: 0.35178107023239136\n",
      "Epoch 2, Loss: 0.3703903257846832\n",
      "Epoch 2, Loss: 0.5382128357887268\n",
      "Epoch 1, Loss: 0.6031412482261658\n",
      "Epoch 1, Loss: 0.48641300201416016\n",
      "Epoch 1, Loss: 0.07167118042707443\n",
      "Epoch 3, Loss: 0.10702555626630783\n",
      "Epoch 1, Loss: 1.712319016456604\n",
      "Epoch 1, Loss: 0.15326468646526337\n",
      "Epoch 2, Loss: 0.16924917697906494\n",
      "Epoch 2, Loss: 0.09727644920349121\n",
      "Epoch 3, Loss: 0.0829804465174675\n",
      "Epoch 2, Loss: 0.16301506757736206\n",
      "Epoch 1, Loss: 1.426863670349121\n",
      "Epoch 4, Loss: 0.026268349960446358\n",
      "Epoch 2, Loss: 0.2967650890350342\n",
      "Epoch 3, Loss: 0.2475355714559555\n",
      "Epoch 2, Loss: 0.6696708798408508\n",
      "Epoch 2, Loss: 0.3619872033596039\n",
      "Epoch 1, Loss: 0.642055332660675\n",
      "Epoch 3, Loss: 0.30575835704803467\n",
      "Epoch 1, Loss: 0.31716033816337585\n",
      "Epoch 5, Loss: 0.13315731287002563\n",
      "Epoch 4, Loss: 0.09444059431552887\n",
      "Epoch 1, Loss: 0.056594014167785645\n",
      "Epoch 4, Loss: 0.09057165682315826\n",
      "Epoch 3, Loss: 0.36549898982048035\n",
      "Epoch 3, Loss: 0.06995070725679398\n",
      "Epoch 2, Loss: 0.10153454542160034\n",
      "Epoch 3, Loss: 0.5076761841773987\n",
      "Epoch 4, Loss: 0.1547277271747589\n",
      "Epoch 3, Loss: 0.10531015694141388\n",
      "Epoch 5, Loss: 0.2418644279241562\n",
      "Epoch 2, Loss: 0.11645649373531342\n",
      "Epoch 2, Loss: 0.16165664792060852\n",
      "Epoch 6, Loss: 0.12199171632528305\n",
      "Epoch 2, Loss: 0.5155367851257324\n",
      "Epoch 4, Loss: 0.13597770035266876\n",
      "Epoch 4, Loss: 0.23112425208091736\n",
      "Epoch 5, Loss: 0.02615024708211422\n",
      "Epoch 6, Loss: 0.1509634554386139\n",
      "Epoch 4, Loss: 0.6758583784103394\n",
      "Epoch 4, Loss: 0.058650560677051544\n",
      "Epoch 5, Loss: 0.020118828862905502\n",
      "Epoch 3, Loss: 0.223679780960083\n",
      "Epoch 7, Loss: 0.04419947415590286\n",
      "Epoch 3, Loss: 0.47338899970054626\n",
      "Epoch 7, Loss: 0.03678615763783455\n",
      "Epoch 8, Loss: 0.007976996712386608\n",
      "Epoch 5, Loss: 0.2949257791042328\n",
      "Epoch 6, Loss: 0.0795191302895546\n",
      "Epoch 3, Loss: 0.37811553478240967\n",
      "Epoch 5, Loss: 0.06817203015089035\n",
      "Epoch 5, Loss: 0.48081886768341064\n",
      "Epoch 6, Loss: 0.035482846200466156\n",
      "Epoch 5, Loss: 0.1432521790266037\n",
      "Epoch 3, Loss: 0.08251729607582092\n",
      "Epoch 4, Loss: 0.08935695886611938\n",
      "Epoch 9, Loss: 0.02850782871246338\n",
      "Epoch 7, Loss: 0.10885801166296005\n",
      "Epoch 8, Loss: 0.020382076501846313\n",
      "Epoch 4, Loss: 0.6034448146820068\n",
      "Epoch 6, Loss: 0.03857967257499695\n",
      "Epoch 6, Loss: 0.22282016277313232\n",
      "Epoch 7, Loss: 0.10220180451869965\n",
      "Epoch 4, Loss: 0.2718428671360016\n",
      "Epoch 6, Loss: 0.11184867471456528\n",
      "Epoch 8, Loss: 0.0718655064702034\n",
      "Epoch 6, Loss: 0.19598515331745148\n",
      "Epoch 10, Loss: 0.058264583349227905\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005503332667576141, num_heads=4, num_layers=4; total time=   1.0s\n",
      "Epoch 4, Loss: 0.05507776141166687\n",
      "Epoch 8, Loss: 0.11441582441329956\n",
      "Epoch 5, Loss: 0.00967094860970974\n",
      "Epoch 7, Loss: 0.09627323597669601\n",
      "Epoch 9, Loss: 0.06987255811691284\n",
      "Epoch 9, Loss: 0.022438248619437218\n",
      "Epoch 7, Loss: 0.05412589758634567\n",
      "Epoch 7, Loss: 0.03513218089938164\n",
      "Epoch 5, Loss: 0.10285335034132004\n",
      "Epoch 7, Loss: 0.07812486588954926\n",
      "Epoch 5, Loss: 0.38972002267837524\n",
      "Epoch 9, Loss: 0.07104983180761337\n",
      "Epoch 10, Loss: 0.10207831114530563\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005503332667576141, num_heads=4, num_layers=4; total time=   1.1s\n",
      "Epoch 6, Loss: 0.0429498590528965\n",
      "Epoch 8, Loss: 0.13358059525489807\n",
      "Epoch 10, Loss: 0.01284588873386383\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005503332667576141, num_heads=4, num_layers=4; total time=   1.1s\n",
      "Epoch 5, Loss: 0.20169129967689514\n",
      "Epoch 10, Loss: 0.02273065596818924\n",
      "Epoch 8, Loss: 0.01216736901551485\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005503332667576141, num_heads=4, num_layers=4; total time=   1.1s\n",
      "Epoch 8, Loss: 0.006274274084717035\n",
      "Epoch 8, Loss: 0.07945355027914047\n",
      "Epoch 6, Loss: 0.04878461733460426\n",
      "Epoch 6, Loss: 0.14588017761707306\n",
      "Epoch 9, Loss: 0.11202429980039597\n",
      "Epoch 7, Loss: 0.09010082483291626\n",
      "Epoch 9, Loss: 0.04350360110402107\n",
      "Epoch 9, Loss: 0.05014241114258766\n",
      "Epoch 6, Loss: 0.1616503894329071\n",
      "Epoch 10, Loss: 0.06188468635082245\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005503332667576141, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 9, Loss: 0.14840419590473175\n",
      "Epoch 7, Loss: 0.03405899181962013\n",
      "Epoch 8, Loss: 0.07965444028377533\n",
      "Epoch 7, Loss: 0.08981362730264664\n",
      "Epoch 10, Loss: 0.10322438180446625\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005503332667576141, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 10, Loss: 0.0662282183766365\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005503332667576141, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 7, Loss: 0.05368997901678085\n",
      "Epoch 8, Loss: 0.06217366084456444\n",
      "Epoch 10, Loss: 0.19927828013896942\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005503332667576141, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 9, Loss: 0.03498714044690132\n",
      "Epoch 8, Loss: 0.12787078320980072\n",
      "Epoch 9, Loss: 0.1393618881702423\n",
      "Epoch 8, Loss: 0.007821563631296158\n",
      "Epoch 10, Loss: 0.005663650576025248\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005503332667576141, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 9, Loss: 0.11144016683101654\n",
      "Epoch 10, Loss: 0.1819024533033371\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005503332667576141, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 9, Loss: 0.03620057925581932\n",
      "Epoch 10, Loss: 0.0642646849155426\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005503332667576141, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.07829425483942032\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005503332667576141, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.33295395970344543\n",
      "Epoch 1, Loss: 0.5732856392860413\n",
      "Epoch 1, Loss: 2.181440830230713\n",
      "Epoch 1, Loss: 0.7151066064834595\n",
      "Epoch 1, Loss: 0.3262200653553009\n",
      "Epoch 2, Loss: 0.07916384190320969\n",
      "Epoch 1, Loss: 0.08951485902070999\n",
      "Epoch 1, Loss: 1.6115871667861938\n",
      "Epoch 2, Loss: 0.5065252184867859\n",
      "Epoch 2, Loss: 0.2597842216491699\n",
      "Epoch 1, Loss: 1.1626886129379272\n",
      "Epoch 3, Loss: 0.33265963196754456\n",
      "Epoch 2, Loss: 0.4042237102985382\n",
      "Epoch 2, Loss: 0.1198086142539978\n",
      "Epoch 2, Loss: 0.39133045077323914\n",
      "Epoch 2, Loss: 0.20991244912147522\n",
      "Epoch 3, Loss: 0.16831070184707642\n",
      "Epoch 1, Loss: 0.765469491481781\n",
      "Epoch 3, Loss: 0.2438322752714157\n",
      "Epoch 4, Loss: 0.23469078540802002\n",
      "Epoch 1, Loss: 0.09650957584381104\n",
      "Epoch 3, Loss: 0.03688672184944153\n",
      "Epoch 1, Loss: 0.21224315464496613\n",
      "Epoch 2, Loss: 0.05019282549619675\n",
      "Epoch 4, Loss: 0.5874211192131042\n",
      "Epoch 1, Loss: 0.2047756314277649\n",
      "Epoch 3, Loss: 0.372825026512146\n",
      "Epoch 3, Loss: 0.21877223253250122\n",
      "Epoch 4, Loss: 0.09916265308856964\n",
      "Epoch 5, Loss: 0.06795693188905716\n",
      "Epoch 4, Loss: 0.1323326826095581\n",
      "Epoch 5, Loss: 0.6497723460197449\n",
      "Epoch 3, Loss: 0.22191902995109558\n",
      "Epoch 2, Loss: 0.044672977179288864\n",
      "Epoch 5, Loss: 0.15818668901920319\n",
      "Epoch 4, Loss: 0.2880890965461731\n",
      "Epoch 3, Loss: 0.34868305921554565\n",
      "Epoch 4, Loss: 0.06236584857106209\n",
      "Epoch 6, Loss: 0.021571513265371323\n",
      "Epoch 2, Loss: 0.6460514664649963\n",
      "Epoch 2, Loss: 0.4664616882801056\n",
      "Epoch 2, Loss: 0.33311018347740173\n",
      "Epoch 6, Loss: 0.45971205830574036\n",
      "Epoch 5, Loss: 0.19322845339775085\n",
      "Epoch 6, Loss: 0.17027178406715393\n",
      "Epoch 5, Loss: 0.1047993078827858\n",
      "Epoch 7, Loss: 0.07627416402101517\n",
      "Epoch 4, Loss: 0.45009341835975647\n",
      "Epoch 3, Loss: 0.3929840922355652\n",
      "Epoch 5, Loss: 0.10512737184762955\n",
      "Epoch 4, Loss: 0.5259143114089966\n",
      "Epoch 7, Loss: 0.22955144941806793\n",
      "Epoch 6, Loss: 0.03791366517543793\n",
      "Epoch 7, Loss: 0.0881597250699997\n",
      "Epoch 8, Loss: 0.12527547776699066\n",
      "Epoch 3, Loss: 0.16022218763828278\n",
      "Epoch 3, Loss: 0.07670126110315323\n",
      "Epoch 6, Loss: 0.0903659462928772\n",
      "Epoch 5, Loss: 0.2796632945537567\n",
      "Epoch 3, Loss: 0.1378493756055832\n",
      "Epoch 8, Loss: 0.07495077699422836\n",
      "Epoch 8, Loss: 0.03508364036679268\n",
      "Epoch 4, Loss: 0.32682088017463684\n",
      "Epoch 6, Loss: 0.14268864691257477\n",
      "Epoch 5, Loss: 0.4891415238380432\n",
      "Epoch 9, Loss: 0.11418449133634567\n",
      "Epoch 7, Loss: 0.08216391503810883\n",
      "Epoch 7, Loss: 0.010460861958563328\n",
      "Epoch 9, Loss: 0.02567221224308014\n",
      "Epoch 9, Loss: 0.043108999729156494\n",
      "Epoch 6, Loss: 0.09142881631851196\n",
      "Epoch 4, Loss: 0.04449114203453064\n",
      "Epoch 4, Loss: 0.009107274003326893\n",
      "Epoch 5, Loss: 0.11022071540355682\n",
      "Epoch 8, Loss: 0.1350296288728714\n",
      "Epoch 10, Loss: 0.06567257642745972\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.0005461992883242034, num_heads=4, num_layers=4; total time=   1.0s\n",
      "Epoch 10, Loss: 0.07271357625722885\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.0005461992883242034, num_heads=4, num_layers=4; total time=   1.0s\n",
      "Epoch 4, Loss: 0.1333647072315216\n",
      "Epoch 8, Loss: 0.027378607541322708\n",
      "Epoch 7, Loss: 0.10038816183805466\n",
      "Epoch 6, Loss: 0.28660932183265686\n",
      "Epoch 10, Loss: 0.06125911325216293\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.0005461992883242034, num_heads=4, num_layers=4; total time=   1.0s\n",
      "Epoch 9, Loss: 0.13263994455337524\n",
      "Epoch 5, Loss: 0.15913406014442444\n",
      "Epoch 6, Loss: 0.020229171961545944\n",
      "Epoch 9, Loss: 0.07850635796785355\n",
      "Epoch 7, Loss: 0.016746781766414642\n",
      "Epoch 5, Loss: 0.281141459941864\n",
      "Epoch 5, Loss: 0.0802135318517685\n",
      "Epoch 10, Loss: 0.08405964076519012\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.0005461992883242034, num_heads=4, num_layers=4; total time=   1.1s\n",
      "Epoch 7, Loss: 0.10166557878255844\n",
      "Epoch 8, Loss: 0.03745998814702034\n",
      "Epoch 10, Loss: 0.08602229505777359\n",
      "Epoch 6, Loss: 0.14756636321544647\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.0005461992883242034, num_heads=4, num_layers=4; total time=   1.1s\n",
      "Epoch 7, Loss: 0.060619231313467026\n",
      "Epoch 9, Loss: 0.02194768376648426\n",
      "Epoch 6, Loss: 0.18194679915905\n",
      "Epoch 8, Loss: 0.04636767879128456\n",
      "Epoch 6, Loss: 0.13160236179828644\n",
      "Epoch 8, Loss: 0.02991160750389099\n",
      "Epoch 10, Loss: 0.045849937945604324\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.0005461992883242034, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 7, Loss: 0.053925372660160065\n",
      "Epoch 8, Loss: 0.131602481007576\n",
      "Epoch 9, Loss: 0.10671257227659225\n",
      "Epoch 7, Loss: 0.0423540323972702\n",
      "Epoch 9, Loss: 0.05117395520210266\n",
      "Epoch 7, Loss: 0.0797254741191864\n",
      "Epoch 10, Loss: 0.14383883774280548\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.0005461992883242034, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 9, Loss: 0.14712309837341309\n",
      "Epoch 8, Loss: 0.009620838798582554\n",
      "Epoch 10, Loss: 0.11285342276096344\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.0005461992883242034, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 8, Loss: 0.010464870370924473\n",
      "Epoch 8, Loss: 0.01596459560096264\n",
      "Epoch 10, Loss: 0.1071675643324852\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.0005461992883242034, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 9, Loss: 0.040840182453393936\n",
      "Epoch 9, Loss: 0.008669443428516388\n",
      "Epoch 9, Loss: 0.0641666054725647\n",
      "Epoch 10, Loss: 0.08118744194507599\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.0005461992883242034, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 10, Loss: 0.04130464419722557\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.0005461992883242034, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.11133602261543274\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.0005461992883242034, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.9417943358421326\n",
      "Epoch 1, Loss: 0.2501734495162964\n",
      "Epoch 2, Loss: 0.06275385618209839\n",
      "Epoch 1, Loss: 0.020691493526101112\n",
      "Epoch 1, Loss: 0.1957246959209442\n",
      "Epoch 1, Loss: 0.09977163374423981\n",
      "Epoch 1, Loss: 0.15348216891288757\n",
      "Epoch 2, Loss: 0.37710532546043396\n",
      "Epoch 1, Loss: 0.3707619309425354\n",
      "Epoch 2, Loss: 0.36026740074157715\n",
      "Epoch 2, Loss: 0.5181397199630737\n",
      "Epoch 1, Loss: 0.4394000768661499\n",
      "Epoch 3, Loss: 0.24963515996932983\n",
      "Epoch 2, Loss: 0.42999815940856934\n",
      "Epoch 2, Loss: 0.6047731637954712\n",
      "Epoch 3, Loss: 0.19955837726593018\n",
      "Epoch 1, Loss: 2.1794774532318115\n",
      "Epoch 2, Loss: 0.14005154371261597\n",
      "Epoch 4, Loss: 0.3957239091396332\n",
      "Epoch 3, Loss: 0.013453120365738869\n",
      "Epoch 1, Loss: 0.49984505772590637\n",
      "Epoch 2, Loss: 0.09429479390382767\n",
      "Epoch 1, Loss: 0.6473096013069153\n",
      "Epoch 4, Loss: 0.027087241411209106\n",
      "Epoch 1, Loss: 5.107220649719238\n",
      "Epoch 3, Loss: 0.13609883189201355\n",
      "Epoch 3, Loss: 0.1570013463497162\n",
      "Epoch 5, Loss: 0.26927992701530457\n",
      "Epoch 3, Loss: 0.0540040023624897\n",
      "Epoch 4, Loss: 0.25209909677505493\n",
      "Epoch 2, Loss: 0.26235872507095337\n",
      "Epoch 3, Loss: 0.27730703353881836\n",
      "Epoch 5, Loss: 0.10862645506858826\n",
      "Epoch 2, Loss: 0.13814887404441833\n",
      "Epoch 3, Loss: 0.2718479037284851\n",
      "Epoch 6, Loss: 0.10073351114988327\n",
      "Epoch 4, Loss: 0.044898539781570435\n",
      "Epoch 4, Loss: 0.02182537503540516\n",
      "Epoch 6, Loss: 0.1680607795715332\n",
      "Epoch 4, Loss: 0.1767169088125229\n",
      "Epoch 5, Loss: 0.26853659749031067\n",
      "Epoch 7, Loss: 0.01967003010213375\n",
      "Epoch 2, Loss: 0.12207774817943573\n",
      "Epoch 4, Loss: 0.12184720486402512\n",
      "Epoch 2, Loss: 2.0548367500305176\n",
      "Epoch 3, Loss: 0.3297394812107086\n",
      "Epoch 3, Loss: 0.18874426186084747\n",
      "Epoch 5, Loss: 0.11935103684663773\n",
      "Epoch 5, Loss: 0.14190472662448883\n",
      "Epoch 4, Loss: 0.17095284163951874\n",
      "Epoch 7, Loss: 0.10736570507287979\n",
      "Epoch 5, Loss: 0.29257115721702576\n",
      "Epoch 8, Loss: 0.03632747381925583\n",
      "Epoch 6, Loss: 0.09010696411132812\n",
      "Epoch 3, Loss: 0.3858107328414917\n",
      "Epoch 9, Loss: 0.09528470784425735\n",
      "Epoch 5, Loss: 0.02484087273478508\n",
      "Epoch 5, Loss: 0.05020585656166077\n",
      "Epoch 6, Loss: 0.1450294405221939\n",
      "Epoch 4, Loss: 0.13395841419696808\n",
      "Epoch 8, Loss: 0.03519811853766441\n",
      "Epoch 6, Loss: 0.13047997653484344\n",
      "Epoch 6, Loss: 0.1738419532775879\n",
      "Epoch 4, Loss: 0.6679614782333374\n",
      "Epoch 7, Loss: 0.006957813166081905\n",
      "Epoch 3, Loss: 0.4100383222103119\n",
      "Epoch 10, Loss: 0.13116829097270966\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0005471145572183635, num_heads=4, num_layers=4; total time=   1.0s\n",
      "Epoch 6, Loss: 0.060897089540958405\n",
      "Epoch 7, Loss: 0.038972970098257065\n",
      "Epoch 7, Loss: 0.060971397906541824\n",
      "Epoch 6, Loss: 0.03813813254237175\n",
      "Epoch 8, Loss: 0.05314372852444649\n",
      "Epoch 7, Loss: 0.0507856085896492\n",
      "Epoch 9, Loss: 0.025459246709942818\n",
      "Epoch 5, Loss: 0.011678057722747326\n",
      "Epoch 4, Loss: 0.27520179748535156\n",
      "Epoch 5, Loss: 0.6355645060539246\n",
      "Epoch 8, Loss: 0.014955384656786919\n",
      "Epoch 10, Loss: 0.06000324338674545\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0005471145572183635, num_heads=4, num_layers=4; total time=   1.1s\n",
      "Epoch 9, Loss: 0.11541658639907837\n",
      "Epoch 4, Loss: 0.015831537544727325\n",
      "Epoch 7, Loss: 0.08318720012903214\n",
      "Epoch 7, Loss: 0.11358686536550522\n",
      "Epoch 8, Loss: 0.01731475442647934\n",
      "Epoch 8, Loss: 0.007918253540992737\n",
      "Epoch 6, Loss: 0.052672743797302246\n",
      "Epoch 9, Loss: 0.07340043038129807\n",
      "Epoch 8, Loss: 0.10196812450885773\n",
      "Epoch 9, Loss: 0.030214587226510048\n",
      "Epoch 5, Loss: 0.08550515025854111\n",
      "Epoch 10, Loss: 0.11672653257846832\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0005471145572183635, num_heads=4, num_layers=4; total time=   1.2s\n",
      "Epoch 8, Loss: 0.09882672876119614\n",
      "Epoch 9, Loss: 0.038132503628730774\n",
      "Epoch 5, Loss: 0.33013981580734253\n",
      "Epoch 6, Loss: 0.3611999452114105\n",
      "Epoch 10, Loss: 0.11726617813110352\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0005471145572183635, num_heads=4, num_layers=4; total time=   1.2s\n",
      "Epoch 10, Loss: 0.06149761378765106\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0005471145572183635, num_heads=4, num_layers=4; total time=   1.2s\n",
      "Epoch 7, Loss: 0.11798915266990662\n",
      "Epoch 9, Loss: 0.049229465425014496\n",
      "Epoch 9, Loss: 0.0688520148396492\n",
      "Epoch 10, Loss: 0.07593367993831635\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0005471145572183635, num_heads=4, num_layers=4; total time=   1.2s\n",
      "Epoch 6, Loss: 0.025745248422026634\n",
      "Epoch 7, Loss: 0.12005715817213058\n",
      "Epoch 6, Loss: 0.6562417149543762\n",
      "Epoch 8, Loss: 0.11583662033081055\n",
      "Epoch 10, Loss: 0.015341215766966343\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0005471145572183635, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 10, Loss: 0.02798883616924286\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0005471145572183635, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 8, Loss: 0.02124795690178871\n",
      "Epoch 7, Loss: 0.08190160244703293\n",
      "Epoch 9, Loss: 0.06333673745393753\n",
      "Epoch 7, Loss: 0.7435769438743591\n",
      "Epoch 9, Loss: 0.046493567526340485\n",
      "Epoch 8, Loss: 0.13805542886257172\n",
      "Epoch 10, Loss: 0.015421637333929539\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0005471145572183635, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 8, Loss: 0.661918580532074\n",
      "Epoch 10, Loss: 0.12197913974523544\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0005471145572183635, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 9, Loss: 0.13547350466251373\n",
      "Epoch 9, Loss: 0.4804811477661133\n",
      "Epoch 10, Loss: 0.0816723182797432\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0005471145572183635, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.29790520668029785\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0005471145572183635, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.09280797094106674\n",
      "Epoch 1, Loss: 0.7918865084648132\n",
      "Epoch 1, Loss: 1.6767905950546265\n",
      "Epoch 1, Loss: 0.20051303505897522\n",
      "Epoch 1, Loss: 0.2634071707725525\n",
      "Epoch 2, Loss: 0.493184894323349\n",
      "Epoch 2, Loss: 0.05147223919630051\n",
      "Epoch 1, Loss: 0.06499280780553818\n",
      "Epoch 2, Loss: 0.5152965784072876\n",
      "Epoch 1, Loss: 0.5484959483146667\n",
      "Epoch 2, Loss: 0.1895882934331894\n",
      "Epoch 3, Loss: 0.09566272795200348\n",
      "Epoch 2, Loss: 0.1892755627632141\n",
      "Epoch 1, Loss: 0.485953152179718\n",
      "Epoch 1, Loss: 0.9964874982833862\n",
      "Epoch 3, Loss: 0.3990980088710785\n",
      "Epoch 4, Loss: 0.0869794711470604\n",
      "Epoch 3, Loss: 0.14732396602630615\n",
      "Epoch 3, Loss: 0.10289941728115082\n",
      "Epoch 1, Loss: 1.4585845470428467\n",
      "Epoch 2, Loss: 0.15840758383274078\n",
      "Epoch 2, Loss: 0.977957010269165\n",
      "Epoch 1, Loss: 0.09897889196872711\n",
      "Epoch 3, Loss: 0.1965910941362381\n",
      "Epoch 4, Loss: 0.34522727131843567\n",
      "Epoch 1, Loss: 0.17972205579280853\n",
      "Epoch 5, Loss: 0.21607144176959991\n",
      "Epoch 4, Loss: 0.09462124854326248\n",
      "Epoch 2, Loss: 0.3750888705253601\n",
      "Epoch 3, Loss: 0.3616012632846832\n",
      "Epoch 3, Loss: 0.08589696884155273\n",
      "Epoch 4, Loss: 0.44081735610961914\n",
      "Epoch 2, Loss: 0.04457869008183479\n",
      "Epoch 2, Loss: 0.3649011254310608\n",
      "Epoch 5, Loss: 0.13764069974422455\n",
      "Epoch 2, Loss: 0.1978471279144287\n",
      "Epoch 6, Loss: 0.16028600931167603\n",
      "Epoch 4, Loss: 0.06682192534208298\n",
      "Epoch 5, Loss: 0.4801182448863983\n",
      "Epoch 5, Loss: 0.1970837116241455\n",
      "Epoch 3, Loss: 0.3187306225299835\n",
      "Epoch 2, Loss: 0.19536100327968597\n",
      "Epoch 4, Loss: 0.18859437108039856\n",
      "Epoch 4, Loss: 0.2175222933292389\n",
      "Epoch 7, Loss: 0.05533306673169136\n",
      "Epoch 6, Loss: 0.016168290749192238\n",
      "Epoch 3, Loss: 0.41091400384902954\n",
      "Epoch 6, Loss: 0.1525593101978302\n",
      "Epoch 5, Loss: 0.036474984139204025\n",
      "Epoch 6, Loss: 0.3253749907016754\n",
      "Epoch 7, Loss: 0.03635154664516449\n",
      "Epoch 3, Loss: 0.02824767865240574\n",
      "Epoch 4, Loss: 0.1152711734175682\n",
      "Epoch 8, Loss: 0.02071942389011383\n",
      "Epoch 5, Loss: 0.4360944926738739\n",
      "Epoch 5, Loss: 0.06629110872745514\n",
      "Epoch 3, Loss: 0.31844422221183777\n",
      "Epoch 3, Loss: 0.12747333943843842\n",
      "Epoch 7, Loss: 0.054933369159698486\n",
      "Epoch 6, Loss: 0.08452816307544708\n",
      "Epoch 8, Loss: 0.11092324554920197\n",
      "Epoch 9, Loss: 0.05553876981139183\n",
      "Epoch 7, Loss: 0.14613957703113556\n",
      "Epoch 5, Loss: 0.09591514617204666\n",
      "Epoch 4, Loss: 0.441272109746933\n",
      "Epoch 6, Loss: 0.315244197845459\n",
      "Epoch 8, Loss: 0.02008826844394207\n",
      "Epoch 7, Loss: 0.09170899540185928\n",
      "Epoch 6, Loss: 0.05132242664694786\n",
      "Epoch 9, Loss: 0.14482702314853668\n",
      "Epoch 10, Loss: 0.09218140691518784\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005399774545413866, num_heads=4, num_layers=2; total time=   1.0s\n",
      "Epoch 8, Loss: 0.0397660955786705\n",
      "Epoch 4, Loss: 0.5387567281723022\n",
      "Epoch 4, Loss: 0.1938052922487259\n",
      "Epoch 9, Loss: 0.05784305930137634\n",
      "Epoch 10, Loss: 0.1238197535276413\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005399774545413866, num_heads=4, num_layers=2; total time=   1.0s\n",
      "Epoch 6, Loss: 0.1504785716533661\n",
      "Epoch 4, Loss: 0.030802585184574127\n",
      "Epoch 5, Loss: 0.20855459570884705\n",
      "Epoch 8, Loss: 0.04923759028315544\n",
      "Epoch 7, Loss: 0.10227400064468384\n",
      "Epoch 7, Loss: 0.11345356702804565\n",
      "Epoch 5, Loss: 0.46391561627388\n",
      "Epoch 10, Loss: 0.08812961727380753\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005399774545413866, num_heads=4, num_layers=2; total time=   1.1s\n",
      "Epoch 9, Loss: 0.020948128774762154\n",
      "Epoch 9, Loss: 0.014211175963282585\n",
      "Epoch 7, Loss: 0.1328074038028717\n",
      "Epoch 6, Loss: 0.03572697564959526\n",
      "Epoch 5, Loss: 0.1673186868429184\n",
      "Epoch 8, Loss: 0.14188207685947418\n",
      "Epoch 8, Loss: 0.008183632045984268\n",
      "Epoch 5, Loss: 0.05354004725813866\n",
      "Epoch 6, Loss: 0.277567058801651\n",
      "Epoch 10, Loss: 0.0186772421002388\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005399774545413866, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 10, Loss: 0.059807147830724716\n",
      "Epoch 8, Loss: 0.06442902982234955\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005399774545413866, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 7, Loss: 0.02279376983642578\n",
      "Epoch 9, Loss: 0.11001286655664444\n",
      "Epoch 6, Loss: 0.03884308040142059\n",
      "Epoch 9, Loss: 0.055321093648672104\n",
      "Epoch 6, Loss: 0.08443733304738998\n",
      "Epoch 9, Loss: 0.022602809593081474\n",
      "Epoch 8, Loss: 0.09993176907300949\n",
      "Epoch 10, Loss: 0.05516822636127472\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005399774545413866, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 7, Loss: 0.12354691326618195\n",
      "Epoch 10, Loss: 0.13668297231197357\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005399774545413866, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 7, Loss: 0.02367968112230301\n",
      "Epoch 7, Loss: 0.053525619208812714\n",
      "Epoch 10, Loss: 0.03361261636018753\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005399774545413866, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 9, Loss: 0.15858711302280426\n",
      "Epoch 8, Loss: 0.05999404564499855\n",
      "Epoch 8, Loss: 0.08107273280620575\n",
      "Epoch 8, Loss: 0.013809910044074059\n",
      "Epoch 10, Loss: 0.15122640132904053\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005399774545413866, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 9, Loss: 0.07833010703325272\n",
      "Epoch 9, Loss: 0.09908031672239304\n",
      "Epoch 9, Loss: 0.012778792530298233\n",
      "Epoch 10, Loss: 0.1291518360376358\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005399774545413866, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.06473389267921448\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005399774545413866, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.03555969521403313\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0005399774545413866, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.179438516497612\n",
      "Epoch 1, Loss: 0.2152358889579773\n",
      "Epoch 1, Loss: 0.21602948009967804\n",
      "Epoch 1, Loss: 0.4386722445487976\n",
      "Epoch 1, Loss: 0.8560212850570679\n",
      "Epoch 2, Loss: 0.6936837434768677\n",
      "Epoch 1, Loss: 0.042214471846818924\n",
      "Epoch 1, Loss: 0.06325137615203857\n",
      "Epoch 2, Loss: 0.26868367195129395\n",
      "Epoch 2, Loss: 0.0968567281961441\n",
      "Epoch 2, Loss: 0.32506707310676575\n",
      "Epoch 1, Loss: 0.2669305205345154\n",
      "Epoch 1, Loss: 0.04963945224881172\n",
      "Epoch 2, Loss: 0.8260918259620667\n",
      "Epoch 3, Loss: 0.13318748772144318\n",
      "Epoch 2, Loss: 0.15287205576896667\n",
      "Epoch 2, Loss: 0.4317672848701477\n",
      "Epoch 3, Loss: 0.1471116691827774\n",
      "Epoch 3, Loss: 0.1567191183567047\n",
      "Epoch 1, Loss: 1.4940273761749268\n",
      "Epoch 1, Loss: 0.22959378361701965\n",
      "Epoch 3, Loss: 0.34924766421318054\n",
      "Epoch 4, Loss: 0.07868010550737381\n",
      "Epoch 2, Loss: 0.10436047613620758\n",
      "Epoch 2, Loss: 0.5663254261016846\n",
      "Epoch 3, Loss: 0.07062317430973053\n",
      "Epoch 3, Loss: 0.2812947928905487\n",
      "Epoch 3, Loss: 0.07181210815906525\n",
      "Epoch 4, Loss: 0.022149642929434776\n",
      "Epoch 1, Loss: 0.2931245267391205\n",
      "Epoch 4, Loss: 0.011356676928699017\n",
      "Epoch 4, Loss: 0.3888358473777771\n",
      "Epoch 5, Loss: 0.24031420052051544\n",
      "Epoch 2, Loss: 0.14455409348011017\n",
      "Epoch 4, Loss: 0.14302822947502136\n",
      "Epoch 4, Loss: 0.1560637503862381\n",
      "Epoch 5, Loss: 0.08568472415208817\n",
      "Epoch 4, Loss: 0.07375794649124146\n",
      "Epoch 5, Loss: 0.06418561935424805\n",
      "Epoch 3, Loss: 0.1894346922636032\n",
      "Epoch 3, Loss: 0.049158599227666855\n",
      "Epoch 6, Loss: 0.21610143780708313\n",
      "Epoch 2, Loss: 0.5582516193389893\n",
      "Epoch 5, Loss: 0.03143927827477455\n",
      "Epoch 5, Loss: 0.21584965288639069\n",
      "Epoch 6, Loss: 0.12645556032657623\n",
      "Epoch 2, Loss: 0.2031116783618927\n",
      "Epoch 3, Loss: 0.2207399159669876\n",
      "Epoch 7, Loss: 0.07980324327945709\n",
      "Epoch 6, Loss: 0.11335243284702301\n",
      "Epoch 5, Loss: 0.19361494481563568\n",
      "Epoch 4, Loss: 0.13546167314052582\n",
      "Epoch 3, Loss: 0.17153918743133545\n",
      "Epoch 5, Loss: 0.35878562927246094\n",
      "Epoch 6, Loss: 0.07141034305095673\n",
      "Epoch 4, Loss: 0.08156690746545792\n",
      "Epoch 7, Loss: 0.07117683440446854\n",
      "Epoch 6, Loss: 0.041966512799263\n",
      "Epoch 8, Loss: 0.014095810241997242\n",
      "Epoch 3, Loss: 0.2136239856481552\n",
      "Epoch 7, Loss: 0.03943251073360443\n",
      "Epoch 7, Loss: 0.09503550827503204\n",
      "Epoch 6, Loss: 0.1408102661371231\n",
      "Epoch 7, Loss: 0.06966982036828995\n",
      "Epoch 8, Loss: 0.01456149946898222\n",
      "Epoch 6, Loss: 0.28744521737098694\n",
      "Epoch 4, Loss: 0.5108866095542908\n",
      "Epoch 5, Loss: 0.019650129601359367\n",
      "Epoch 5, Loss: 0.2629709541797638\n",
      "Epoch 9, Loss: 0.047761596739292145\n",
      "Epoch 4, Loss: 0.0868213102221489\n",
      "Epoch 8, Loss: 0.014145460911095142\n",
      "Epoch 7, Loss: 0.11943402886390686\n",
      "Epoch 8, Loss: 0.08890969306230545\n",
      "Epoch 10, Loss: 0.10691025108098984\n",
      "Epoch 8, Loss: 0.09753657132387161\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0005325529682784314, num_heads=4, num_layers=4; total time=   1.0s\n",
      "Epoch 9, Loss: 0.015320110134780407\n",
      "Epoch 5, Loss: 0.4688737392425537\n",
      "Epoch 4, Loss: 0.039100151509046555\n",
      "Epoch 9, Loss: 0.009989190846681595\n",
      "Epoch 6, Loss: 0.1828191876411438\n",
      "Epoch 6, Loss: 0.05086439475417137\n",
      "Epoch 7, Loss: 0.04240547493100166\n",
      "Epoch 10, Loss: 0.04955170676112175\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0005325529682784314, num_heads=4, num_layers=4; total time=   1.1s\n",
      "Epoch 9, Loss: 0.056118711829185486\n",
      "Epoch 5, Loss: 0.21353496611118317\n",
      "Epoch 8, Loss: 0.01783766597509384\n",
      "Epoch 10, Loss: 0.04285678640007973\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0005325529682784314, num_heads=4, num_layers=4; total time=   1.1s\n",
      "Epoch 9, Loss: 0.1415834277868271\n",
      "Epoch 6, Loss: 0.2844213545322418\n",
      "Epoch 10, Loss: 0.017155122011899948\n",
      "Epoch 8, Loss: 0.015821333974599838\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0005325529682784314, num_heads=4, num_layers=4; total time=   1.2s\n",
      "Epoch 7, Loss: 0.08483964204788208\n",
      "Epoch 9, Loss: 0.0314275398850441\n",
      "Epoch 5, Loss: 0.020469920709729195\n",
      "Epoch 7, Loss: 0.059307750314474106\n",
      "Epoch 10, Loss: 0.13792146742343903\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0005325529682784314, num_heads=4, num_layers=4; total time=   1.2s\n",
      "Epoch 6, Loss: 0.17150692641735077\n",
      "Epoch 9, Loss: 0.05298854038119316\n",
      "Epoch 10, Loss: 0.09686174243688583\n",
      "Epoch 8, Loss: 0.07012474536895752\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0005325529682784314, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 7, Loss: 0.1186390221118927\n",
      "Epoch 6, Loss: 0.09103962779045105\n",
      "Epoch 8, Loss: 0.009684238582849503\n",
      "Epoch 7, Loss: 0.054969459772109985\n",
      "Epoch 10, Loss: 0.08726299554109573\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0005325529682784314, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 9, Loss: 0.0316399447619915\n",
      "Epoch 9, Loss: 0.043601203709840775\n",
      "Epoch 8, Loss: 0.039904672652482986\n",
      "Epoch 8, Loss: 0.017523467540740967\n",
      "Epoch 7, Loss: 0.1018865555524826\n",
      "Epoch 10, Loss: 0.01119979564100504\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0005325529682784314, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 10, Loss: 0.092791847884655\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0005325529682784314, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 9, Loss: 0.04253276810050011\n",
      "Epoch 9, Loss: 0.05805129557847977\n",
      "Epoch 8, Loss: 0.05022181198000908\n",
      "Epoch 10, Loss: 0.08666523545980453\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0005325529682784314, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.09352043271064758\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0005325529682784314, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Epoch 9, Loss: 0.009022319689393044\n",
      "Epoch 10, Loss: 0.011720818467438221\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=512, head_dim=8, lr=0.0005325529682784314, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.42757150530815125\n",
      "Epoch 1, Loss: 0.10100562870502472\n",
      "Epoch 1, Loss: 0.1419329196214676\n",
      "Epoch 2, Loss: 0.16106756031513214\n",
      "Epoch 2, Loss: 0.4222889542579651\n",
      "Epoch 1, Loss: 0.05869358032941818\n",
      "Epoch 2, Loss: 0.28652119636535645\n",
      "Epoch 1, Loss: 0.7098754644393921\n",
      "Epoch 1, Loss: 0.09789974242448807\n",
      "Epoch 1, Loss: 0.8815429210662842\n",
      "Epoch 3, Loss: 0.05133835971355438\n",
      "Epoch 3, Loss: 0.2872787117958069\n",
      "Epoch 1, Loss: 0.9453753232955933\n",
      "Epoch 1, Loss: 1.1455949544906616\n",
      "Epoch 3, Loss: 0.12386123090982437\n",
      "Epoch 2, Loss: 0.5961736440658569\n",
      "Epoch 2, Loss: 0.07533661276102066\n",
      "Epoch 2, Loss: 0.4912707209587097\n",
      "Epoch 1, Loss: 0.24242231249809265\n",
      "Epoch 4, Loss: 0.13441847264766693\n",
      "Epoch 2, Loss: 0.0687764510512352\n",
      "Epoch 4, Loss: 0.13938239216804504\n",
      "Epoch 1, Loss: 0.16440542042255402\n",
      "Epoch 1, Loss: 0.19122813642024994\n",
      "Epoch 4, Loss: 0.012831002473831177\n",
      "Epoch 3, Loss: 0.057639285922050476\n",
      "Epoch 5, Loss: 0.20657941699028015\n",
      "Epoch 3, Loss: 0.0588017962872982\n",
      "Epoch 5, Loss: 0.022639472037553787\n",
      "Epoch 3, Loss: 0.34816974401474\n",
      "Epoch 2, Loss: 0.18804574012756348\n",
      "Epoch 2, Loss: 0.05113302543759346\n",
      "Epoch 3, Loss: 0.4293511211872101\n",
      "Epoch 6, Loss: 0.04619051516056061\n",
      "Epoch 4, Loss: 0.12294816970825195\n",
      "Epoch 2, Loss: 0.23903079330921173\n",
      "Epoch 5, Loss: 0.08678458631038666\n",
      "Epoch 2, Loss: 0.3826424479484558\n",
      "Epoch 4, Loss: 0.14757829904556274\n",
      "Epoch 2, Loss: 0.3144991993904114\n",
      "Epoch 6, Loss: 0.11118333786725998\n",
      "Epoch 3, Loss: 0.3644237220287323\n",
      "Epoch 4, Loss: 0.3171358108520508\n",
      "Epoch 3, Loss: 0.37126532196998596\n",
      "Epoch 7, Loss: 0.1022341400384903\n",
      "Epoch 4, Loss: 0.3829708695411682\n",
      "Epoch 6, Loss: 0.11734005063772202\n",
      "Epoch 5, Loss: 0.27995556592941284\n",
      "Epoch 7, Loss: 0.024530116468667984\n",
      "Epoch 5, Loss: 0.23520231246948242\n",
      "Epoch 3, Loss: 0.13231948018074036\n",
      "Epoch 5, Loss: 0.14282509684562683\n",
      "Epoch 3, Loss: 0.0527983196079731\n",
      "Epoch 8, Loss: 0.09906451404094696\n",
      "Epoch 3, Loss: 0.16719816625118256\n",
      "Epoch 4, Loss: 0.47460004687309265\n",
      "Epoch 8, Loss: 0.02319391258060932\n",
      "Epoch 7, Loss: 0.05882307514548302\n",
      "Epoch 4, Loss: 0.43293944001197815\n",
      "Epoch 6, Loss: 0.19987870752811432\n",
      "Epoch 5, Loss: 0.1522778570652008\n",
      "Epoch 6, Loss: 0.11649206280708313\n",
      "Epoch 9, Loss: 0.04813831299543381\n",
      "Epoch 6, Loss: 0.04128221422433853\n",
      "Epoch 9, Loss: 0.0722930058836937\n",
      "Epoch 4, Loss: 0.009320962242782116\n",
      "Epoch 8, Loss: 0.010587622411549091\n",
      "Epoch 7, Loss: 0.058814603835344315\n",
      "Epoch 4, Loss: 0.1303108036518097\n",
      "Epoch 5, Loss: 0.2372448593378067\n",
      "Epoch 5, Loss: 0.3392227292060852\n",
      "Epoch 7, Loss: 0.021887408569455147\n",
      "Epoch 4, Loss: 0.02966134063899517\n",
      "Epoch 10, Loss: 0.008679835125803947\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0005092912372832396, num_heads=4, num_layers=2; total time=   1.1s\n",
      "Epoch 6, Loss: 0.028013527393341064\n",
      "Epoch 10, Loss: 0.09132587164640427\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0005092912372832396, num_heads=4, num_layers=2; total time=   1.1s\n",
      "Epoch 7, Loss: 0.0565500482916832\n",
      "Epoch 9, Loss: 0.020611830055713654\n",
      "Epoch 5, Loss: 0.0840093269944191\n",
      "Epoch 8, Loss: 0.007784770801663399\n",
      "Epoch 6, Loss: 0.06808020919561386\n",
      "Epoch 8, Loss: 0.11625171452760696\n",
      "Epoch 5, Loss: 0.1165945753455162\n",
      "Epoch 8, Loss: 0.03752323240041733\n",
      "Epoch 7, Loss: 0.050938766449689865\n",
      "Epoch 6, Loss: 0.16329000890254974\n",
      "Epoch 5, Loss: 0.055452194064855576\n",
      "Epoch 9, Loss: 0.05544601380825043\n",
      "Epoch 10, Loss: 0.050415486097335815\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0005092912372832396, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 9, Loss: 0.13860680162906647\n",
      "Epoch 9, Loss: 0.0915394127368927\n",
      "Epoch 7, Loss: 0.034538011997938156\n",
      "Epoch 6, Loss: 0.11915869265794754\n",
      "Epoch 6, Loss: 0.14476260542869568\n",
      "Epoch 7, Loss: 0.06097927317023277\n",
      "Epoch 8, Loss: 0.12650907039642334\n",
      "Epoch 6, Loss: 0.02348315715789795\n",
      "Epoch 10, Loss: 0.11316078156232834\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0005092912372832396, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 10, Loss: 0.11255384981632233\n",
      "Epoch 10, Loss: 0.1052466332912445\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0005092912372832396, num_heads=4, num_layers=2; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0005092912372832396, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 7, Loss: 0.0638246089220047\n",
      "Epoch 8, Loss: 0.09652923047542572\n",
      "Epoch 9, Loss: 0.157596156001091\n",
      "Epoch 8, Loss: 0.055520981550216675\n",
      "Epoch 7, Loss: 0.07311420887708664\n",
      "Epoch 7, Loss: 0.07322485744953156\n",
      "Epoch 10, Loss: 0.1297258734703064\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0005092912372832396, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 9, Loss: 0.15996283292770386\n",
      "Epoch 8, Loss: 0.010740203782916069\n",
      "Epoch 9, Loss: 0.10411210358142853\n",
      "Epoch 8, Loss: 0.06749293953180313\n",
      "Epoch 8, Loss: 0.012960460036993027\n",
      "Epoch 10, Loss: 0.16367562115192413\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0005092912372832396, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 0.011298353783786297\n",
      "Epoch 10, Loss: 0.14259827136993408\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0005092912372832396, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 0.0296600554138422\n",
      "Epoch 9, Loss: 0.02021721564233303\n",
      "Epoch 10, Loss: 0.04367465898394585\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0005092912372832396, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.025743622332811356\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0005092912372832396, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.05562152713537216\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0005092912372832396, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.24168622493743896\n",
      "Epoch 1, Loss: 0.02524910680949688\n",
      "Epoch 1, Loss: 1.759515404701233\n",
      "Epoch 1, Loss: 0.04541332274675369\n",
      "Epoch 1, Loss: 2.0858986377716064\n",
      "Epoch 1, Loss: 2.5253729820251465\n",
      "Epoch 2, Loss: 0.43678978085517883\n",
      "Epoch 1, Loss: 0.13882021605968475\n",
      "Epoch 2, Loss: 0.6319466829299927\n",
      "Epoch 1, Loss: 0.16392840445041656\n",
      "Epoch 2, Loss: 0.26729321479797363\n",
      "Epoch 2, Loss: 0.46392548084259033\n",
      "Epoch 1, Loss: 0.24763420224189758\n",
      "Epoch 3, Loss: 0.10939792543649673\n",
      "Epoch 2, Loss: 0.5268116593360901\n",
      "Epoch 2, Loss: 0.6275200843811035\n",
      "Epoch 2, Loss: 0.5296148061752319\n",
      "Epoch 3, Loss: 0.042168743908405304\n",
      "Epoch 4, Loss: 0.10215257853269577\n",
      "Epoch 3, Loss: 0.16906216740608215\n",
      "Epoch 3, Loss: 0.010443895123898983\n",
      "Epoch 2, Loss: 0.6105307340621948\n",
      "Epoch 3, Loss: 0.08037842065095901\n",
      "Epoch 4, Loss: 0.15532806515693665\n",
      "Epoch 2, Loss: 0.25073960423469543\n",
      "Epoch 3, Loss: 0.08393853902816772\n",
      "Epoch 5, Loss: 0.17840394377708435\n",
      "Epoch 4, Loss: 0.23045668005943298\n",
      "Epoch 4, Loss: 0.4825194776058197\n",
      "Epoch 3, Loss: 0.098537378013134\n",
      "Epoch 6, Loss: 0.09383592009544373\n",
      "Epoch 1, Loss: 0.19057148694992065\n",
      "Epoch 4, Loss: 0.2632353603839874\n",
      "Epoch 5, Loss: 0.3132983446121216\n",
      "Epoch 3, Loss: 0.1409703940153122\n",
      "Epoch 3, Loss: 0.0920223519206047\n",
      "Epoch 4, Loss: 0.19611713290214539\n",
      "Epoch 1, Loss: 0.4356236159801483\n",
      "Epoch 5, Loss: 0.23701980710029602\n",
      "Epoch 5, Loss: 0.524794340133667\n",
      "Epoch 1, Loss: 0.18526390194892883\n",
      "Epoch 7, Loss: 0.015713222324848175\n",
      "Epoch 6, Loss: 0.2161940187215805\n",
      "Epoch 5, Loss: 0.4764697849750519\n",
      "Epoch 4, Loss: 0.46834462881088257\n",
      "Epoch 2, Loss: 0.28755033016204834\n",
      "Epoch 5, Loss: 0.3061681389808655\n",
      "Epoch 6, Loss: 0.07914231717586517\n",
      "Epoch 4, Loss: 0.10185033082962036\n",
      "Epoch 8, Loss: 0.02770848013460636\n",
      "Epoch 6, Loss: 0.36598682403564453\n",
      "Epoch 2, Loss: 0.4547297954559326\n",
      "Epoch 4, Loss: 0.13267283141613007\n",
      "Epoch 6, Loss: 0.500910758972168\n",
      "Epoch 5, Loss: 0.6479037404060364\n",
      "Epoch 7, Loss: 0.06703956425189972\n",
      "Epoch 7, Loss: 0.007215521764010191\n",
      "Epoch 2, Loss: 0.21310558915138245\n",
      "Epoch 5, Loss: 0.25271984934806824\n",
      "Epoch 3, Loss: 0.1661655753850937\n",
      "Epoch 6, Loss: 0.1591658890247345\n",
      "Epoch 9, Loss: 0.06908198446035385\n",
      "Epoch 7, Loss: 0.18156690895557404\n",
      "Epoch 8, Loss: 0.008294234983623028\n",
      "Epoch 6, Loss: 0.5418660044670105\n",
      "Epoch 8, Loss: 0.05464419350028038\n",
      "Epoch 7, Loss: 0.39480307698249817\n",
      "Epoch 3, Loss: 0.16090284287929535\n",
      "Epoch 10, Loss: 0.07411317527294159\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.000504099995277545, num_heads=4, num_layers=2; total time=   1.1s\n",
      "Epoch 5, Loss: 0.0583285354077816\n",
      "Epoch 6, Loss: 0.19320130348205566\n",
      "Epoch 7, Loss: 0.032497894018888474\n",
      "Epoch 3, Loss: 0.26443877816200256\n",
      "Epoch 9, Loss: 0.045779548585414886\n",
      "Epoch 9, Loss: 0.11121991276741028\n",
      "Epoch 8, Loss: 0.06588689237833023\n",
      "Epoch 4, Loss: 0.0070517719723284245\n",
      "Epoch 7, Loss: 0.3269353210926056\n",
      "Epoch 8, Loss: 0.2516978681087494\n",
      "Epoch 6, Loss: 0.024669578298926353\n",
      "Epoch 7, Loss: 0.06306997686624527\n",
      "Epoch 10, Loss: 0.10357459634542465\n",
      "Epoch 9, Loss: 0.041591182351112366\n",
      "Epoch 10, Loss: 0.10229592770338058\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.000504099995277545, num_heads=4, num_layers=2; total time=   1.2s\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.000504099995277545, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 8, Loss: 0.046460237354040146\n",
      "Epoch 4, Loss: 0.01466494332998991\n",
      "Epoch 8, Loss: 0.14232897758483887\n",
      "Epoch 5, Loss: 0.06309140473604202\n",
      "Epoch 9, Loss: 0.130241259932518\n",
      "Epoch 4, Loss: 0.11237740516662598\n",
      "Epoch 10, Loss: 0.08309166878461838\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.000504099995277545, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 8, Loss: 0.022656679153442383\n",
      "Epoch 9, Loss: 0.11806899309158325\n",
      "Epoch 7, Loss: 0.0586383081972599\n",
      "Epoch 10, Loss: 0.0602802149951458\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.000504099995277545, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 9, Loss: 0.04505061358213425\n",
      "Epoch 6, Loss: 0.12578271329402924\n",
      "Epoch 5, Loss: 0.14168396592140198\n",
      "Epoch 10, Loss: 0.1346203088760376\n",
      "Epoch 5, Loss: 0.0359501875936985\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.000504099995277545, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 9, Loss: 0.06399573385715485\n",
      "Epoch 10, Loss: 0.045299138873815536\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.000504099995277545, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 7, Loss: 0.083462193608284\n",
      "Epoch 8, Loss: 0.042992349714040756\n",
      "Epoch 6, Loss: 0.1694922149181366\n",
      "Epoch 6, Loss: 0.07362928241491318\n",
      "Epoch 10, Loss: 0.10257020592689514\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.000504099995277545, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 8, Loss: 0.019596759229898453\n",
      "Epoch 9, Loss: 0.009186827577650547\n",
      "Epoch 7, Loss: 0.10299772024154663\n",
      "Epoch 7, Loss: 0.07926063984632492\n",
      "Epoch 9, Loss: 0.008094328455626965\n",
      "Epoch 10, Loss: 0.017850730568170547\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.000504099995277545, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 8, Loss: 0.06906533986330032\n",
      "Epoch 8, Loss: 0.009404285810887814\n",
      "Epoch 10, Loss: 0.0402052104473114\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.000504099995277545, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 0.021181516349315643\n",
      "Epoch 9, Loss: 0.02468373253941536\n",
      "Epoch 10, Loss: 0.013152020052075386\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.000504099995277545, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.07159928232431412\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=16, lr=0.000504099995277545, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 1.7218878269195557\n",
      "Epoch 1, Loss: 3.2160122394561768\n",
      "Epoch 1, Loss: 2.526401996612549\n",
      "Epoch 2, Loss: 0.24106542766094208\n",
      "Epoch 1, Loss: 0.3796577751636505\n",
      "Epoch 2, Loss: 1.0465093851089478\n",
      "Epoch 1, Loss: 0.22552421689033508\n",
      "Epoch 2, Loss: 0.6547957062721252\n",
      "Epoch 1, Loss: 2.2306013107299805\n",
      "Epoch 1, Loss: 0.033408477902412415\n",
      "Epoch 2, Loss: 0.08349160850048065\n",
      "Epoch 3, Loss: 0.13312390446662903\n",
      "Epoch 1, Loss: 1.0507258176803589\n",
      "Epoch 3, Loss: 0.2506229877471924\n",
      "Epoch 1, Loss: 1.8733720779418945\n",
      "Epoch 1, Loss: 0.1231587752699852\n",
      "Epoch 2, Loss: 0.16124069690704346\n",
      "Epoch 3, Loss: 0.04230369254946709\n",
      "Epoch 2, Loss: 0.4383975565433502\n",
      "Epoch 2, Loss: 0.44754642248153687\n",
      "Epoch 3, Loss: 0.2601870000362396\n",
      "Epoch 1, Loss: 0.19853925704956055\n",
      "Epoch 4, Loss: 0.42834529280662537\n",
      "Epoch 1, Loss: 1.085803747177124\n",
      "Epoch 4, Loss: 0.24968649446964264\n",
      "Epoch 4, Loss: 0.3552594482898712\n",
      "Epoch 2, Loss: 0.05520991235971451\n",
      "Epoch 3, Loss: 0.16054485738277435\n",
      "Epoch 2, Loss: 0.2930700480937958\n",
      "Epoch 3, Loss: 0.03661437705159187\n",
      "Epoch 2, Loss: 0.5562543869018555\n",
      "Epoch 5, Loss: 0.503136396408081\n",
      "Epoch 4, Loss: 0.1286308467388153\n",
      "Epoch 3, Loss: 0.06273142993450165\n",
      "Epoch 5, Loss: 0.512301504611969\n",
      "Epoch 5, Loss: 0.5762156844139099\n",
      "Epoch 4, Loss: 0.03024626336991787\n",
      "Epoch 6, Loss: 0.3840257525444031\n",
      "Epoch 2, Loss: 0.33995506167411804\n",
      "Epoch 3, Loss: 0.17880785465240479\n",
      "Epoch 2, Loss: 0.0461592972278595\n",
      "Epoch 6, Loss: 0.5297422409057617\n",
      "Epoch 3, Loss: 0.2098691612482071\n",
      "Epoch 4, Loss: 0.3399006426334381\n",
      "Epoch 6, Loss: 0.6198961138725281\n",
      "Epoch 4, Loss: 0.06891145557165146\n",
      "Epoch 3, Loss: 0.0856591984629631\n",
      "Epoch 5, Loss: 0.0146413529291749\n",
      "Epoch 5, Loss: 0.029582057148218155\n",
      "Epoch 7, Loss: 0.2166437953710556\n",
      "Epoch 4, Loss: 0.36946624517440796\n",
      "Epoch 7, Loss: 0.40286922454833984\n",
      "Epoch 5, Loss: 0.5615730285644531\n",
      "Epoch 7, Loss: 0.5096355080604553\n",
      "Epoch 6, Loss: 0.034700069576501846\n",
      "Epoch 3, Loss: 0.25871971249580383\n",
      "Epoch 3, Loss: 0.15390709042549133\n",
      "Epoch 4, Loss: 0.5546330213546753\n",
      "Epoch 8, Loss: 0.08575382083654404\n",
      "Epoch 6, Loss: 0.08443612605333328\n",
      "Epoch 5, Loss: 0.2010093629360199\n",
      "Epoch 4, Loss: 0.11805901676416397\n",
      "Epoch 5, Loss: 0.31996020674705505\n",
      "Epoch 8, Loss: 0.3420480489730835\n",
      "Epoch 8, Loss: 0.24370595812797546\n",
      "Epoch 6, Loss: 0.5420601963996887\n",
      "Epoch 7, Loss: 0.09566514939069748\n",
      "Epoch 9, Loss: 0.025730835273861885\n",
      "Epoch 7, Loss: 0.07866296172142029\n",
      "Epoch 4, Loss: 0.03608408197760582\n",
      "Epoch 5, Loss: 0.5772459506988525\n",
      "Epoch 4, Loss: 0.45010966062545776Epoch 6, Loss: 0.14176663756370544\n",
      "\n",
      "Epoch 5, Loss: 0.23826028406620026\n",
      "Epoch 9, Loss: 0.1866457611322403\n",
      "Epoch 6, Loss: 0.16757144033908844\n",
      "Epoch 8, Loss: 0.1027148887515068\n",
      "Epoch 10, Loss: 0.03599989786744118\n",
      "Epoch 9, Loss: 0.11388116329908371\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.0004987240826926053, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 7, Loss: 0.38897621631622314\n",
      "Epoch 8, Loss: 0.03358541429042816\n",
      "Epoch 10, Loss: 0.0897035002708435\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.0004987240826926053, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 7, Loss: 0.03729904070496559\n",
      "Epoch 6, Loss: 0.3946892023086548\n",
      "Epoch 5, Loss: 0.09527325630187988\n",
      "Epoch 9, Loss: 0.057364728301763535\n",
      "Epoch 10, Loss: 0.042032815515995026\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.0004987240826926053, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 7, Loss: 0.051458850502967834Epoch 5, Loss: 0.3129304349422455\n",
      "\n",
      "Epoch 6, Loss: 0.1265736222267151\n",
      "Epoch 8, Loss: 0.214274600148201\n",
      "Epoch 9, Loss: 0.009029194712638855\n",
      "Epoch 10, Loss: 0.014582144096493721\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.0004987240826926053, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 8, Loss: 0.010364962741732597\n",
      "Epoch 7, Loss: 0.19440187513828278\n",
      "Epoch 9, Loss: 0.08408130705356598\n",
      "Epoch 6, Loss: 0.11556803435087204\n",
      "Epoch 10, Loss: 0.021964237093925476\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.0004987240826926053, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 8, Loss: 0.016132941469550133\n",
      "Epoch 6, Loss: 0.1164955273270607\n",
      "Epoch 7, Loss: 0.01979418657720089\n",
      "Epoch 9, Loss: 0.048638224601745605\n",
      "Epoch 10, Loss: 0.02396063506603241\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.0004987240826926053, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 8, Loss: 0.0767207071185112\n",
      "Epoch 9, Loss: 0.04881969466805458\n",
      "Epoch 8, Loss: 0.023437375202775\n",
      "Epoch 7, Loss: 0.05460750311613083\n",
      "Epoch 7, Loss: 0.017998024821281433\n",
      "Epoch 10, Loss: 0.08523871004581451\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.0004987240826926053, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 9, Loss: 0.052637308835983276\n",
      "Epoch 10, Loss: 0.1006728932261467\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.0004987240826926053, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 8, Loss: 0.03043898195028305\n",
      "Epoch 8, Loss: 0.009093082509934902\n",
      "Epoch 9, Loss: 0.07769782841205597\n",
      "Epoch 10, Loss: 0.0903674066066742\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.0004987240826926053, num_heads=4, num_layers=2; total time=   1.7s\n",
      "Epoch 9, Loss: 0.09550034254789352\n",
      "Epoch 9, Loss: 0.021513409912586212\n",
      "Epoch 10, Loss: 0.10172533988952637\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.0004987240826926053, num_heads=4, num_layers=2; total time=   1.8s\n",
      "Epoch 10, Loss: 0.05505194514989853\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.0004987240826926053, num_heads=4, num_layers=2; total time=   1.8s\n",
      "Epoch 10, Loss: 0.14126287400722504\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.0004987240826926053, num_heads=4, num_layers=2; total time=   1.8s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.164525106549263\n",
      "Epoch 1, Loss: 0.28072431683540344\n",
      "Epoch 2, Loss: 0.23086482286453247\n",
      "Epoch 2, Loss: 0.3278852105140686\n",
      "Epoch 1, Loss: 0.29048508405685425\n",
      "Epoch 1, Loss: 0.2696937024593353\n",
      "Epoch 1, Loss: 0.10970190912485123\n",
      "Epoch 1, Loss: 1.6064705848693848\n",
      "Epoch 3, Loss: 0.19442453980445862\n",
      "Epoch 2, Loss: 0.08060220628976822\n",
      "Epoch 1, Loss: 0.15137289464473724\n",
      "Epoch 1, Loss: 0.36689475178718567\n",
      "Epoch 3, Loss: 0.10547793656587601\n",
      "Epoch 2, Loss: 0.2646891176700592\n",
      "Epoch 2, Loss: 0.25377118587493896\n",
      "Epoch 1, Loss: 0.11885412782430649\n",
      "Epoch 4, Loss: 0.03445924073457718\n",
      "Epoch 1, Loss: 0.06335099041461945\n",
      "Epoch 2, Loss: 0.5318520069122314\n",
      "Epoch 3, Loss: 0.18587379157543182\n",
      "Epoch 1, Loss: 0.3526993989944458\n",
      "Epoch 4, Loss: 0.008449457585811615\n",
      "Epoch 2, Loss: 0.5178262591362\n",
      "Epoch 2, Loss: 0.08645223081111908\n",
      "Epoch 5, Loss: 0.07270616292953491\n",
      "Epoch 1, Loss: 0.4907405972480774\n",
      "Epoch 3, Loss: 0.4330710470676422\n",
      "Epoch 3, Loss: 0.20264217257499695\n",
      "Epoch 4, Loss: 0.10465604066848755\n",
      "Epoch 2, Loss: 0.4143776595592499\n",
      "Epoch 5, Loss: 0.06579349935054779\n",
      "Epoch 3, Loss: 0.06938998401165009\n",
      "Epoch 2, Loss: 0.3809209167957306\n",
      "Epoch 6, Loss: 0.12094009667634964\n",
      "Epoch 6, Loss: 0.09567614644765854\n",
      "Epoch 3, Loss: 0.1453968733549118\n",
      "Epoch 4, Loss: 0.03798346966505051\n",
      "Epoch 5, Loss: 0.02797219716012478\n",
      "Epoch 2, Loss: 0.08043777942657471\n",
      "Epoch 4, Loss: 0.13893172144889832\n",
      "Epoch 3, Loss: 0.2258615642786026\n",
      "Epoch 4, Loss: 0.6310308575630188\n",
      "Epoch 2, Loss: 0.31231704354286194\n",
      "Epoch 3, Loss: 0.05817101523280144\n",
      "Epoch 7, Loss: 0.07897781580686569\n",
      "Epoch 7, Loss: 0.05394604429602623\n",
      "Epoch 3, Loss: 0.10197824984788895\n",
      "Epoch 6, Loss: 0.0326385460793972\n",
      "Epoch 5, Loss: 0.24472254514694214\n",
      "Epoch 5, Loss: 0.0536385178565979\n",
      "Epoch 4, Loss: 0.06884529441595078\n",
      "Epoch 8, Loss: 0.01113086473196745\n",
      "Epoch 5, Loss: 0.4915851354598999\n",
      "Epoch 3, Loss: 0.3603501319885254\n",
      "Epoch 8, Loss: 0.020265726372599602\n",
      "Epoch 3, Loss: 0.2262924164533615\n",
      "Epoch 4, Loss: 0.12320715188980103\n",
      "Epoch 4, Loss: 0.06627336144447327\n",
      "Epoch 7, Loss: 0.06733870506286621\n",
      "Epoch 9, Loss: 0.012220527976751328\n",
      "Epoch 6, Loss: 0.14576536417007446\n",
      "Epoch 4, Loss: 0.025778213515877724\n",
      "Epoch 6, Loss: 0.11471886932849884\n",
      "Epoch 9, Loss: 0.014305810444056988\n",
      "Epoch 5, Loss: 0.20749101042747498\n",
      "Epoch 8, Loss: 0.07042767852544785\n",
      "Epoch 10, Loss: 0.036966145038604736\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005019503823036697, num_heads=4, num_layers=2; total time=   0.9s\n",
      "Epoch 6, Loss: 0.24932552874088287\n",
      "Epoch 5, Loss: 0.023164482787251472\n",
      "Epoch 4, Loss: 0.11487551033496857\n",
      "Epoch 7, Loss: 0.033628713339567184\n",
      "Epoch 4, Loss: 0.1413305252790451\n",
      "Epoch 10, Loss: 0.04827113822102547\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005019503823036697, num_heads=4, num_layers=2; total time=   1.0s\n",
      "Epoch 9, Loss: 0.04125041142106056\n",
      "Epoch 5, Loss: 0.16431915760040283\n",
      "Epoch 6, Loss: 0.17338654398918152\n",
      "Epoch 5, Loss: 0.1455935686826706\n",
      "Epoch 6, Loss: 0.02705925516784191\n",
      "Epoch 7, Loss: 0.0927366241812706\n",
      "Epoch 7, Loss: 0.08860011398792267\n",
      "Epoch 8, Loss: 0.0202241912484169\n",
      "Epoch 10, Loss: 0.01374853402376175\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005019503823036697, num_heads=4, num_layers=2; total time=   1.0s\n",
      "Epoch 5, Loss: 0.04871419817209244\n",
      "Epoch 5, Loss: 0.01508220937103033\n",
      "Epoch 7, Loss: 0.06404558569192886\n",
      "Epoch 6, Loss: 0.11084021627902985\n",
      "Epoch 8, Loss: 0.054267868399620056\n",
      "Epoch 6, Loss: 0.14136095345020294\n",
      "Epoch 7, Loss: 0.07077427208423615\n",
      "Epoch 8, Loss: 0.032560084015131\n",
      "Epoch 9, Loss: 0.0724254697561264\n",
      "Epoch 8, Loss: 0.02086692303419113\n",
      "Epoch 6, Loss: 0.10704516619443893\n",
      "Epoch 7, Loss: 0.02736416459083557\n",
      "Epoch 6, Loss: 0.02779458463191986\n",
      "Epoch 9, Loss: 0.10658304393291473\n",
      "Epoch 7, Loss: 0.05292725935578346\n",
      "Epoch 8, Loss: 0.0756891593337059\n",
      "Epoch 10, Loss: 0.1030299961566925\n",
      "Epoch 9, Loss: 0.010072463192045689\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005019503823036697, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 9, Loss: 0.05207592248916626\n",
      "Epoch 10, Loss: 0.17093750834465027\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005019503823036697, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 8, Loss: 0.010496527887880802\n",
      "Epoch 7, Loss: 0.07931405305862427\n",
      "Epoch 10, Loss: 0.03469109907746315\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005019503823036697, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 9, Loss: 0.047021497040987015\n",
      "Epoch 8, Loss: 0.006420678459107876\n",
      "Epoch 7, Loss: 0.14590992033481598\n",
      "Epoch 10, Loss: 0.08965931832790375\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005019503823036697, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 9, Loss: 0.0448828861117363\n",
      "Epoch 9, Loss: 0.029935486614704132\n",
      "Epoch 8, Loss: 0.10251860320568085\n",
      "Epoch 10, Loss: 0.013989252038300037\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005019503823036697, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 8, Loss: 0.08406129479408264\n",
      "Epoch 10, Loss: 0.0733235701918602\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005019503823036697, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.06773587316274643\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005019503823036697, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 0.03746241703629494\n",
      "Epoch 9, Loss: 0.048469725996255875\n",
      "Epoch 10, Loss: 0.014184253290295601\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005019503823036697, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.01131441630423069\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=256, head_dim=16, lr=0.0005019503823036697, num_heads=4, num_layers=2; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 1.4380037784576416\n",
      "Epoch 1, Loss: 0.45078301429748535\n",
      "Epoch 1, Loss: 0.228165864944458\n",
      "Epoch 1, Loss: 0.03925478830933571\n",
      "Epoch 1, Loss: 0.07696013897657394\n",
      "Epoch 1, Loss: 0.6030438542366028\n",
      "Epoch 2, Loss: 0.27102407813072205\n",
      "Epoch 1, Loss: 0.20236194133758545\n",
      "Epoch 1, Loss: 0.24705618619918823\n",
      "Epoch 1, Loss: 1.767648696899414\n",
      "Epoch 2, Loss: 0.2159789353609085\n",
      "Epoch 2, Loss: 0.17399220168590546\n",
      "Epoch 2, Loss: 0.485917329788208\n",
      "Epoch 2, Loss: 0.4689098000526428\n",
      "Epoch 3, Loss: 0.1369086503982544\n",
      "Epoch 2, Loss: 0.07732567936182022\n",
      "Epoch 3, Loss: 0.3344178795814514\n",
      "Epoch 1, Loss: 0.13716256618499756\n",
      "Epoch 2, Loss: 0.22273927927017212\n",
      "Epoch 2, Loss: 0.41679635643959045\n",
      "Epoch 1, Loss: 0.6998955011367798\n",
      "Epoch 2, Loss: 0.5332823991775513\n",
      "Epoch 4, Loss: 0.39376896619796753\n",
      "Epoch 3, Loss: 0.16181743144989014\n",
      "Epoch 3, Loss: 0.057021159678697586\n",
      "Epoch 1, Loss: 0.10914763063192368\n",
      "Epoch 3, Loss: 0.07199156284332275\n",
      "Epoch 3, Loss: 0.2941230833530426\n",
      "Epoch 4, Loss: 0.12266146391630173\n",
      "Epoch 2, Loss: 0.18582837283611298\n",
      "Epoch 3, Loss: 0.05646558851003647\n",
      "Epoch 4, Loss: 0.05420356243848801\n",
      "Epoch 5, Loss: 0.4704947769641876\n",
      "Epoch 3, Loss: 0.17366203665733337\n",
      "Epoch 4, Loss: 0.10899952054023743\n",
      "Epoch 4, Loss: 0.0854090079665184\n",
      "Epoch 3, Loss: 0.13387975096702576\n",
      "Epoch 2, Loss: 0.06373652070760727\n",
      "Epoch 5, Loss: 0.016476323828101158\n",
      "Epoch 2, Loss: 0.43860045075416565\n",
      "Epoch 6, Loss: 0.36056289076805115\n",
      "Epoch 4, Loss: 0.28920942544937134\n",
      "Epoch 5, Loss: 0.22237202525138855\n",
      "Epoch 5, Loss: 0.03362203389406204\n",
      "Epoch 5, Loss: 0.21583278477191925\n",
      "Epoch 6, Loss: 0.08079738169908524\n",
      "Epoch 4, Loss: 0.2962089478969574\n",
      "Epoch 3, Loss: 0.11989052593708038\n",
      "Epoch 4, Loss: 0.10470083355903625\n",
      "Epoch 7, Loss: 0.20342524349689484\n",
      "Epoch 4, Loss: 0.05725644528865814\n",
      "Epoch 5, Loss: 0.13678178191184998\n",
      "Epoch 6, Loss: 0.13862387835979462\n",
      "Epoch 6, Loss: 0.07249002158641815\n",
      "Epoch 8, Loss: 0.08442461490631104\n",
      "Epoch 7, Loss: 0.14106963574886322\n",
      "Epoch 6, Loss: 0.14687472581863403\n",
      "Epoch 3, Loss: 0.08034636825323105\n",
      "Epoch 3, Loss: 0.32414743304252625\n",
      "Epoch 5, Loss: 0.48770561814308167\n",
      "Epoch 5, Loss: 0.06258377432823181\n",
      "Epoch 7, Loss: 0.03493344038724899\n",
      "Epoch 5, Loss: 0.21115660667419434\n",
      "Epoch 7, Loss: 0.06681010127067566\n",
      "Epoch 6, Loss: 0.0389380156993866\n",
      "Epoch 4, Loss: 0.02468051202595234\n",
      "Epoch 8, Loss: 0.10810653865337372\n",
      "Epoch 7, Loss: 0.03605042025446892\n",
      "Epoch 9, Loss: 0.04087238013744354\n",
      "Epoch 6, Loss: 0.4688112139701843\n",
      "Epoch 4, Loss: 0.3214007019996643\n",
      "Epoch 8, Loss: 0.01715121790766716\n",
      "Epoch 9, Loss: 0.04017617180943489\n",
      "Epoch 4, Loss: 0.07664395123720169\n",
      "Epoch 5, Loss: 0.0479084737598896\n",
      "Epoch 6, Loss: 0.09584392607212067\n",
      "Epoch 10, Loss: 0.057085566222667694\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004650399893788239, num_heads=8, num_layers=4; total time=   1.4s\n",
      "Epoch 8, Loss: 0.028135888278484344\n",
      "Epoch 7, Loss: 0.04395637288689613\n",
      "Epoch 6, Loss: 0.1533743441104889\n",
      "Epoch 8, Loss: 0.013325204141438007\n",
      "Epoch 10, Loss: 0.0077845933847129345\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004650399893788239, num_heads=8, num_layers=4; total time=   1.4s\n",
      "Epoch 9, Loss: 0.06068083271384239\n",
      "Epoch 9, Loss: 0.009802337735891342\n",
      "Epoch 7, Loss: 0.3299786448478699\n",
      "Epoch 5, Loss: 0.15007175505161285\n",
      "Epoch 6, Loss: 0.08280302584171295\n",
      "Epoch 5, Loss: 0.182644322514534\n",
      "Epoch 7, Loss: 0.07183563709259033\n",
      "Epoch 9, Loss: 0.058061353862285614\n",
      "Epoch 8, Loss: 0.09728506207466125\n",
      "Epoch 7, Loss: 0.04796912893652916\n",
      "Epoch 10, Loss: 0.09269499778747559\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004650399893788239, num_heads=8, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.025875231251120567\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004650399893788239, num_heads=8, num_layers=4; total time=   1.6s\n",
      "Epoch 10, Loss: 0.09101305902004242\n",
      "Epoch 8, Loss: 0.17861080169677734\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004650399893788239, num_heads=8, num_layers=4; total time=   1.6s\n",
      "Epoch 8, Loss: 0.02585473097860813\n",
      "Epoch 9, Loss: 0.12293842434883118\n",
      "Epoch 6, Loss: 0.03626522794365883\n",
      "Epoch 8, Loss: 0.01913653314113617\n",
      "Epoch 7, Loss: 0.05084724724292755\n",
      "Epoch 6, Loss: 0.1322752684354782\n",
      "Epoch 9, Loss: 0.07497480511665344\n",
      "Epoch 10, Loss: 0.1007104441523552\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004650399893788239, num_heads=8, num_layers=4; total time=   1.7s\n",
      "Epoch 9, Loss: 0.01626138761639595\n",
      "Epoch 9, Loss: 0.058137763291597366\n",
      "Epoch 7, Loss: 0.0416032150387764\n",
      "Epoch 8, Loss: 0.014520461671054363\n",
      "Epoch 10, Loss: 0.03340480849146843\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004650399893788239, num_heads=8, num_layers=4; total time=   1.8s\n",
      "Epoch 7, Loss: 0.03773524612188339\n",
      "Epoch 10, Loss: 0.08834464102983475\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004650399893788239, num_heads=8, num_layers=4; total time=   1.9s\n",
      "Epoch 10, Loss: 0.03892398625612259\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004650399893788239, num_heads=8, num_layers=4; total time=   1.9s\n",
      "Epoch 9, Loss: 0.01160605438053608\n",
      "Epoch 8, Loss: 0.0981069952249527\n",
      "Epoch 8, Loss: 0.013328302651643753\n",
      "Epoch 10, Loss: 0.03188806027173996\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004650399893788239, num_heads=8, num_layers=4; total time=   1.9s\n",
      "Epoch 9, Loss: 0.13009756803512573\n",
      "Epoch 9, Loss: 0.055139921605587006\n",
      "Epoch 10, Loss: 0.1126607358455658\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004650399893788239, num_heads=8, num_layers=4; total time=   2.0s\n",
      "Epoch 10, Loss: 0.08392909914255142\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004650399893788239, num_heads=8, num_layers=4; total time=   2.0s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.3788530230522156\n",
      "Epoch 1, Loss: 0.042532339692115784\n",
      "Epoch 1, Loss: 0.14416074752807617\n",
      "Epoch 1, Loss: 0.05681813135743141\n",
      "Epoch 1, Loss: 0.11953503638505936\n",
      "Epoch 1, Loss: 0.06895749270915985\n",
      "Epoch 2, Loss: 0.17158500850200653\n",
      "Epoch 1, Loss: 0.019211310893297195\n",
      "Epoch 2, Loss: 0.37688085436820984\n",
      "Epoch 2, Loss: 0.14587034285068512\n",
      "Epoch 1, Loss: 1.0586504936218262\n",
      "Epoch 2, Loss: 0.6987693309783936\n",
      "Epoch 2, Loss: 0.1168239414691925\n",
      "Epoch 3, Loss: 0.2528715133666992\n",
      "Epoch 1, Loss: 0.18587931990623474\n",
      "Epoch 2, Loss: 0.20157919824123383\n",
      "Epoch 1, Loss: 0.6424128413200378\n",
      "Epoch 1, Loss: 0.31080231070518494\n",
      "Epoch 3, Loss: 0.05465850979089737\n",
      "Epoch 2, Loss: 0.645930826663971\n",
      "Epoch 3, Loss: 0.11447253823280334\n",
      "Epoch 1, Loss: 1.0367934703826904\n",
      "Epoch 4, Loss: 0.1500585973262787\n",
      "Epoch 3, Loss: 0.036512043327093124\n",
      "Epoch 2, Loss: 0.022137973457574844\n",
      "Epoch 2, Loss: 0.29832497239112854\n",
      "Epoch 3, Loss: 0.07762536406517029\n",
      "Epoch 3, Loss: 0.06777112185955048\n",
      "Epoch 4, Loss: 0.0711582601070404\n",
      "Epoch 5, Loss: 0.05231655761599541\n",
      "Epoch 2, Loss: 0.1563195437192917\n",
      "Epoch 2, Loss: 0.030321253463625908\n",
      "Epoch 4, Loss: 0.027362562716007233\n",
      "Epoch 3, Loss: 0.06002076715230942\n",
      "Epoch 4, Loss: 0.08700142055749893\n",
      "Epoch 2, Loss: 0.04808269068598747\n",
      "Epoch 5, Loss: 0.17637746036052704\n",
      "Epoch 4, Loss: 0.15290583670139313\n",
      "Epoch 3, Loss: 0.2619324326515198\n",
      "Epoch 6, Loss: 0.05438340827822685\n",
      "Epoch 3, Loss: 0.14187945425510406\n",
      "Epoch 4, Loss: 0.04337547346949577\n",
      "Epoch 5, Loss: 0.03523286432027817\n",
      "Epoch 3, Loss: 0.2305528223514557\n",
      "Epoch 6, Loss: 0.11440376937389374\n",
      "Epoch 3, Loss: 0.30124861001968384\n",
      "Epoch 4, Loss: 0.12140095233917236\n",
      "Epoch 4, Loss: 0.45308876037597656\n",
      "Epoch 7, Loss: 0.09294301271438599\n",
      "Epoch 5, Loss: 0.025434788316488266\n",
      "Epoch 5, Loss: 0.32846885919570923\n",
      "Epoch 3, Loss: 0.307955801486969\n",
      "Epoch 4, Loss: 0.030508102849125862\n",
      "Epoch 6, Loss: 0.07088018953800201\n",
      "Epoch 5, Loss: 0.07469075918197632\n",
      "Epoch 7, Loss: 0.025596728548407555\n",
      "Epoch 8, Loss: 0.07883479446172714\n",
      "Epoch 5, Loss: 0.3018706738948822\n",
      "Epoch 4, Loss: 0.31095728278160095\n",
      "Epoch 4, Loss: 0.08329791575670242\n",
      "Epoch 7, Loss: 0.054156869649887085\n",
      "Epoch 6, Loss: 0.2305608093738556\n",
      "Epoch 6, Loss: 0.05215734243392944\n",
      "Epoch 6, Loss: 0.017572851851582527\n",
      "Epoch 8, Loss: 0.013874383643269539\n",
      "Epoch 9, Loss: 0.03953338414430618\n",
      "Epoch 4, Loss: 0.45351436734199524\n",
      "Epoch 5, Loss: 0.09672921150922775\n",
      "Epoch 8, Loss: 0.01935209147632122\n",
      "Epoch 10, Loss: 0.012412488460540771\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004545256739057259, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 6, Loss: 0.20853407680988312\n",
      "Epoch 5, Loss: 0.33160367608070374\n",
      "Epoch 9, Loss: 0.05645952746272087\n",
      "Epoch 7, Loss: 0.013977832160890102\n",
      "Epoch 7, Loss: 0.07176076620817184\n",
      "Epoch 5, Loss: 0.15310576558113098\n",
      "Epoch 7, Loss: 0.04801934212446213\n",
      "Epoch 5, Loss: 0.02143719233572483\n",
      "Epoch 5, Loss: 0.306161493062973\n",
      "Epoch 6, Loss: 0.11690498888492584\n",
      "Epoch 9, Loss: 0.009270929731428623\n",
      "Epoch 10, Loss: 0.08013193309307098\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004545256739057259, num_heads=8, num_layers=2; total time=   1.4s\n",
      "Epoch 8, Loss: 0.013697733171284199\n",
      "Epoch 6, Loss: 0.13434936106204987\n",
      "Epoch 8, Loss: 0.03893934190273285\n",
      "Epoch 8, Loss: 0.013314555399119854\n",
      "Epoch 7, Loss: 0.055505916476249695\n",
      "Epoch 6, Loss: 0.033127039670944214\n",
      "Epoch 10, Loss: 0.024313097819685936\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004545256739057259, num_heads=8, num_layers=2; total time=   1.5s\n",
      "Epoch 6, Loss: 0.07223138213157654\n",
      "Epoch 9, Loss: 0.06344042718410492\n",
      "Epoch 9, Loss: 0.011968232691287994\n",
      "Epoch 6, Loss: 0.11318325251340866\n",
      "Epoch 7, Loss: 0.04951893910765648\n",
      "Epoch 7, Loss: 0.016490576788783073\n",
      "Epoch 9, Loss: 0.03487309440970421\n",
      "Epoch 7, Loss: 0.03341766819357872\n",
      "Epoch 7, Loss: 0.1042943224310875\n",
      "Epoch 10, Loss: 0.012567725963890553\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004545256739057259, num_heads=8, num_layers=2; total time=   1.7s\n",
      "Epoch 10, Loss: 0.12027519941329956\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004545256739057259, num_heads=8, num_layers=2; total time=   1.6s\n",
      "Epoch 8, Loss: 0.005241249222308397\n",
      "Epoch 7, Loss: 0.021309876814484596\n",
      "Epoch 8, Loss: 0.008418225683271885\n",
      "Epoch 10, Loss: 0.035175684839487076\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004545256739057259, num_heads=8, num_layers=2; total time=   1.7s\n",
      "Epoch 8, Loss: 0.017959587275981903\n",
      "Epoch 9, Loss: 0.05009281262755394\n",
      "Epoch 8, Loss: 0.07052090018987656\n",
      "Epoch 8, Loss: 0.09687986969947815\n",
      "Epoch 9, Loss: 0.02878105267882347\n",
      "Epoch 9, Loss: 0.0863683745265007\n",
      "Epoch 8, Loss: 0.04632054641842842\n",
      "Epoch 9, Loss: 0.02184058167040348\n",
      "Epoch 10, Loss: 0.10847122222185135\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004545256739057259, num_heads=8, num_layers=2; total time=   1.8s\n",
      "Epoch 9, Loss: 0.1347387731075287\n",
      "Epoch 10, Loss: 0.06016325205564499\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004545256739057259, num_heads=8, num_layers=2; total time=   1.8s\n",
      "Epoch 10, Loss: 0.14477866888046265\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004545256739057259, num_heads=8, num_layers=2; total time=   1.8s\n",
      "Epoch 9, Loss: 0.11654378473758698\n",
      "Epoch 10, Loss: 0.007696958724409342\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004545256739057259, num_heads=8, num_layers=2; total time=   1.9s\n",
      "Epoch 10, Loss: 0.1188788041472435\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004545256739057259, num_heads=8, num_layers=2; total time=   1.9s\n",
      "Epoch 10, Loss: 0.15812721848487854\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0004545256739057259, num_heads=8, num_layers=2; total time=   1.9s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.1974397748708725\n",
      "Epoch 1, Loss: 0.5919038653373718\n",
      "Epoch 1, Loss: 1.2805551290512085\n",
      "Epoch 1, Loss: 0.6917691230773926\n",
      "Epoch 2, Loss: 0.44138142466545105\n",
      "Epoch 1, Loss: 0.25887489318847656\n",
      "Epoch 1, Loss: 1.4154759645462036\n",
      "Epoch 2, Loss: 0.10129625350236893\n",
      "Epoch 2, Loss: 0.08466371893882751\n",
      "Epoch 1, Loss: 1.0269850492477417\n",
      "Epoch 3, Loss: 0.17270292341709137Epoch 1, Loss: 0.9338205456733704\n",
      "Epoch 3, Loss: 0.28869253396987915\n",
      "Epoch 3, Loss: 0.21770967543125153\n",
      "Epoch 2, Loss: 0.20261141657829285\n",
      "\n",
      "Epoch 2, Loss: 0.23689314723014832\n",
      "Epoch 2, Loss: 0.04713134095072746\n",
      "Epoch 1, Loss: 0.31091004610061646\n",
      "Epoch 1, Loss: 0.06739357858896255\n",
      "Epoch 2, Loss: 0.13050977885723114\n",
      "Epoch 4, Loss: 0.26497358083724976\n",
      "Epoch 4, Loss: 0.46083304286003113\n",
      "Epoch 2, Loss: 0.05728860944509506\n",
      "Epoch 1, Loss: 0.23437567055225372\n",
      "Epoch 3, Loss: 0.20429068803787231\n",
      "Epoch 3, Loss: 0.0877443179488182\n",
      "Epoch 1, Loss: 0.15211661159992218\n",
      "Epoch 5, Loss: 0.13084420561790466\n",
      "Epoch 3, Loss: 0.3034132122993469\n",
      "Epoch 4, Loss: 0.01817331463098526\n",
      "Epoch 2, Loss: 0.20026858150959015\n",
      "Epoch 3, Loss: 0.32026711106300354\n",
      "Epoch 5, Loss: 0.3662031292915344\n",
      "Epoch 2, Loss: 0.42163529992103577\n",
      "Epoch 3, Loss: 0.2842162251472473\n",
      "Epoch 4, Loss: 0.06575437635183334\n",
      "Epoch 2, Loss: 0.024560898542404175\n",
      "Epoch 4, Loss: 0.30204686522483826\n",
      "Epoch 5, Loss: 0.12224746495485306\n",
      "Epoch 4, Loss: 0.41881921887397766\n",
      "Epoch 2, Loss: 0.3311677575111389\n",
      "Epoch 6, Loss: 0.04258705675601959\n",
      "Epoch 6, Loss: 0.17686456441879272\n",
      "Epoch 4, Loss: 0.36994537711143494\n",
      "Epoch 6, Loss: 0.15818308293819427\n",
      "Epoch 3, Loss: 0.2243194729089737\n",
      "Epoch 5, Loss: 0.06307056546211243\n",
      "Epoch 4, Loss: 0.39954692125320435\n",
      "Epoch 3, Loss: 0.19442123174667358\n",
      "Epoch 7, Loss: 0.04787181317806244\n",
      "Epoch 5, Loss: 0.11894858628511429\n",
      "Epoch 3, Loss: 0.35878750681877136\n",
      "Epoch 7, Loss: 0.0515744574368\n",
      "Epoch 5, Loss: 0.2967083156108856\n",
      "Epoch 6, Loss: 0.11202508211135864\n",
      "Epoch 7, Loss: 0.07317917793989182\n",
      "Epoch 5, Loss: 0.42163708806037903\n",
      "Epoch 3, Loss: 0.13289456069469452\n",
      "Epoch 8, Loss: 0.0906762108206749\n",
      "Epoch 5, Loss: 0.2760419547557831\n",
      "Epoch 4, Loss: 0.05652172863483429\n",
      "Epoch 6, Loss: 0.018991120159626007\n",
      "Epoch 8, Loss: 0.024381017312407494\n",
      "Epoch 8, Loss: 0.009480458684265614\n",
      "Epoch 4, Loss: 0.02160959504544735\n",
      "Epoch 4, Loss: 0.032491471618413925\n",
      "Epoch 7, Loss: 0.09072566777467728\n",
      "Epoch 6, Loss: 0.31063172221183777\n",
      "Epoch 9, Loss: 0.11192307621240616\n",
      "Epoch 6, Loss: 0.13398708403110504\n",
      "Epoch 7, Loss: 0.04213815927505493\n",
      "Epoch 9, Loss: 0.02380410209298134\n",
      "Epoch 9, Loss: 0.06154978275299072\n",
      "Epoch 4, Loss: 0.03289986029267311\n",
      "Epoch 5, Loss: 0.029355786740779877\n",
      "Epoch 10, Loss: 0.09276048839092255\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0005100480622802254, num_heads=2, num_layers=4; total time=   1.2s\n",
      "Epoch 8, Loss: 0.040908798575401306\n",
      "Epoch 6, Loss: 0.1154508963227272\n",
      "Epoch 8, Loss: 0.10353228449821472\n",
      "Epoch 10, Loss: 0.06760628521442413\n",
      "Epoch 5, Loss: 0.12030438333749771\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0005100480622802254, num_heads=2, num_layers=4; total time=   1.3s\n",
      "Epoch 7, Loss: 0.044546905905008316\n",
      "Epoch 5, Loss: 0.21283550560474396\n",
      "Epoch 10, Loss: 0.11387170106172562\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0005100480622802254, num_heads=2, num_layers=4; total time=   1.3s\n",
      "Epoch 7, Loss: 0.16204997897148132\n",
      "Epoch 9, Loss: 0.02086554281413555\n",
      "Epoch 5, Loss: 0.1173243448138237\n",
      "Epoch 6, Loss: 0.09496688842773438\n",
      "Epoch 7, Loss: 0.030737051740288734\n",
      "Epoch 8, Loss: 0.04930083453655243\n",
      "Epoch 9, Loss: 0.12395742535591125\n",
      "Epoch 8, Loss: 0.05748875066637993\n",
      "Epoch 6, Loss: 0.1811477243900299\n",
      "Epoch 10, Loss: 0.04026787728071213\n",
      "Epoch 6, Loss: 0.16764841973781586\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0005100480622802254, num_heads=2, num_layers=4; total time=   1.4s\n",
      "Epoch 8, Loss: 0.0375739149749279\n",
      "Epoch 9, Loss: 0.09946860373020172\n",
      "Epoch 6, Loss: 0.1294126957654953\n",
      "Epoch 10, Loss: 0.09504611045122147\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0005100480622802254, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Epoch 7, Loss: 0.10477341711521149\n",
      "Epoch 9, Loss: 0.020811034366488457\n",
      "Epoch 7, Loss: 0.04254809767007828\n",
      "Epoch 7, Loss: 0.08537472784519196\n",
      "Epoch 9, Loss: 0.08763671666383743\n",
      "Epoch 10, Loss: 0.13513995707035065\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0005100480622802254, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Epoch 7, Loss: 0.05980253219604492\n",
      "Epoch 8, Loss: 0.05489711835980415\n",
      "Epoch 8, Loss: 0.020507095381617546\n",
      "Epoch 10, Loss: 0.037219732999801636\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0005100480622802254, num_heads=2, num_layers=4; total time=   1.7s\n",
      "Epoch 10, Loss: 0.1303529590368271\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0005100480622802254, num_heads=2, num_layers=4; total time=   1.6s\n",
      "Epoch 8, Loss: 0.01489940658211708\n",
      "Epoch 8, Loss: 0.015357257798314095\n",
      "Epoch 9, Loss: 0.013587233610451221\n",
      "Epoch 9, Loss: 0.08191119879484177\n",
      "Epoch 9, Loss: 0.023207880556583405\n",
      "Epoch 9, Loss: 0.03037973865866661\n",
      "Epoch 10, Loss: 0.018940256908535957\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0005100480622802254, num_heads=2, num_layers=4; total time=   1.7s\n",
      "Epoch 10, Loss: 0.1054651215672493\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0005100480622802254, num_heads=2, num_layers=4; total time=   1.7s\n",
      "Epoch 10, Loss: 0.06848077476024628\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0005100480622802254, num_heads=2, num_layers=4; total time=   1.7s\n",
      "Epoch 10, Loss: 0.06068951636552811\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.0005100480622802254, num_heads=2, num_layers=4; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 3.2498221397399902\n",
      "Epoch 1, Loss: 0.9545509219169617\n",
      "Epoch 1, Loss: 1.4872078895568848\n",
      "Epoch 2, Loss: 2.9297685623168945\n",
      "Epoch 1, Loss: 0.8230948448181152\n",
      "Epoch 2, Loss: 1.3041996955871582\n",
      "Epoch 1, Loss: 0.9771004915237427\n",
      "Epoch 1, Loss: 0.11786248534917831\n",
      "Epoch 2, Loss: 0.7998510003089905\n",
      "Epoch 3, Loss: 2.595768451690674\n",
      "Epoch 1, Loss: 0.21634474396705627\n",
      "Epoch 2, Loss: 0.6775892972946167\n",
      "Epoch 1, Loss: 0.5822632312774658\n",
      "Epoch 3, Loss: 1.13323974609375\n",
      "Epoch 1, Loss: 1.3614710569381714\n",
      "Epoch 3, Loss: 0.6562795639038086\n",
      "Epoch 2, Loss: 0.8121470212936401\n",
      "Epoch 1, Loss: 0.05189966782927513\n",
      "Epoch 2, Loss: 0.07648155093193054\n",
      "Epoch 4, Loss: 2.2967259883880615\n",
      "Epoch 1, Loss: 2.504971981048584\n",
      "Epoch 2, Loss: 0.14791229367256165\n",
      "Epoch 3, Loss: 0.5560248494148254\n",
      "Epoch 4, Loss: 0.5293386578559875\n",
      "Epoch 1, Loss: 0.4229211211204529\n",
      "Epoch 4, Loss: 0.9832195043563843\n",
      "Epoch 5, Loss: 2.0109527111053467\n",
      "Epoch 2, Loss: 1.1909270286560059\n",
      "Epoch 2, Loss: 0.4733227491378784\n",
      "Epoch 3, Loss: 0.6807471513748169\n",
      "Epoch 2, Loss: 0.0407918356359005\n",
      "Epoch 5, Loss: 0.8455045819282532\n",
      "Epoch 3, Loss: 0.09688864648342133\n",
      "Epoch 5, Loss: 0.41582655906677246\n",
      "Epoch 6, Loss: 1.7518588304519653\n",
      "Epoch 2, Loss: 2.241539716720581\n",
      "Epoch 3, Loss: 0.0470203198492527\n",
      "Epoch 4, Loss: 0.44818341732025146\n",
      "Epoch 2, Loss: 0.32263144850730896\n",
      "Epoch 4, Loss: 0.5396204590797424\n",
      "Epoch 7, Loss: 1.5042567253112793\n",
      "Epoch 6, Loss: 0.32226598262786865\n",
      "Epoch 6, Loss: 0.7153326272964478\n",
      "Epoch 3, Loss: 0.37978965044021606\n",
      "Epoch 3, Loss: 1.0377615690231323\n",
      "Epoch 4, Loss: 0.05980358645319939\n",
      "Epoch 5, Loss: 0.3652535378932953\n",
      "Epoch 8, Loss: 1.2860366106033325\n",
      "Epoch 5, Loss: 0.4302826523780823\n",
      "Epoch 4, Loss: 0.030735665932297707\n",
      "Epoch 3, Loss: 0.03709472343325615\n",
      "Epoch 7, Loss: 0.23443104326725006\n",
      "Epoch 3, Loss: 1.989924430847168\n",
      "Epoch 3, Loss: 0.23642095923423767\n",
      "Epoch 7, Loss: 0.59931880235672\n",
      "Epoch 6, Loss: 0.29445940256118774\n",
      "Epoch 4, Loss: 0.8933326601982117\n",
      "Epoch 9, Loss: 1.0857809782028198\n",
      "Epoch 4, Loss: 0.2959975004196167\n",
      "Epoch 5, Loss: 0.03539031744003296\n",
      "Epoch 6, Loss: 0.33974090218544006\n",
      "Epoch 5, Loss: 0.025119571015238762\n",
      "Epoch 8, Loss: 0.16781868040561676\n",
      "Epoch 8, Loss: 0.5029972791671753\n",
      "Epoch 10, Loss: 0.9137587547302246\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13519801961688718, feed_forward_dim=512, head_dim=8, lr=5e-05, num_heads=8, num_layers=4; total time=   1.1s\n",
      "Epoch 4, Loss: 0.031655021011829376\n",
      "Epoch 4, Loss: 1.757118821144104\n",
      "Epoch 7, Loss: 0.24813014268875122\n",
      "Epoch 4, Loss: 0.174539715051651\n",
      "Epoch 6, Loss: 0.02382276952266693\n",
      "Epoch 5, Loss: 0.2268509417772293\n",
      "Epoch 7, Loss: 0.2598787546157837\n",
      "Epoch 6, Loss: 0.025896798819303513\n",
      "Epoch 9, Loss: 0.41466936469078064\n",
      "Epoch 9, Loss: 0.11719409376382828\n",
      "Epoch 5, Loss: 0.7673475742340088\n",
      "Epoch 8, Loss: 0.21513518691062927\n",
      "Epoch 5, Loss: 1.5310771465301514\n",
      "Epoch 10, Loss: 0.34441086649894714\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13519801961688718, feed_forward_dim=512, head_dim=8, lr=5e-05, num_heads=8, num_layers=4; total time=   1.3s\n",
      "Epoch 7, Loss: 0.03150927275419235\n",
      "Epoch 5, Loss: 0.12857641279697418\n",
      "Epoch 6, Loss: 0.17208799719810486\n",
      "Epoch 7, Loss: 0.022899655625224113\n",
      "Epoch 8, Loss: 0.19846898317337036\n",
      "Epoch 5, Loss: 0.025651631876826286\n",
      "Epoch 10, Loss: 0.0745953842997551\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13519801961688718, feed_forward_dim=512, head_dim=8, lr=5e-05, num_heads=8, num_layers=4; total time=   1.3s\n",
      "Epoch 9, Loss: 0.1972315013408661\n",
      "Epoch 6, Loss: 0.6484805941581726\n",
      "Epoch 9, Loss: 0.15374894440174103\n",
      "Epoch 6, Loss: 1.3287193775177002\n",
      "Epoch 8, Loss: 0.03632805868983269\n",
      "Epoch 7, Loss: 0.13006120920181274\n",
      "Epoch 6, Loss: 0.10917888581752777\n",
      "Epoch 8, Loss: 0.02858412079513073\n",
      "Epoch 6, Loss: 0.020841123536229134\n",
      "Epoch 10, Loss: 0.1860571652650833\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13519801961688718, feed_forward_dim=512, head_dim=8, lr=5e-05, num_heads=8, num_layers=4; total time=   1.4s\n",
      "Epoch 10, Loss: 0.12109337002038956\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13519801961688718, feed_forward_dim=512, head_dim=8, lr=5e-05, num_heads=8, num_layers=4; total time=   1.5s\n",
      "Epoch 7, Loss: 0.5504838228225708\n",
      "Epoch 9, Loss: 0.03757662698626518\n",
      "Epoch 7, Loss: 1.135863184928894\n",
      "Epoch 9, Loss: 0.03695526719093323\n",
      "Epoch 7, Loss: 0.01822749152779579\n",
      "Epoch 8, Loss: 0.10179446637630463\n",
      "Epoch 8, Loss: 0.46460115909576416\n",
      "Epoch 7, Loss: 0.10000704973936081\n",
      "Epoch 10, Loss: 0.036116473376750946\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13519801961688718, feed_forward_dim=512, head_dim=8, lr=5e-05, num_heads=8, num_layers=4; total time=   1.6s\n",
      "Epoch 10, Loss: 0.04350505769252777\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13519801961688718, feed_forward_dim=512, head_dim=8, lr=5e-05, num_heads=8, num_layers=4; total time=   1.6s\n",
      "Epoch 8, Loss: 0.9612500667572021\n",
      "Epoch 8, Loss: 0.015642235055565834\n",
      "Epoch 8, Loss: 0.10121993720531464\n",
      "Epoch 9, Loss: 0.08531232178211212\n",
      "Epoch 9, Loss: 0.38662317395210266\n",
      "Epoch 9, Loss: 0.7985301613807678\n",
      "Epoch 9, Loss: 0.013342407532036304\n",
      "Epoch 10, Loss: 0.07540048658847809\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13519801961688718, feed_forward_dim=512, head_dim=8, lr=5e-05, num_heads=8, num_layers=4; total time=   1.7s\n",
      "Epoch 9, Loss: 0.10297852754592896\n",
      "Epoch 10, Loss: 0.010984809137880802\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13519801961688718, feed_forward_dim=512, head_dim=8, lr=5e-05, num_heads=8, num_layers=4; total time=   1.8s\n",
      "Epoch 10, Loss: 0.6548550128936768\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13519801961688718, feed_forward_dim=512, head_dim=8, lr=5e-05, num_heads=8, num_layers=4; total time=   1.7s\n",
      "Epoch 10, Loss: 0.3280555307865143\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13519801961688718, feed_forward_dim=512, head_dim=8, lr=5e-05, num_heads=8, num_layers=4; total time=   1.8s\n",
      "Epoch 10, Loss: 0.10819998383522034\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.13519801961688718, feed_forward_dim=512, head_dim=8, lr=5e-05, num_heads=8, num_layers=4; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 1.0147684812545776\n",
      "Epoch 1, Loss: 0.8607233762741089\n",
      "Epoch 1, Loss: 0.8337370753288269\n",
      "Epoch 1, Loss: 0.6565917134284973\n",
      "Epoch 1, Loss: 0.5642614364624023\n",
      "Epoch 2, Loss: 0.33396199345588684\n",
      "Epoch 2, Loss: 0.387674480676651\n",
      "Epoch 1, Loss: 1.0259180068969727\n",
      "Epoch 2, Loss: 0.351742148399353\n",
      "Epoch 1, Loss: 1.59609854221344\n",
      "Epoch 2, Loss: 0.18479487299919128\n",
      "Epoch 3, Loss: 0.07884084433317184\n",
      "Epoch 3, Loss: 0.12539729475975037\n",
      "Epoch 1, Loss: 0.48778459429740906\n",
      "Epoch 2, Loss: 0.1408025324344635\n",
      "Epoch 3, Loss: 0.11772765964269638\n",
      "Epoch 2, Loss: 0.4148273169994354\n",
      "Epoch 1, Loss: 0.15683011710643768\n",
      "Epoch 4, Loss: 0.14213143289089203\n",
      "Epoch 4, Loss: 0.023649564012885094\n",
      "Epoch 2, Loss: 0.7229296565055847\n",
      "Epoch 1, Loss: 0.3103414475917816\n",
      "Epoch 4, Loss: 0.0948164314031601\n",
      "Epoch 3, Loss: 0.08155635744333267\n",
      "Epoch 1, Loss: 0.24715973436832428\n",
      "Epoch 3, Loss: 0.09255247563123703\n",
      "Epoch 2, Loss: 0.12768088281154633\n",
      "Epoch 1, Loss: 0.9675755500793457\n",
      "Epoch 3, Loss: 0.023124558851122856\n",
      "Epoch 5, Loss: 0.11084619164466858\n",
      "Epoch 2, Loss: 0.034981220960617065\n",
      "Epoch 5, Loss: 0.1781194508075714\n",
      "Epoch 5, Loss: 0.22408951818943024\n",
      "Epoch 6, Loss: 0.20830649137496948\n",
      "Epoch 3, Loss: 0.21587391197681427\n",
      "Epoch 4, Loss: 0.18299953639507294\n",
      "Epoch 2, Loss: 0.08564732223749161\n",
      "Epoch 4, Loss: 0.03347203508019447\n",
      "Epoch 4, Loss: 0.10303639620542526\n",
      "Epoch 7, Loss: 0.2429867833852768\n",
      "Epoch 3, Loss: 0.08528613299131393\n",
      "Epoch 6, Loss: 0.2455008178949356\n",
      "Epoch 2, Loss: 0.3446098268032074\n",
      "Epoch 3, Loss: 0.08177092671394348\n",
      "Epoch 6, Loss: 0.265423059463501\n",
      "Epoch 2, Loss: 0.07794704288244247\n",
      "Epoch 4, Loss: 0.06197582557797432\n",
      "Epoch 5, Loss: 0.23262543976306915\n",
      "Epoch 5, Loss: 0.12969231605529785\n",
      "Epoch 8, Loss: 0.21664944291114807\n",
      "Epoch 5, Loss: 0.18504084646701813\n",
      "Epoch 3, Loss: 0.16404768824577332\n",
      "Epoch 7, Loss: 0.2524249255657196\n",
      "Epoch 7, Loss: 0.246128648519516\n",
      "Epoch 4, Loss: 0.0847930908203125\n",
      "Epoch 9, Loss: 0.1584850251674652\n",
      "Epoch 6, Loss: 0.19254915416240692\n",
      "Epoch 5, Loss: 0.1410827785730362\n",
      "Epoch 3, Loss: 0.06179477274417877\n",
      "Epoch 4, Loss: 0.16709358990192413\n",
      "Epoch 8, Loss: 0.20374152064323425\n",
      "Epoch 6, Loss: 0.18859544396400452\n",
      "Epoch 3, Loss: 0.14429959654808044\n",
      "Epoch 6, Loss: 0.22440814971923828\n",
      "Epoch 4, Loss: 0.17027141153812408\n",
      "Epoch 8, Loss: 0.20422719419002533\n",
      "Epoch 10, Loss: 0.09544213116168976\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00023612664582509387, num_heads=4, num_layers=4; total time=   0.9s\n",
      "Epoch 7, Loss: 0.1121421605348587\n",
      "Epoch 9, Loss: 0.14097262918949127\n",
      "Epoch 7, Loss: 0.13122598826885223\n",
      "Epoch 5, Loss: 0.0430910624563694\n",
      "Epoch 6, Loss: 0.2846868932247162\n",
      "Epoch 9, Loss: 0.13886593282222748\n",
      "Epoch 5, Loss: 0.19286665320396423\n",
      "Epoch 7, Loss: 0.2544589638710022\n",
      "Epoch 4, Loss: 0.07013797760009766\n",
      "Epoch 8, Loss: 0.04881976172327995\n",
      "Epoch 5, Loss: 0.10452686995267868\n",
      "Epoch 4, Loss: 0.12081097066402435\n",
      "Epoch 8, Loss: 0.06658878922462463\n",
      "Epoch 10, Loss: 0.08832330256700516\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00023612664582509387, num_heads=4, num_layers=4; total time=   1.1s\n",
      "Epoch 10, Loss: 0.08913777768611908\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00023612664582509387, num_heads=4, num_layers=4; total time=   1.1s\n",
      "Epoch 7, Loss: 0.3625074028968811\n",
      "Epoch 6, Loss: 0.014971975237131119\n",
      "Epoch 8, Loss: 0.211661234498024\n",
      "Epoch 9, Loss: 0.022233715280890465\n",
      "Epoch 6, Loss: 0.14968805015087128\n",
      "Epoch 5, Loss: 0.19549842178821564\n",
      "Epoch 6, Loss: 0.05120795592665672\n",
      "Epoch 9, Loss: 0.02354229986667633\n",
      "Epoch 5, Loss: 0.05378524586558342\n",
      "Epoch 8, Loss: 0.36237072944641113\n",
      "Epoch 10, Loss: 0.032417796552181244\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00023612664582509387, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 7, Loss: 0.018347807228565216\n",
      "Epoch 9, Loss: 0.1477910876274109\n",
      "Epoch 7, Loss: 0.08617933839559555\n",
      "Epoch 10, Loss: 0.01320367120206356\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00023612664582509387, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 7, Loss: 0.04711000248789787\n",
      "Epoch 6, Loss: 0.2703791558742523\n",
      "Epoch 9, Loss: 0.30160799622535706\n",
      "Epoch 10, Loss: 0.08211126923561096\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00023612664582509387, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 8, Loss: 0.03526287525892258\n",
      "Epoch 6, Loss: 0.02388235554099083\n",
      "Epoch 8, Loss: 0.040626317262649536\n",
      "Epoch 8, Loss: 0.06523909419775009\n",
      "Epoch 10, Loss: 0.21665744483470917\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00023612664582509387, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 7, Loss: 0.2561953067779541\n",
      "Epoch 9, Loss: 0.03766462206840515\n",
      "Epoch 9, Loss: 0.026330769062042236\n",
      "Epoch 7, Loss: 0.03576403111219406\n",
      "Epoch 9, Loss: 0.07327759265899658\n",
      "Epoch 10, Loss: 0.02513187564909458\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00023612664582509387, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Epoch 8, Loss: 0.18537668883800507\n",
      "Epoch 10, Loss: 0.037159111350774765\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00023612664582509387, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Epoch 8, Loss: 0.05100022256374359\n",
      "Epoch 10, Loss: 0.05833301320672035\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00023612664582509387, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Epoch 9, Loss: 0.10609366744756699\n",
      "Epoch 9, Loss: 0.04217494651675224\n",
      "Epoch 10, Loss: 0.04659516364336014\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00023612664582509387, num_heads=4, num_layers=4; total time=   1.6s\n",
      "Epoch 10, Loss: 0.02148209512233734\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00023612664582509387, num_heads=4, num_layers=4; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 2.364957571029663\n",
      "Epoch 1, Loss: 0.11089874058961868\n",
      "Epoch 1, Loss: 0.3964066505432129\n",
      "Epoch 2, Loss: 1.508337378501892\n",
      "Epoch 1, Loss: 0.2041161209344864\n",
      "Epoch 1, Loss: 3.060887098312378\n",
      "Epoch 1, Loss: 0.03991566225886345\n",
      "Epoch 2, Loss: 0.09222504496574402\n",
      "Epoch 1, Loss: 0.38794198632240295\n",
      "Epoch 1, Loss: 1.0495903491973877\n",
      "Epoch 2, Loss: 0.10317584127187729\n",
      "Epoch 2, Loss: 2.0859484672546387\n",
      "Epoch 2, Loss: 0.08752395212650299\n",
      "Epoch 3, Loss: 0.06645545363426208\n",
      "Epoch 1, Loss: 0.36222824454307556\n",
      "Epoch 3, Loss: 0.8545606136322021\n",
      "Epoch 1, Loss: 0.02896084450185299\n",
      "Epoch 2, Loss: 0.053962744772434235\n",
      "Epoch 2, Loss: 0.14385706186294556\n",
      "Epoch 1, Loss: 0.0743768960237503\n",
      "Epoch 3, Loss: 0.01484963484108448\n",
      "Epoch 4, Loss: 0.04152128845453262\n",
      "Epoch 1, Loss: 0.7320408225059509\n",
      "Epoch 4, Loss: 0.4106138050556183\n",
      "Epoch 3, Loss: 1.301759123802185\n",
      "Epoch 2, Loss: 0.5997310876846313\n",
      "Epoch 3, Loss: 0.1028144583106041\n",
      "Epoch 4, Loss: 0.0601741299033165\n",
      "Epoch 3, Loss: 0.022897833958268166\n",
      "Epoch 3, Loss: 0.07072639465332031\n",
      "Epoch 2, Loss: 0.08213042467832565\n",
      "Epoch 2, Loss: 0.033905912190675735\n",
      "Epoch 5, Loss: 0.0314054936170578\n",
      "Epoch 5, Loss: 0.14059701561927795\n",
      "Epoch 4, Loss: 0.1170981302857399\n",
      "Epoch 4, Loss: 0.7114984393119812\n",
      "Epoch 2, Loss: 0.38484814763069153\n",
      "Epoch 3, Loss: 0.2919222116470337\n",
      "Epoch 5, Loss: 0.12668083608150482\n",
      "Epoch 6, Loss: 0.040542833507061005\n",
      "Epoch 2, Loss: 0.029078830033540726\n",
      "Epoch 4, Loss: 0.10183099657297134\n",
      "Epoch 6, Loss: 0.02559089846909046\n",
      "Epoch 4, Loss: 0.03692943602800369\n",
      "Epoch 3, Loss: 0.02321660704910755\n",
      "Epoch 3, Loss: 0.019849473610520363\n",
      "Epoch 5, Loss: 0.09272076189517975\n",
      "Epoch 7, Loss: 0.05824974179267883\n",
      "Epoch 4, Loss: 0.13011744618415833\n",
      "Epoch 5, Loss: 0.32037490606307983\n",
      "Epoch 7, Loss: 0.015305429697036743\n",
      "Epoch 6, Loss: 0.12990479171276093\n",
      "Epoch 3, Loss: 0.17496047914028168\n",
      "Epoch 3, Loss: 0.051783520728349686\n",
      "Epoch 6, Loss: 0.057904768735170364\n",
      "Epoch 8, Loss: 0.14575323462486267\n",
      "Epoch 5, Loss: 0.14176839590072632\n",
      "Epoch 4, Loss: 0.007815681397914886\n",
      "Epoch 5, Loss: 0.024910418316721916\n",
      "Epoch 4, Loss: 0.08079206198453903\n",
      "Epoch 6, Loss: 0.12031582742929459\n",
      "Epoch 7, Loss: 0.09484629333019257\n",
      "Epoch 8, Loss: 0.009061042219400406\n",
      "Epoch 5, Loss: 0.09450292587280273\n",
      "Epoch 7, Loss: 0.04041127860546112\n",
      "Epoch 9, Loss: 0.2427169233560562\n",
      "Epoch 6, Loss: 0.13837598264217377\n",
      "Epoch 4, Loss: 0.03654666990041733\n",
      "Epoch 5, Loss: 0.12813256680965424\n",
      "Epoch 4, Loss: 0.09149302542209625\n",
      "Epoch 9, Loss: 0.009982251562178135\n",
      "Epoch 8, Loss: 0.049215372651815414\n",
      "Epoch 6, Loss: 0.01214064285159111\n",
      "Epoch 5, Loss: 0.014288743957877159\n",
      "Epoch 7, Loss: 0.07483725994825363\n",
      "Epoch 6, Loss: 0.13931965827941895\n",
      "Epoch 10, Loss: 0.30867114663124084\n",
      "Epoch 8, Loss: 0.03966664895415306\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.00016486047100146268, num_heads=4, num_layers=2; total time=   1.1s\n",
      "Epoch 7, Loss: 0.10583817958831787\n",
      "Epoch 6, Loss: 0.11784984171390533\n",
      "Epoch 10, Loss: 0.013271442614495754\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.00016486047100146268, num_heads=4, num_layers=2; total time=   1.1s\n",
      "Epoch 9, Loss: 0.019356712698936462\n",
      "Epoch 5, Loss: 0.09697852283716202\n",
      "Epoch 9, Loss: 0.04774530604481697\n",
      "Epoch 7, Loss: 0.017737412825226784\n",
      "Epoch 5, Loss: 0.014633738435804844\n",
      "Epoch 8, Loss: 0.13827237486839294\n",
      "Epoch 7, Loss: 0.20329762995243073\n",
      "Epoch 8, Loss: 0.06393956393003464\n",
      "Epoch 6, Loss: 0.017749087885022163\n",
      "Epoch 10, Loss: 0.046996280550956726\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.00016486047100146268, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 10, Loss: 0.008401521481573582\n",
      "Epoch 8, Loss: 0.02038634940981865\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.00016486047100146268, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 9, Loss: 0.03394158557057381\n",
      "Epoch 7, Loss: 0.07418891042470932\n",
      "Epoch 9, Loss: 0.2409617006778717\n",
      "Epoch 6, Loss: 0.012783179059624672\n",
      "Epoch 7, Loss: 0.009900317527353764\n",
      "Epoch 8, Loss: 0.24172204732894897\n",
      "Epoch 6, Loss: 0.14031267166137695\n",
      "Epoch 9, Loss: 0.012679757550358772\n",
      "Epoch 10, Loss: 0.021854151040315628\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.00016486047100146268, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 10, Loss: 0.3451513648033142\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.00016486047100146268, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 9, Loss: 0.2429197132587433\n",
      "Epoch 7, Loss: 0.0199710875749588\n",
      "Epoch 8, Loss: 0.03097030334174633\n",
      "Epoch 8, Loss: 0.005543544888496399\n",
      "Epoch 10, Loss: 0.00899954978376627\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.00016486047100146268, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 7, Loss: 0.17456504702568054\n",
      "Epoch 10, Loss: 0.2115880250930786\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.00016486047100146268, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 9, Loss: 0.009517003782093525\n",
      "Epoch 9, Loss: 0.009445414878427982\n",
      "Epoch 8, Loss: 0.01920076087117195\n",
      "Epoch 8, Loss: 0.18457508087158203\n",
      "Epoch 10, Loss: 0.012892358936369419\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.00016486047100146268, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.012791849672794342\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.00016486047100146268, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 0.011170828714966774\n",
      "Epoch 9, Loss: 0.16914065182209015\n",
      "Epoch 10, Loss: 0.004270498640835285\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.00016486047100146268, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.1380653828382492\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.00016486047100146268, num_heads=4, num_layers=2; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 1.486653447151184\n",
      "Epoch 1, Loss: 1.0259872674942017\n",
      "Epoch 1, Loss: 1.0422694683074951\n",
      "Epoch 1, Loss: 0.7846766710281372\n",
      "Epoch 2, Loss: 0.35081857442855835\n",
      "Epoch 1, Loss: 0.16677488386631012\n",
      "Epoch 1, Loss: 0.3250649869441986\n",
      "Epoch 1, Loss: 0.13761429488658905\n",
      "Epoch 2, Loss: 0.3913298547267914\n",
      "Epoch 1, Loss: 1.6781628131866455\n",
      "Epoch 2, Loss: 0.34577476978302\n",
      "Epoch 3, Loss: 0.02315412275493145\n",
      "Epoch 2, Loss: 0.2347172498703003\n",
      "Epoch 2, Loss: 0.12095382809638977\n",
      "Epoch 3, Loss: 0.11317772418260574\n",
      "Epoch 2, Loss: 0.21745462715625763\n",
      "Epoch 4, Loss: 0.2204188108444214\n",
      "Epoch 1, Loss: 0.02440902404487133\n",
      "Epoch 2, Loss: 0.016048794612288475\n",
      "Epoch 1, Loss: 0.4580628573894501\n",
      "Epoch 3, Loss: 0.03406812250614166\n",
      "Epoch 3, Loss: 0.06274853646755219\n",
      "Epoch 2, Loss: 0.6633180379867554\n",
      "Epoch 1, Loss: 1.279335379600525\n",
      "Epoch 4, Loss: 0.11804409325122833\n",
      "Epoch 3, Loss: 0.2059188187122345\n",
      "Epoch 5, Loss: 0.4253191351890564\n",
      "Epoch 1, Loss: 0.7366434931755066\n",
      "Epoch 3, Loss: 0.11121394485235214\n",
      "Epoch 4, Loss: 0.07999929040670395\n",
      "Epoch 3, Loss: 0.09501370787620544\n",
      "Epoch 4, Loss: 0.09792234748601913\n",
      "Epoch 2, Loss: 0.1776747703552246\n",
      "Epoch 5, Loss: 0.2302798479795456\n",
      "Epoch 2, Loss: 0.1392243206501007\n",
      "Epoch 6, Loss: 0.4347366392612457\n",
      "Epoch 4, Loss: 0.08808876574039459\n",
      "Epoch 4, Loss: 0.16039980947971344\n",
      "Epoch 2, Loss: 0.41923093795776367\n",
      "Epoch 5, Loss: 0.19866542518138885\n",
      "Epoch 3, Loss: 0.18096326291561127\n",
      "Epoch 5, Loss: 0.2058083713054657\n",
      "Epoch 7, Loss: 0.3088620901107788\n",
      "Epoch 4, Loss: 0.06011882796883583\n",
      "Epoch 6, Loss: 0.29092785716056824\n",
      "Epoch 2, Loss: 0.19291172921657562\n",
      "Epoch 3, Loss: 0.02368377149105072\n",
      "Epoch 3, Loss: 0.16825222969055176\n",
      "Epoch 6, Loss: 0.2648312747478485\n",
      "Epoch 5, Loss: 0.09910683333873749\n",
      "Epoch 5, Loss: 0.07611624896526337\n",
      "Epoch 6, Loss: 0.2328866571187973\n",
      "Epoch 3, Loss: 0.09475748986005783\n",
      "Epoch 7, Loss: 0.27964991331100464\n",
      "Epoch 4, Loss: 0.11972642689943314\n",
      "Epoch 8, Loss: 0.16174083948135376\n",
      "Epoch 5, Loss: 0.012111417949199677\n",
      "Epoch 7, Loss: 0.25161081552505493\n",
      "Epoch 4, Loss: 0.04131890460848808\n",
      "Epoch 6, Loss: 0.04578983783721924\n",
      "Epoch 6, Loss: 0.06711429357528687\n",
      "Epoch 7, Loss: 0.1893233209848404\n",
      "Epoch 3, Loss: 0.0843232050538063\n",
      "Epoch 9, Loss: 0.057439085096120834\n",
      "Epoch 8, Loss: 0.21558243036270142\n",
      "Epoch 4, Loss: 0.23043765127658844\n",
      "Epoch 5, Loss: 0.2611595094203949\n",
      "Epoch 8, Loss: 0.1891038864850998\n",
      "Epoch 7, Loss: 0.06573862582445145\n",
      "Epoch 6, Loss: 0.012006659060716629\n",
      "Epoch 4, Loss: 0.15588371455669403\n",
      "Epoch 10, Loss: 0.018687408417463303\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0002890481362067132, num_heads=8, num_layers=4; total time=   1.0s\n",
      "Epoch 8, Loss: 0.11753299832344055\n",
      "Epoch 5, Loss: 0.09070008248090744\n",
      "Epoch 9, Loss: 0.14064352214336395\n",
      "Epoch 7, Loss: 0.03214360773563385\n",
      "Epoch 4, Loss: 0.1951025277376175\n",
      "Epoch 9, Loss: 0.1165444552898407\n",
      "Epoch 8, Loss: 0.08056962490081787\n",
      "Epoch 5, Loss: 0.19871124625205994\n",
      "Epoch 6, Loss: 0.3888278901576996\n",
      "Epoch 9, Loss: 0.05561196058988571\n",
      "Epoch 7, Loss: 0.03629568591713905\n",
      "Epoch 10, Loss: 0.08103334903717041\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0002890481362067132, num_heads=8, num_layers=4; total time=   1.1s\n",
      "Epoch 5, Loss: 0.3121917247772217\n",
      "Epoch 10, Loss: 0.056651826947927475\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0002890481362067132, num_heads=8, num_layers=4; total time=   1.1s\n",
      "Epoch 8, Loss: 0.029957829043269157\n",
      "Epoch 9, Loss: 0.06516645848751068\n",
      "Epoch 6, Loss: 0.05699160322546959\n",
      "Epoch 10, Loss: 0.02144758217036724\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0002890481362067132, num_heads=8, num_layers=4; total time=   1.1s\n",
      "Epoch 7, Loss: 0.4095270335674286\n",
      "Epoch 6, Loss: 0.12562035024166107\n",
      "Epoch 5, Loss: 0.2603185772895813\n",
      "Epoch 9, Loss: 0.04223787039518356\n",
      "Epoch 8, Loss: 0.04455336928367615\n",
      "Epoch 10, Loss: 0.033722952008247375\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0002890481362067132, num_heads=8, num_layers=4; total time=   1.2s\n",
      "Epoch 6, Loss: 0.37127113342285156\n",
      "Epoch 8, Loss: 0.34806984663009644\n",
      "Epoch 7, Loss: 0.0695343092083931\n",
      "Epoch 6, Loss: 0.2231985479593277\n",
      "Epoch 7, Loss: 0.012234401889145374\n",
      "Epoch 10, Loss: 0.03402089327573776\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0002890481362067132, num_heads=8, num_layers=4; total time=   1.3s\n",
      "Epoch 9, Loss: 0.028883758932352066\n",
      "Epoch 9, Loss: 0.2562606632709503\n",
      "Epoch 7, Loss: 0.3278249204158783\n",
      "Epoch 8, Loss: 0.057332396507263184\n",
      "Epoch 8, Loss: 0.009186462499201298\n",
      "Epoch 7, Loss: 0.1368466019630432\n",
      "Epoch 10, Loss: 0.009917903691530228\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0002890481362067132, num_heads=8, num_layers=4; total time=   1.4s\n",
      "Epoch 10, Loss: 0.15779118239879608\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0002890481362067132, num_heads=8, num_layers=4; total time=   1.4s\n",
      "Epoch 9, Loss: 0.07341231405735016\n",
      "Epoch 9, Loss: 0.034862879663705826\n",
      "Epoch 8, Loss: 0.22882312536239624\n",
      "Epoch 8, Loss: 0.060677409172058105\n",
      "Epoch 10, Loss: 0.08872456848621368\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0002890481362067132, num_heads=8, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.045218802988529205\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0002890481362067132, num_heads=8, num_layers=4; total time=   1.5s\n",
      "Epoch 9, Loss: 0.12972016632556915\n",
      "Epoch 9, Loss: 0.023987537249922752\n",
      "Epoch 10, Loss: 0.06224258989095688\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0002890481362067132, num_heads=8, num_layers=4; total time=   1.6s\n",
      "Epoch 10, Loss: 0.026581041514873505\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0002890481362067132, num_heads=8, num_layers=4; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.5960477590560913\n",
      "Epoch 1, Loss: 2.618105888366699\n",
      "Epoch 2, Loss: 0.08001097291707993\n",
      "Epoch 1, Loss: 0.799450695514679\n",
      "Epoch 3, Loss: 0.30966439843177795\n",
      "Epoch 1, Loss: 0.2361879199743271\n",
      "Epoch 1, Loss: 1.3376678228378296\n",
      "Epoch 2, Loss: 0.5102378129959106\n",
      "Epoch 1, Loss: 1.2820734977722168\n",
      "Epoch 1, Loss: 0.5197188258171082\n",
      "Epoch 2, Loss: 0.03753016144037247\n",
      "Epoch 1, Loss: 0.04319123923778534\n",
      "Epoch 4, Loss: 0.26834630966186523\n",
      "Epoch 1, Loss: 0.45310360193252563\n",
      "Epoch 2, Loss: 0.10468432307243347\n",
      "Epoch 3, Loss: 0.0707390308380127\n",
      "Epoch 1, Loss: 0.9411778450012207\n",
      "Epoch 2, Loss: 0.23194001615047455\n",
      "Epoch 2, Loss: 0.11860103905200958\n",
      "Epoch 1, Loss: 1.5775436162948608\n",
      "Epoch 3, Loss: 0.3828245997428894\n",
      "Epoch 5, Loss: 0.10612323135137558\n",
      "Epoch 2, Loss: 0.11106668412685394\n",
      "Epoch 1, Loss: 0.9042403101921082\n",
      "Epoch 2, Loss: 0.1347045749425888\n",
      "Epoch 4, Loss: 0.4819350242614746\n",
      "Epoch 6, Loss: 0.022607751190662384\n",
      "Epoch 3, Loss: 0.3712204694747925\n",
      "Epoch 2, Loss: 0.1232791617512703\n",
      "Epoch 4, Loss: 0.36806032061576843\n",
      "Epoch 3, Loss: 0.17158415913581848\n",
      "Epoch 3, Loss: 0.15100127458572388\n",
      "Epoch 2, Loss: 0.024736160412430763\n",
      "Epoch 2, Loss: 0.28347527980804443\n",
      "Epoch 3, Loss: 0.2826038897037506\n",
      "Epoch 7, Loss: 0.0522390678524971\n",
      "Epoch 5, Loss: 0.7047043442726135\n",
      "Epoch 3, Loss: 0.07354055345058441\n",
      "Epoch 2, Loss: 0.08490443229675293\n",
      "Epoch 5, Loss: 0.16413146257400513\n",
      "Epoch 4, Loss: 0.5374093055725098\n",
      "Epoch 4, Loss: 0.04036219045519829\n",
      "Epoch 4, Loss: 0.44600406289100647\n",
      "Epoch 6, Loss: 0.6079835295677185\n",
      "Epoch 3, Loss: 0.30151575803756714\n",
      "Epoch 8, Loss: 0.11419018357992172\n",
      "Epoch 3, Loss: 0.33757391571998596\n",
      "Epoch 6, Loss: 0.0267594363540411\n",
      "Epoch 3, Loss: 0.26907265186309814\n",
      "Epoch 4, Loss: 0.23756834864616394\n",
      "Epoch 4, Loss: 0.09648886322975159\n",
      "Epoch 7, Loss: 0.38167300820350647\n",
      "Epoch 9, Loss: 0.1275051236152649\n",
      "Epoch 5, Loss: 0.04693315550684929\n",
      "Epoch 5, Loss: 0.3921550214290619\n",
      "Epoch 5, Loss: 0.44499170780181885\n",
      "Epoch 3, Loss: 0.4452722370624542\n",
      "Epoch 7, Loss: 0.024705741554498672\n",
      "Epoch 8, Loss: 0.17246544361114502\n",
      "Epoch 4, Loss: 0.17266494035720825\n",
      "Epoch 4, Loss: 0.5528683662414551\n",
      "Epoch 5, Loss: 0.014320154674351215\n",
      "Epoch 10, Loss: 0.0878789871931076\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0005148433492669223, num_heads=8, num_layers=2; total time=   0.9s\n",
      "Epoch 5, Loss: 0.10631466656923294\n",
      "Epoch 4, Loss: 0.39116567373275757\n",
      "Epoch 6, Loss: 0.0949554592370987\n",
      "Epoch 8, Loss: 0.09197099506855011\n",
      "Epoch 6, Loss: 0.2832491397857666\n",
      "Epoch 9, Loss: 0.04848821461200714\n",
      "Epoch 4, Loss: 0.4031120240688324\n",
      "Epoch 6, Loss: 0.17993083596229553\n",
      "Epoch 7, Loss: 0.07196221500635147\n",
      "Epoch 5, Loss: 0.03703494742512703\n",
      "Epoch 9, Loss: 0.14165470004081726\n",
      "Epoch 6, Loss: 0.030785169452428818\n",
      "Epoch 7, Loss: 0.11278383433818817\n",
      "Epoch 6, Loss: 0.04099467024207115\n",
      "Epoch 5, Loss: 0.4985591173171997\n",
      "Epoch 5, Loss: 0.25130778551101685\n",
      "Epoch 10, Loss: 0.025361154228448868\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0005148433492669223, num_heads=8, num_layers=2; total time=   1.1s\n",
      "Epoch 7, Loss: 0.053080882877111435\n",
      "Epoch 10, Loss: 0.12910325825214386\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0005148433492669223, num_heads=8, num_layers=2; total time=   1.1s\n",
      "Epoch 6, Loss: 0.03258909657597542\n",
      "Epoch 8, Loss: 0.020999133586883545\n",
      "Epoch 8, Loss: 0.023620618507266045\n",
      "Epoch 7, Loss: 0.05629704147577286\n",
      "Epoch 6, Loss: 0.32328906655311584\n",
      "Epoch 5, Loss: 0.16502147912979126\n",
      "Epoch 7, Loss: 0.05985293164849281\n",
      "Epoch 8, Loss: 0.045828260481357574\n",
      "Epoch 6, Loss: 0.08514788746833801\n",
      "Epoch 9, Loss: 0.007224026136100292\n",
      "Epoch 7, Loss: 0.09732727706432343\n",
      "Epoch 8, Loss: 0.09166955202817917\n",
      "Epoch 9, Loss: 0.026342999190092087\n",
      "Epoch 7, Loss: 0.1612185537815094\n",
      "Epoch 9, Loss: 0.1037023514509201\n",
      "Epoch 6, Loss: 0.03053196519613266\n",
      "Epoch 8, Loss: 0.03430183604359627\n",
      "Epoch 7, Loss: 0.008626406081020832\n",
      "Epoch 10, Loss: 0.0289069265127182\n",
      "Epoch 10, Loss: 0.07996078580617905\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0005148433492669223, num_heads=8, num_layers=2; total time=   1.3s\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0005148433492669223, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 8, Loss: 0.1164347231388092\n",
      "Epoch 9, Loss: 0.09530032426118851\n",
      "Epoch 10, Loss: 0.15516316890716553\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0005148433492669223, num_heads=8, num_layers=2; total time=   1.3s\n",
      "Epoch 8, Loss: 0.08085694909095764\n",
      "Epoch 9, Loss: 0.008481006138026714\n",
      "Epoch 7, Loss: 0.05802611634135246\n",
      "Epoch 10, Loss: 0.06636907160282135\n",
      "Epoch 8, Loss: 0.031186584383249283\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0005148433492669223, num_heads=8, num_layers=2; total time=   1.4s\n",
      "Epoch 9, Loss: 0.0748174637556076\n",
      "Epoch 10, Loss: 0.01641344651579857\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0005148433492669223, num_heads=8, num_layers=2; total time=   1.4s\n",
      "Epoch 9, Loss: 0.08050456643104553\n",
      "Epoch 8, Loss: 0.14208893477916718\n",
      "Epoch 9, Loss: 0.09279172122478485\n",
      "Epoch 10, Loss: 0.023303238674998283\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0005148433492669223, num_heads=8, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.12439240515232086\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0005148433492669223, num_heads=8, num_layers=2; total time=   1.5s\n",
      "Epoch 9, Loss: 0.17294611036777496\n",
      "Epoch 10, Loss: 0.12889914214611053\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0005148433492669223, num_heads=8, num_layers=2; total time=   1.5s\n",
      "Epoch 10, Loss: 0.1336366832256317\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.1, feed_forward_dim=256, head_dim=8, lr=0.0005148433492669223, num_heads=8, num_layers=2; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 1.1343787908554077\n",
      "Epoch 1, Loss: 0.14785067737102509\n",
      "Epoch 1, Loss: 0.4550412595272064\n",
      "Epoch 2, Loss: 0.2256281077861786\n",
      "Epoch 2, Loss: 0.08492206782102585\n",
      "Epoch 1, Loss: 0.04811961576342583\n",
      "Epoch 1, Loss: 0.06097567826509476\n",
      "Epoch 1, Loss: 0.20671959221363068\n",
      "Epoch 1, Loss: 1.696965217590332\n",
      "Epoch 3, Loss: 0.03165973350405693\n",
      "Epoch 2, Loss: 0.05824203044176102\n",
      "Epoch 3, Loss: 0.10653822869062424\n",
      "Epoch 2, Loss: 0.1122104600071907\n",
      "Epoch 1, Loss: 0.881058394908905\n",
      "Epoch 1, Loss: 0.925508975982666\n",
      "Epoch 2, Loss: 0.16158223152160645\n",
      "Epoch 2, Loss: 0.6236798763275146\n",
      "Epoch 1, Loss: 1.1222881078720093\n",
      "Epoch 4, Loss: 0.21878677606582642\n",
      "Epoch 2, Loss: 0.09503751248121262\n",
      "Epoch 3, Loss: 0.1148662343621254\n",
      "Epoch 3, Loss: 0.040177349001169205\n",
      "Epoch 4, Loss: 0.04331471398472786\n",
      "Epoch 1, Loss: 0.19637420773506165\n",
      "Epoch 1, Loss: 2.2441484928131104\n",
      "Epoch 2, Loss: 0.2794158458709717\n",
      "Epoch 5, Loss: 0.34776929020881653\n",
      "Epoch 3, Loss: 0.09550079703330994\n",
      "Epoch 3, Loss: 0.0407382994890213\n",
      "Epoch 2, Loss: 0.1913290172815323\n",
      "Epoch 4, Loss: 0.2033432126045227\n",
      "Epoch 3, Loss: 0.14982245862483978\n",
      "Epoch 6, Loss: 0.32603371143341064\n",
      "Epoch 2, Loss: 0.36044424772262573\n",
      "Epoch 5, Loss: 0.02153046615421772\n",
      "Epoch 4, Loss: 0.016032151877880096\n",
      "Epoch 2, Loss: 0.17708341777324677\n",
      "Epoch 2, Loss: 0.7792266011238098\n",
      "Epoch 5, Loss: 0.149092435836792\n",
      "Epoch 3, Loss: 0.12683850526809692\n",
      "Epoch 4, Loss: 0.06490401178598404\n",
      "Epoch 3, Loss: 0.04549834504723549\n",
      "Epoch 4, Loss: 0.03583388030529022\n",
      "Epoch 7, Loss: 0.21650728583335876\n",
      "Epoch 4, Loss: 0.07448296993970871\n",
      "Epoch 6, Loss: 0.042327750474214554\n",
      "Epoch 5, Loss: 0.050954561680555344\n",
      "Epoch 6, Loss: 0.0634901374578476\n",
      "Epoch 8, Loss: 0.1024593710899353\n",
      "Epoch 3, Loss: 0.08795761317014694\n",
      "Epoch 5, Loss: 0.0724271908402443\n",
      "Epoch 3, Loss: 0.12176541984081268\n",
      "Epoch 5, Loss: 0.26451659202575684\n",
      "Epoch 4, Loss: 0.21281296014785767\n",
      "Epoch 5, Loss: 0.02390100620687008\n",
      "Epoch 6, Loss: 0.04669291898608208\n",
      "Epoch 3, Loss: 0.08678239583969116\n",
      "Epoch 7, Loss: 0.017473656684160233\n",
      "Epoch 9, Loss: 0.02771628275513649\n",
      "Epoch 7, Loss: 0.0463840626180172\n",
      "Epoch 4, Loss: 0.2052612602710724\n",
      "Epoch 4, Loss: 0.07842783629894257\n",
      "Epoch 7, Loss: 0.01663411222398281\n",
      "Epoch 4, Loss: 0.07847747206687927\n",
      "Epoch 6, Loss: 0.3882695138454437\n",
      "Epoch 10, Loss: 0.012195080518722534\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.2031422376104452, feed_forward_dim=128, head_dim=32, lr=0.0003149372588186189, num_heads=4, num_layers=2; total time=   1.0s\n",
      "Epoch 6, Loss: 0.045126788318157196\n",
      "Epoch 6, Loss: 0.042421720921993256\n",
      "Epoch 8, Loss: 0.024550756439566612\n",
      "Epoch 8, Loss: 0.02364197000861168\n",
      "Epoch 4, Loss: 0.13927476108074188\n",
      "Epoch 5, Loss: 0.2922479808330536\n",
      "Epoch 8, Loss: 0.007878836244344711\n",
      "Epoch 5, Loss: 0.3069096505641937\n",
      "Epoch 9, Loss: 0.007029037456959486\n",
      "Epoch 5, Loss: 0.05801187455654144\n",
      "Epoch 7, Loss: 0.06561288237571716\n",
      "Epoch 7, Loss: 0.011127403937280178\n",
      "Epoch 9, Loss: 0.0526864267885685\n",
      "Epoch 7, Loss: 0.38593199849128723\n",
      "Epoch 6, Loss: 0.2884727716445923\n",
      "Epoch 5, Loss: 0.2662879526615143\n",
      "Epoch 5, Loss: 0.2994834780693054\n",
      "Epoch 9, Loss: 0.022131696343421936\n",
      "Epoch 6, Loss: 0.27412477135658264\n",
      "Epoch 10, Loss: 0.011779502034187317\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.2031422376104452, feed_forward_dim=128, head_dim=32, lr=0.0003149372588186189, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 6, Loss: 0.023959936574101448\n",
      "Epoch 8, Loss: 0.012121187523007393\n",
      "Epoch 8, Loss: 0.049748264253139496\n",
      "Epoch 10, Loss: 0.07162057608366013\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.2031422376104452, feed_forward_dim=128, head_dim=32, lr=0.0003149372588186189, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 7, Loss: 0.22531388700008392\n",
      "Epoch 6, Loss: 0.3105285167694092\n",
      "Epoch 9, Loss: 0.032866235822439194\n",
      "Epoch 8, Loss: 0.29188403487205505\n",
      "Epoch 10, Loss: 0.030034665018320084\n",
      "Epoch 7, Loss: 0.17182007431983948\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.2031422376104452, feed_forward_dim=128, head_dim=32, lr=0.0003149372588186189, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 9, Loss: 0.01874479465186596\n",
      "Epoch 7, Loss: 0.018451964482665062\n",
      "Epoch 8, Loss: 0.14618980884552002\n",
      "Epoch 10, Loss: 0.034808702766895294\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.2031422376104452, feed_forward_dim=128, head_dim=32, lr=0.0003149372588186189, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 6, Loss: 0.47660619020462036\n",
      "Epoch 7, Loss: 0.2734124958515167\n",
      "Epoch 9, Loss: 0.17706389725208282\n",
      "Epoch 10, Loss: 0.007618970237672329\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.2031422376104452, feed_forward_dim=128, head_dim=32, lr=0.0003149372588186189, num_heads=4, num_layers=2; total time=   1.2s\n",
      "Epoch 8, Loss: 0.07553157955408096\n",
      "Epoch 8, Loss: 0.02402069978415966\n",
      "Epoch 9, Loss: 0.08389951288700104\n",
      "Epoch 8, Loss: 0.19448931515216827\n",
      "Epoch 10, Loss: 0.08230369538068771\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.2031422376104452, feed_forward_dim=128, head_dim=32, lr=0.0003149372588186189, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 7, Loss: 0.5116161108016968\n",
      "Epoch 9, Loss: 0.02454017661511898\n",
      "Epoch 9, Loss: 0.016472341492772102\n",
      "Epoch 10, Loss: 0.057400912046432495\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.2031422376104452, feed_forward_dim=128, head_dim=32, lr=0.0003149372588186189, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 9, Loss: 0.11367905884981155\n",
      "Epoch 8, Loss: 0.43703019618988037\n",
      "Epoch 10, Loss: 0.023526379838585854\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.2031422376104452, feed_forward_dim=128, head_dim=32, lr=0.0003149372588186189, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 10, Loss: 0.008120431564748287\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.2031422376104452, feed_forward_dim=128, head_dim=32, lr=0.0003149372588186189, num_heads=4, num_layers=2; total time=   1.3s\n",
      "Epoch 10, Loss: 0.054917000234127045\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.2031422376104452, feed_forward_dim=128, head_dim=32, lr=0.0003149372588186189, num_heads=4, num_layers=2; total time=   1.4s\n",
      "Epoch 9, Loss: 0.31520187854766846\n",
      "Epoch 10, Loss: 0.18489527702331543\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.2031422376104452, feed_forward_dim=128, head_dim=32, lr=0.0003149372588186189, num_heads=4, num_layers=2; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.3431731164455414\n",
      "Epoch 1, Loss: 1.3525338172912598\n",
      "Epoch 1, Loss: 0.4375716745853424\n",
      "Epoch 1, Loss: 0.26129162311553955\n",
      "Epoch 1, Loss: 1.069140076637268\n",
      "Epoch 2, Loss: 0.1940222829580307\n",
      "Epoch 1, Loss: 0.17567111551761627\n",
      "Epoch 1, Loss: 0.10935642570257187\n",
      "Epoch 2, Loss: 0.7383018136024475\n",
      "Epoch 2, Loss: 0.035525500774383545\n",
      "Epoch 2, Loss: 0.21500490605831146\n",
      "Epoch 1, Loss: 0.08479738980531693\n",
      "Epoch 3, Loss: 0.20836421847343445\n",
      "Epoch 2, Loss: 0.1044096127152443\n",
      "Epoch 2, Loss: 0.528932511806488\n",
      "Epoch 2, Loss: 0.03819790109992027\n",
      "Epoch 3, Loss: 0.3312576711177826\n",
      "Epoch 1, Loss: 0.27771610021591187\n",
      "Epoch 1, Loss: 0.09462647885084152\n",
      "Epoch 3, Loss: 0.17405995726585388\n",
      "Epoch 4, Loss: 0.19864848256111145\n",
      "Epoch 3, Loss: 0.03956995904445648\n",
      "Epoch 3, Loss: 0.2133086770772934\n",
      "Epoch 1, Loss: 0.10592138767242432\n",
      "Epoch 3, Loss: 0.08024080842733383\n",
      "Epoch 1, Loss: 0.28703323006629944\n",
      "Epoch 2, Loss: 0.041082095354795456\n",
      "Epoch 4, Loss: 0.1349816620349884\n",
      "Epoch 4, Loss: 0.205849751830101\n",
      "Epoch 3, Loss: 0.06791719049215317\n",
      "Epoch 5, Loss: 0.15240763127803802\n",
      "Epoch 2, Loss: 0.07426974922418594\n",
      "Epoch 2, Loss: 0.09188953042030334\n",
      "Epoch 4, Loss: 0.08409889787435532\n",
      "Epoch 4, Loss: 0.1078847274184227\n",
      "Epoch 5, Loss: 0.1959507167339325\n",
      "Epoch 2, Loss: 0.05139372870326042\n",
      "Epoch 4, Loss: 0.045272309333086014\n",
      "Epoch 6, Loss: 0.10405222326517105\n",
      "Epoch 4, Loss: 0.09428195655345917\n",
      "Epoch 3, Loss: 0.06429539620876312\n",
      "Epoch 5, Loss: 0.10811816155910492\n",
      "Epoch 7, Loss: 0.08261411637067795\n",
      "Epoch 2, Loss: 0.10295100510120392\n",
      "Epoch 6, Loss: 0.15425173938274384\n",
      "Epoch 3, Loss: 0.06250324845314026\n",
      "Epoch 3, Loss: 0.1515030413866043\n",
      "Epoch 5, Loss: 0.1077595204114914\n",
      "Epoch 5, Loss: 0.09003102779388428\n",
      "Epoch 5, Loss: 0.046470701694488525\n",
      "Epoch 8, Loss: 0.08036753535270691\n",
      "Epoch 5, Loss: 0.0710480809211731\n",
      "Epoch 3, Loss: 0.07609310746192932\n",
      "Epoch 6, Loss: 0.17675340175628662\n",
      "Epoch 4, Loss: 0.14374226331710815\n",
      "Epoch 4, Loss: 0.0320875346660614\n",
      "Epoch 7, Loss: 0.10343074053525925\n",
      "Epoch 6, Loss: 0.1549893468618393\n",
      "Epoch 9, Loss: 0.08267679065465927\n",
      "Epoch 6, Loss: 0.044969867914915085\n",
      "Epoch 4, Loss: 0.03283572196960449\n",
      "Epoch 6, Loss: 0.068642757833004\n",
      "Epoch 3, Loss: 0.1183311939239502\n",
      "Epoch 7, Loss: 0.2567152976989746\n",
      "Epoch 6, Loss: 0.03537127375602722\n",
      "Epoch 8, Loss: 0.06909409910440445\n",
      "Epoch 7, Loss: 0.21682427823543549\n",
      "Epoch 5, Loss: 0.015903420746326447\n",
      "Epoch 10, Loss: 0.07114577293395996\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0001955554522860426, num_heads=2, num_layers=3; total time=   1.1s\n",
      "Epoch 4, Loss: 0.05564960092306137\n",
      "Epoch 8, Loss: 0.30339160561561584\n",
      "Epoch 7, Loss: 0.026982953771948814\n",
      "Epoch 7, Loss: 0.030310392379760742\n",
      "Epoch 5, Loss: 0.07750565558671951\n",
      "Epoch 9, Loss: 0.05926067382097244\n",
      "Epoch 5, Loss: 0.025099758058786392\n",
      "Epoch 4, Loss: 0.14433665573596954\n",
      "Epoch 8, Loss: 0.2408471405506134\n",
      "Epoch 7, Loss: 0.016660161316394806\n",
      "Epoch 9, Loss: 0.30349552631378174\n",
      "Epoch 8, Loss: 0.01769854500889778\n",
      "Epoch 6, Loss: 0.027671221643686295\n",
      "Epoch 8, Loss: 0.011304185725748539\n",
      "Epoch 10, Loss: 0.0638151615858078\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0001955554522860426, num_heads=2, num_layers=3; total time=   1.2s\n",
      "Epoch 6, Loss: 0.03240973874926567\n",
      "Epoch 9, Loss: 0.2282237708568573\n",
      "Epoch 5, Loss: 0.029714146628975868\n",
      "Epoch 10, Loss: 0.265236496925354\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0001955554522860426, num_heads=2, num_layers=3; total time=   1.3s\n",
      "Epoch 6, Loss: 0.03188571706414223\n",
      "Epoch 8, Loss: 0.023317091166973114\n",
      "Epoch 5, Loss: 0.1125941053032875\n",
      "Epoch 9, Loss: 0.0205979123711586\n",
      "Epoch 7, Loss: 0.03371693566441536\n",
      "Epoch 9, Loss: 0.020673708990216255\n",
      "Epoch 10, Loss: 0.18743380904197693\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0001955554522860426, num_heads=2, num_layers=3; total time=   1.4s\n",
      "Epoch 7, Loss: 0.027248837053775787\n",
      "Epoch 7, Loss: 0.03370783478021622\n",
      "Epoch 9, Loss: 0.035961978137493134\n",
      "Epoch 6, Loss: 0.02451455220580101\n",
      "Epoch 6, Loss: 0.0628955289721489\n",
      "Epoch 10, Loss: 0.02375379577279091\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0001955554522860426, num_heads=2, num_layers=3; total time=   1.3s\n",
      "Epoch 10, Loss: 0.041728463023900986\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0001955554522860426, num_heads=2, num_layers=3; total time=   1.4s\n",
      "Epoch 8, Loss: 0.02369893155992031\n",
      "Epoch 10, Loss: 0.04078931733965874\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0001955554522860426, num_heads=2, num_layers=3; total time=   1.4s\n",
      "Epoch 8, Loss: 0.016834957525134087\n",
      "Epoch 7, Loss: 0.032099928706884384\n",
      "Epoch 7, Loss: 0.03393442556262016\n",
      "Epoch 8, Loss: 0.05243025720119476\n",
      "Epoch 9, Loss: 0.012577079236507416\n",
      "Epoch 9, Loss: 0.014784769155085087\n",
      "Epoch 8, Loss: 0.03166760876774788\n",
      "Epoch 9, Loss: 0.055895403027534485\n",
      "Epoch 8, Loss: 0.031400009989738464\n",
      "Epoch 10, Loss: 0.013625403866171837\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0001955554522860426, num_heads=2, num_layers=3; total time=   1.5s\n",
      "Epoch 9, Loss: 0.019720343872904778\n",
      "Epoch 10, Loss: 0.036629416048526764\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0001955554522860426, num_heads=2, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.022094350308179855\n",
      "Epoch 9, Loss: 0.042571086436510086\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0001955554522860426, num_heads=2, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.010636572726070881\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0001955554522860426, num_heads=2, num_layers=3; total time=   1.6s\n",
      "Epoch 10, Loss: 0.04854658618569374\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0001955554522860426, num_heads=2, num_layers=3; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.5990976691246033\n",
      "Epoch 1, Loss: 0.36944395303726196\n",
      "Epoch 1, Loss: 1.367699384689331\n",
      "Epoch 2, Loss: 0.4149797558784485\n",
      "Epoch 1, Loss: 0.37474244832992554\n",
      "Epoch 1, Loss: 0.045022886246442795\n",
      "Epoch 1, Loss: 0.6907901167869568\n",
      "Epoch 2, Loss: 0.1904599666595459\n",
      "Epoch 1, Loss: 0.42766061425209045\n",
      "Epoch 2, Loss: 1.0410575866699219\n",
      "Epoch 3, Loss: 0.2773638367652893\n",
      "Epoch 1, Loss: 0.25857827067375183\n",
      "Epoch 2, Loss: 0.005085891578346491\n",
      "Epoch 2, Loss: 0.2462558150291443\n",
      "Epoch 3, Loss: 0.08018792420625687\n",
      "Epoch 1, Loss: 2.7856836318969727\n",
      "Epoch 4, Loss: 0.1772381067276001\n",
      "Epoch 2, Loss: 0.5017731189727783\n",
      "Epoch 3, Loss: 0.7557416558265686\n",
      "Epoch 2, Loss: 0.2523402273654938\n",
      "Epoch 2, Loss: 0.14603659510612488\n",
      "Epoch 3, Loss: 0.015005698427557945\n",
      "Epoch 4, Loss: 0.031924325972795486\n",
      "Epoch 3, Loss: 0.16616107523441315\n",
      "Epoch 5, Loss: 0.12420637905597687\n",
      "Epoch 3, Loss: 0.34698086977005005\n",
      "Epoch 4, Loss: 0.5263415575027466\n",
      "Epoch 6, Loss: 0.1051209568977356\n",
      "Epoch 2, Loss: 2.2864975929260254\n",
      "Epoch 3, Loss: 0.133626326918602\n",
      "Epoch 5, Loss: 0.036150652915239334\n",
      "Epoch 4, Loss: 0.024709848687052727\n",
      "Epoch 1, Loss: 0.6799317598342896\n",
      "Epoch 1, Loss: 0.19556574523448944\n",
      "Epoch 4, Loss: 0.13344135880470276\n",
      "Epoch 3, Loss: 0.07426617294549942\n",
      "Epoch 5, Loss: 0.35705700516700745\n",
      "Epoch 7, Loss: 0.10885936766862869\n",
      "Epoch 6, Loss: 0.06635546684265137\n",
      "Epoch 4, Loss: 0.23487251996994019\n",
      "Epoch 4, Loss: 0.06948807090520859\n",
      "Epoch 5, Loss: 0.01785426214337349\n",
      "Epoch 1, Loss: 3.6152637004852295\n",
      "Epoch 8, Loss: 0.12528561055660248\n",
      "Epoch 2, Loss: 0.4675131142139435\n",
      "Epoch 2, Loss: 0.10011116415262222\n",
      "Epoch 7, Loss: 0.09488964080810547\n",
      "Epoch 4, Loss: 0.037688009440898895\n",
      "Epoch 6, Loss: 0.22343075275421143\n",
      "Epoch 5, Loss: 0.12819990515708923\n",
      "Epoch 3, Loss: 1.8317084312438965\n",
      "Epoch 6, Loss: 0.008139116689562798\n",
      "Epoch 9, Loss: 0.13847383856773376\n",
      "Epoch 5, Loss: 0.15585049986839294\n",
      "Epoch 5, Loss: 0.04882650077342987\n",
      "Epoch 7, Loss: 0.145299032330513\n",
      "Epoch 8, Loss: 0.10499134659767151\n",
      "Epoch 2, Loss: 3.052429437637329\n",
      "Epoch 3, Loss: 0.2986502945423126\n",
      "Epoch 3, Loss: 0.04955587908625603\n",
      "Epoch 10, Loss: 0.15249590575695038\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.4, feed_forward_dim=256, head_dim=8, lr=8.887488024651383e-05, num_heads=4, num_layers=3; total time=   1.0s\n",
      "Epoch 5, Loss: 0.027677297592163086\n",
      "Epoch 7, Loss: 0.0036604353226721287\n",
      "Epoch 4, Loss: 1.430629849433899\n",
      "Epoch 6, Loss: 0.11711984872817993\n",
      "Epoch 8, Loss: 0.10554758459329605\n",
      "Epoch 6, Loss: 0.13623706996440887\n",
      "Epoch 6, Loss: 0.05971115827560425\n",
      "Epoch 9, Loss: 0.09598330408334732\n",
      "Epoch 8, Loss: 0.006946819368749857\n",
      "Epoch 4, Loss: 0.03449108079075813\n",
      "Epoch 6, Loss: 0.038013000041246414\n",
      "Epoch 7, Loss: 0.10492018610239029\n",
      "Epoch 9, Loss: 0.09765881299972534\n",
      "Epoch 7, Loss: 0.1449711173772812\n",
      "Epoch 10, Loss: 0.07552265375852585\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.4, feed_forward_dim=256, head_dim=8, lr=8.887488024651383e-05, num_heads=4, num_layers=3; total time=   1.1s\n",
      "Epoch 5, Loss: 1.0733160972595215\n",
      "Epoch 3, Loss: 2.524118423461914\n",
      "Epoch 4, Loss: 0.1656479388475418\n",
      "Epoch 9, Loss: 0.011582601815462112\n",
      "Epoch 7, Loss: 0.05444436892867088\n",
      "Epoch 7, Loss: 0.08109291642904282\n",
      "Epoch 10, Loss: 0.11112958192825317\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.4, feed_forward_dim=256, head_dim=8, lr=8.887488024651383e-05, num_heads=4, num_layers=3; total time=   1.2s\n",
      "Epoch 5, Loss: 0.04190133139491081\n",
      "Epoch 10, Loss: 0.012945585884153843\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.4, feed_forward_dim=256, head_dim=8, lr=8.887488024651383e-05, num_heads=4, num_layers=3; total time=   1.1s\n",
      "Epoch 8, Loss: 0.1130983978509903\n",
      "Epoch 4, Loss: 2.053372621536255\n",
      "Epoch 8, Loss: 0.13984966278076172\n",
      "Epoch 5, Loss: 0.07441233098506927\n",
      "Epoch 6, Loss: 0.7716895937919617\n",
      "Epoch 8, Loss: 0.06727844476699829\n",
      "Epoch 8, Loss: 0.09879317134618759\n",
      "Epoch 9, Loss: 0.1281447857618332\n",
      "Epoch 6, Loss: 0.05753003805875778\n",
      "Epoch 9, Loss: 0.12787489593029022\n",
      "Epoch 5, Loss: 1.6163997650146484\n",
      "Epoch 9, Loss: 0.07223305851221085\n",
      "Epoch 9, Loss: 0.11010909080505371\n",
      "Epoch 6, Loss: 0.024033771827816963\n",
      "Epoch 7, Loss: 0.5246719717979431\n",
      "Epoch 10, Loss: 0.10828574001789093\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.4, feed_forward_dim=256, head_dim=8, lr=8.887488024651383e-05, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Epoch 10, Loss: 0.14451557397842407\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.4, feed_forward_dim=256, head_dim=8, lr=8.887488024651383e-05, num_heads=4, num_layers=3; total time=   1.3s\n",
      "Epoch 7, Loss: 0.06529516726732254\n",
      "Epoch 10, Loss: 0.10347186774015427\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.4, feed_forward_dim=256, head_dim=8, lr=8.887488024651383e-05, num_heads=4, num_layers=3; total time=   1.3s\n",
      "Epoch 10, Loss: 0.06757079809904099\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.4, feed_forward_dim=256, head_dim=8, lr=8.887488024651383e-05, num_heads=4, num_layers=3; total time=   1.3s\n",
      "Epoch 6, Loss: 1.2385413646697998\n",
      "Epoch 7, Loss: 0.00609233882278204\n",
      "Epoch 8, Loss: 0.3310994803905487\n",
      "Epoch 8, Loss: 0.06745725125074387\n",
      "Epoch 7, Loss: 0.9144101738929749\n",
      "Epoch 9, Loss: 0.19181212782859802\n",
      "Epoch 8, Loss: 0.014401538297533989\n",
      "Epoch 9, Loss: 0.05933770909905434\n",
      "Epoch 10, Loss: 0.09991857409477234\n",
      "Epoch 8, Loss: 0.6399559378623962\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.4, feed_forward_dim=256, head_dim=8, lr=8.887488024651383e-05, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 9, Loss: 0.035710398107767105\n",
      "Epoch 10, Loss: 0.04670803248882294\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.4, feed_forward_dim=256, head_dim=8, lr=8.887488024651383e-05, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Epoch 10, Loss: 0.06259410828351974\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.4, feed_forward_dim=256, head_dim=8, lr=8.887488024651383e-05, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Epoch 9, Loss: 0.4180779457092285\n",
      "Epoch 10, Loss: 0.250419020652771\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.4, feed_forward_dim=256, head_dim=8, lr=8.887488024651383e-05, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.04037368297576904\n",
      "Epoch 1, Loss: 0.6915201544761658\n",
      "Epoch 1, Loss: 0.1004859209060669\n",
      "Epoch 1, Loss: 0.047548551112413406\n",
      "Epoch 2, Loss: 0.023938797414302826\n",
      "Epoch 1, Loss: 1.0009843111038208\n",
      "Epoch 1, Loss: 0.10378389805555344\n",
      "Epoch 1, Loss: 1.2531486749649048\n",
      "Epoch 2, Loss: 0.06124597787857056\n",
      "Epoch 2, Loss: 0.5689399242401123\n",
      "Epoch 3, Loss: 0.021415866911411285\n",
      "Epoch 2, Loss: 0.036604199558496475\n",
      "Epoch 2, Loss: 0.8284763693809509\n",
      "Epoch 1, Loss: 0.8088564872741699\n",
      "Epoch 1, Loss: 1.6747361421585083\n",
      "Epoch 1, Loss: 0.061750736087560654\n",
      "Epoch 2, Loss: 1.0984121561050415\n",
      "Epoch 3, Loss: 0.45729655027389526\n",
      "Epoch 4, Loss: 0.021090472117066383\n",
      "Epoch 3, Loss: 0.03603507950901985\n",
      "Epoch 3, Loss: 0.6703476309776306\n",
      "Epoch 3, Loss: 0.03669990971684456\n",
      "Epoch 2, Loss: 0.06095781549811363\n",
      "Epoch 1, Loss: 0.3810986578464508\n",
      "Epoch 1, Loss: 0.6429747343063354\n",
      "Epoch 4, Loss: 0.35998520255088806\n",
      "Epoch 2, Loss: 0.6636217832565308\n",
      "Epoch 5, Loss: 0.024234969168901443\n",
      "Epoch 2, Loss: 0.055738817900419235\n",
      "Epoch 2, Loss: 1.4921919107437134\n",
      "Epoch 4, Loss: 0.5314967632293701\n",
      "Epoch 4, Loss: 0.02615060843527317\n",
      "Epoch 4, Loss: 0.035342972725629807\n",
      "Epoch 3, Loss: 0.9466473460197449\n",
      "Epoch 3, Loss: 0.03193972632288933\n",
      "Epoch 5, Loss: 0.2872157096862793\n",
      "Epoch 2, Loss: 0.2810961902141571\n",
      "Epoch 6, Loss: 0.02150617726147175\n",
      "Epoch 2, Loss: 0.5337196588516235\n",
      "Epoch 5, Loss: 0.02576065994799137\n",
      "Epoch 3, Loss: 1.3288615942001343\n",
      "Epoch 3, Loss: 0.5429304838180542\n",
      "Epoch 5, Loss: 0.028743505477905273\n",
      "Epoch 5, Loss: 0.418649822473526\n",
      "Epoch 7, Loss: 0.01962239108979702\n",
      "Epoch 4, Loss: 0.017231784760951996\n",
      "Epoch 4, Loss: 0.8081436157226562\n",
      "Epoch 6, Loss: 0.2200302630662918\n",
      "Epoch 3, Loss: 0.04992888122797012\n",
      "Epoch 6, Loss: 0.031192494556307793\n",
      "Epoch 8, Loss: 0.0163993239402771\n",
      "Epoch 4, Loss: 0.4302395284175873\n",
      "Epoch 3, Loss: 0.4303586184978485\n",
      "Epoch 7, Loss: 0.17440944910049438\n",
      "Epoch 6, Loss: 0.023541590198874474\n",
      "Epoch 4, Loss: 1.1667262315750122\n",
      "Epoch 6, Loss: 0.31665778160095215\n",
      "Epoch 3, Loss: 0.2016075849533081\n",
      "Epoch 5, Loss: 0.6806458830833435\n",
      "Epoch 9, Loss: 0.013588444329798222\n",
      "Epoch 5, Loss: 0.013647261075675488\n",
      "Epoch 7, Loss: 0.03565390035510063\n",
      "Epoch 5, Loss: 0.3317941129207611\n",
      "Epoch 7, Loss: 0.02108108066022396\n",
      "Epoch 8, Loss: 0.1426268368959427\n",
      "Epoch 7, Loss: 0.23598229885101318\n",
      "Epoch 4, Loss: 0.043686799705028534\n",
      "Epoch 4, Loss: 0.3432775139808655\n",
      "Epoch 5, Loss: 1.0221723318099976\n",
      "Epoch 6, Loss: 0.01718260534107685\n",
      "Epoch 6, Loss: 0.5698770880699158\n",
      "Epoch 8, Loss: 0.03734181448817253\n",
      "Epoch 10, Loss: 0.011505775153636932\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3401494909091537, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=2, num_layers=4; total time=   1.1s\n",
      "Epoch 4, Loss: 0.1394243836402893\n",
      "Epoch 9, Loss: 0.12822361290454865\n",
      "Epoch 8, Loss: 0.018888922408223152\n",
      "Epoch 6, Loss: 0.2526901662349701\n",
      "Epoch 8, Loss: 0.17249110341072083\n",
      "Epoch 5, Loss: 0.27161043882369995\n",
      "Epoch 6, Loss: 0.8840721845626831\n",
      "Epoch 7, Loss: 0.023854924365878105\n",
      "Epoch 9, Loss: 0.034969110041856766\n",
      "Epoch 10, Loss: 0.11759497970342636\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3401494909091537, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=2, num_layers=4; total time=   1.2s\n",
      "Epoch 5, Loss: 0.03753698244690895\n",
      "Epoch 7, Loss: 0.4667643904685974\n",
      "Epoch 9, Loss: 0.019102836027741432\n",
      "Epoch 5, Loss: 0.09189785271883011\n",
      "Epoch 10, Loss: 0.02971077151596546\n",
      "Epoch 9, Loss: 0.1265934854745865\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3401494909091537, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=2, num_layers=4; total time=   1.3s\n",
      "Epoch 7, Loss: 0.18232449889183044\n",
      "Epoch 8, Loss: 0.028830593451857567\n",
      "Epoch 8, Loss: 0.37555044889450073\n",
      "Epoch 7, Loss: 0.7543800473213196\n",
      "Epoch 10, Loss: 0.01596110127866268\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3401494909091537, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=2, num_layers=4; total time=   1.4s\n",
      "Epoch 6, Loss: 0.21134132146835327\n",
      "Epoch 6, Loss: 0.03341212496161461\n",
      "Epoch 10, Loss: 0.09486015141010284\n",
      "Epoch 6, Loss: 0.062708280980587\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3401494909091537, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=2, num_layers=4; total time=   1.4s\n",
      "Epoch 8, Loss: 0.13233737647533417\n",
      "Epoch 9, Loss: 0.3001529574394226\n",
      "Epoch 8, Loss: 0.6397497653961182\n",
      "Epoch 9, Loss: 0.03035934455692768\n",
      "Epoch 10, Loss: 0.22988128662109375\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3401494909091537, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Epoch 9, Loss: 0.09314990043640137\n",
      "Epoch 7, Loss: 0.028676418587565422\n",
      "Epoch 7, Loss: 0.16610342264175415\n",
      "Epoch 9, Loss: 0.5389893651008606\n",
      "Epoch 7, Loss: 0.047623392194509506\n",
      "Epoch 10, Loss: 0.06516169011592865\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3401494909091537, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.027761640027165413\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3401494909091537, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=2, num_layers=4; total time=   1.6s\n",
      "Epoch 8, Loss: 0.02378792129456997\n",
      "Epoch 10, Loss: 0.44613373279571533\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3401494909091537, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=2, num_layers=4; total time=   1.5s\n",
      "Epoch 8, Loss: 0.13351453840732574\n",
      "Epoch 8, Loss: 0.04167579114437103\n",
      "Epoch 9, Loss: 0.02056371606886387\n",
      "Epoch 9, Loss: 0.04426038637757301\n",
      "Epoch 9, Loss: 0.10889337956905365\n",
      "Epoch 10, Loss: 0.017445679754018784\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3401494909091537, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=2, num_layers=4; total time=   1.7s\n",
      "Epoch 10, Loss: 0.05128525197505951\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3401494909091537, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=2, num_layers=4; total time=   1.7s\n",
      "Epoch 10, Loss: 0.09482929855585098\n",
      "[CV] END activation=elu, batch_size=16, dropout_rate=0.3401494909091537, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=2, num_layers=4; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.5055168271064758\n",
      "Epoch 1, Loss: 0.09340843558311462\n",
      "Epoch 1, Loss: 0.1956242024898529\n",
      "Epoch 1, Loss: 0.3424709141254425\n",
      "Epoch 1, Loss: 1.048300862312317\n",
      "Epoch 1, Loss: 0.07346519082784653\n",
      "Epoch 2, Loss: 0.030742892995476723\n",
      "Epoch 1, Loss: 0.9658897519111633\n",
      "Epoch 1, Loss: 3.6177051067352295\n",
      "Epoch 1, Loss: 0.1446528136730194\n",
      "Epoch 2, Loss: 0.14177623391151428\n",
      "Epoch 2, Loss: 0.1241709515452385\n",
      "Epoch 1, Loss: 2.054520606994629\n",
      "Epoch 1, Loss: 0.11865779757499695\n",
      "Epoch 3, Loss: 0.12193650752305984\n",
      "Epoch 2, Loss: 0.3792835474014282\n",
      "Epoch 2, Loss: 0.024472108110785484\n",
      "Epoch 2, Loss: 0.15555210411548615\n",
      "Epoch 1, Loss: 0.8450177907943726\n",
      "Epoch 3, Loss: 0.12670207023620605\n",
      "Epoch 3, Loss: 0.07121992856264114\n",
      "Epoch 4, Loss: 0.2337264120578766\n",
      "Epoch 2, Loss: 0.28826233744621277\n",
      "Epoch 2, Loss: 1.8126585483551025\n",
      "Epoch 2, Loss: 0.0710151419043541\n",
      "Epoch 3, Loss: 0.07587812840938568\n",
      "Epoch 2, Loss: 0.9199845194816589\n",
      "Epoch 2, Loss: 0.1379166543483734\n",
      "Epoch 3, Loss: 0.13106109201908112\n",
      "Epoch 4, Loss: 0.029940325766801834\n",
      "Epoch 5, Loss: 0.1762971132993698\n",
      "Epoch 3, Loss: 0.042955558747053146\n",
      "Epoch 4, Loss: 0.04240616038441658\n",
      "Epoch 2, Loss: 0.2345637083053589\n",
      "Epoch 3, Loss: 0.11065304279327393\n",
      "Epoch 3, Loss: 0.6493071913719177\n",
      "Epoch 4, Loss: 0.078482985496521\n",
      "Epoch 4, Loss: 0.17503958940505981\n",
      "Epoch 3, Loss: 0.16932444274425507\n",
      "Epoch 6, Loss: 0.0725599005818367\n",
      "Epoch 5, Loss: 0.04817740619182587\n",
      "Epoch 5, Loss: 0.02651052735745907\n",
      "Epoch 3, Loss: 0.29341059923171997\n",
      "Epoch 3, Loss: 0.0798376202583313\n",
      "Epoch 4, Loss: 0.03661229833960533\n",
      "Epoch 7, Loss: 0.012040034867823124\n",
      "Epoch 6, Loss: 0.05057895928621292\n",
      "Epoch 4, Loss: 0.10645513236522675\n",
      "Epoch 5, Loss: 0.20498766005039215\n",
      "Epoch 5, Loss: 0.10360733419656754\n",
      "Epoch 3, Loss: 0.1157955527305603\n",
      "Epoch 6, Loss: 0.05190487578511238\n",
      "Epoch 4, Loss: 0.2848614752292633\n",
      "Epoch 4, Loss: 0.06728845089673996\n",
      "Epoch 5, Loss: 0.06855687499046326\n",
      "Epoch 4, Loss: 0.1538231074810028\n",
      "Epoch 4, Loss: 0.046985942870378494\n",
      "Epoch 8, Loss: 0.02056209370493889\n",
      "Epoch 7, Loss: 0.043487440794706345\n",
      "Epoch 7, Loss: 0.026108792051672935\n",
      "Epoch 6, Loss: 0.029339641332626343\n",
      "Epoch 6, Loss: 0.04041781276464462\n",
      "Epoch 6, Loss: 0.272513747215271\n",
      "Epoch 5, Loss: 0.3324233591556549\n",
      "Epoch 5, Loss: 0.05081760883331299\n",
      "Epoch 5, Loss: 0.03053566999733448\n",
      "Epoch 4, Loss: 0.222977414727211\n",
      "Epoch 8, Loss: 0.011840210296213627\n",
      "Epoch 9, Loss: 0.0613328292965889\n",
      "Epoch 5, Loss: 0.2841133773326874\n",
      "Epoch 8, Loss: 0.01606210507452488\n",
      "Epoch 5, Loss: 0.05994262918829918\n",
      "Epoch 6, Loss: 0.03730534017086029\n",
      "Epoch 7, Loss: 0.25612348318099976\n",
      "Epoch 7, Loss: 0.012832988053560257\n",
      "Epoch 7, Loss: 0.008814966306090355\n",
      "Epoch 6, Loss: 0.25308865308761597\n",
      "Epoch 9, Loss: 0.02067248523235321\n",
      "Epoch 10, Loss: 0.08789650350809097\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00029452664743207906, num_heads=4, num_layers=4; total time=   1.1s\n",
      "Epoch 6, Loss: 0.2804417908191681\n",
      "Epoch 5, Loss: 0.2902405261993408\n",
      "Epoch 9, Loss: 0.0107267452403903\n",
      "Epoch 6, Loss: 0.42979732155799866\n",
      "Epoch 8, Loss: 0.03994050249457359\n",
      "Epoch 7, Loss: 0.048081059008836746\n",
      "Epoch 10, Loss: 0.03013758547604084\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00029452664743207906, num_heads=4, num_layers=4; total time=   1.1s\n",
      "Epoch 8, Loss: 0.18845900893211365\n",
      "Epoch 8, Loss: 0.012772554531693459\n",
      "Epoch 6, Loss: 0.05082356557250023\n",
      "Epoch 7, Loss: 0.47380536794662476\n",
      "Epoch 7, Loss: 0.19015227258205414\n",
      "Epoch 10, Loss: 0.0285373255610466\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00029452664743207906, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 9, Loss: 0.06926766037940979\n",
      "Epoch 8, Loss: 0.04005981981754303\n",
      "Epoch 6, Loss: 0.25924912095069885\n",
      "Epoch 7, Loss: 0.46896278858184814\n",
      "Epoch 9, Loss: 0.030489137396216393\n",
      "Epoch 9, Loss: 0.11055038869380951\n",
      "Epoch 10, Loss: 0.06832507997751236\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00029452664743207906, num_heads=4, num_layers=4; total time=   1.3s\n",
      "Epoch 8, Loss: 0.1083131656050682\n",
      "Epoch 8, Loss: 0.5829552412033081\n",
      "Epoch 7, Loss: 0.024987604469060898\n",
      "Epoch 9, Loss: 0.019752178341150284\n",
      "Epoch 7, Loss: 0.17874659597873688\n",
      "Epoch 8, Loss: 0.4153318405151367\n",
      "Epoch 10, Loss: 0.030368855223059654\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00029452664743207906, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 10, Loss: 0.053534165024757385\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00029452664743207906, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 9, Loss: 0.06359167397022247\n",
      "Epoch 9, Loss: 0.5797519087791443\n",
      "Epoch 8, Loss: 0.016209229826927185\n",
      "Epoch 10, Loss: 0.010766737163066864\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00029452664743207906, num_heads=4, num_layers=4; total time=   1.4s\n",
      "Epoch 9, Loss: 0.31339165568351746\n",
      "Epoch 8, Loss: 0.09590576589107513\n",
      "Epoch 10, Loss: 0.05905788764357567\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00029452664743207906, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.4941551387310028\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00029452664743207906, num_heads=4, num_layers=4; total time=   1.5s\n",
      "Epoch 9, Loss: 0.025497883558273315\n",
      "Epoch 10, Loss: 0.1990775167942047\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00029452664743207906, num_heads=4, num_layers=4; total time=   1.6s\n",
      "Epoch 9, Loss: 0.04556358605623245\n",
      "Epoch 10, Loss: 0.02661817893385887\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00029452664743207906, num_heads=4, num_layers=4; total time=   1.7s\n",
      "Epoch 10, Loss: 0.03469662740826607\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.00029452664743207906, num_heads=4, num_layers=4; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.0667760819196701\n",
      "Epoch 1, Loss: 0.337311327457428\n",
      "Epoch 2, Loss: 2.088111162185669\n",
      "Epoch 1, Loss: 0.5085799098014832\n",
      "Epoch 1, Loss: 0.09656444191932678\n",
      "Epoch 1, Loss: 0.4646010994911194\n",
      "Epoch 1, Loss: 0.221028134226799\n",
      "Epoch 2, Loss: 0.6318925619125366\n",
      "Epoch 3, Loss: 0.14034083485603333\n",
      "Epoch 1, Loss: 1.479030728340149\n",
      "Epoch 2, Loss: 1.2149780988693237\n",
      "Epoch 3, Loss: 0.2761649191379547\n",
      "Epoch 2, Loss: 0.6178598999977112\n",
      "Epoch 2, Loss: 1.531705379486084\n",
      "Epoch 1, Loss: 1.1601390838623047\n",
      "Epoch 2, Loss: 1.035065770149231\n",
      "Epoch 1, Loss: 0.042724139988422394\n",
      "Epoch 1, Loss: 0.1318993866443634\n",
      "Epoch 4, Loss: 0.40043875575065613\n",
      "Epoch 1, Loss: 0.7932741641998291\n",
      "Epoch 3, Loss: 0.34366196393966675\n",
      "Epoch 3, Loss: 0.3839341998100281\n",
      "Epoch 2, Loss: 0.3527574837207794\n",
      "Epoch 1, Loss: 0.3596465289592743\n",
      "Epoch 3, Loss: 0.2108106017112732\n",
      "Epoch 4, Loss: 0.026139970868825912\n",
      "Epoch 2, Loss: 0.18279044330120087\n",
      "Epoch 3, Loss: 0.2589195966720581\n",
      "Epoch 5, Loss: 0.759858250617981\n",
      "Epoch 2, Loss: 1.5215378999710083\n",
      "Epoch 4, Loss: 0.061990685760974884\n",
      "Epoch 2, Loss: 1.4615610837936401\n",
      "Epoch 4, Loss: 0.09136423468589783\n",
      "Epoch 6, Loss: 0.5134615898132324\n",
      "Epoch 5, Loss: 0.11581318825483322\n",
      "Epoch 3, Loss: 0.7361223101615906\n",
      "Epoch 4, Loss: 0.1734379231929779\n",
      "Epoch 2, Loss: 0.15961198508739471\n",
      "Epoch 2, Loss: 0.930270791053772\n",
      "Epoch 4, Loss: 0.0692058652639389\n",
      "Epoch 5, Loss: 0.3010006248950958\n",
      "Epoch 3, Loss: 0.5481085181236267\n",
      "Epoch 3, Loss: 0.058946799486875534\n",
      "Epoch 7, Loss: 0.17009013891220093\n",
      "Epoch 5, Loss: 0.1031518280506134\n",
      "Epoch 6, Loss: 0.19794033467769623\n",
      "Epoch 3, Loss: 0.14678801596164703\n",
      "Epoch 5, Loss: 0.5138640999794006\n",
      "Epoch 7, Loss: 0.14756500720977783\n",
      "Epoch 6, Loss: 0.3290669918060303\n",
      "Epoch 5, Loss: 0.2938464283943176\n",
      "Epoch 4, Loss: 0.3707130253314972\n",
      "Epoch 4, Loss: 0.31851136684417725\n",
      "Epoch 8, Loss: 0.016542727127671242\n",
      "Epoch 6, Loss: 0.18850961327552795\n",
      "Epoch 3, Loss: 0.3070453107357025\n",
      "Epoch 3, Loss: 0.4148043394088745\n",
      "Epoch 4, Loss: 0.2218487411737442\n",
      "Epoch 4, Loss: 0.476595014333725\n",
      "Epoch 8, Loss: 0.05772735923528671\n",
      "Epoch 9, Loss: 0.06127148121595383\n",
      "Epoch 6, Loss: 0.39684349298477173\n",
      "Epoch 7, Loss: 0.16305160522460938\n",
      "Epoch 7, Loss: 0.1762906312942505\n",
      "Epoch 6, Loss: 0.30738168954849243\n",
      "Epoch 5, Loss: 0.07384474575519562\n",
      "Epoch 5, Loss: 0.08071864396333694\n",
      "Epoch 10, Loss: 0.17459137737751007\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0008661694719142919, num_heads=8, num_layers=4; total time=   1.1s\n",
      "Epoch 9, Loss: 0.011814809404313564\n",
      "Epoch 4, Loss: 0.041175488382577896\n",
      "Epoch 8, Loss: 0.02930210530757904\n",
      "Epoch 5, Loss: 0.6374775171279907\n",
      "Epoch 8, Loss: 0.09814299643039703\n",
      "Epoch 7, Loss: 0.15249982476234436\n",
      "Epoch 7, Loss: 0.15530970692634583\n",
      "Epoch 4, Loss: 0.23221196234226227\n",
      "Epoch 5, Loss: 0.5420722365379333\n",
      "Epoch 10, Loss: 0.028604064136743546\n",
      "Epoch 6, Loss: 0.04298803210258484\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0008661694719142919, num_heads=8, num_layers=4; total time=   1.2s\n",
      "Epoch 6, Loss: 0.03908170014619827\n",
      "Epoch 9, Loss: 0.023040462285280228\n",
      "Epoch 8, Loss: 0.040892116725444794\n",
      "Epoch 9, Loss: 0.03763766586780548\n",
      "Epoch 6, Loss: 0.3261094093322754\n",
      "Epoch 8, Loss: 0.026912661269307137\n",
      "Epoch 5, Loss: 0.20022040605545044\n",
      "Epoch 6, Loss: 0.3830324411392212\n",
      "Epoch 10, Loss: 0.09233502298593521\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0008661694719142919, num_heads=8, num_layers=4; total time=   1.2s\n",
      "Epoch 7, Loss: 0.10346497595310211\n",
      "Epoch 5, Loss: 0.0556357279419899\n",
      "Epoch 7, Loss: 0.1449662446975708\n",
      "Epoch 10, Loss: 0.03155166655778885\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0008661694719142919, num_heads=8, num_layers=4; total time=   1.2s\n",
      "Epoch 9, Loss: 0.033949192613363266\n",
      "Epoch 9, Loss: 0.041364818811416626\n",
      "Epoch 7, Loss: 0.06574365496635437\n",
      "Epoch 8, Loss: 0.21333198249340057\n",
      "Epoch 10, Loss: 0.11264849454164505\n",
      "Epoch 8, Loss: 0.1522553414106369\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0008661694719142919, num_heads=8, num_layers=4; total time=   1.3s\n",
      "Epoch 6, Loss: 0.27716267108917236\n",
      "Epoch 10, Loss: 0.08891509473323822\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0008661694719142919, num_heads=8, num_layers=4; total time=   1.3s\n",
      "Epoch 6, Loss: 0.025605976581573486\n",
      "Epoch 7, Loss: 0.13471154868602753\n",
      "Epoch 9, Loss: 0.1997583955526352\n",
      "Epoch 8, Loss: 0.021518254652619362\n",
      "Epoch 9, Loss: 0.1414494812488556\n",
      "Epoch 7, Loss: 0.17222408950328827\n",
      "Epoch 7, Loss: 0.08113254606723785\n",
      "Epoch 8, Loss: 0.01858392544090748\n",
      "Epoch 10, Loss: 0.130239799618721\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0008661694719142919, num_heads=8, num_layers=4; total time=   1.4s\n",
      "Epoch 10, Loss: 0.09348692744970322\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0008661694719142919, num_heads=8, num_layers=4; total time=   1.4s\n",
      "Epoch 9, Loss: 0.10986942052841187\n",
      "Epoch 8, Loss: 0.05182160064578056\n",
      "Epoch 8, Loss: 0.12570057809352875\n",
      "Epoch 9, Loss: 0.039812151342630386\n",
      "Epoch 10, Loss: 0.1936090886592865\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0008661694719142919, num_heads=8, num_layers=4; total time=   1.5s\n",
      "Epoch 9, Loss: 0.01440573763102293\n",
      "Epoch 10, Loss: 0.11240144073963165\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0008661694719142919, num_heads=8, num_layers=4; total time=   1.6s\n",
      "Epoch 9, Loss: 0.12412133812904358\n",
      "Epoch 10, Loss: 0.08615799993276596\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0008661694719142919, num_heads=8, num_layers=4; total time=   1.6s\n",
      "Epoch 10, Loss: 0.05405459925532341\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.0008661694719142919, num_heads=8, num_layers=4; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.12894918024539948\n",
      "Epoch 1, Loss: 0.32151755690574646\n",
      "Epoch 1, Loss: 0.5116241574287415\n",
      "Epoch 1, Loss: 0.5073670148849487\n",
      "Epoch 1, Loss: 0.10445274412631989\n",
      "Epoch 1, Loss: 0.018315965309739113\n",
      "Epoch 2, Loss: 0.19218966364860535\n",
      "Epoch 1, Loss: 1.9746184349060059\n",
      "Epoch 1, Loss: 0.23640528321266174\n",
      "Epoch 2, Loss: 0.09894362092018127\n",
      "Epoch 2, Loss: 0.03439280018210411\n",
      "Epoch 2, Loss: 0.599599301815033\n",
      "Epoch 2, Loss: 0.2774859666824341\n",
      "Epoch 3, Loss: 0.10507528483867645\n",
      "Epoch 2, Loss: 0.2955041527748108\n",
      "Epoch 1, Loss: 0.24530386924743652\n",
      "Epoch 3, Loss: 0.2173767387866974\n",
      "Epoch 3, Loss: 0.2940594553947449\n",
      "Epoch 1, Loss: 0.0642104297876358\n",
      "Epoch 1, Loss: 0.04424029216170311\n",
      "Epoch 1, Loss: 0.2533917725086212\n",
      "Epoch 2, Loss: 0.4829936623573303\n",
      "Epoch 2, Loss: 0.07212063670158386\n",
      "Epoch 4, Loss: 0.01782953552901745\n",
      "Epoch 3, Loss: 0.03809316083788872\n",
      "Epoch 3, Loss: 0.17235425114631653\n",
      "Epoch 3, Loss: 0.08407580107450485\n",
      "Epoch 2, Loss: 0.26701849699020386\n",
      "Epoch 4, Loss: 0.13876451551914215\n",
      "Epoch 5, Loss: 0.05514821037650108\n",
      "Epoch 3, Loss: 0.16852429509162903\n",
      "Epoch 4, Loss: 0.21129989624023438\n",
      "Epoch 4, Loss: 0.17599086463451385\n",
      "Epoch 2, Loss: 0.047480322420597076\n",
      "Epoch 3, Loss: 0.06168903037905693\n",
      "Epoch 2, Loss: 0.26399850845336914\n",
      "Epoch 2, Loss: 0.19311119616031647\n",
      "Epoch 4, Loss: 0.23812152445316315\n",
      "Epoch 6, Loss: 0.08474625647068024\n",
      "Epoch 5, Loss: 0.04624394327402115\n",
      "Epoch 4, Loss: 0.05242590978741646\n",
      "Epoch 5, Loss: 0.11644618213176727\n",
      "Epoch 3, Loss: 0.1692853569984436\n",
      "Epoch 5, Loss: 0.3205522298812866\n",
      "Epoch 4, Loss: 0.2684307098388672\n",
      "Epoch 7, Loss: 0.04694227874279022\n",
      "Epoch 4, Loss: 0.0902823880314827\n",
      "Epoch 6, Loss: 0.07752431929111481\n",
      "Epoch 6, Loss: 0.04170028120279312\n",
      "Epoch 5, Loss: 0.14577588438987732\n",
      "Epoch 3, Loss: 0.18572473526000977\n",
      "Epoch 3, Loss: 0.11672034114599228\n",
      "Epoch 3, Loss: 0.052600398659706116\n",
      "Epoch 8, Loss: 0.009384618140757084\n",
      "Epoch 7, Loss: 0.07595010846853256\n",
      "Epoch 5, Loss: 0.13140448927879333\n",
      "Epoch 4, Loss: 0.06637435406446457\n",
      "Epoch 6, Loss: 0.1987714320421219\n",
      "Epoch 5, Loss: 0.4781113266944885\n",
      "Epoch 6, Loss: 0.04386698082089424\n",
      "Epoch 7, Loss: 0.08119138330221176\n",
      "Epoch 5, Loss: 0.027841057628393173\n",
      "Epoch 9, Loss: 0.013720317743718624\n",
      "Epoch 4, Loss: 0.027248915284872055\n",
      "Epoch 7, Loss: 0.05063648894429207\n",
      "Epoch 4, Loss: 0.06264986097812653\n",
      "Epoch 7, Loss: 0.011167027987539768\n",
      "Epoch 4, Loss: 0.02095276303589344\n",
      "Epoch 8, Loss: 0.08657189458608627\n",
      "Epoch 8, Loss: 0.07034699618816376\n",
      "Epoch 6, Loss: 0.4898252487182617\n",
      "Epoch 5, Loss: 0.07799052447080612\n",
      "Epoch 6, Loss: 0.04113112390041351\n",
      "Epoch 6, Loss: 0.10121464729309082\n",
      "Epoch 10, Loss: 0.037497106939554214\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1891624472122529, feed_forward_dim=128, head_dim=16, lr=0.0004050840324762774, num_heads=8, num_layers=3; total time=   1.0s\n",
      "Epoch 8, Loss: 0.012228140607476234\n",
      "Epoch 9, Loss: 0.04771444946527481\n",
      "Epoch 5, Loss: 0.03749476373195648\n",
      "Epoch 9, Loss: 0.050966501235961914\n",
      "Epoch 8, Loss: 0.04036825895309448\n",
      "Epoch 7, Loss: 0.3717939257621765\n",
      "Epoch 5, Loss: 0.06817374378442764\n",
      "Epoch 9, Loss: 0.06730641424655914\n",
      "Epoch 7, Loss: 0.0691501572728157\n",
      "Epoch 5, Loss: 0.08300717175006866\n",
      "Epoch 10, Loss: 0.022351909428834915\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1891624472122529, feed_forward_dim=128, head_dim=16, lr=0.0004050840324762774, num_heads=8, num_layers=3; total time=   1.1s\n",
      "Epoch 6, Loss: 0.10107971727848053\n",
      "Epoch 10, Loss: 0.01837044022977352\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1891624472122529, feed_forward_dim=128, head_dim=16, lr=0.0004050840324762774, num_heads=8, num_layers=3; total time=   1.1s\n",
      "Epoch 7, Loss: 0.03204547241330147\n",
      "Epoch 9, Loss: 0.077665314078331\n",
      "Epoch 8, Loss: 0.22389787435531616\n",
      "Epoch 6, Loss: 0.06321118026971817\n",
      "Epoch 10, Loss: 0.12421540170907974\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1891624472122529, feed_forward_dim=128, head_dim=16, lr=0.0004050840324762774, num_heads=8, num_layers=3; total time=   1.1s\n",
      "Epoch 8, Loss: 0.06400447338819504\n",
      "Epoch 8, Loss: 0.01638546958565712\n",
      "Epoch 6, Loss: 0.10174502432346344\n",
      "Epoch 6, Loss: 0.0722833201289177\n",
      "Epoch 7, Loss: 0.0654996857047081\n",
      "Epoch 9, Loss: 0.10354169458150864\n",
      "Epoch 10, Loss: 0.08781395107507706\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1891624472122529, feed_forward_dim=128, head_dim=16, lr=0.0004050840324762774, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 9, Loss: 0.03275075927376747\n",
      "Epoch 7, Loss: 0.021427327767014503\n",
      "Epoch 7, Loss: 0.06959405541419983\n",
      "Epoch 7, Loss: 0.023841295391321182\n",
      "Epoch 10, Loss: 0.044334787875413895\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1891624472122529, feed_forward_dim=128, head_dim=16, lr=0.0004050840324762774, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 9, Loss: 0.046431027352809906\n",
      "Epoch 8, Loss: 0.022875353693962097\n",
      "Epoch 10, Loss: 0.011597349308431149\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1891624472122529, feed_forward_dim=128, head_dim=16, lr=0.0004050840324762774, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 8, Loss: 0.008756943047046661\n",
      "Epoch 10, Loss: 0.062041930854320526\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1891624472122529, feed_forward_dim=128, head_dim=16, lr=0.0004050840324762774, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Epoch 8, Loss: 0.009035960771143436\n",
      "Epoch 8, Loss: 0.023353729397058487\n",
      "Epoch 9, Loss: 0.015128251165151596\n",
      "Epoch 9, Loss: 0.03023173287510872\n",
      "Epoch 9, Loss: 0.03317246213555336\n",
      "Epoch 9, Loss: 0.015690874308347702\n",
      "Epoch 10, Loss: 0.03308010846376419\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1891624472122529, feed_forward_dim=128, head_dim=16, lr=0.0004050840324762774, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Epoch 10, Loss: 0.04565267264842987\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1891624472122529, feed_forward_dim=128, head_dim=16, lr=0.0004050840324762774, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.039029620587825775\n",
      "Epoch 10, Loss: 0.03369160369038582\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1891624472122529, feed_forward_dim=128, head_dim=16, lr=0.0004050840324762774, num_heads=8, num_layers=3; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1891624472122529, feed_forward_dim=128, head_dim=16, lr=0.0004050840324762774, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.011067166924476624\n",
      "Epoch 1, Loss: 1.9950835704803467\n",
      "Epoch 1, Loss: 0.8103553056716919\n",
      "Epoch 1, Loss: 0.04929453134536743\n",
      "Epoch 2, Loss: 0.695974588394165\n",
      "Epoch 1, Loss: 1.0704245567321777\n",
      "Epoch 2, Loss: 0.17358921468257904\n",
      "Epoch 1, Loss: 0.4287208020687103\n",
      "Epoch 3, Loss: 0.09578736126422882\n",
      "Epoch 1, Loss: 2.2905032634735107\n",
      "Epoch 2, Loss: 0.1336291879415512\n",
      "Epoch 1, Loss: 0.8977124094963074\n",
      "Epoch 2, Loss: 0.07970377802848816\n",
      "Epoch 1, Loss: 0.34139159321784973\n",
      "Epoch 3, Loss: 0.020110640674829483\n",
      "Epoch 2, Loss: 0.25076982378959656\n",
      "Epoch 4, Loss: 0.07812321931123734\n",
      "Epoch 2, Loss: 0.014021173119544983\n",
      "Epoch 3, Loss: 0.08689111471176147\n",
      "Epoch 3, Loss: 0.03688415512442589\n",
      "Epoch 4, Loss: 0.039714839309453964\n",
      "Epoch 2, Loss: 0.19951854646205902\n",
      "Epoch 2, Loss: 0.8860441446304321\n",
      "Epoch 1, Loss: 0.5822367072105408\n",
      "Epoch 1, Loss: 0.13300156593322754\n",
      "Epoch 1, Loss: 2.1000492572784424\n",
      "Epoch 3, Loss: 0.1539202332496643\n",
      "Epoch 5, Loss: 0.30841630697250366\n",
      "Epoch 3, Loss: 0.14937244355678558\n",
      "Epoch 2, Loss: 0.02773010917007923\n",
      "Epoch 5, Loss: 0.0921591967344284\n",
      "Epoch 4, Loss: 0.009031042456626892\n",
      "Epoch 4, Loss: 0.2595040500164032\n",
      "Epoch 3, Loss: 0.16894426941871643\n",
      "Epoch 6, Loss: 0.06101139634847641\n",
      "Epoch 3, Loss: 0.036436472088098526\n",
      "Epoch 4, Loss: 0.21329346299171448\n",
      "Epoch 2, Loss: 0.1417342722415924\n",
      "Epoch 5, Loss: 0.29668891429901123\n",
      "Epoch 6, Loss: 0.4500080943107605\n",
      "Epoch 2, Loss: 0.767875611782074\n",
      "Epoch 4, Loss: 0.32434216141700745\n",
      "Epoch 2, Loss: 0.031764596700668335\n",
      "Epoch 7, Loss: 0.018506893888115883\n",
      "Epoch 3, Loss: 0.1301269382238388\n",
      "Epoch 5, Loss: 0.03216865286231041\n",
      "Epoch 4, Loss: 0.17404474318027496\n",
      "Epoch 6, Loss: 0.2021678239107132\n",
      "Epoch 5, Loss: 0.37059706449508667\n",
      "Epoch 8, Loss: 0.008649117313325405\n",
      "Epoch 7, Loss: 0.4302521347999573\n",
      "Epoch 3, Loss: 0.17689953744411469\n",
      "Epoch 6, Loss: 0.03598432615399361\n",
      "Epoch 3, Loss: 0.08514551818370819\n",
      "Epoch 4, Loss: 0.05081435665488243\n",
      "Epoch 5, Loss: 0.12436140328645706\n",
      "Epoch 3, Loss: 0.17619651556015015\n",
      "Epoch 9, Loss: 0.029545558616518974\n",
      "Epoch 8, Loss: 0.3297044336795807\n",
      "Epoch 7, Loss: 0.09288964420557022\n",
      "Epoch 4, Loss: 0.17632333934307098\n",
      "Epoch 5, Loss: 0.2803676724433899\n",
      "Epoch 6, Loss: 0.03164515271782875\n",
      "Epoch 6, Loss: 0.27690979838371277\n",
      "Epoch 10, Loss: 0.04461450129747391\n",
      "Epoch 9, Loss: 0.2000267505645752\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0003169010763710836, num_heads=2, num_layers=2; total time=   0.9s\n",
      "Epoch 7, Loss: 0.015806810930371284\n",
      "Epoch 4, Loss: 0.040090300142765045\n",
      "Epoch 8, Loss: 0.024643491953611374\n",
      "Epoch 5, Loss: 0.25037816166877747\n",
      "Epoch 4, Loss: 0.16941756010055542\n",
      "Epoch 7, Loss: 0.010066422633826733\n",
      "Epoch 5, Loss: 0.10915114730596542\n",
      "Epoch 6, Loss: 0.26918962597846985\n",
      "Epoch 4, Loss: 0.2734977900981903\n",
      "Epoch 7, Loss: 0.15087690949440002\n",
      "Epoch 10, Loss: 0.09313249588012695\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0003169010763710836, num_heads=2, num_layers=2; total time=   1.1s\n",
      "Epoch 8, Loss: 0.006860489957034588\n",
      "Epoch 9, Loss: 0.019477227702736855\n",
      "Epoch 6, Loss: 0.44493740797042847\n",
      "Epoch 8, Loss: 0.046989426016807556\n",
      "Epoch 7, Loss: 0.18900218605995178\n",
      "Epoch 8, Loss: 0.0632910281419754\n",
      "Epoch 6, Loss: 0.03533121198415756\n",
      "Epoch 5, Loss: 0.384774386882782\n",
      "Epoch 10, Loss: 0.05259155109524727\n",
      "Epoch 9, Loss: 0.01760304719209671\n",
      "Epoch 5, Loss: 0.047957893460989\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0003169010763710836, num_heads=2, num_layers=2; total time=   1.2s\n",
      "Epoch 5, Loss: 0.18847757577896118\n",
      "Epoch 9, Loss: 0.08315375447273254\n",
      "Epoch 10, Loss: 0.024119671434164047\n",
      "Epoch 8, Loss: 0.09784938395023346\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0003169010763710836, num_heads=2, num_layers=2; total time=   1.3s\n",
      "Epoch 9, Loss: 0.03996224328875542\n",
      "Epoch 7, Loss: 0.5085904002189636\n",
      "Epoch 7, Loss: 0.015468883328139782\n",
      "Epoch 6, Loss: 0.046693019568920135\n",
      "Epoch 6, Loss: 0.513400673866272\n",
      "Epoch 6, Loss: 0.06614050269126892\n",
      "Epoch 9, Loss: 0.03893910348415375\n",
      "Epoch 8, Loss: 0.45224905014038086\n",
      "Epoch 10, Loss: 0.06001592054963112\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0003169010763710836, num_heads=2, num_layers=2; total time=   1.4s\n",
      "Epoch 10, Loss: 0.0877140685915947\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0003169010763710836, num_heads=2, num_layers=2; total time=   1.4s\n",
      "Epoch 8, Loss: 0.0422862209379673\n",
      "Epoch 7, Loss: 0.4970247149467468\n",
      "Epoch 7, Loss: 0.010877071879804134\n",
      "Epoch 10, Loss: 0.02117244340479374\n",
      "Epoch 9, Loss: 0.33270615339279175\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0003169010763710836, num_heads=2, num_layers=2; total time=   1.4s\n",
      "Epoch 7, Loss: 0.02186029963195324\n",
      "Epoch 9, Loss: 0.07334277778863907\n",
      "Epoch 8, Loss: 0.03143773600459099\n",
      "Epoch 8, Loss: 0.38939520716667175\n",
      "Epoch 10, Loss: 0.20448614656925201\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0003169010763710836, num_heads=2, num_layers=2; total time=   1.5s\n",
      "Epoch 8, Loss: 0.007039771415293217\n",
      "Epoch 10, Loss: 0.07343268394470215\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0003169010763710836, num_heads=2, num_layers=2; total time=   1.6s\n",
      "Epoch 9, Loss: 0.08012692630290985\n",
      "Epoch 9, Loss: 0.24639877676963806\n",
      "Epoch 9, Loss: 0.013585961423814297\n",
      "Epoch 10, Loss: 0.10550492256879807\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0003169010763710836, num_heads=2, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.1287132352590561\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0003169010763710836, num_heads=2, num_layers=2; total time=   1.6s\n",
      "Epoch 10, Loss: 0.019552305340766907\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0003169010763710836, num_heads=2, num_layers=2; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 2.0291919708251953\n",
      "Epoch 1, Loss: 1.2125540971755981\n",
      "Epoch 1, Loss: 1.1082210540771484\n",
      "Epoch 1, Loss: 0.6236582398414612\n",
      "Epoch 1, Loss: 0.1656169295310974\n",
      "Epoch 2, Loss: 0.7151880860328674\n",
      "Epoch 1, Loss: 0.32193711400032043\n",
      "Epoch 2, Loss: 0.21087339520454407\n",
      "Epoch 2, Loss: 0.06404921412467957\n",
      "Epoch 1, Loss: 0.9012240767478943\n",
      "Epoch 2, Loss: 0.28366556763648987\n",
      "Epoch 2, Loss: 0.08739645034074783\n",
      "Epoch 1, Loss: 1.287845492362976\n",
      "Epoch 2, Loss: 0.0408586785197258\n",
      "Epoch 3, Loss: 0.17773234844207764\n",
      "Epoch 1, Loss: 0.770527720451355\n",
      "Epoch 3, Loss: 0.11340171843767166\n",
      "Epoch 3, Loss: 0.05450640991330147\n",
      "Epoch 3, Loss: 0.15454448759555817\n",
      "Epoch 3, Loss: 0.12724776566028595\n",
      "Epoch 1, Loss: 0.2805918753147125\n",
      "Epoch 2, Loss: 0.19824501872062683\n",
      "Epoch 2, Loss: 0.26955291628837585\n",
      "Epoch 1, Loss: 0.12128714472055435\n",
      "Epoch 4, Loss: 0.27899786829948425\n",
      "Epoch 4, Loss: 0.21980351209640503\n",
      "Epoch 2, Loss: 0.20177151262760162\n",
      "Epoch 1, Loss: 0.06626390665769577\n",
      "Epoch 4, Loss: 0.31056052446365356\n",
      "Epoch 3, Loss: 0.14943823218345642\n",
      "Epoch 5, Loss: 0.39711490273475647\n",
      "Epoch 5, Loss: 0.4209116995334625\n",
      "Epoch 4, Loss: 0.24714501202106476\n",
      "Epoch 4, Loss: 0.050477974116802216\n",
      "Epoch 2, Loss: 0.17754295468330383\n",
      "Epoch 3, Loss: 0.08031037449836731\n",
      "Epoch 2, Loss: 0.06132575497031212\n",
      "Epoch 5, Loss: 0.37405601143836975\n",
      "Epoch 6, Loss: 0.3408861756324768\n",
      "Epoch 3, Loss: 0.0820796862244606\n",
      "Epoch 4, Loss: 0.16466084122657776\n",
      "Epoch 6, Loss: 0.5283145904541016\n",
      "Epoch 3, Loss: 0.1567239910364151\n",
      "Epoch 5, Loss: 0.22279463708400726\n",
      "Epoch 5, Loss: 0.009419778361916542\n",
      "Epoch 2, Loss: 0.14150232076644897\n",
      "Epoch 7, Loss: 0.20910872519016266\n",
      "Epoch 3, Loss: 0.2002851963043213\n",
      "Epoch 6, Loss: 0.3039867877960205\n",
      "Epoch 7, Loss: 0.48733484745025635\n",
      "Epoch 3, Loss: 0.07969225198030472\n",
      "Epoch 4, Loss: 0.30596813559532166\n",
      "Epoch 5, Loss: 0.08982224762439728\n",
      "Epoch 4, Loss: 0.23274292051792145\n",
      "Epoch 6, Loss: 0.04004976898431778\n",
      "Epoch 6, Loss: 0.12548217177391052\n",
      "Epoch 8, Loss: 0.36863741278648376\n",
      "Epoch 8, Loss: 0.08583910763263702\n",
      "Epoch 4, Loss: 0.265750914812088\n",
      "Epoch 7, Loss: 0.18680274486541748\n",
      "Epoch 5, Loss: 0.430122435092926\n",
      "Epoch 4, Loss: 0.1171913743019104\n",
      "Epoch 4, Loss: 0.05513044819235802\n",
      "Epoch 9, Loss: 0.23384951055049896\n",
      "Epoch 6, Loss: 0.025630153715610504\n",
      "Epoch 5, Loss: 0.3101072907447815\n",
      "Epoch 3, Loss: 0.03017531707882881\n",
      "Epoch 9, Loss: 0.02353050373494625\n",
      "Epoch 7, Loss: 0.044245440512895584\n",
      "Epoch 7, Loss: 0.06274853646755219\n",
      "Epoch 5, Loss: 0.29599320888519287\n",
      "Epoch 8, Loss: 0.09113413840532303\n",
      "Epoch 10, Loss: 0.12519219517707825\n",
      "Epoch 10, Loss: 0.022324712947010994\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0003449986173325634, num_heads=8, num_layers=3; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0003449986173325634, num_heads=8, num_layers=3; total time=   1.2s\n",
      "Epoch 5, Loss: 0.025440124794840813\n",
      "Epoch 6, Loss: 0.2702685594558716\n",
      "Epoch 8, Loss: 0.020162880420684814\n",
      "Epoch 7, Loss: 0.020488817244768143\n",
      "Epoch 5, Loss: 0.07960914820432663\n",
      "Epoch 8, Loss: 0.04172388091683388\n",
      "Epoch 4, Loss: 0.06112217158079147\n",
      "Epoch 6, Loss: 0.37185677886009216\n",
      "Epoch 9, Loss: 0.045161448419094086\n",
      "Epoch 6, Loss: 0.2415435016155243\n",
      "Epoch 7, Loss: 0.17411984503269196\n",
      "Epoch 9, Loss: 0.013119651935994625\n",
      "Epoch 6, Loss: 0.032581627368927\n",
      "Epoch 8, Loss: 0.05025141313672066\n",
      "Epoch 9, Loss: 0.0407046414911747\n",
      "Epoch 10, Loss: 0.04902971163392067\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0003449986173325634, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 7, Loss: 0.2323019802570343\n",
      "Epoch 5, Loss: 0.06667078286409378\n",
      "Epoch 6, Loss: 0.058657750487327576\n",
      "Epoch 7, Loss: 0.15900854766368866\n",
      "Epoch 10, Loss: 0.006484172772616148\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0003449986173325634, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 9, Loss: 0.07022590190172195\n",
      "Epoch 8, Loss: 0.08839478343725204\n",
      "Epoch 7, Loss: 0.08102760463953018\n",
      "Epoch 10, Loss: 0.07480594515800476\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0003449986173325634, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Epoch 8, Loss: 0.10316348075866699\n",
      "Epoch 6, Loss: 0.025019953027367592\n",
      "Epoch 8, Loss: 0.08972746878862381\n",
      "Epoch 7, Loss: 0.024853790178894997\n",
      "Epoch 10, Loss: 0.06048654019832611\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0003449986173325634, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 9, Loss: 0.04208163172006607\n",
      "Epoch 8, Loss: 0.08312027901411057\n",
      "Epoch 9, Loss: 0.03205649182200432\n",
      "Epoch 7, Loss: 0.008606734685599804\n",
      "Epoch 8, Loss: 0.020513024181127548\n",
      "Epoch 9, Loss: 0.056977059692144394\n",
      "Epoch 10, Loss: 0.040268659591674805\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0003449986173325634, num_heads=8, num_layers=3; total time=   1.6s\n",
      "Epoch 10, Loss: 0.030618352815508842\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0003449986173325634, num_heads=8, num_layers=3; total time=   1.6s\n",
      "Epoch 9, Loss: 0.04456847161054611\n",
      "Epoch 9, Loss: 0.03395689278841019\n",
      "Epoch 8, Loss: 0.029835909605026245\n",
      "Epoch 10, Loss: 0.061438173055648804\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0003449986173325634, num_heads=8, num_layers=3; total time=   1.6s\n",
      "Epoch 10, Loss: 0.011539468541741371\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0003449986173325634, num_heads=8, num_layers=3; total time=   1.6s\n",
      "Epoch 10, Loss: 0.03222406655550003\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0003449986173325634, num_heads=8, num_layers=3; total time=   1.6s\n",
      "Epoch 9, Loss: 0.03875080496072769\n",
      "Epoch 10, Loss: 0.021693434566259384\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.0003449986173325634, num_heads=8, num_layers=3; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 1.2029352188110352\n",
      "Epoch 1, Loss: 2.125540018081665\n",
      "Epoch 1, Loss: 0.4527791738510132\n",
      "Epoch 1, Loss: 0.23443308472633362\n",
      "Epoch 1, Loss: 1.2028801441192627\n",
      "Epoch 1, Loss: 0.28372007608413696\n",
      "Epoch 2, Loss: 0.1221824586391449\n",
      "Epoch 2, Loss: 0.19198785722255707\n",
      "Epoch 1, Loss: 0.28040069341659546\n",
      "Epoch 2, Loss: 0.8732802867889404\n",
      "Epoch 1, Loss: 2.5863335132598877\n",
      "Epoch 2, Loss: 0.236643984913826\n",
      "Epoch 2, Loss: 0.2045326679944992\n",
      "Epoch 3, Loss: 0.18918263912200928\n",
      "Epoch 3, Loss: 0.15429654717445374\n",
      "Epoch 2, Loss: 0.05275629088282585\n",
      "Epoch 3, Loss: 0.1972876936197281\n",
      "Epoch 3, Loss: 0.13280369341373444\n",
      "Epoch 2, Loss: 0.056493740528821945\n",
      "Epoch 2, Loss: 0.9185899496078491\n",
      "Epoch 3, Loss: 0.11639611423015594\n",
      "Epoch 1, Loss: 0.17384518682956696\n",
      "Epoch 1, Loss: 0.023090820759534836\n",
      "Epoch 4, Loss: 0.3976704776287079\n",
      "Epoch 1, Loss: 2.4152214527130127\n",
      "Epoch 1, Loss: 0.17595846951007843\n",
      "Epoch 4, Loss: 0.015970809385180473\n",
      "Epoch 4, Loss: 0.2058936208486557\n",
      "Epoch 4, Loss: 0.04327326640486717\n",
      "Epoch 3, Loss: 0.18795092403888702\n",
      "Epoch 5, Loss: 0.4532698094844818\n",
      "Epoch 4, Loss: 0.33874446153640747\n",
      "Epoch 2, Loss: 0.05690714344382286\n",
      "Epoch 2, Loss: 0.22097665071487427\n",
      "Epoch 2, Loss: 0.955754280090332\n",
      "Epoch 5, Loss: 0.1666596531867981\n",
      "Epoch 3, Loss: 0.17420974373817444\n",
      "Epoch 5, Loss: 0.12510451674461365\n",
      "Epoch 3, Loss: 0.16933554410934448\n",
      "Epoch 4, Loss: 0.12720754742622375\n",
      "Epoch 6, Loss: 0.3296557664871216\n",
      "Epoch 5, Loss: 0.06006627529859543\n",
      "Epoch 2, Loss: 0.06294935196638107\n",
      "Epoch 5, Loss: 0.41940176486968994\n",
      "Epoch 6, Loss: 0.35390469431877136\n",
      "Epoch 6, Loss: 0.049708519130945206\n",
      "Epoch 6, Loss: 0.06682664155960083\n",
      "Epoch 7, Loss: 0.1730637401342392\n",
      "Epoch 4, Loss: 0.17128007113933563\n",
      "Epoch 3, Loss: 0.12295924872159958\n",
      "Epoch 3, Loss: 0.11696986854076385\n",
      "Epoch 6, Loss: 0.33168235421180725\n",
      "Epoch 3, Loss: 0.17771866917610168\n",
      "Epoch 7, Loss: 0.4318801760673523\n",
      "Epoch 5, Loss: 0.036650702357292175\n",
      "Epoch 4, Loss: 0.13984932005405426\n",
      "Epoch 8, Loss: 0.06580229103565216\n",
      "Epoch 4, Loss: 0.07457424700260162\n",
      "Epoch 3, Loss: 0.03137986734509468\n",
      "Epoch 7, Loss: 0.028333645313978195\n",
      "Epoch 5, Loss: 0.4479661285877228\n",
      "Epoch 7, Loss: 0.1917286217212677\n",
      "Epoch 7, Loss: 0.029871072620153427\n",
      "Epoch 8, Loss: 0.40075352787971497\n",
      "Epoch 4, Loss: 0.040800873190164566\n",
      "Epoch 5, Loss: 0.05749504268169403\n",
      "Epoch 6, Loss: 0.028877127915620804\n",
      "Epoch 9, Loss: 0.04143722727894783\n",
      "Epoch 4, Loss: 0.04755503684282303\n",
      "Epoch 8, Loss: 0.006681885104626417\n",
      "Epoch 8, Loss: 0.07365473359823227\n",
      "Epoch 9, Loss: 0.302895724773407\n",
      "Epoch 6, Loss: 0.6095389127731323\n",
      "Epoch 8, Loss: 0.052523352205753326\n",
      "Epoch 4, Loss: 0.051827214658260345\n",
      "Epoch 5, Loss: 0.02129005268216133\n",
      "Epoch 10, Loss: 0.0795544758439064\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00034881026223717904, num_heads=8, num_layers=3; total time=   1.2s\n",
      "Epoch 9, Loss: 0.027340097352862358\n",
      "Epoch 7, Loss: 0.06996551901102066\n",
      "Epoch 9, Loss: 0.022866474464535713\n",
      "Epoch 5, Loss: 0.07804552465677261\n",
      "Epoch 6, Loss: 0.026106996461749077\n",
      "Epoch 10, Loss: 0.19222694635391235\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00034881026223717904, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 5, Loss: 0.2687196433544159\n",
      "Epoch 7, Loss: 0.5865105390548706\n",
      "Epoch 10, Loss: 0.04599892720580101\n",
      "Epoch 9, Loss: 0.07549994438886642\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00034881026223717904, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 8, Loss: 0.08345382660627365\n",
      "Epoch 6, Loss: 0.026109851896762848\n",
      "Epoch 5, Loss: 0.01252101082354784\n",
      "Epoch 10, Loss: 0.039672501385211945\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00034881026223717904, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Epoch 7, Loss: 0.04764869436621666\n",
      "Epoch 6, Loss: 0.0839131772518158\n",
      "Epoch 8, Loss: 0.4487142562866211\n",
      "Epoch 10, Loss: 0.07181265205144882\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00034881026223717904, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.0590519979596138\n",
      "Epoch 6, Loss: 0.4705056846141815\n",
      "Epoch 7, Loss: 0.05118408054113388\n",
      "Epoch 8, Loss: 0.07005196809768677\n",
      "Epoch 9, Loss: 0.27883294224739075\n",
      "Epoch 6, Loss: 0.01636185310781002\n",
      "Epoch 10, Loss: 0.02463863603770733\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00034881026223717904, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 7, Loss: 0.04101160913705826\n",
      "Epoch 8, Loss: 0.049535781145095825\n",
      "Epoch 10, Loss: 0.13608437776565552\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00034881026223717904, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 9, Loss: 0.06126328185200691\n",
      "Epoch 7, Loss: 0.5137351751327515\n",
      "Epoch 7, Loss: 0.033306580036878586\n",
      "Epoch 8, Loss: 0.019740592688322067\n",
      "Epoch 9, Loss: 0.025078456848859787\n",
      "Epoch 10, Loss: 0.03329363092780113\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00034881026223717904, num_heads=8, num_layers=3; total time=   1.7s\n",
      "Epoch 8, Loss: 0.018330374732613564\n",
      "Epoch 9, Loss: 0.03736221045255661\n",
      "Epoch 8, Loss: 0.4356636703014374\n",
      "Epoch 10, Loss: 0.006844797171652317\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00034881026223717904, num_heads=8, num_layers=3; total time=   1.6s\n",
      "Epoch 9, Loss: 0.005144901107996702\n",
      "Epoch 9, Loss: 0.305058091878891\n",
      "Epoch 10, Loss: 0.0554150715470314\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00034881026223717904, num_heads=8, num_layers=3; total time=   1.7s\n",
      "Epoch 10, Loss: 0.010706187225878239\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00034881026223717904, num_heads=8, num_layers=3; total time=   1.8s\n",
      "Epoch 10, Loss: 0.17491665482521057\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00034881026223717904, num_heads=8, num_layers=3; total time=   1.8s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.4841901361942291\n",
      "Epoch 1, Loss: 0.2128520905971527\n",
      "Epoch 1, Loss: 0.1152971014380455\n",
      "Epoch 1, Loss: 0.21902884542942047\n",
      "Epoch 1, Loss: 1.6789047718048096\n",
      "Epoch 2, Loss: 0.21482345461845398\n",
      "Epoch 1, Loss: 0.20740929245948792\n",
      "Epoch 2, Loss: 0.06805601716041565\n",
      "Epoch 1, Loss: 0.36574506759643555\n",
      "Epoch 1, Loss: 0.8398509621620178\n",
      "Epoch 2, Loss: 0.0724698007106781\n",
      "Epoch 2, Loss: 0.1730145514011383\n",
      "Epoch 1, Loss: 0.8663883805274963\n",
      "Epoch 2, Loss: 1.1883007287979126\n",
      "Epoch 3, Loss: 0.059738777577877045\n",
      "Epoch 1, Loss: 0.45082342624664307\n",
      "Epoch 1, Loss: 0.45013412833213806\n",
      "Epoch 2, Loss: 0.0494251474738121\n",
      "Epoch 3, Loss: 0.04319683462381363\n",
      "Epoch 3, Loss: 0.16408371925354004\n",
      "Epoch 2, Loss: 0.4811526834964752\n",
      "Epoch 1, Loss: 0.06448209285736084\n",
      "Epoch 3, Loss: 0.07816721498966217\n",
      "Epoch 2, Loss: 0.14338015019893646\n",
      "Epoch 3, Loss: 0.7749537825584412\n",
      "Epoch 4, Loss: 0.0100148506462574\n",
      "Epoch 2, Loss: 0.5287786722183228\n",
      "Epoch 4, Loss: 0.13730043172836304\n",
      "Epoch 4, Loss: 0.07568717747926712\n",
      "Epoch 3, Loss: 0.025226568803191185\n",
      "Epoch 2, Loss: 0.25851404666900635\n",
      "Epoch 3, Loss: 0.22367146611213684\n",
      "Epoch 2, Loss: 0.24529539048671722\n",
      "Epoch 5, Loss: 0.03732023015618324\n",
      "Epoch 4, Loss: 0.06927385926246643\n",
      "Epoch 3, Loss: 0.046783044934272766\n",
      "Epoch 5, Loss: 0.09353077411651611\n",
      "Epoch 4, Loss: 0.4640783667564392\n",
      "Epoch 3, Loss: 0.27794986963272095\n",
      "Epoch 5, Loss: 0.10544811934232712\n",
      "Epoch 2, Loss: 0.04190729185938835\n",
      "Epoch 6, Loss: 0.09132274240255356\n",
      "Epoch 4, Loss: 0.06982365995645523\n",
      "Epoch 6, Loss: 0.0787118598818779\n",
      "Epoch 5, Loss: 0.05135296657681465\n",
      "Epoch 3, Loss: 0.14364323019981384\n",
      "Epoch 4, Loss: 0.0710974633693695\n",
      "Epoch 3, Loss: 0.1474449634552002\n",
      "Epoch 6, Loss: 0.09047496318817139\n",
      "Epoch 4, Loss: 0.04426075518131256\n",
      "Epoch 5, Loss: 0.2471277117729187\n",
      "Epoch 7, Loss: 0.12248484790325165\n",
      "Epoch 4, Loss: 0.10963832587003708\n",
      "Epoch 7, Loss: 0.05092627555131912\n",
      "Epoch 5, Loss: 0.08782317489385605\n",
      "Epoch 6, Loss: 0.03698734939098358\n",
      "Epoch 3, Loss: 0.027368590235710144\n",
      "Epoch 7, Loss: 0.08028867095708847\n",
      "Epoch 5, Loss: 0.010180027224123478\n",
      "Epoch 8, Loss: 0.12114928662776947\n",
      "Epoch 4, Loss: 0.10375763475894928\n",
      "Epoch 8, Loss: 0.02743145264685154\n",
      "Epoch 4, Loss: 0.13173484802246094\n",
      "Epoch 6, Loss: 0.12095165252685547\n",
      "Epoch 5, Loss: 0.08485271036624908\n",
      "Epoch 6, Loss: 0.07085969299077988\n",
      "Epoch 5, Loss: 0.024393515661358833\n",
      "Epoch 7, Loss: 0.032969698309898376\n",
      "Epoch 9, Loss: 0.01850089244544506\n",
      "Epoch 9, Loss: 0.09633351117372513\n",
      "Epoch 6, Loss: 0.019689280539751053\n",
      "Epoch 8, Loss: 0.06816105544567108\n",
      "Epoch 4, Loss: 0.016940228641033173\n",
      "Epoch 6, Loss: 0.11397429555654526\n",
      "Epoch 7, Loss: 0.07202654331922531\n",
      "Epoch 5, Loss: 0.1471715122461319\n",
      "Epoch 10, Loss: 0.06252608448266983\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.2587926976237612, feed_forward_dim=128, head_dim=32, lr=0.0001369915467282404, num_heads=8, num_layers=3; total time=   1.2s\n",
      "Epoch 7, Loss: 0.03836818411946297\n",
      "Epoch 6, Loss: 0.003517978359013796\n",
      "Epoch 10, Loss: 0.022009946405887604\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.2587926976237612, feed_forward_dim=128, head_dim=32, lr=0.0001369915467282404, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 5, Loss: 0.11093920469284058\n",
      "Epoch 8, Loss: 0.03176940977573395\n",
      "Epoch 9, Loss: 0.05624737963080406\n",
      "Epoch 8, Loss: 0.08560686558485031\n",
      "Epoch 7, Loss: 0.06525720655918121\n",
      "Epoch 6, Loss: 0.15995971858501434\n",
      "Epoch 8, Loss: 0.01641595922410488\n",
      "Epoch 10, Loss: 0.04356299340724945\n",
      "Epoch 7, Loss: 0.11338409781455994\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.2587926976237612, feed_forward_dim=128, head_dim=32, lr=0.0001369915467282404, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 7, Loss: 0.028565788641572\n",
      "Epoch 6, Loss: 0.13280043005943298\n",
      "Epoch 5, Loss: 0.01019721943885088\n",
      "Epoch 9, Loss: 0.12962791323661804\n",
      "Epoch 9, Loss: 0.029120467603206635\n",
      "Epoch 9, Loss: 0.012347912415862083\n",
      "Epoch 8, Loss: 0.1154697835445404\n",
      "Epoch 8, Loss: 0.08904679119586945\n",
      "Epoch 7, Loss: 0.1493930071592331\n",
      "Epoch 8, Loss: 0.07265309244394302\n",
      "Epoch 10, Loss: 0.02164052613079548\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.2587926976237612, feed_forward_dim=128, head_dim=32, lr=0.0001369915467282404, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 7, Loss: 0.14293977618217468\n",
      "Epoch 10, Loss: 0.1838216334581375\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.2587926976237612, feed_forward_dim=128, head_dim=32, lr=0.0001369915467282404, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.02257528342306614\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.2587926976237612, feed_forward_dim=128, head_dim=32, lr=0.0001369915467282404, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 6, Loss: 0.007938279770314693\n",
      "Epoch 9, Loss: 0.14556021988391876\n",
      "Epoch 9, Loss: 0.059376053512096405\n",
      "Epoch 9, Loss: 0.11351101100444794\n",
      "Epoch 8, Loss: 0.12152130156755447\n",
      "Epoch 8, Loss: 0.13387008011341095\n",
      "Epoch 10, Loss: 0.03156470134854317\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.2587926976237612, feed_forward_dim=128, head_dim=32, lr=0.0001369915467282404, num_heads=8, num_layers=3; total time=   1.6s\n",
      "Epoch 10, Loss: 0.15293343365192413\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.2587926976237612, feed_forward_dim=128, head_dim=32, lr=0.0001369915467282404, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 7, Loss: 0.008196410723030567\n",
      "Epoch 10, Loss: 0.13557836413383484\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.2587926976237612, feed_forward_dim=128, head_dim=32, lr=0.0001369915467282404, num_heads=8, num_layers=3; total time=   1.6s\n",
      "Epoch 9, Loss: 0.08946163207292557\n",
      "Epoch 9, Loss: 0.11101909726858139\n",
      "Epoch 10, Loss: 0.06001296639442444\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.2587926976237612, feed_forward_dim=128, head_dim=32, lr=0.0001369915467282404, num_heads=8, num_layers=3; total time=   1.6s\n",
      "Epoch 8, Loss: 0.009825030341744423\n",
      "Epoch 10, Loss: 0.08344198018312454\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.2587926976237612, feed_forward_dim=128, head_dim=32, lr=0.0001369915467282404, num_heads=8, num_layers=3; total time=   1.7s\n",
      "Epoch 9, Loss: 0.011932648718357086\n",
      "Epoch 10, Loss: 0.014089622534811497\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.2587926976237612, feed_forward_dim=128, head_dim=32, lr=0.0001369915467282404, num_heads=8, num_layers=3; total time=   1.8s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.3117561936378479\n",
      "Epoch 1, Loss: 0.4972904622554779\n",
      "Epoch 2, Loss: 8.876229286193848\n",
      "Epoch 1, Loss: 0.12630091607570648\n",
      "Epoch 1, Loss: 0.09764055162668228\n",
      "Epoch 1, Loss: 2.103553533554077\n",
      "Epoch 2, Loss: 8.062198638916016\n",
      "Epoch 1, Loss: 0.3607299029827118\n",
      "Epoch 3, Loss: 2.863405704498291\n",
      "Epoch 1, Loss: 2.9930591583251953\n",
      "Epoch 2, Loss: 7.350261688232422\n",
      "Epoch 1, Loss: 0.6851130723953247\n",
      "Epoch 2, Loss: 7.3130998611450195\n",
      "Epoch 3, Loss: 2.770036458969116\n",
      "Epoch 4, Loss: 0.23055490851402283\n",
      "Epoch 2, Loss: 3.83892560005188\n",
      "Epoch 1, Loss: 0.9366374611854553\n",
      "Epoch 1, Loss: 0.06547007709741592\n",
      "Epoch 2, Loss: 5.920208930969238\n",
      "Epoch 1, Loss: 1.1373696327209473\n",
      "Epoch 3, Loss: 1.9425902366638184\n",
      "Epoch 2, Loss: 4.304159641265869\n",
      "Epoch 5, Loss: 0.3938480615615845\n",
      "Epoch 4, Loss: 0.3295663893222809\n",
      "Epoch 3, Loss: 1.6699484586715698\n",
      "Epoch 1, Loss: 0.31635263562202454\n",
      "Epoch 3, Loss: 1.6034880876541138\n",
      "Epoch 2, Loss: 5.93969202041626\n",
      "Epoch 3, Loss: 1.8684425354003906\n",
      "Epoch 2, Loss: 8.446361541748047\n",
      "Epoch 2, Loss: 7.430467128753662\n",
      "Epoch 6, Loss: 0.8777108788490295\n",
      "Epoch 4, Loss: 0.03859813138842583\n",
      "Epoch 3, Loss: 2.021636962890625\n",
      "Epoch 4, Loss: 0.043610796332359314\n",
      "Epoch 5, Loss: 0.16738128662109375\n",
      "Epoch 4, Loss: 0.16623690724372864\n",
      "Epoch 3, Loss: 1.721556305885315\n",
      "Epoch 2, Loss: 10.173989295959473\n",
      "Epoch 2, Loss: 6.060753345489502\n",
      "Epoch 7, Loss: 0.7191408276557922\n",
      "Epoch 3, Loss: 0.3251335024833679\n",
      "Epoch 4, Loss: 0.1251642256975174\n",
      "Epoch 6, Loss: 0.6804314851760864\n",
      "Epoch 3, Loss: 2.45141339302063\n",
      "Epoch 5, Loss: 0.8316240906715393\n",
      "Epoch 5, Loss: 0.6981692314147949\n",
      "Epoch 8, Loss: 0.36238399147987366\n",
      "Epoch 4, Loss: 0.34055668115615845\n",
      "Epoch 5, Loss: 0.19175685942173004\n",
      "Epoch 3, Loss: 2.6099276542663574\n",
      "Epoch 4, Loss: 0.06531228870153427\n",
      "Epoch 6, Loss: 0.8361824154853821\n",
      "Epoch 7, Loss: 0.7502412796020508\n",
      "Epoch 5, Loss: 0.31354400515556335\n",
      "Epoch 6, Loss: 0.695062518119812\n",
      "Epoch 9, Loss: 0.11731801182031631\n",
      "Epoch 3, Loss: 1.894042730331421\n",
      "Epoch 4, Loss: 2.005114793777466\n",
      "Epoch 5, Loss: 0.08277153968811035\n",
      "Epoch 6, Loss: 0.5044212937355042\n",
      "Epoch 4, Loss: 0.1615368276834488\n",
      "Epoch 7, Loss: 0.4080110788345337\n",
      "Epoch 8, Loss: 0.50913006067276\n",
      "Epoch 10, Loss: 0.06442300975322723\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.39505055105914066, feed_forward_dim=1024, head_dim=16, lr=0.0029556988049796447, num_heads=8, num_layers=4; total time=   1.0s\n",
      "Epoch 6, Loss: 0.6206508874893188\n",
      "Epoch 7, Loss: 0.2982962429523468\n",
      "Epoch 4, Loss: 0.056616876274347305\n",
      "Epoch 5, Loss: 1.0481219291687012\n",
      "Epoch 6, Loss: 0.3861175775527954\n",
      "Epoch 5, Loss: 0.5015215873718262\n",
      "Epoch 8, Loss: 0.10712136328220367\n",
      "Epoch 5, Loss: 0.4085172414779663\n",
      "Epoch 9, Loss: 0.22801560163497925\n",
      "Epoch 7, Loss: 0.46154335141181946\n",
      "Epoch 4, Loss: 0.10274253040552139\n",
      "Epoch 7, Loss: 0.48822811245918274\n",
      "Epoch 8, Loss: 0.06952714920043945\n",
      "Epoch 6, Loss: 0.709567129611969\n",
      "Epoch 9, Loss: 0.04619907960295677\n",
      "Epoch 10, Loss: 0.07688970118761063\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.39505055105914066, feed_forward_dim=1024, head_dim=16, lr=0.0029556988049796447, num_heads=8, num_layers=4; total time=   1.2s\n",
      "Epoch 8, Loss: 0.24294282495975494\n",
      "Epoch 6, Loss: 0.17572680115699768\n",
      "Epoch 7, Loss: 0.45332515239715576\n",
      "Epoch 6, Loss: 0.8804810047149658\n",
      "Epoch 5, Loss: 0.84169602394104\n",
      "Epoch 9, Loss: 0.09589699655771255\n",
      "Epoch 8, Loss: 0.23816092312335968\n",
      "Epoch 10, Loss: 0.1261761486530304\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.39505055105914066, feed_forward_dim=1024, head_dim=16, lr=0.0029556988049796447, num_heads=8, num_layers=4; total time=   1.2s\n",
      "Epoch 7, Loss: 0.4743591248989105\n",
      "Epoch 5, Loss: 0.3000061511993408\n",
      "Epoch 7, Loss: 0.058211296796798706\n",
      "Epoch 10, Loss: 0.20253297686576843\n",
      "Epoch 9, Loss: 0.082095205783844\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.39505055105914066, feed_forward_dim=1024, head_dim=16, lr=0.0029556988049796447, num_heads=8, num_layers=4; total time=   1.3s\n",
      "Epoch 7, Loss: 0.6851083636283875\n",
      "Epoch 6, Loss: 0.9007089734077454\n",
      "Epoch 8, Loss: 0.29544711112976074\n",
      "Epoch 9, Loss: 0.0822315588593483\n",
      "Epoch 8, Loss: 0.20431283116340637\n",
      "Epoch 6, Loss: 0.6168574690818787\n",
      "Epoch 10, Loss: 0.056904543191194534\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.39505055105914066, feed_forward_dim=1024, head_dim=16, lr=0.0029556988049796447, num_heads=8, num_layers=4; total time=   1.3s\n",
      "Epoch 8, Loss: 0.20674118399620056\n",
      "Epoch 8, Loss: 0.29464948177337646\n",
      "Epoch 10, Loss: 0.052452269941568375\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.39505055105914066, feed_forward_dim=1024, head_dim=16, lr=0.0029556988049796447, num_heads=8, num_layers=4; total time=   1.4s\n",
      "Epoch 9, Loss: 0.06607060879468918\n",
      "Epoch 7, Loss: 0.4441744089126587\n",
      "Epoch 9, Loss: 0.11788977682590485\n",
      "Epoch 7, Loss: 0.4914695620536804\n",
      "Epoch 9, Loss: 0.2861105501651764\n",
      "Epoch 9, Loss: 0.0688164010643959\n",
      "Epoch 10, Loss: 0.05985376238822937\n",
      "Epoch 10, Loss: 0.050879135727882385\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.39505055105914066, feed_forward_dim=1024, head_dim=16, lr=0.0029556988049796447, num_heads=8, num_layers=4; total time=   1.4s\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.39505055105914066, feed_forward_dim=1024, head_dim=16, lr=0.0029556988049796447, num_heads=8, num_layers=4; total time=   1.5s\n",
      "Epoch 8, Loss: 0.11162330955266953\n",
      "Epoch 8, Loss: 0.22642457485198975\n",
      "Epoch 10, Loss: 0.25253647565841675\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.39505055105914066, feed_forward_dim=1024, head_dim=16, lr=0.0029556988049796447, num_heads=8, num_layers=4; total time=   1.5s\n",
      "Epoch 10, Loss: 0.0735161304473877\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.39505055105914066, feed_forward_dim=1024, head_dim=16, lr=0.0029556988049796447, num_heads=8, num_layers=4; total time=   1.5s\n",
      "Epoch 9, Loss: 0.06668338924646378\n",
      "Epoch 9, Loss: 0.06560850143432617\n",
      "Epoch 10, Loss: 0.17971526086330414\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.39505055105914066, feed_forward_dim=1024, head_dim=16, lr=0.0029556988049796447, num_heads=8, num_layers=4; total time=   1.6s\n",
      "Epoch 10, Loss: 0.06300973147153854\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.39505055105914066, feed_forward_dim=1024, head_dim=16, lr=0.0029556988049796447, num_heads=8, num_layers=4; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 1.547532320022583\n",
      "Epoch 1, Loss: 0.159742534160614\n",
      "Epoch 1, Loss: 0.8717128038406372\n",
      "Epoch 1, Loss: 0.10834173858165741\n",
      "Epoch 1, Loss: 1.9053303003311157\n",
      "Epoch 2, Loss: 0.26130107045173645\n",
      "Epoch 1, Loss: 0.3864210844039917\n",
      "Epoch 2, Loss: 0.3008267879486084\n",
      "Epoch 2, Loss: 0.3115317225456238\n",
      "Epoch 2, Loss: 0.03431728109717369\n",
      "Epoch 3, Loss: 0.41911378502845764\n",
      "Epoch 1, Loss: 0.0749497339129448\n",
      "Epoch 2, Loss: 0.2899019122123718\n",
      "Epoch 3, Loss: 0.072898268699646\n",
      "Epoch 1, Loss: 0.4567849040031433\n",
      "Epoch 3, Loss: 0.247645765542984\n",
      "Epoch 1, Loss: 0.3604291081428528\n",
      "Epoch 2, Loss: 0.06255140900611877\n",
      "Epoch 4, Loss: 0.6053625345230103\n",
      "Epoch 3, Loss: 0.09382715821266174\n",
      "Epoch 1, Loss: 1.6172605752944946\n",
      "Epoch 4, Loss: 0.12270395457744598\n",
      "Epoch 2, Loss: 0.3075712323188782\n",
      "Epoch 1, Loss: 1.3668900728225708\n",
      "Epoch 5, Loss: 0.4710794687271118\n",
      "Epoch 1, Loss: 0.2594955563545227\n",
      "Epoch 3, Loss: 0.11495961248874664\n",
      "Epoch 3, Loss: 0.24178975820541382\n",
      "Epoch 4, Loss: 0.3744415044784546\n",
      "Epoch 2, Loss: 0.05506451055407524\n",
      "Epoch 2, Loss: 0.0671924576163292\n",
      "Epoch 3, Loss: 0.02994123473763466\n",
      "Epoch 4, Loss: 0.018960703164339066\n",
      "Epoch 5, Loss: 0.13963942229747772\n",
      "Epoch 2, Loss: 0.21517236530780792\n",
      "Epoch 2, Loss: 0.1668427288532257\n",
      "Epoch 5, Loss: 0.2649756371974945\n",
      "Epoch 4, Loss: 0.4628327786922455\n",
      "Epoch 6, Loss: 0.24495041370391846\n",
      "Epoch 2, Loss: 0.12936845421791077\n",
      "Epoch 3, Loss: 0.27019003033638\n",
      "Epoch 6, Loss: 0.060690172016620636\n",
      "Epoch 5, Loss: 0.10751854628324509\n",
      "Epoch 4, Loss: 0.17069804668426514\n",
      "Epoch 3, Loss: 0.24798986315727234\n",
      "Epoch 4, Loss: 0.14858001470565796\n",
      "Epoch 7, Loss: 0.09432744979858398\n",
      "Epoch 6, Loss: 0.10422752052545547\n",
      "Epoch 5, Loss: 0.5826904773712158\n",
      "Epoch 7, Loss: 0.022969018667936325\n",
      "Epoch 3, Loss: 0.13888534903526306\n",
      "Epoch 3, Loss: 0.17846660315990448\n",
      "Epoch 6, Loss: 0.1127588301897049\n",
      "Epoch 5, Loss: 0.04855841025710106\n",
      "Epoch 4, Loss: 0.19814792275428772\n",
      "Epoch 8, Loss: 0.05565737560391426\n",
      "Epoch 7, Loss: 0.019326111301779747\n",
      "Epoch 3, Loss: 0.20458002388477325\n",
      "Epoch 5, Loss: 0.16010034084320068\n",
      "Epoch 8, Loss: 0.05013827234506607\n",
      "Epoch 6, Loss: 0.46135324239730835\n",
      "Epoch 4, Loss: 0.13840898871421814\n",
      "Epoch 9, Loss: 0.09672244638204575\n",
      "Epoch 7, Loss: 0.046570513397455215\n",
      "Epoch 6, Loss: 0.01946422830224037\n",
      "Epoch 9, Loss: 0.07300419360399246\n",
      "Epoch 8, Loss: 0.026600336655974388\n",
      "Epoch 4, Loss: 0.4737984240055084\n",
      "Epoch 6, Loss: 0.06003659591078758\n",
      "Epoch 7, Loss: 0.2600330412387848\n",
      "Epoch 5, Loss: 0.05700148269534111\n",
      "Epoch 4, Loss: 0.44794028997421265\n",
      "Epoch 10, Loss: 0.15071514248847961\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00046870694723177007, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 5, Loss: 0.023255838081240654\n",
      "Epoch 10, Loss: 0.0546535961329937\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00046870694723177007, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 8, Loss: 0.008798021823167801\n",
      "Epoch 4, Loss: 0.07078728079795837\n",
      "Epoch 9, Loss: 0.07841258496046066\n",
      "Epoch 8, Loss: 0.10394979268312454\n",
      "Epoch 7, Loss: 0.06830571591854095\n",
      "Epoch 7, Loss: 0.013743743300437927\n",
      "Epoch 6, Loss: 0.008934465236961842\n",
      "Epoch 9, Loss: 0.024379106238484383\n",
      "Epoch 5, Loss: 0.5115490555763245\n",
      "Epoch 6, Loss: 0.028082294389605522\n",
      "Epoch 10, Loss: 0.1190033107995987\n",
      "Epoch 5, Loss: 0.44512471556663513\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00046870694723177007, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.03821399435400963\n",
      "Epoch 8, Loss: 0.10032286494970322\n",
      "Epoch 5, Loss: 0.015769654884934425\n",
      "Epoch 10, Loss: 0.053226031363010406\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00046870694723177007, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 8, Loss: 0.04869404062628746\n",
      "Epoch 7, Loss: 0.053486187011003494\n",
      "Epoch 6, Loss: 0.3481651246547699\n",
      "Epoch 10, Loss: 0.05408862233161926\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00046870694723177007, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 7, Loss: 0.0873468741774559\n",
      "Epoch 6, Loss: 0.2733425498008728\n",
      "Epoch 9, Loss: 0.08510925620794296\n",
      "Epoch 8, Loss: 0.10357312858104706\n",
      "Epoch 9, Loss: 0.08216430246829987\n",
      "Epoch 6, Loss: 0.06805884838104248\n",
      "Epoch 8, Loss: 0.10059084743261337\n",
      "Epoch 7, Loss: 0.15634329617023468\n",
      "Epoch 10, Loss: 0.04106619581580162\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00046870694723177007, num_heads=8, num_layers=3; total time=   1.7s\n",
      "Epoch 7, Loss: 0.10596870630979538\n",
      "Epoch 9, Loss: 0.09434622526168823\n",
      "Epoch 10, Loss: 0.06855982542037964\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00046870694723177007, num_heads=8, num_layers=3; total time=   1.7s\n",
      "Epoch 9, Loss: 0.06143590062856674\n",
      "Epoch 7, Loss: 0.09611949324607849\n",
      "Epoch 8, Loss: 0.04307388886809349\n",
      "Epoch 10, Loss: 0.050021059811115265\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00046870694723177007, num_heads=8, num_layers=3; total time=   1.7s\n",
      "Epoch 8, Loss: 0.025099417194724083\n",
      "Epoch 10, Loss: 0.019140077754855156\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00046870694723177007, num_heads=8, num_layers=3; total time=   1.8s\n",
      "Epoch 9, Loss: 0.02250928431749344\n",
      "Epoch 8, Loss: 0.06015338748693466\n",
      "Epoch 9, Loss: 0.036098662763834\n",
      "Epoch 10, Loss: 0.06415358185768127\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00046870694723177007, num_heads=8, num_layers=3; total time=   1.9s\n",
      "Epoch 9, Loss: 0.015024025924503803\n",
      "Epoch 10, Loss: 0.09393361955881119\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00046870694723177007, num_heads=8, num_layers=3; total time=   1.9s\n",
      "Epoch 10, Loss: 0.009925282560288906\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=8, lr=0.00046870694723177007, num_heads=8, num_layers=3; total time=   1.9s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.8168983459472656\n",
      "Epoch 1, Loss: 0.6222367882728577\n",
      "Epoch 1, Loss: 0.06970710307359695\n",
      "Epoch 1, Loss: 0.08798346668481827\n",
      "Epoch 1, Loss: 0.06724430620670319\n",
      "Epoch 1, Loss: 0.7646494507789612\n",
      "Epoch 1, Loss: 0.5158008337020874\n",
      "Epoch 1, Loss: 1.1628423929214478\n",
      "Epoch 2, Loss: 0.2314913272857666\n",
      "Epoch 2, Loss: 0.10976745188236237\n",
      "Epoch 2, Loss: 0.37073037028312683\n",
      "Epoch 2, Loss: 0.2859920859336853\n",
      "Epoch 1, Loss: 2.2376532554626465\n",
      "Epoch 1, Loss: 0.2384047657251358\n",
      "Epoch 2, Loss: 0.11568763107061386\n",
      "Epoch 2, Loss: 0.06433741003274918\n",
      "Epoch 3, Loss: 0.36083993315696716\n",
      "Epoch 3, Loss: 0.08108828216791153\n",
      "Epoch 3, Loss: 0.3162027895450592\n",
      "Epoch 2, Loss: 0.07062864303588867\n",
      "Epoch 1, Loss: 2.627901554107666\n",
      "Epoch 2, Loss: 0.10977153480052948\n",
      "Epoch 1, Loss: 0.3292924761772156\n",
      "Epoch 2, Loss: 0.2718041241168976\n",
      "Epoch 3, Loss: 0.0726422518491745\n",
      "Epoch 4, Loss: 0.3784637749195099\n",
      "Epoch 3, Loss: 0.13167338073253632\n",
      "Epoch 2, Loss: 0.27668288350105286\n",
      "Epoch 4, Loss: 0.286674439907074\n",
      "Epoch 3, Loss: 0.28408563137054443\n",
      "Epoch 4, Loss: 0.04456879571080208\n",
      "Epoch 3, Loss: 0.21383698284626007\n",
      "Epoch 4, Loss: 0.02870778739452362\n",
      "Epoch 3, Loss: 0.1527451127767563\n",
      "Epoch 5, Loss: 0.23703895509243011\n",
      "Epoch 3, Loss: 0.16133403778076172\n",
      "Epoch 5, Loss: 0.13372546434402466\n",
      "Epoch 2, Loss: 0.817886471748352\n",
      "Epoch 4, Loss: 0.03066418506205082\n",
      "Epoch 5, Loss: 0.14982420206069946\n",
      "Epoch 2, Loss: 0.07123429328203201\n",
      "Epoch 3, Loss: 0.1594253033399582\n",
      "Epoch 4, Loss: 0.24196135997772217\n",
      "Epoch 4, Loss: 0.31098803877830505\n",
      "Epoch 5, Loss: 0.1152842789888382\n",
      "Epoch 6, Loss: 0.10379084944725037\n",
      "Epoch 6, Loss: 0.048059623688459396\n",
      "Epoch 6, Loss: 0.12929067015647888\n",
      "Epoch 4, Loss: 0.39952021837234497\n",
      "Epoch 4, Loss: 0.03706832230091095\n",
      "Epoch 7, Loss: 0.06283304840326309\n",
      "Epoch 6, Loss: 0.0951877012848854\n",
      "Epoch 5, Loss: 0.2319679856300354\n",
      "Epoch 4, Loss: 0.6042931079864502\n",
      "Epoch 5, Loss: 0.042136300355196\n",
      "Epoch 3, Loss: 0.05641571432352066\n",
      "Epoch 7, Loss: 0.06050485372543335\n",
      "Epoch 3, Loss: 0.2176927775144577\n",
      "Epoch 7, Loss: 0.043577928096055984\n",
      "Epoch 5, Loss: 0.09221576899290085\n",
      "Epoch 8, Loss: 0.08809563517570496\n",
      "Epoch 7, Loss: 0.026004452258348465\n",
      "Epoch 6, Loss: 0.10412159562110901\n",
      "Epoch 8, Loss: 0.10940536111593246\n",
      "Epoch 5, Loss: 0.37986481189727783\n",
      "Epoch 8, Loss: 0.012245328165590763\n",
      "Epoch 6, Loss: 0.06898168474435806\n",
      "Epoch 5, Loss: 0.6387858986854553\n",
      "Epoch 5, Loss: 0.07557251304388046\n",
      "Epoch 9, Loss: 0.12262284755706787\n",
      "Epoch 4, Loss: 0.11524992436170578\n",
      "Epoch 4, Loss: 0.11483737081289291\n",
      "Epoch 8, Loss: 0.006537401117384434\n",
      "Epoch 9, Loss: 0.1230149120092392\n",
      "Epoch 6, Loss: 0.02664603851735592\n",
      "Epoch 9, Loss: 0.04203515127301216\n",
      "Epoch 7, Loss: 0.02677304856479168\n",
      "Epoch 7, Loss: 0.0340462364256382\n",
      "Epoch 10, Loss: 0.11879604309797287\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00047085580584058155, num_heads=8, num_layers=3; total time=   1.2s\n",
      "Epoch 6, Loss: 0.22514095902442932\n",
      "Epoch 6, Loss: 0.4260130822658539\n",
      "Epoch 9, Loss: 0.03545474261045456\n",
      "Epoch 10, Loss: 0.07321356981992722\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00047085580584058155, num_heads=8, num_layers=3; total time=   1.2s\n",
      "Epoch 6, Loss: 0.10675337165594101\n",
      "Epoch 5, Loss: 0.01932246796786785\n",
      "Epoch 8, Loss: 0.014967159368097782\n",
      "Epoch 10, Loss: 0.09001791477203369\n",
      "Epoch 7, Loss: 0.06032752990722656\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00047085580584058155, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 5, Loss: 0.415171355009079\n",
      "Epoch 8, Loss: 0.03912024572491646\n",
      "Epoch 7, Loss: 0.0843702033162117\n",
      "Epoch 10, Loss: 0.057137731462717056\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00047085580584058155, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 8, Loss: 0.10913513600826263\n",
      "Epoch 9, Loss: 0.041215166449546814\n",
      "Epoch 7, Loss: 0.18917611241340637\n",
      "Epoch 9, Loss: 0.08490518480539322\n",
      "Epoch 7, Loss: 0.06091021001338959\n",
      "Epoch 6, Loss: 0.5447314977645874\n",
      "Epoch 8, Loss: 0.02258564904332161\n",
      "Epoch 6, Loss: 0.027126504108309746\n",
      "Epoch 10, Loss: 0.03910459205508232\n",
      "Epoch 10, Loss: 0.11155574023723602\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00047085580584058155, num_heads=8, num_layers=3; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00047085580584058155, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Epoch 8, Loss: 0.015896940603852272\n",
      "Epoch 7, Loss: 0.49786531925201416\n",
      "Epoch 9, Loss: 0.03682475537061691\n",
      "Epoch 9, Loss: 0.10839973390102386\n",
      "Epoch 8, Loss: 0.04948055371642113\n",
      "Epoch 7, Loss: 0.07366219162940979\n",
      "Epoch 10, Loss: 0.08611281961202621\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00047085580584058155, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 8, Loss: 0.3603687584400177\n",
      "Epoch 10, Loss: 0.06839956343173981\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00047085580584058155, num_heads=8, num_layers=3; total time=   1.6s\n",
      "Epoch 9, Loss: 0.021884186193346977\n",
      "Epoch 9, Loss: 0.021320803090929985\n",
      "Epoch 8, Loss: 0.07955751568078995\n",
      "Epoch 9, Loss: 0.20970739424228668\n",
      "Epoch 10, Loss: 0.050771985203027725\n",
      "Epoch 10, Loss: 0.06790263205766678\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00047085580584058155, num_heads=8, num_layers=3; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00047085580584058155, num_heads=8, num_layers=3; total time=   1.6s\n",
      "Epoch 9, Loss: 0.04729942977428436\n",
      "Epoch 10, Loss: 0.09353403747081757\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00047085580584058155, num_heads=8, num_layers=3; total time=   1.7s\n",
      "Epoch 10, Loss: 0.013404639437794685\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00047085580584058155, num_heads=8, num_layers=3; total time=   1.7s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.25995755195617676\n",
      "Epoch 1, Loss: 0.7540158033370972\n",
      "Epoch 1, Loss: 0.92839115858078\n",
      "Epoch 1, Loss: 0.6852610111236572\n",
      "Epoch 2, Loss: 0.18130771815776825\n",
      "Epoch 1, Loss: 0.059517618268728256\n",
      "Epoch 1, Loss: 0.17251460254192352\n",
      "Epoch 2, Loss: 0.07745489478111267\n",
      "Epoch 1, Loss: 0.10408826917409897\n",
      "Epoch 2, Loss: 0.11365535855293274\n",
      "Epoch 1, Loss: 0.8318268656730652\n",
      "Epoch 3, Loss: 0.18017826974391937\n",
      "Epoch 2, Loss: 0.06254656612873077\n",
      "Epoch 2, Loss: 0.5613922476768494\n",
      "Epoch 1, Loss: 0.4015069603919983\n",
      "Epoch 2, Loss: 0.07215248793363571\n",
      "Epoch 1, Loss: 1.9138894081115723\n",
      "Epoch 1, Loss: 0.11761852353811264\n",
      "Epoch 3, Loss: 0.33405545353889465\n",
      "Epoch 4, Loss: 0.06330431252717972\n",
      "Epoch 3, Loss: 0.29816997051239014\n",
      "Epoch 3, Loss: 0.31402674317359924\n",
      "Epoch 1, Loss: 0.15460698306560516\n",
      "Epoch 2, Loss: 0.01883905753493309\n",
      "Epoch 2, Loss: 0.37150105834007263\n",
      "Epoch 3, Loss: 0.1367260366678238\n",
      "Epoch 4, Loss: 0.3396146893501282\n",
      "Epoch 2, Loss: 0.3146284222602844\n",
      "Epoch 2, Loss: 0.03809406980872154\n",
      "Epoch 5, Loss: 0.038498543202877045\n",
      "Epoch 3, Loss: 0.10061953961849213\n",
      "Epoch 4, Loss: 0.261898010969162\n",
      "Epoch 4, Loss: 0.4175695478916168\n",
      "Epoch 3, Loss: 0.04423031955957413\n",
      "Epoch 2, Loss: 0.49042031168937683\n",
      "Epoch 5, Loss: 0.1899823546409607\n",
      "Epoch 4, Loss: 0.10756749659776688\n",
      "Epoch 6, Loss: 0.07680640369653702\n",
      "Epoch 5, Loss: 0.08413746953010559\n",
      "Epoch 3, Loss: 0.2225230634212494\n",
      "Epoch 2, Loss: 0.5203970074653625\n",
      "Epoch 3, Loss: 0.07550306618213654\n",
      "Epoch 3, Loss: 0.2860463857650757\n",
      "Epoch 5, Loss: 0.27098414301872253\n",
      "Epoch 4, Loss: 0.042985089123249054\n",
      "Epoch 6, Loss: 0.056827347725629807\n",
      "Epoch 7, Loss: 0.07367026805877686\n",
      "Epoch 4, Loss: 0.14973461627960205\n",
      "Epoch 5, Loss: 0.2284425050020218\n",
      "Epoch 6, Loss: 0.01488998532295227\n",
      "Epoch 3, Loss: 0.11159677058458328\n",
      "Epoch 4, Loss: 0.42522716522216797\n",
      "Epoch 8, Loss: 0.033459946513175964\n",
      "Epoch 4, Loss: 0.3801928460597992\n",
      "Epoch 4, Loss: 0.1857459545135498\n",
      "Epoch 7, Loss: 0.021961955353617668\n",
      "Epoch 5, Loss: 0.018856657668948174\n",
      "Epoch 6, Loss: 0.10354047268629074\n",
      "Epoch 3, Loss: 0.14330735802650452\n",
      "Epoch 7, Loss: 0.053398050367832184\n",
      "Epoch 6, Loss: 0.17214033007621765\n",
      "Epoch 5, Loss: 0.1829598844051361\n",
      "Epoch 9, Loss: 0.01023747120052576\n",
      "Epoch 4, Loss: 0.06046939268708229\n",
      "Epoch 6, Loss: 0.05890107527375221\n",
      "Epoch 5, Loss: 0.24285009503364563\n",
      "Epoch 8, Loss: 0.06735222041606903\n",
      "Epoch 7, Loss: 0.026064051315188408\n",
      "Epoch 8, Loss: 0.10723941773176193\n",
      "Epoch 5, Loss: 0.5700929164886475\n",
      "Epoch 10, Loss: 0.020792167633771896\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00048220450409241063, num_heads=2, num_layers=3; total time=   1.0s\n",
      "Epoch 6, Loss: 0.08134590089321136\n",
      "Epoch 7, Loss: 0.05817241594195366\n",
      "Epoch 5, Loss: 0.06579186022281647\n",
      "Epoch 9, Loss: 0.11741620302200317\n",
      "Epoch 4, Loss: 0.06570818275213242\n",
      "Epoch 5, Loss: 0.20004265010356903\n",
      "Epoch 7, Loss: 0.032679781317710876\n",
      "Epoch 9, Loss: 0.11152216792106628\n",
      "Epoch 6, Loss: 0.08023223280906677\n",
      "Epoch 8, Loss: 0.04485331103205681\n",
      "Epoch 6, Loss: 0.4621198773384094\n",
      "Epoch 10, Loss: 0.12410643696784973\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00048220450409241063, num_heads=2, num_layers=3; total time=   1.1s\n",
      "Epoch 8, Loss: 0.022114083170890808\n",
      "Epoch 7, Loss: 0.012196146883070469\n",
      "Epoch 10, Loss: 0.07147692143917084\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00048220450409241063, num_heads=2, num_layers=3; total time=   1.1s\n",
      "Epoch 8, Loss: 0.009341948665678501\n",
      "Epoch 6, Loss: 0.15322643518447876\n",
      "Epoch 9, Loss: 0.10258055478334427\n",
      "Epoch 5, Loss: 0.21169263124465942\n",
      "Epoch 6, Loss: 0.01740860752761364\n",
      "Epoch 7, Loss: 0.013661867938935757\n",
      "Epoch 9, Loss: 0.062015220522880554\n",
      "Epoch 9, Loss: 0.025562074035406113\n",
      "Epoch 10, Loss: 0.13598226010799408\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00048220450409241063, num_heads=2, num_layers=3; total time=   1.2s\n",
      "Epoch 7, Loss: 0.2666488587856293\n",
      "Epoch 8, Loss: 0.038524869829416275\n",
      "Epoch 7, Loss: 0.04913304001092911\n",
      "Epoch 7, Loss: 0.04323851689696312\n",
      "Epoch 8, Loss: 0.04547883942723274\n",
      "Epoch 10, Loss: 0.10119717568159103\n",
      "Epoch 10, Loss: 0.03473502770066261\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00048220450409241063, num_heads=2, num_layers=3; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00048220450409241063, num_heads=2, num_layers=3; total time=   1.3s\n",
      "Epoch 9, Loss: 0.08553045243024826\n",
      "Epoch 8, Loss: 0.10763419419527054\n",
      "Epoch 6, Loss: 0.17038895189762115\n",
      "Epoch 8, Loss: 0.08875781297683716\n",
      "Epoch 9, Loss: 0.10827089846134186\n",
      "Epoch 10, Loss: 0.08134002238512039\n",
      "Epoch 8, Loss: 0.009869677014648914\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00048220450409241063, num_heads=2, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.02822028659284115\n",
      "Epoch 9, Loss: 0.0888027474284172\n",
      "Epoch 7, Loss: 0.0562589056789875\n",
      "Epoch 10, Loss: 0.14129772782325745\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00048220450409241063, num_heads=2, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.04868808761239052\n",
      "Epoch 10, Loss: 0.03064655512571335\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00048220450409241063, num_heads=2, num_layers=3; total time=   1.4s\n",
      "Epoch 10, Loss: 0.05589592084288597\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00048220450409241063, num_heads=2, num_layers=3; total time=   1.4s\n",
      "Epoch 8, Loss: 0.016987815499305725\n",
      "Epoch 10, Loss: 0.08498333394527435\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00048220450409241063, num_heads=2, num_layers=3; total time=   1.5s\n",
      "Epoch 9, Loss: 0.05653054267168045\n",
      "Epoch 10, Loss: 0.09471716731786728\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=16, lr=0.00048220450409241063, num_heads=2, num_layers=3; total time=   1.6s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.08228615671396255\n",
      "Epoch 1, Loss: 0.169758602976799\n",
      "Epoch 1, Loss: 0.14969056844711304\n",
      "Epoch 2, Loss: 0.1260218322277069\n",
      "Epoch 1, Loss: 0.9847988486289978\n",
      "Epoch 1, Loss: 0.8034324645996094\n",
      "Epoch 1, Loss: 0.07885531336069107\n",
      "Epoch 2, Loss: 0.3183159828186035\n",
      "Epoch 1, Loss: 0.5030996203422546\n",
      "Epoch 2, Loss: 0.13401101529598236\n",
      "Epoch 2, Loss: 0.075587697327137\n",
      "Epoch 3, Loss: 0.02610534429550171\n",
      "Epoch 2, Loss: 0.38941946625709534\n",
      "Epoch 1, Loss: 0.32062119245529175\n",
      "Epoch 3, Loss: 0.07975881546735764\n",
      "Epoch 2, Loss: 0.11548677086830139\n",
      "Epoch 1, Loss: 1.6862304210662842\n",
      "Epoch 2, Loss: 0.06531532853841782\n",
      "Epoch 3, Loss: 0.10636183619499207\n",
      "Epoch 4, Loss: 0.08011380583047867\n",
      "Epoch 3, Loss: 0.16656360030174255\n",
      "Epoch 4, Loss: 0.12303847819566727\n",
      "Epoch 3, Loss: 0.06357055902481079\n",
      "Epoch 2, Loss: 0.06998172402381897\n",
      "Epoch 4, Loss: 0.021858368068933487\n",
      "Epoch 5, Loss: 0.041223399341106415\n",
      "Epoch 3, Loss: 0.14571914076805115\n",
      "Epoch 5, Loss: 0.14304690062999725\n",
      "Epoch 4, Loss: 0.3257615864276886\n",
      "Epoch 2, Loss: 0.388095498085022\n",
      "Epoch 4, Loss: 0.07690782099962234\n",
      "Epoch 3, Loss: 0.23951327800750732\n",
      "Epoch 6, Loss: 0.009252065792679787\n",
      "Epoch 5, Loss: 0.03021666221320629\n",
      "Epoch 6, Loss: 0.06123080477118492\n",
      "Epoch 1, Loss: 0.07953004539012909\n",
      "Epoch 4, Loss: 0.34511512517929077\n",
      "Epoch 5, Loss: 0.2576664984226227\n",
      "Epoch 3, Loss: 0.2230708748102188\n",
      "Epoch 1, Loss: 0.9418273568153381\n",
      "Epoch 5, Loss: 0.17782802879810333\n",
      "Epoch 7, Loss: 0.03336150944232941\n",
      "Epoch 4, Loss: 0.2460663914680481\n",
      "Epoch 3, Loss: 0.0065764873288571835\n",
      "Epoch 1, Loss: 0.07498573511838913\n",
      "Epoch 6, Loss: 0.06134060025215149\n",
      "Epoch 7, Loss: 0.02225675620138645\n",
      "Epoch 6, Loss: 0.11637268960475922\n",
      "Epoch 5, Loss: 0.33277928829193115\n",
      "Epoch 8, Loss: 0.043602000921964645\n",
      "Epoch 6, Loss: 0.11925000697374344\n",
      "Epoch 7, Loss: 0.048497267067432404\n",
      "Epoch 2, Loss: 0.34015822410583496\n",
      "Epoch 4, Loss: 0.12093799561262131\n",
      "Epoch 4, Loss: 0.20190437138080597\n",
      "Epoch 7, Loss: 0.030077649280428886\n",
      "Epoch 5, Loss: 0.12517274916172028\n",
      "Epoch 9, Loss: 0.02184215560555458\n",
      "Epoch 2, Loss: 0.14292171597480774\n",
      "Epoch 8, Loss: 0.04447097331285477\n",
      "Epoch 6, Loss: 0.2042761892080307\n",
      "Epoch 2, Loss: 0.4104430675506592\n",
      "Epoch 8, Loss: 0.016543524339795113\n",
      "Epoch 10, Loss: 0.009277948178350925\n",
      "Epoch 8, Loss: 0.019552554935216904\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=0.00043246339996608874, num_heads=8, num_layers=3; total time=   1.0s\n",
      "Epoch 7, Loss: 0.029462255537509918\n",
      "Epoch 7, Loss: 0.08402106165885925\n",
      "Epoch 5, Loss: 0.019106563180685043\n",
      "Epoch 5, Loss: 0.40720078349113464\n",
      "Epoch 3, Loss: 0.07163549959659576\n",
      "Epoch 9, Loss: 0.06480106711387634\n",
      "Epoch 6, Loss: 0.038438133895397186\n",
      "Epoch 3, Loss: 0.2678167521953583\n",
      "Epoch 9, Loss: 0.009945416823029518\n",
      "Epoch 9, Loss: 0.058002106845378876\n",
      "Epoch 3, Loss: 0.037746332585811615\n",
      "Epoch 10, Loss: 0.04973667114973068\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=0.00043246339996608874, num_heads=8, num_layers=3; total time=   1.1s\n",
      "Epoch 8, Loss: 0.010569551028311253\n",
      "Epoch 6, Loss: 0.4262014925479889\n",
      "Epoch 8, Loss: 0.027147777378559113\n",
      "Epoch 10, Loss: 0.025556284934282303\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=0.00043246339996608874, num_heads=8, num_layers=3; total time=   1.1s\n",
      "Epoch 6, Loss: 0.03131125122308731\n",
      "Epoch 7, Loss: 0.03133520483970642\n",
      "Epoch 4, Loss: 0.05394411087036133\n",
      "Epoch 10, Loss: 0.09717202931642532\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=0.00043246339996608874, num_heads=8, num_layers=3; total time=   1.1s\n",
      "Epoch 4, Loss: 0.3827373683452606\n",
      "Epoch 9, Loss: 0.04830758273601532\n",
      "Epoch 4, Loss: 0.1307101994752884\n",
      "Epoch 8, Loss: 0.0711834579706192\n",
      "Epoch 9, Loss: 0.04006136953830719\n",
      "Epoch 7, Loss: 0.32120898365974426\n",
      "Epoch 5, Loss: 0.1514558494091034\n",
      "Epoch 5, Loss: 0.272030770778656\n",
      "Epoch 7, Loss: 0.08460558205842972\n",
      "Epoch 10, Loss: 0.07868527621030807\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=0.00043246339996608874, num_heads=8, num_layers=3; total time=   1.2s\n",
      "Epoch 9, Loss: 0.09600278735160828\n",
      "Epoch 10, Loss: 0.08608661592006683\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=0.00043246339996608874, num_heads=8, num_layers=3; total time=   1.2s\n",
      "Epoch 5, Loss: 0.20140491425991058\n",
      "Epoch 8, Loss: 0.18131929636001587\n",
      "Epoch 6, Loss: 0.10501984506845474\n",
      "Epoch 6, Loss: 0.11617948114871979\n",
      "Epoch 10, Loss: 0.08585204929113388\n",
      "Epoch 8, Loss: 0.09235252439975739\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=0.00043246339996608874, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 9, Loss: 0.06852185726165771\n",
      "Epoch 6, Loss: 0.0971541479229927\n",
      "Epoch 7, Loss: 0.026945162564516068\n",
      "Epoch 7, Loss: 0.03272266313433647\n",
      "Epoch 9, Loss: 0.053512461483478546\n",
      "Epoch 10, Loss: 0.011262044310569763\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=0.00043246339996608874, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Epoch 7, Loss: 0.012991014868021011\n",
      "Epoch 8, Loss: 0.0144111393019557\n",
      "Epoch 8, Loss: 0.043128639459609985\n",
      "Epoch 10, Loss: 0.014957754872739315\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=0.00043246339996608874, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 8, Loss: 0.028338216245174408\n",
      "Epoch 9, Loss: 0.05404428020119667\n",
      "Epoch 9, Loss: 0.097584567964077\n",
      "Epoch 9, Loss: 0.0809483677148819\n",
      "Epoch 10, Loss: 0.07301608473062515\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=0.00043246339996608874, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Epoch 10, Loss: 0.13072149455547333\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=0.00043246339996608874, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Epoch 10, Loss: 0.09242400527000427\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=0.00043246339996608874, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.26086553931236267\n",
      "Epoch 1, Loss: 0.0775282233953476\n",
      "Epoch 1, Loss: 1.3330318927764893\n",
      "Epoch 1, Loss: 0.9234353303909302\n",
      "Epoch 1, Loss: 0.38707026839256287\n",
      "Epoch 1, Loss: 0.1648334413766861\n",
      "Epoch 2, Loss: 0.36240068078041077\n",
      "Epoch 1, Loss: 0.2181503027677536\n",
      "Epoch 2, Loss: 0.2759891748428345\n",
      "Epoch 2, Loss: 0.2899278998374939\n",
      "Epoch 2, Loss: 0.10097797960042953\n",
      "Epoch 1, Loss: 0.6489802002906799\n",
      "Epoch 2, Loss: 0.2417346090078354\n",
      "Epoch 3, Loss: 0.06074338033795357\n",
      "Epoch 3, Loss: 0.19102641940116882\n",
      "Epoch 1, Loss: 0.24211385846138\n",
      "Epoch 2, Loss: 0.05605582147836685\n",
      "Epoch 3, Loss: 0.18624036014080048\n",
      "Epoch 2, Loss: 0.15968511998653412\n",
      "Epoch 1, Loss: 0.05649781972169876\n",
      "Epoch 3, Loss: 0.13259005546569824\n",
      "Epoch 1, Loss: 1.0644079446792603\n",
      "Epoch 4, Loss: 0.06057516485452652\n",
      "Epoch 4, Loss: 0.029388824477791786\n",
      "Epoch 3, Loss: 0.1318674385547638\n",
      "Epoch 1, Loss: 2.571743965148926\n",
      "Epoch 2, Loss: 0.1037421002984047\n",
      "Epoch 2, Loss: 0.04798891022801399\n",
      "Epoch 4, Loss: 0.37207701802253723\n",
      "Epoch 3, Loss: 0.22466468811035156\n",
      "Epoch 5, Loss: 0.06247532740235329\n",
      "Epoch 3, Loss: 0.17181721329689026\n",
      "Epoch 5, Loss: 0.1504717618227005\n",
      "Epoch 4, Loss: 0.3340297043323517\n",
      "Epoch 2, Loss: 0.18924126029014587\n",
      "Epoch 2, Loss: 0.26174241304397583\n",
      "Epoch 5, Loss: 0.4121798276901245\n",
      "Epoch 3, Loss: 0.18925516307353973\n",
      "Epoch 4, Loss: 0.17910940945148468\n",
      "Epoch 6, Loss: 0.12220092862844467\n",
      "Epoch 2, Loss: 0.7434508800506592\n",
      "Epoch 3, Loss: 0.19618909060955048\n",
      "Epoch 6, Loss: 0.10467424243688583\n",
      "Epoch 4, Loss: 0.0439954474568367\n",
      "Epoch 6, Loss: 0.320428729057312\n",
      "Epoch 4, Loss: 0.0508185438811779\n",
      "Epoch 5, Loss: 0.3314912021160126\n",
      "Epoch 7, Loss: 0.08309410512447357\n",
      "Epoch 3, Loss: 0.20541958510875702\n",
      "Epoch 5, Loss: 0.060532666742801666\n",
      "Epoch 7, Loss: 0.026140131056308746\n",
      "Epoch 3, Loss: 0.027730459347367287\n",
      "Epoch 4, Loss: 0.06845880299806595\n",
      "Epoch 7, Loss: 0.18554919958114624\n",
      "Epoch 5, Loss: 0.08822568506002426\n",
      "Epoch 6, Loss: 0.21097443997859955\n",
      "Epoch 3, Loss: 0.11493134498596191\n",
      "Epoch 8, Loss: 0.010354535654187202\n",
      "Epoch 8, Loss: 0.026891198009252548\n",
      "Epoch 5, Loss: 0.030377080664038658\n",
      "Epoch 6, Loss: 0.020289268344640732\n",
      "Epoch 4, Loss: 0.2876394987106323\n",
      "Epoch 4, Loss: 0.08388396352529526\n",
      "Epoch 5, Loss: 0.008569854311645031\n",
      "Epoch 4, Loss: 0.3903639614582062\n",
      "Epoch 8, Loss: 0.08466856926679611\n",
      "Epoch 9, Loss: 0.01908690668642521\n",
      "Epoch 7, Loss: 0.09057516604661942\n",
      "Epoch 9, Loss: 0.04811442643404007\n",
      "Epoch 6, Loss: 0.09814819693565369\n",
      "Epoch 6, Loss: 0.07657144218683243\n",
      "Epoch 4, Loss: 0.3052741587162018\n",
      "Epoch 10, Loss: 0.0484149195253849\n",
      "Epoch 10, Loss: 0.07374250888824463\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=32, lr=0.0004311432253684024, num_heads=8, num_layers=3; total time=   1.0s\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=32, lr=0.0004311432253684024, num_heads=8, num_layers=3; total time=   1.0s\n",
      "Epoch 8, Loss: 0.029936539009213448\n",
      "Epoch 5, Loss: 0.1938702017068863\n",
      "Epoch 9, Loss: 0.03949492797255516\n",
      "Epoch 7, Loss: 0.057078488171100616\n",
      "Epoch 5, Loss: 0.1299028992652893\n",
      "Epoch 6, Loss: 0.05358794704079628\n",
      "Epoch 5, Loss: 0.3664262592792511\n",
      "Epoch 9, Loss: 0.0349150225520134\n",
      "Epoch 7, Loss: 0.05114203318953514\n",
      "Epoch 10, Loss: 0.04760237783193588\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=32, lr=0.0004311432253684024, num_heads=8, num_layers=3; total time=   1.1s\n",
      "Epoch 7, Loss: 0.08573972433805466\n",
      "Epoch 6, Loss: 0.06601720303297043\n",
      "Epoch 6, Loss: 0.07376138120889664\n",
      "Epoch 8, Loss: 0.09277626872062683\n",
      "Epoch 5, Loss: 0.586661159992218\n",
      "Epoch 10, Loss: 0.07407795637845993\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=32, lr=0.0004311432253684024, num_heads=8, num_layers=3; total time=   1.1s\n",
      "Epoch 8, Loss: 0.015991777181625366\n",
      "Epoch 7, Loss: 0.08802933990955353\n",
      "Epoch 6, Loss: 0.2289707511663437\n",
      "Epoch 8, Loss: 0.04835202172398567\n",
      "Epoch 9, Loss: 0.08543077111244202\n",
      "Epoch 9, Loss: 0.02760833129286766\n",
      "Epoch 7, Loss: 0.008715258911252022\n",
      "Epoch 6, Loss: 0.6433594226837158\n",
      "Epoch 7, Loss: 0.015970494598150253\n",
      "Epoch 9, Loss: 0.01715089939534664\n",
      "Epoch 8, Loss: 0.0639415830373764\n",
      "Epoch 7, Loss: 0.10352803021669388\n",
      "Epoch 10, Loss: 0.04633089527487755\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=32, lr=0.0004311432253684024, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 10, Loss: 0.047303926199674606\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=32, lr=0.0004311432253684024, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 10, Loss: 0.016525372862815857\n",
      "Epoch 8, Loss: 0.03066481277346611\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=32, lr=0.0004311432253684024, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 7, Loss: 0.5267634391784668\n",
      "Epoch 8, Loss: 0.014051263220608234\n",
      "Epoch 9, Loss: 0.02209983952343464\n",
      "Epoch 8, Loss: 0.04487771540880203\n",
      "Epoch 9, Loss: 0.07292824983596802\n",
      "Epoch 9, Loss: 0.04876616597175598\n",
      "Epoch 8, Loss: 0.3453506827354431\n",
      "Epoch 10, Loss: 0.006501614581793547\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=32, lr=0.0004311432253684024, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.05588262155652046\n",
      "Epoch 10, Loss: 0.09692811220884323\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=32, lr=0.0004311432253684024, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Epoch 10, Loss: 0.05890399217605591\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=32, lr=0.0004311432253684024, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.18300087749958038\n",
      "Epoch 10, Loss: 0.09468283504247665\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=32, lr=0.0004311432253684024, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Epoch 10, Loss: 0.0798218846321106\n",
      "[CV] END activation=elu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=32, lr=0.0004311432253684024, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 1.00956130027771\n",
      "Epoch 1, Loss: 1.0543920993804932\n",
      "Epoch 1, Loss: 2.2258944511413574\n",
      "Epoch 1, Loss: 0.5753235816955566\n",
      "Epoch 1, Loss: 3.963836908340454\n",
      "Epoch 2, Loss: 0.12053490430116653\n",
      "Epoch 2, Loss: 0.05898290127515793\n",
      "Epoch 2, Loss: 0.5040552020072937\n",
      "Epoch 1, Loss: 0.22391358017921448\n",
      "Epoch 1, Loss: 1.0662012100219727\n",
      "Epoch 1, Loss: 0.10870219022035599\n",
      "Epoch 2, Loss: 0.024834085255861282\n",
      "Epoch 3, Loss: 0.29607343673706055\n",
      "Epoch 1, Loss: 0.4774550497531891\n",
      "Epoch 3, Loss: 0.18882067501544952\n",
      "Epoch 2, Loss: 1.5949139595031738\n",
      "Epoch 1, Loss: 2.8362057209014893\n",
      "Epoch 3, Loss: 0.0728071928024292\n",
      "Epoch 2, Loss: 0.16334643959999084\n",
      "Epoch 1, Loss: 0.10055480152368546\n",
      "Epoch 2, Loss: 0.415542870759964\n",
      "Epoch 4, Loss: 0.44380736351013184\n",
      "Epoch 4, Loss: 0.39084649085998535\n",
      "Epoch 2, Loss: 0.1319388449192047\n",
      "Epoch 1, Loss: 0.10333365947008133\n",
      "Epoch 3, Loss: 0.26978233456611633\n",
      "Epoch 2, Loss: 0.03707953169941902\n",
      "Epoch 4, Loss: 0.3318403959274292\n",
      "Epoch 3, Loss: 0.2969764173030853\n",
      "Epoch 2, Loss: 0.8328572511672974\n",
      "Epoch 3, Loss: 0.10789564251899719\n",
      "Epoch 5, Loss: 0.34293609857559204\n",
      "Epoch 3, Loss: 0.16004624962806702\n",
      "Epoch 5, Loss: 0.3343032896518707\n",
      "Epoch 4, Loss: 0.2774629592895508\n",
      "Epoch 2, Loss: 0.3545813262462616\n",
      "Epoch 3, Loss: 0.19295518100261688\n",
      "Epoch 5, Loss: 0.5635790824890137\n",
      "Epoch 4, Loss: 0.1005193367600441\n",
      "Epoch 6, Loss: 0.15995948016643524\n",
      "Epoch 2, Loss: 0.22910676896572113\n",
      "Epoch 4, Loss: 0.06004662439227104\n",
      "Epoch 3, Loss: 0.05320620536804199\n",
      "Epoch 3, Loss: 0.23946607112884521\n",
      "Epoch 6, Loss: 0.18311309814453125\n",
      "Epoch 4, Loss: 0.043263889849185944\n",
      "Epoch 5, Loss: 0.12102516740560532\n",
      "Epoch 6, Loss: 0.5459047555923462\n",
      "Epoch 4, Loss: 0.3920323848724365\n",
      "Epoch 7, Loss: 0.0429144911468029\n",
      "Epoch 7, Loss: 0.05812368914484978\n",
      "Epoch 3, Loss: 0.07962404191493988\n",
      "Epoch 5, Loss: 0.03801979124546051\n",
      "Epoch 5, Loss: 0.49924588203430176\n",
      "Epoch 7, Loss: 0.3908238112926483\n",
      "Epoch 3, Loss: 0.07279857248067856\n",
      "Epoch 4, Loss: 0.2390713095664978\n",
      "Epoch 4, Loss: 0.1884857416152954\n",
      "Epoch 5, Loss: 0.16546203196048737\n",
      "Epoch 6, Loss: 0.021476076915860176\n",
      "Epoch 8, Loss: 0.03327374905347824\n",
      "Epoch 8, Loss: 0.021250184625387192\n",
      "Epoch 5, Loss: 0.36993464827537537\n",
      "Epoch 8, Loss: 0.21821171045303345\n",
      "Epoch 6, Loss: 0.7759601473808289\n",
      "Epoch 9, Loss: 0.089330293238163\n",
      "Epoch 6, Loss: 0.0719238892197609\n",
      "Epoch 6, Loss: 0.14657385647296906\n",
      "Epoch 7, Loss: 0.03462317958474159\n",
      "Epoch 5, Loss: 0.10759660601615906\n",
      "Epoch 9, Loss: 0.057651568204164505\n",
      "Epoch 5, Loss: 0.5182301998138428\n",
      "Epoch 4, Loss: 0.04882419481873512\n",
      "Epoch 4, Loss: 0.04087195172905922\n",
      "Epoch 10, Loss: 0.13876335322856903\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0004336016216806708, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 6, Loss: 0.2287498414516449\n",
      "Epoch 9, Loss: 0.08626709133386612\n",
      "Epoch 7, Loss: 0.7536389827728271\n",
      "Epoch 8, Loss: 0.09197608381509781\n",
      "Epoch 7, Loss: 0.06894869357347488\n",
      "Epoch 10, Loss: 0.11180273443460464\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0004336016216806708, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 7, Loss: 0.04817730560898781\n",
      "Epoch 6, Loss: 0.024379868060350418\n",
      "Epoch 5, Loss: 0.08983553200960159\n",
      "Epoch 7, Loss: 0.1024550348520279\n",
      "Epoch 10, Loss: 0.025126000866293907\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0004336016216806708, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.12106240540742874\n",
      "Epoch 8, Loss: 0.5630409717559814\n",
      "Epoch 5, Loss: 0.14169926941394806\n",
      "Epoch 8, Loss: 0.031237328425049782\n",
      "Epoch 6, Loss: 0.6255130171775818\n",
      "Epoch 9, Loss: 0.33866485953330994\n",
      "Epoch 7, Loss: 0.03461036831140518\n",
      "Epoch 8, Loss: 0.04079274460673332\n",
      "Epoch 8, Loss: 0.014454374089837074\n",
      "Epoch 6, Loss: 0.06536536663770676\n",
      "Epoch 10, Loss: 0.09881794452667236\n",
      "Epoch 7, Loss: 0.5287462472915649\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0004336016216806708, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 9, Loss: 0.008912459015846252\n",
      "Epoch 6, Loss: 0.11079729348421097\n",
      "Epoch 10, Loss: 0.1608305126428604\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0004336016216806708, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 9, Loss: 0.05105118453502655\n",
      "Epoch 9, Loss: 0.050067607313394547\n",
      "Epoch 8, Loss: 0.08303558826446533\n",
      "Epoch 10, Loss: 0.0218742024153471\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0004336016216806708, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 7, Loss: 0.018892468884587288\n",
      "Epoch 8, Loss: 0.3461366891860962\n",
      "Epoch 7, Loss: 0.03107602708041668\n",
      "Epoch 10, Loss: 0.09579762816429138\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0004336016216806708, num_heads=8, num_layers=3; total time=   1.6s\n",
      "Epoch 10, Loss: 0.0848204493522644\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0004336016216806708, num_heads=8, num_layers=3; total time=   1.6s\n",
      "Epoch 9, Loss: 0.10317469388246536\n",
      "Epoch 8, Loss: 0.008799749426543713\n",
      "Epoch 9, Loss: 0.1738768219947815\n",
      "Epoch 8, Loss: 0.007711528800427914\n",
      "Epoch 10, Loss: 0.08161617815494537\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0004336016216806708, num_heads=8, num_layers=3; total time=   1.7s\n",
      "Epoch 10, Loss: 0.05409631133079529\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0004336016216806708, num_heads=8, num_layers=3; total time=   1.7s\n",
      "Epoch 9, Loss: 0.0306587815284729\n",
      "Epoch 9, Loss: 0.04291307181119919\n",
      "Epoch 10, Loss: 0.04136168211698532\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0004336016216806708, num_heads=8, num_layers=3; total time=   1.8s\n",
      "Epoch 10, Loss: 0.07058774679899216\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.0004336016216806708, num_heads=8, num_layers=3; total time=   1.8s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 0.13263581693172455\n",
      "Epoch 1, Loss: 0.6795322299003601\n",
      "Epoch 1, Loss: 1.255046010017395\n",
      "Epoch 1, Loss: 1.1604292392730713\n",
      "Epoch 1, Loss: 0.09472205489873886\n",
      "Epoch 1, Loss: 0.38076314330101013\n",
      "Epoch 2, Loss: 0.09991065412759781\n",
      "Epoch 1, Loss: 0.16033253073692322\n",
      "Epoch 2, Loss: 0.19372650980949402\n",
      "Epoch 1, Loss: 0.040895652025938034\n",
      "Epoch 1, Loss: 0.46224331855773926\n",
      "Epoch 2, Loss: 0.12126030772924423\n",
      "Epoch 2, Loss: 0.016186147928237915\n",
      "Epoch 2, Loss: 0.4114841818809509\n",
      "Epoch 2, Loss: 0.01949714869260788\n",
      "Epoch 3, Loss: 0.11280206590890884\n",
      "Epoch 3, Loss: 0.26274052262306213\n",
      "Epoch 2, Loss: 0.35613757371902466\n",
      "Epoch 1, Loss: 0.15229292213916779\n",
      "Epoch 3, Loss: 0.4176734685897827\n",
      "Epoch 3, Loss: 0.20508554577827454\n",
      "Epoch 1, Loss: 0.4537639319896698\n",
      "Epoch 2, Loss: 0.3853211998939514\n",
      "Epoch 4, Loss: 0.009787420742213726\n",
      "Epoch 2, Loss: 0.37319403886795044\n",
      "Epoch 1, Loss: 0.7130296230316162\n",
      "Epoch 4, Loss: 0.3288831412792206\n",
      "Epoch 3, Loss: 0.08962508291006088\n",
      "Epoch 3, Loss: 0.17752109467983246\n",
      "Epoch 4, Loss: 0.4657832682132721\n",
      "Epoch 5, Loss: 0.04863317310810089\n",
      "Epoch 3, Loss: 0.11296266317367554\n",
      "Epoch 4, Loss: 0.5345380306243896\n",
      "Epoch 5, Loss: 0.19784550368785858\n",
      "Epoch 2, Loss: 0.2449439913034439\n",
      "Epoch 4, Loss: 0.05017458647489548\n",
      "Epoch 2, Loss: 0.04260355979204178\n",
      "Epoch 5, Loss: 0.43188878893852234\n",
      "Epoch 2, Loss: 0.030713044106960297\n",
      "Epoch 3, Loss: 0.020176099613308907\n",
      "Epoch 6, Loss: 0.08708681911230087\n",
      "Epoch 6, Loss: 0.07188308984041214\n",
      "Epoch 4, Loss: 0.18991029262542725\n",
      "Epoch 3, Loss: 0.27604857087135315\n",
      "Epoch 5, Loss: 0.31526753306388855\n",
      "Epoch 6, Loss: 0.2589816749095917\n",
      "Epoch 4, Loss: 0.0731574222445488\n",
      "Epoch 5, Loss: 0.17044998705387115\n",
      "Epoch 7, Loss: 0.05577455461025238\n",
      "Epoch 4, Loss: 0.14842425286769867\n",
      "Epoch 7, Loss: 0.034169621765613556\n",
      "Epoch 3, Loss: 0.24215304851531982\n",
      "Epoch 3, Loss: 0.2525328993797302\n",
      "Epoch 5, Loss: 0.08952565491199493\n",
      "Epoch 7, Loss: 0.09886039793491364\n",
      "Epoch 6, Loss: 0.08484018594026566\n",
      "Epoch 3, Loss: 0.11486111581325531\n",
      "Epoch 4, Loss: 0.11285950243473053\n",
      "Epoch 5, Loss: 0.15166078507900238\n",
      "Epoch 8, Loss: 0.01413086336106062\n",
      "Epoch 6, Loss: 0.13282813131809235\n",
      "Epoch 8, Loss: 0.06859126687049866\n",
      "Epoch 8, Loss: 0.029766032472252846\n",
      "Epoch 4, Loss: 0.19628964364528656Epoch 4, Loss: 0.34118083119392395\n",
      "\n",
      "Epoch 6, Loss: 0.022267470136284828\n",
      "Epoch 5, Loss: 0.20248860120773315\n",
      "Epoch 7, Loss: 0.015450970269739628\n",
      "Epoch 9, Loss: 0.009927523322403431\n",
      "Epoch 7, Loss: 0.03231446444988251\n",
      "Epoch 6, Loss: 0.1217324510216713\n",
      "Epoch 9, Loss: 0.11007454991340637\n",
      "Epoch 4, Loss: 0.03816744312644005\n",
      "Epoch 5, Loss: 0.08928360790014267\n",
      "Epoch 9, Loss: 0.04945717006921768\n",
      "Epoch 7, Loss: 0.021479133516550064\n",
      "Epoch 8, Loss: 0.07562268525362015\n",
      "Epoch 6, Loss: 0.09064827859401703\n",
      "Epoch 10, Loss: 0.11439775675535202\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=0.0004368593122678423, num_heads=8, num_layers=3; total time=   1.0s\n",
      "Epoch 7, Loss: 0.04664655774831772\n",
      "Epoch 10, Loss: 0.033671196550130844\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=0.0004368593122678423, num_heads=8, num_layers=3; total time=   1.1s\n",
      "Epoch 8, Loss: 0.006978270132094622\n",
      "Epoch 5, Loss: 0.06118741258978844\n",
      "Epoch 10, Loss: 0.10691063851118088\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=0.0004368593122678423, num_heads=8, num_layers=3; total time=   1.1s\n",
      "Epoch 6, Loss: 0.11734834313392639\n",
      "Epoch 5, Loss: 0.08400904387235641\n",
      "Epoch 5, Loss: 0.2065339833498001\n",
      "Epoch 9, Loss: 0.15960443019866943\n",
      "Epoch 7, Loss: 0.01098011713474989\n",
      "Epoch 8, Loss: 0.022596705704927444\n",
      "Epoch 8, Loss: 0.06082933023571968\n",
      "Epoch 9, Loss: 0.04904400184750557\n",
      "Epoch 6, Loss: 0.016184678301215172\n",
      "Epoch 7, Loss: 0.0921165719628334\n",
      "Epoch 10, Loss: 0.1875065565109253\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=0.0004368593122678423, num_heads=8, num_layers=3; total time=   1.2s\n",
      "Epoch 8, Loss: 0.02871767431497574\n",
      "Epoch 6, Loss: 0.08561371266841888\n",
      "Epoch 9, Loss: 0.05218054726719856\n",
      "Epoch 9, Loss: 0.08646749705076218\n",
      "Epoch 10, Loss: 0.08122769743204117\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=0.0004368593122678423, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 6, Loss: 0.061823856085538864\n",
      "Epoch 7, Loss: 0.057517457753419876\n",
      "Epoch 9, Loss: 0.07989922910928726\n",
      "Epoch 7, Loss: 0.03540142998099327\n",
      "Epoch 8, Loss: 0.041630618274211884\n",
      "Epoch 10, Loss: 0.07620271295309067\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=0.0004368593122678423, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 10, Loss: 0.07366236299276352\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=0.0004368593122678423, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 10, Loss: 0.0912882387638092\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=0.0004368593122678423, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 8, Loss: 0.09744251519441605\n",
      "Epoch 7, Loss: 0.01578698679804802\n",
      "Epoch 9, Loss: 0.02253246121108532\n",
      "Epoch 8, Loss: 0.010212543420493603\n",
      "Epoch 9, Loss: 0.0943169891834259\n",
      "Epoch 8, Loss: 0.05606551095843315\n",
      "Epoch 10, Loss: 0.041527848690748215\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=0.0004368593122678423, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 9, Loss: 0.030424369499087334\n",
      "Epoch 10, Loss: 0.05670693889260292\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=0.0004368593122678423, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.11269255727529526\n",
      "Epoch 10, Loss: 0.04859717935323715\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=0.0004368593122678423, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.12750740349292755\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=0.0004368593122678423, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Fitting 12 folds for each of 1 candidates, totalling 12 fits\n",
      "Epoch 1, Loss: 2.3891336917877197\n",
      "Epoch 1, Loss: 0.26984483003616333\n",
      "Epoch 2, Loss: 0.7175922393798828\n",
      "Epoch 1, Loss: 0.08189443498849869\n",
      "Epoch 1, Loss: 0.23643258213996887\n",
      "Epoch 1, Loss: 0.8015479445457458\n",
      "Epoch 2, Loss: 0.24538534879684448\n",
      "Epoch 3, Loss: 0.06874430179595947\n",
      "Epoch 1, Loss: 0.10588380694389343\n",
      "Epoch 1, Loss: 0.08385217189788818\n",
      "Epoch 1, Loss: 1.2679082155227661\n",
      "Epoch 2, Loss: 0.30372560024261475\n",
      "Epoch 2, Loss: 0.16491389274597168\n",
      "Epoch 2, Loss: 0.08209595084190369\n",
      "Epoch 3, Loss: 0.18788720667362213\n",
      "Epoch 4, Loss: 0.15044569969177246\n",
      "Epoch 1, Loss: 0.9307929873466492\n",
      "Epoch 1, Loss: 0.014379882253706455\n",
      "Epoch 3, Loss: 0.1718176156282425\n",
      "Epoch 2, Loss: 0.12905970215797424\n",
      "Epoch 3, Loss: 0.05530119687318802\n",
      "Epoch 2, Loss: 0.24714234471321106\n",
      "Epoch 4, Loss: 0.05522473156452179\n",
      "Epoch 2, Loss: 0.4622822105884552\n",
      "Epoch 3, Loss: 0.39380139112472534\n",
      "Epoch 5, Loss: 0.4126928746700287\n",
      "Epoch 1, Loss: 0.563606858253479\n",
      "Epoch 1, Loss: 0.09584042429924011\n",
      "Epoch 5, Loss: 0.053261566907167435\n",
      "Epoch 4, Loss: 0.07184161990880966\n",
      "Epoch 3, Loss: 0.03992925584316254\n",
      "Epoch 2, Loss: 0.14549708366394043\n",
      "Epoch 2, Loss: 0.0779012143611908\n",
      "Epoch 4, Loss: 0.07074586302042007\n",
      "Epoch 3, Loss: 0.09525460749864578\n",
      "Epoch 3, Loss: 0.0924108475446701\n",
      "Epoch 6, Loss: 0.5265186429023743\n",
      "Epoch 4, Loss: 0.37085673213005066\n",
      "Epoch 6, Loss: 0.09235973656177521\n",
      "Epoch 5, Loss: 0.14423587918281555\n",
      "Epoch 2, Loss: 0.08430206030607224\n",
      "Epoch 2, Loss: 0.1294788420200348\n",
      "Epoch 3, Loss: 0.11058901995420456\n",
      "Epoch 4, Loss: 0.090509332716465\n",
      "Epoch 3, Loss: 0.4743339717388153\n",
      "Epoch 4, Loss: 0.05371623486280441\n",
      "Epoch 4, Loss: 0.3136148154735565\n",
      "Epoch 7, Loss: 0.470468670129776\n",
      "Epoch 5, Loss: 0.1680576354265213\n",
      "Epoch 7, Loss: 0.06677354127168655\n",
      "Epoch 6, Loss: 0.07801472395658493\n",
      "Epoch 5, Loss: 0.03867672011256218\n",
      "Epoch 8, Loss: 0.3353394567966461\n",
      "Epoch 3, Loss: 0.2735288441181183\n",
      "Epoch 8, Loss: 0.019648870453238487\n",
      "Epoch 7, Loss: 0.012919392436742783\n",
      "Epoch 5, Loss: 0.39111724495887756\n",
      "Epoch 4, Loss: 0.4192052483558655\n",
      "Epoch 3, Loss: 0.0366666316986084\n",
      "Epoch 9, Loss: 0.19334055483341217\n",
      "Epoch 6, Loss: 0.03559371456503868\n",
      "Epoch 5, Loss: 0.1746746003627777\n",
      "Epoch 5, Loss: 0.02981146052479744\n",
      "Epoch 4, Loss: 0.050957247614860535\n",
      "Epoch 6, Loss: 0.07012049853801727\n",
      "Epoch 9, Loss: 0.009351927787065506\n",
      "Epoch 8, Loss: 0.022165024653077126\n",
      "Epoch 4, Loss: 0.26246270537376404\n",
      "Epoch 10, Loss: 0.08896320313215256\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.000434414094157503, num_heads=8, num_layers=3; total time=   1.0s\n",
      "Epoch 7, Loss: 0.051264334470033646\n",
      "Epoch 5, Loss: 0.1872147023677826\n",
      "Epoch 6, Loss: 0.3046174645423889\n",
      "Epoch 4, Loss: 0.09099701792001724\n",
      "Epoch 9, Loss: 0.05926276743412018\n",
      "Epoch 6, Loss: 0.14072780311107635\n",
      "Epoch 10, Loss: 0.03359517082571983\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.000434414094157503, num_heads=8, num_layers=3; total time=   1.0s\n",
      "Epoch 5, Loss: 0.012631899677217007\n",
      "Epoch 6, Loss: 0.01875118911266327\n",
      "Epoch 7, Loss: 0.07512370496988297\n",
      "Epoch 8, Loss: 0.1286415457725525\n",
      "Epoch 7, Loss: 0.16702961921691895\n",
      "Epoch 10, Loss: 0.06341945379972458\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.000434414094157503, num_heads=8, num_layers=3; total time=   1.1s\n",
      "Epoch 6, Loss: 0.051414452493190765\n",
      "Epoch 5, Loss: 0.1264013946056366\n",
      "Epoch 5, Loss: 0.023470139130949974\n",
      "Epoch 7, Loss: 0.043922845274209976\n",
      "Epoch 8, Loss: 0.04271058365702629\n",
      "Epoch 6, Loss: 0.053837813436985016\n",
      "Epoch 7, Loss: 0.05104551091790199\n",
      "Epoch 9, Loss: 0.1605486124753952\n",
      "Epoch 8, Loss: 0.06582164019346237\n",
      "Epoch 7, Loss: 0.059547096490859985\n",
      "Epoch 9, Loss: 0.014047438278794289\n",
      "Epoch 8, Loss: 0.0388203039765358\n",
      "Epoch 8, Loss: 0.007741778157651424\n",
      "Epoch 6, Loss: 0.02569577470421791\n",
      "Epoch 7, Loss: 0.04294441640377045\n",
      "Epoch 9, Loss: 0.02811555191874504\n",
      "Epoch 6, Loss: 0.03567017242312431\n",
      "Epoch 10, Loss: 0.12770164012908936\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.000434414094157503, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 8, Loss: 0.12933450937271118\n",
      "Epoch 10, Loss: 0.013418078422546387\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.000434414094157503, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 9, Loss: 0.04555380716919899\n",
      "Epoch 8, Loss: 0.010692315176129341\n",
      "Epoch 9, Loss: 0.0140591561794281\n",
      "Epoch 7, Loss: 0.05907363072037697\n",
      "Epoch 10, Loss: 0.04478467255830765\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.000434414094157503, num_heads=8, num_layers=3; total time=   1.3s\n",
      "Epoch 7, Loss: 0.036091674119234085\n",
      "Epoch 9, Loss: 0.1598552167415619\n",
      "Epoch 10, Loss: 0.07995525747537613\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.000434414094157503, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Epoch 10, Loss: 0.01499893143773079\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.000434414094157503, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.014239334501326084\n",
      "Epoch 8, Loss: 0.03862985968589783\n",
      "Epoch 8, Loss: 0.079864002764225\n",
      "Epoch 10, Loss: 0.12941204011440277\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.000434414094157503, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Epoch 10, Loss: 0.03288784250617027\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.000434414094157503, num_heads=8, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.012234320864081383\n",
      "Epoch 9, Loss: 0.103347048163414\n",
      "Epoch 10, Loss: 0.08587242662906647\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.000434414094157503, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 10, Loss: 0.018551940098404884\n",
      "[CV] END activation=elu, batch_size=32, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.000434414094157503, num_heads=8, num_layers=3; total time=   1.5s\n",
      "Epoch 1, Loss: 0.19020579755306244\n",
      "Epoch 2, Loss: 0.2924084961414337\n",
      "Epoch 3, Loss: 0.11397664994001389\n",
      "Epoch 4, Loss: 0.04925808683037758\n",
      "Epoch 5, Loss: 0.09256971627473831\n",
      "Epoch 6, Loss: 0.07472740113735199\n",
      "Epoch 7, Loss: 0.023247353732585907\n",
      "Epoch 8, Loss: 0.010871305130422115\n",
      "Epoch 9, Loss: 0.03745986521244049\n",
      "Epoch 10, Loss: 0.04969765990972519\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=SKTimeToSKLearnCV(sktime_splitter=ExpandingWindowSplitter(fh=[1, 7], initial_window=365, step_length=30),\n",
       "         y=array([[0.07575, 0.08068, 0.09333],\n",
       "       [0.08068, 0.09333, 0.13503],\n",
       "       ...,\n",
       "       [0.22176, 0.21108, 0.19289],\n",
       "       [0.21108, 0.19289, 0.17323]], dtype=float32)),\n",
       "              estimator=TFTEstimator(), n_iter=200, n_jobs=-1,\n",
       "              scoring=&#x27;neg_mean_absolute_error&#x27;,\n",
       "              search_spaces={&#x27;a...\n",
       "                             &#x27;dropout_rate&#x27;: Real(low=0.1, high=0.4, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;feed_forward_dim&#x27;: Categorical(categories=(128, 256, 512, 1024), prior=None),\n",
       "                             &#x27;head_dim&#x27;: Categorical(categories=(8, 16, 32), prior=None),\n",
       "                             &#x27;lr&#x27;: Real(low=5e-05, high=0.005, prior=&#x27;log-uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;num_heads&#x27;: Categorical(categories=(2, 4, 8), prior=None),\n",
       "                             &#x27;num_layers&#x27;: Categorical(categories=(1, 2, 3, 4), prior=None)},\n",
       "              verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;BayesSearchCV<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>BayesSearchCV(cv=SKTimeToSKLearnCV(sktime_splitter=ExpandingWindowSplitter(fh=[1, 7], initial_window=365, step_length=30),\n",
       "         y=array([[0.07575, 0.08068, 0.09333],\n",
       "       [0.08068, 0.09333, 0.13503],\n",
       "       ...,\n",
       "       [0.22176, 0.21108, 0.19289],\n",
       "       [0.21108, 0.19289, 0.17323]], dtype=float32)),\n",
       "              estimator=TFTEstimator(), n_iter=200, n_jobs=-1,\n",
       "              scoring=&#x27;neg_mean_absolute_error&#x27;,\n",
       "              search_spaces={&#x27;a...\n",
       "                             &#x27;dropout_rate&#x27;: Real(low=0.1, high=0.4, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;feed_forward_dim&#x27;: Categorical(categories=(128, 256, 512, 1024), prior=None),\n",
       "                             &#x27;head_dim&#x27;: Categorical(categories=(8, 16, 32), prior=None),\n",
       "                             &#x27;lr&#x27;: Real(low=5e-05, high=0.005, prior=&#x27;log-uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;num_heads&#x27;: Categorical(categories=(2, 4, 8), prior=None),\n",
       "                             &#x27;num_layers&#x27;: Categorical(categories=(1, 2, 3, 4), prior=None)},\n",
       "              verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: TFTEstimator</label><div class=\"sk-toggleable__content fitted\"><pre>TFTEstimator()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">TFTEstimator</label><div class=\"sk-toggleable__content fitted\"><pre>TFTEstimator()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=SKTimeToSKLearnCV(sktime_splitter=ExpandingWindowSplitter(fh=[1, 7], initial_window=365, step_length=30),\n",
       "         y=array([[0.07575, 0.08068, 0.09333],\n",
       "       [0.08068, 0.09333, 0.13503],\n",
       "       ...,\n",
       "       [0.22176, 0.21108, 0.19289],\n",
       "       [0.21108, 0.19289, 0.17323]], dtype=float32)),\n",
       "              estimator=TFTEstimator(), n_iter=200, n_jobs=-1,\n",
       "              scoring='neg_mean_absolute_error',\n",
       "              search_spaces={'a...\n",
       "                             'dropout_rate': Real(low=0.1, high=0.4, prior='uniform', transform='normalize'),\n",
       "                             'feed_forward_dim': Categorical(categories=(128, 256, 512, 1024), prior=None),\n",
       "                             'head_dim': Categorical(categories=(8, 16, 32), prior=None),\n",
       "                             'lr': Real(low=5e-05, high=0.005, prior='log-uniform', transform='normalize'),\n",
       "                             'num_heads': Categorical(categories=(2, 4, 8), prior=None),\n",
       "                             'num_layers': Categorical(categories=(1, 2, 3, 4), prior=None)},\n",
       "              verbose=2)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wrap the model with BayesSearchCV\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=TFTEstimator(\n",
    "        look_back=look_back,\n",
    "        n_steps_ahead=n_steps_ahead\n",
    "    ),\n",
    "    search_spaces=search_space,\n",
    "    n_iter=200,\n",
    "    # cv=TimeSeriesSplit(n_splits=5),\n",
    "    cv=SKTimeToSKLearnCV(expanding_splitter, y_train),\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    "    # random_state=42\n",
    ")\n",
    "\n",
    "# Fit the search\n",
    "bayes_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import json\n",
    "# import joblib\n",
    "\n",
    "# # Save the best hyperparameters\n",
    "# with open('../models/lookback7/best_tft_hyperparams.json', 'w') as f:\n",
    "#     json.dump(bayes_search.best_estimator_.model_params, f)\n",
    "#     # json.dump(bayes_search.best_params_, f)\n",
    "\n",
    "# # Save the state_dict of the best model\n",
    "# torch.save(bayes_search.best_estimator_.model.state_dict(), '../models/lookback7/best_tft_model.pth')\n",
    "\n",
    "# # Save the BayesSearchCV object (optional)\n",
    "# joblib.dump(bayes_search, '../models/lookback7/best_bayes_search.pkl')\n",
    "\n",
    "# # Save additional metadata (e.g., best score)\n",
    "# best_score = -bayes_search.best_score_\n",
    "# with open('../models/lookback7/best_tft_score.txt', 'w') as f:\n",
    "#     f.write(str(best_score))\n",
    "\n",
    "# # with open('../models/lookback7/best_tft_hyperparams.json', 'r') as f:\n",
    "# #     model_params = json.load(f)\n",
    "\n",
    "# # exclude_keys = ['batch_size', 'lr']  # List of keys to exclude\n",
    "# # model_params = {k: v for k, v in model_params.items() if k not in exclude_keys}\n",
    "\n",
    "# # # Add new parameters\n",
    "# # model_params.update({'look_back': 7, 'n_steps_ahead': 3})\n",
    "\n",
    "# # model_params\n",
    "\n",
    "# # Load the saved hyperparameters\n",
    "# with open('../models/lookback7/best_tft_hyperparams.json', 'r') as f:\n",
    "#     model_params = json.load(f)\n",
    "\n",
    "# # Reinitialize the model using the saved hyperparameters\n",
    "# best_model = Seq2SeqTemporalFusionTransformerWrapper(**model_params)\n",
    "\n",
    "# # Load the saved state_dict into the model\n",
    "# state_dict = torch.load('../models/lookback7/best_tft_model.pth', weights_only=True)\n",
    "# best_model.load_state_dict(state_dict)\n",
    "\n",
    "# # Set the model to evaluation mode\n",
    "# best_model.eval()\n",
    "\n",
    "# print(\"Best model loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the BayesSearchCV object\n",
    "joblib.dump(bayes_search, \"../models/lookback7/bayes_search_tft_seq2seq.pkl\")\n",
    "print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load the BayesSearchCV object\n",
    "best_model = joblib.load(\"../models/lookback7/bayes_search_tft_seq2seq.pkl\")\n",
    "print(\"Model loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.9505518078804016\n",
      "Mean Absolute Error (MAE): 0.8998581767082214\n",
      "Mean Absolute Percentage Error (MAPE): 5.73951530456543\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions\n",
    "y_pred_inverse = scaler.inverse_transform(y_pred)\n",
    "y_test_inverse = scaler.inverse_transform(y_test)\n",
    "\n",
    "# Evaluate the predictions\n",
    "mse = root_mean_squared_error(y_test_inverse, y_pred_inverse)\n",
    "mae = mean_absolute_error(y_test_inverse, y_pred_inverse)\n",
    "mape = mean_absolute_percentage_error(y_test_inverse, y_pred_inverse)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape}\")\n",
    "\n",
    "# save metrics as dataframe and save to csv\n",
    "metrics = pd.DataFrame({'MSE': [mse], 'MAE': [mae], 'MAPE': [mape]})\n",
    "metrics.to_csv('../results/metrics/lookback7/tft_seq2seq_metrics.csv', index=False)\n",
    "\n",
    "# Save the predictions as .npy file\n",
    "np.save('../results/predictions/test/lookback7/tft_seq2seq_predictions.npy', y_pred_inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test, label=\"True Values\")\n",
    "plt.plot(y_pred, label=\"Predicted Values\")\n",
    "plt.legend()\n",
    "plt.title(\"True vs Predicted Values\")\n",
    "plt.xlabel(\"Sample Index\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pf/4hxrldrx2g7g5x19dwlvk36w0000gn/T/ipykernel_60058/3212807902.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X, dtype=torch.float32)  # Shape: (batch_size, look_back, 1)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Define the number of future days to predict\n",
    "future_days = 300\n",
    "\n",
    "# Get the most recent data\n",
    "recent_data = X_test[-1].reshape(1, -1, 1)  # Shape: (1, look_back, 1)\n",
    "recent_data = torch.tensor(recent_data, dtype=torch.float32)\n",
    "\n",
    "# Initialize a list to store all predictions\n",
    "predictions = []  # This will store predictions for all future days\n",
    "\n",
    "# Make predictions for future_days\n",
    "for _ in range(future_days):\n",
    "    # Predict the next step\n",
    "    prediction = best_model.predict(recent_data)  # Shape: (1, n_steps_ahead)\n",
    "    \n",
    "    # Convert prediction to a PyTorch tensor\n",
    "    prediction_tensor = torch.tensor(prediction, dtype=torch.float32)\n",
    "    \n",
    "    # Append the prediction to the predictions list\n",
    "    predictions.append(prediction_tensor.squeeze().tolist())  # Shape: (n_steps_ahead,)\n",
    "    \n",
    "    # Update recent_data for the next iteration\n",
    "    # Use the first predicted value to update recent_data\n",
    "    recent_data = torch.cat([recent_data[:, 1:, :], prediction_tensor[:, 0].unsqueeze(1).unsqueeze(-1)], dim=1)\n",
    "\n",
    "# Convert predictions list to a numpy array\n",
    "predictions = np.array(predictions)  # Shape: (future_days, n_steps_ahead)\n",
    "\n",
    "# Inverse transform the predictions using the scaler\n",
    "predictions_inverse = scaler.inverse_transform(predictions)  # Shape: (future_days, n_steps_ahead)\n",
    "\n",
    "# Split the inverse-transformed predictions into separate arrays\n",
    "predictions_1_inverse = predictions_inverse[:, 0]  # First predicted value\n",
    "predictions_2_inverse = predictions_inverse[:, 1]  # Second predicted value\n",
    "predictions_3_inverse = predictions_inverse[:, 2]  # Third predicted value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "module_name = \"arima_garch_forecast\"\n",
    "module_path = \"/Users/binnu/Library/CloudStorage/OneDrive-student.vgu.edu.vn/VGU/Current Program/Project/Bitcoin Prediction/src/utils/prediction.py\"\n",
    "\n",
    "# Load the module\n",
    "spec = importlib.util.spec_from_file_location(module_name, module_path)\n",
    "module = importlib.util.module_from_spec(spec)\n",
    "sys.modules[module_name] = module\n",
    "spec.loader.exec_module(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pca_df = pd.read_csv(\"../data/final/test_pca_df.csv\", parse_dates=[\"Date\"], index_col=\"Date\")\n",
    "val_pca_df = pd.read_csv(\"../data/final/val_pca_df.csv\", parse_dates=[\"Date\"], index_col=\"Date\")\n",
    "val_exog = val_pca_df.drop(columns=[\"btc_close\"])\n",
    "test_exog = test_pca_df.drop(columns=[\"btc_close\"])\n",
    "# concat val and test exog\n",
    "exog = pd.concat([val_exog, test_exog])\n",
    "\n",
    "arimax_garch_future = module.arima_garch_forecast(exog, '../models', future_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_date = test_residuals_df.index[-1]\n",
    "\n",
    "# Undo log-transform (ARIMA-GARCH predictions + TFT predictions)\n",
    "final_predictions = []\n",
    "\n",
    "for i in range(3):\n",
    "    final_predictions.append(np.exp(predictions_inverse[:, i] + arimax_garch_future) - 1)\n",
    "\n",
    "future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=len(final_predictions[0]))\n",
    "\n",
    "# Create the DataFrame of future predictions\n",
    "df_predictions =  pd.DataFrame(final_predictions).T  # Transpose to make each array a column\n",
    "\n",
    "# Rename the index to 'Day' for clarity\n",
    "df_predictions.index = future_dates\n",
    "\n",
    "df_predictions.columns = ['Forecast Price (Case 1)', 'Forecast Price (Case 2)', 'Forecast Price (Case 3)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_actual_values = np.exp(test_pca_df[\"btc_close\"]) - 1\n",
    "test_arima_garch_pred = test_residuals_df[\"SARIMA-GARCH Prediction\"]\n",
    "test_arima_garch_pred_org = np.exp(test_arima_garch_pred) - 1\n",
    "# load np.save('../results/predictions/test/lookback7/tft_seq2seq_predictions.npy', y_pred_inverse)\n",
    "test_tft_pred = np.load('../results/predictions/test/lookback7/tft_seq2seq_predictions.npy')\n",
    "\n",
    "test_tft_pred_list = []\n",
    "combined_test_pred_list = []\n",
    "combined_test_pred_org_list = []\n",
    "\n",
    "for i in range(3):\n",
    "    test_tft_pred_list.append(test_tft_pred[:, i])\n",
    "    combined_test_pred = test_arima_garch_pred[look_back+2:] + test_tft_pred_list[i]\n",
    "    combined_test_pred_list.append(combined_test_pred)\n",
    "    combined_test_pred_org_list.append(np.exp(combined_test_pred) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(test_pca_df.index, test_actual_values, label=\"Actual Values\", color=\"black\")\n",
    "plt.plot(test_pca_df.index,test_arima_garch_pred_org, label=\"SARIMA-GARCH Forecast\", color=\"grey\")\n",
    "for i in range(3):\n",
    "    plt.plot(combined_test_pred_org_list[i], label=f\"Predicted Values (Case {i + 1})\")\n",
    "plt.plot(df_predictions.index, df_predictions[\"Forecast Price (Case 1)\"], label=\"Forecast Price (Case 1)\", color=\"blue\")\n",
    "plt.plot(df_predictions.index, df_predictions[\"Forecast Price (Case 2)\"], label=\"Forecast Price (Case 2)\", color=\"red\")\n",
    "plt.plot(df_predictions.index, df_predictions[\"Forecast Price (Case 3)\"], label=\"Forecast Price (Case 3)\", color=\"green\")\n",
    "\n",
    "plt.title(\"Forecast Comparison on Test Set\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"BTC Close Price\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "# plt.savefig(\"../results/images/test/merge.png\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Slice the last 60 days of data\n",
    "last_60_days = slice(-30, None)  # Slice to get the last 60 elements\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot actual values (last 60 days)\n",
    "plt.plot(test_pca_df.index[last_60_days], test_actual_values[last_60_days], label=\"Actual Values\", color=\"black\")\n",
    "\n",
    "# Plot SARIMA-GARCH forecast (last 60 days)\n",
    "plt.plot(test_pca_df.index[last_60_days], test_arima_garch_pred_org[last_60_days], label=\"SARIMA-GARCH Forecast\", color=\"grey\")\n",
    "\n",
    "# Plot predicted values for each case (last 60 days)\n",
    "for i in range(3):\n",
    "    plt.plot(test_pca_df.index[last_60_days], combined_test_pred_org_list[i][last_60_days], label=f\"Predicted Values (Case {i + 1})\")\n",
    "\n",
    "# Plot forecast prices for each case (last 60 days)\n",
    "plt.plot(df_predictions.index, df_predictions[\"Forecast Price (Case 1)\"], label=\"Forecast Price (Case 1)\", color=\"blue\")\n",
    "plt.plot(df_predictions.index, df_predictions[\"Forecast Price (Case 2)\"], label=\"Forecast Price (Case 2)\", color=\"red\")\n",
    "plt.plot(df_predictions.index, df_predictions[\"Forecast Price (Case 3)\"], label=\"Forecast Price (Case 3)\", color=\"green\")\n",
    "\n",
    "# Add plot details\n",
    "plt.title(\"Forecast Comparison on Test Set (Last 60 Days)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"BTC Close Price\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Save or display the plot\n",
    "# plt.savefig(\"../results/images/test/merge_last_60_days.png\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
