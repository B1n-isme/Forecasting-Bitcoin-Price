{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### look back values for btc_close price\n",
    "look_back_values = [1, 2, 5, 10, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from skopt import BayesSearchCV\n",
    "from skorch import NeuralNetRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "import math\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import Callback\n",
    "from tqdm import tqdm\n",
    "\n",
    "class TqdmProgressBar(Callback):\n",
    "    def on_train_begin(self, net, **kwargs):\n",
    "        self.epochs = net.max_epochs\n",
    "        self.pbar = tqdm(total=self.epochs, desc=\"Training Progress\", unit=\"epoch\")\n",
    "\n",
    "    def on_epoch_end(self, net, **kwargs):\n",
    "        self.pbar.update(1)  # Increment the progress bar by one epoch\n",
    "\n",
    "    def on_train_end(self, net, **kwargs):\n",
    "        self.pbar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_residuals_df = pd.read_csv(\"../data/final/train_residuals_df.csv\", parse_dates=[\"Date\"], index_col=\"Date\")\n",
    "test_residuals_df = pd.read_csv(\"../data/final/test_residuals_df.csv\", parse_dates=[\"Date\"], index_col=\"Date\")\n",
    "\n",
    "train_residual = train_residuals_df[\"Residuals\"]\n",
    "test_residual = test_residuals_df[\"Residuals\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/residual_scaler.pkl']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_residual_scaled = scaler.fit_transform(train_residual.values.reshape(-1, 1))\n",
    "test_residual_scaled = scaler.transform(test_residual.values.reshape(-1, 1))\n",
    "\n",
    "# save scaler\n",
    "joblib.dump(scaler, \"../models/residual_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_residual_scaled = train_residual_scaled.astype(np.float32)\n",
    "test_residual_scaled = test_residual_scaled.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, max_len, hidden_dim):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.position_encoding = nn.Parameter(torch.zeros(1, max_len, hidden_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.position_encoding[:, :x.size(1), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Seq2SeqTemporalFusionTransformer(nn.Module):\n",
    "    def __init__(self, look_back, num_heads, hidden_dim, feed_forward_dim, dropout_rate,\n",
    "                 num_layers=1, activation=\"relu\", input_feature_dim=1, n_steps_ahead=1):\n",
    "        super(Seq2SeqTemporalFusionTransformer, self).__init__()\n",
    "        self.look_back = look_back\n",
    "        self.n_steps_ahead = n_steps_ahead\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Input projection\n",
    "        self.input_projection = nn.Linear(input_feature_dim, hidden_dim)\n",
    "\n",
    "        # Positional encoding\n",
    "        self.positional_encoding = PositionalEncoding(max_len=look_back + n_steps_ahead, hidden_dim=hidden_dim)\n",
    "\n",
    "        # Define the activation function dynamically\n",
    "        if activation == \"relu\":\n",
    "            self.activation_fn = nn.ReLU()\n",
    "        elif activation == \"gelu\":\n",
    "            self.activation_fn = nn.GELU()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation function: {activation}\")\n",
    "\n",
    "        # Encoder layers\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            nn.ModuleDict({\n",
    "                \"multi_head_attention\": nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=num_heads, batch_first=True),\n",
    "                \"layer_norm1\": nn.LayerNorm(hidden_dim),\n",
    "                \"feed_forward\": nn.Sequential(\n",
    "                    nn.Linear(hidden_dim, feed_forward_dim),\n",
    "                    self.activation_fn,\n",
    "                    nn.Dropout(dropout_rate),\n",
    "                    nn.Linear(feed_forward_dim, hidden_dim)\n",
    "                ),\n",
    "                \"layer_norm2\": nn.LayerNorm(hidden_dim)\n",
    "            })\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # Decoder layers\n",
    "        self.decoder_layers = nn.ModuleList([\n",
    "            nn.ModuleDict({\n",
    "                \"self_attention\": nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=num_heads, batch_first=True),\n",
    "                \"cross_attention\": nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=num_heads, batch_first=True),\n",
    "                \"layer_norm1\": nn.LayerNorm(hidden_dim),\n",
    "                \"feed_forward\": nn.Sequential(\n",
    "                    nn.Linear(hidden_dim, feed_forward_dim),\n",
    "                    self.activation_fn,\n",
    "                    nn.Dropout(dropout_rate),\n",
    "                    nn.Linear(feed_forward_dim, hidden_dim)\n",
    "                ),\n",
    "                \"layer_norm2\": nn.LayerNorm(hidden_dim)\n",
    "            })\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(hidden_dim, input_feature_dim)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        # Input projection\n",
    "        src = self.input_projection(src)  # Shape: (batch_size, look_back, hidden_dim)\n",
    "        tgt = self.input_projection(tgt)  # Shape: (batch_size, n_steps_ahead, hidden_dim)\n",
    "\n",
    "        # Add positional encoding\n",
    "        src = src + self.positional_encoding(src)\n",
    "        tgt = tgt + self.positional_encoding(tgt)\n",
    "\n",
    "        # Encoder\n",
    "        for layer in self.encoder_layers:\n",
    "            # Self-attention\n",
    "            attn_output, _ = layer[\"multi_head_attention\"](src, src, src)\n",
    "            src = layer[\"layer_norm1\"](src + attn_output)\n",
    "\n",
    "            # Feed-forward network\n",
    "            ff_output = layer[\"feed_forward\"](src)\n",
    "            src = layer[\"layer_norm2\"](src + ff_output)\n",
    "\n",
    "        # Decoder\n",
    "        for layer in self.decoder_layers:\n",
    "            # Self-attention\n",
    "            self_attn_output, _ = layer[\"self_attention\"](tgt, tgt, tgt)\n",
    "            tgt = layer[\"layer_norm1\"](tgt + self_attn_output)\n",
    "\n",
    "            # Cross-attention (attends to encoder output)\n",
    "            cross_attn_output, _ = layer[\"cross_attention\"](tgt, src, src)\n",
    "            tgt = layer[\"layer_norm1\"](tgt + cross_attn_output)\n",
    "\n",
    "            # Feed-forward network\n",
    "            ff_output = layer[\"feed_forward\"](tgt)\n",
    "            tgt = layer[\"layer_norm2\"](tgt + ff_output)\n",
    "\n",
    "        # Output projection\n",
    "        outputs = self.output_layer(tgt)  # Shape: (batch_size, n_steps_ahead, input_feature_dim)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters Tuning using Bayes Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqTemporalFusionTransformerWrapper(nn.Module):\n",
    "    def __init__(self, look_back, num_heads, head_dim, feed_forward_dim, dropout_rate, num_layers, activation, n_steps_ahead):\n",
    "        super(Seq2SeqTemporalFusionTransformerWrapper, self).__init__()\n",
    "        self.look_back = look_back\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = head_dim\n",
    "        self.feed_forward_dim = feed_forward_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.num_layers = num_layers\n",
    "        self.activation = activation\n",
    "        self.n_steps_ahead = n_steps_ahead\n",
    "        \n",
    "        # Initialize the Seq2Seq TFT model\n",
    "        self.model = Seq2SeqTemporalFusionTransformer(\n",
    "            look_back=look_back,\n",
    "            num_heads=num_heads,\n",
    "            hidden_dim=num_heads * head_dim,\n",
    "            feed_forward_dim=feed_forward_dim,\n",
    "            dropout_rate=dropout_rate,\n",
    "            num_layers=num_layers,\n",
    "            activation=activation,\n",
    "            input_feature_dim=1,  # Assuming univariate time series\n",
    "            n_steps_ahead=n_steps_ahead\n",
    "        )\n",
    "\n",
    "    def forward(self, src, tgt=None):\n",
    "        if src.dim() == 2:\n",
    "            src = src.unsqueeze(-1)  # Add feature dimension if missing\n",
    "        \n",
    "        # If tgt is not provided (during inference), initialize it with zeros\n",
    "        if tgt is None:\n",
    "            tgt = torch.zeros(src.size(0), self.n_steps_ahead, 1).to(src.device)  # Shape: (batch_size, n_steps_ahead, 1)\n",
    "        \n",
    "        # Ensure tgt is 3D: (batch_size, n_steps_ahead, input_feature_dim)\n",
    "        if tgt.dim() == 2:\n",
    "            tgt = tgt.unsqueeze(-1)  # Add feature dimension if missing\n",
    "        \n",
    "        # Forward pass through the model\n",
    "        outputs = self.model(src, tgt)  # Shape: (batch_size, n_steps_ahead, 1)\n",
    "        \n",
    "        # Reshape output to (batch_size, n_steps_ahead)\n",
    "        outputs = outputs.squeeze(-1)  # Remove the last dimension if it's 1\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def state_dict(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Override to save only the state_dict of the underlying model.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'hyperparameters': {\n",
    "                'look_back': self.look_back,\n",
    "                'num_heads': self.num_heads,\n",
    "                'head_dim': self.head_dim,\n",
    "                'feed_forward_dim': self.feed_forward_dim,\n",
    "                'dropout_rate': self.dropout_rate,\n",
    "                'num_layers': self.num_layers,\n",
    "                'activation': self.activation,\n",
    "                'n_steps_ahead': self.n_steps_ahead\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def load_state_dict(self, state_dict, strict=True):\n",
    "        \"\"\"\n",
    "        Override to load the state_dict into the underlying model.\n",
    "        \"\"\"\n",
    "        self.model.load_state_dict(state_dict['model_state_dict'], strict=strict)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict on given input data (e.g., X_test or future data).\n",
    "        \n",
    "        Parameters:\n",
    "        - X (np.ndarray or torch.Tensor): Input data of shape (batch_size, look_back).\n",
    "        \n",
    "        Returns:\n",
    "        - np.ndarray: Predicted values of shape (batch_size, n_steps_ahead).\n",
    "        \"\"\"\n",
    "        if not isinstance(X, torch.Tensor):\n",
    "            X = torch.tensor(X, dtype=torch.float32)\n",
    "\n",
    "        if X.dim() == 2:\n",
    "            X = X.unsqueeze(-1)  # Add feature dimension if missing\n",
    "\n",
    "        # Set the model to evaluation mode\n",
    "        self.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predictions = self.forward(X)  # Forward pass for prediction\n",
    "\n",
    "        return predictions.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search space for BayesSearchCV\n",
    "search_space = {\n",
    "    \"num_heads\": Categorical([2, 4, 8]),  \n",
    "    \"head_dim\": Categorical([8, 16, 32]),  \n",
    "    \"feed_forward_dim\": Categorical([128, 256, 512, 1024]),  \n",
    "    \"dropout_rate\": Real(0.1, 0.4),  \n",
    "    \"lr\": Real(5e-5, 5e-3, prior=\"log-uniform\"), \n",
    "    \"batch_size\": Categorical([16, 32, 64]), \n",
    "    \"num_layers\": Categorical([1, 2, 3, 4]),\n",
    "    \"activation\": Categorical([\"relu\", \"gelu\"]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(722, 7, 1) (722, 3) (722, 7, 1) (722, 3)\n"
     ]
    }
   ],
   "source": [
    "def create_multi_step_dataset(data, look_back, n_steps_ahead=1):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - look_back - n_steps_ahead + 1):\n",
    "        X.append(data[i:i + look_back, 0])  # Input sequence\n",
    "        y.append(data[i + look_back:i + look_back + n_steps_ahead, 0])  # Multi-step target\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Prepare training and testing datasets\n",
    "look_back = 7\n",
    "n_steps_ahead = 3\n",
    "\n",
    "# Create train and test datasets\n",
    "X_train, y_train = create_multi_step_dataset(train_residual_scaled, look_back, n_steps_ahead)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test, y_test = create_multi_step_dataset(test_residual_scaled, look_back, n_steps_ahead)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TFTEstimator(BaseEstimator):\n",
    "    def __init__(self, look_back=7, num_heads=4, head_dim=16, feed_forward_dim=128,\n",
    "                 dropout_rate=0.1, lr=0.001, batch_size=32, num_layers=2, activation=\"relu\", n_steps_ahead=3):\n",
    "        self.look_back = look_back\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = head_dim\n",
    "        self.feed_forward_dim = feed_forward_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        self.activation = activation\n",
    "        self.n_steps_ahead = n_steps_ahead\n",
    "\n",
    "        # Store model hyperparameters\n",
    "        self.model_params = {\n",
    "            \"look_back\": look_back,\n",
    "            \"num_heads\": num_heads,\n",
    "            \"head_dim\": head_dim,\n",
    "            \"feed_forward_dim\": feed_forward_dim,\n",
    "            \"dropout_rate\": dropout_rate,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"activation\": activation,\n",
    "            \"n_steps_ahead\": n_steps_ahead,\n",
    "        }\n",
    "\n",
    "        # # Store training hyperparameters\n",
    "        # self.training_params = {\n",
    "        #     \"lr\": lr,\n",
    "        #     \"batch_size\": batch_size,\n",
    "        # }\n",
    "        \n",
    "        # Initialize the Seq2Seq TFT model\n",
    "        self.model = Seq2SeqTemporalFusionTransformerWrapper(**self.model_params)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Convert inputs to PyTorch tensors\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32)  # Shape: (batch_size, look_back, 1)\n",
    "        y_tensor = torch.tensor(y, dtype=torch.float32)  # Shape: (batch_size, n_steps_ahead, 1)\n",
    "        \n",
    "        # Define loss function and optimizer\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(10):  # Example: 10 epochs\n",
    "            optimizer.zero_grad()\n",
    "            outputs = self.model(X_tensor, y_tensor)  # Forward pass with src and tgt\n",
    "            loss = criterion(outputs, y_tensor)  # Compute loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update weights\n",
    "            print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float32)  # Shape: (batch_size, look_back, 1)\n",
    "            predictions = self.model(X_tensor)  # Forward pass with src only (tgt is initialized internally)\n",
    "        return predictions.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.962406575679779\n",
      "Epoch 1, Loss: 2.16645884513855\n",
      "Epoch 2, Loss: 0.21383409202098846\n",
      "Epoch 1, Loss: 0.2323056161403656\n",
      "Epoch 3, Loss: 0.1499336063861847\n",
      "Epoch 1, Loss: 0.07551693171262741\n",
      "Epoch 2, Loss: 0.727787435054779\n",
      "Epoch 4, Loss: 0.3229321241378784\n",
      "Epoch 1, Loss: 0.038884177803993225\n",
      "Epoch 5, Loss: 0.35998401045799255\n",
      "Epoch 2, Loss: 0.06475327908992767\n",
      "Epoch 3, Loss: 0.14011502265930176\n",
      "Epoch 6, Loss: 0.2703181207180023\n",
      "Epoch 7, Loss: 0.15225014090538025\n",
      "Epoch 4, Loss: 0.19440127909183502\n",
      "Epoch 2, Loss: 0.20757469534873962\n",
      "Epoch 8, Loss: 0.06647145748138428\n",
      "Epoch 3, Loss: 0.1725991815328598\n",
      "Epoch 2, Loss: 0.32068172097206116\n",
      "Epoch 9, Loss: 0.04690491780638695\n",
      "Epoch 5, Loss: 0.4452691674232483\n",
      "Epoch 10, Loss: 0.0785691887140274\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.37986039965435026, feed_forward_dim=256, head_dim=32, lr=0.0003366722096076183, num_heads=4, num_layers=3; total time=   0.9s\n",
      "Epoch 4, Loss: 0.0764637291431427\n",
      "Epoch 6, Loss: 0.5578660368919373\n",
      "Epoch 3, Loss: 0.057350222021341324\n",
      "Epoch 7, Loss: 0.4985561668872833\n",
      "Epoch 3, Loss: 0.031786948442459106\n",
      "Epoch 5, Loss: 0.009145425632596016\n",
      "Epoch 8, Loss: 0.3582879304885864\n",
      "Epoch 4, Loss: 0.026143483817577362\n",
      "Epoch 9, Loss: 0.20184120535850525\n",
      "Epoch 6, Loss: 0.038357943296432495\n",
      "Epoch 4, Loss: 0.09063836932182312\n",
      "Epoch 10, Loss: 0.08590571582317352\n",
      "Epoch 5, Loss: 0.09251343458890915\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.37986039965435026, feed_forward_dim=256, head_dim=32, lr=0.0003366722096076183, num_heads=4, num_layers=3; total time=   1.0s\n",
      "Epoch 7, Loss: 0.0789218619465828\n",
      "Epoch 6, Loss: 0.07913516461849213\n",
      "Epoch 8, Loss: 0.06181688979268074\n",
      "Epoch 5, Loss: 0.17127616703510284\n",
      "Epoch 9, Loss: 0.025165151804685593\n",
      "Epoch 7, Loss: 0.026211533695459366\n",
      "Epoch 6, Loss: 0.10282205790281296\n",
      "Epoch 10, Loss: 0.006554418243467808\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.37986039965435026, feed_forward_dim=256, head_dim=32, lr=0.0003366722096076183, num_heads=4, num_layers=3; total time=   1.2s\n",
      "Epoch 8, Loss: 0.011342234909534454\n",
      "Epoch 7, Loss: 0.020019544288516045\n",
      "Epoch 9, Loss: 0.03595508262515068\n",
      "Epoch 8, Loss: 0.014119111001491547\n",
      "Epoch 10, Loss: 0.05202273651957512\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.37986039965435026, feed_forward_dim=256, head_dim=32, lr=0.0003366722096076183, num_heads=4, num_layers=3; total time=   1.4s\n",
      "Epoch 9, Loss: 0.06026163697242737\n",
      "Epoch 10, Loss: 0.08158162981271744\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.37986039965435026, feed_forward_dim=256, head_dim=32, lr=0.0003366722096076183, num_heads=4, num_layers=3; total time=   1.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.06003379449248314\n",
      "Epoch 1, Loss: 0.2596072554588318\n",
      "Epoch 2, Loss: 0.042613331228494644\n",
      "Epoch 3, Loss: 0.04317356273531914\n",
      "Epoch 2, Loss: 0.1529989391565323\n",
      "Epoch 4, Loss: 0.041086360812187195\n",
      "Epoch 3, Loss: 0.07967446744441986\n",
      "Epoch 5, Loss: 0.03734702244400978\n",
      "Epoch 6, Loss: 0.029965030029416084\n",
      "Epoch 4, Loss: 0.03725719079375267\n",
      "Epoch 7, Loss: 0.0247296504676342\n",
      "Epoch 8, Loss: 0.025135628879070282\n",
      "Epoch 5, Loss: 0.02167494036257267\n",
      "Epoch 9, Loss: 0.022674623876810074\n",
      "Epoch 6, Loss: 0.025740971788764\n",
      "Epoch 10, Loss: 0.020690618082880974\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.19102303296525253, feed_forward_dim=1024, head_dim=32, lr=6.66186589554938e-05, num_heads=2, num_layers=2; total time=   0.4s\n",
      "Epoch 7, Loss: 0.038472872227430344\n",
      "Epoch 8, Loss: 0.0516791045665741\n",
      "Epoch 9, Loss: 0.059684839099645615\n",
      "Epoch 10, Loss: 0.059416551142930984\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.19102303296525253, feed_forward_dim=1024, head_dim=32, lr=6.66186589554938e-05, num_heads=2, num_layers=2; total time=   0.6s\n",
      "Epoch 1, Loss: 0.6677902340888977\n",
      "Epoch 2, Loss: 0.5092302560806274\n",
      "Epoch 3, Loss: 0.38486191630363464\n",
      "Epoch 4, Loss: 0.2778858542442322\n",
      "Epoch 5, Loss: 0.2078724354505539\n",
      "Epoch 1, Loss: 1.5034316778182983\n",
      "Epoch 6, Loss: 0.16498470306396484\n",
      "Epoch 1, Loss: 0.024254966527223587\n",
      "Epoch 7, Loss: 0.14675374329090118\n",
      "Epoch 8, Loss: 0.14510709047317505\n",
      "Epoch 9, Loss: 0.14770832657814026\n",
      "Epoch 2, Loss: 1.1922760009765625\n",
      "Epoch 10, Loss: 0.16151173412799835\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.19102303296525253, feed_forward_dim=1024, head_dim=32, lr=6.66186589554938e-05, num_heads=2, num_layers=2; total time=   0.7s\n",
      "Epoch 2, Loss: 0.019600728526711464\n",
      "Epoch 3, Loss: 0.9295658469200134\n",
      "Epoch 3, Loss: 0.015684811398386955\n",
      "Epoch 4, Loss: 0.6919348239898682\n",
      "Epoch 4, Loss: 0.012571248225867748\n",
      "Epoch 5, Loss: 0.4943842589855194\n",
      "Epoch 6, Loss: 0.34240418672561646\n",
      "Epoch 5, Loss: 0.010570933111011982\n",
      "Epoch 7, Loss: 0.2252756506204605\n",
      "Epoch 6, Loss: 0.008648787625133991\n",
      "Epoch 8, Loss: 0.13645295798778534\n",
      "Epoch 7, Loss: 0.0071918242610991\n",
      "Epoch 9, Loss: 0.0790080800652504\n",
      "Epoch 8, Loss: 0.006813731510192156\n",
      "Epoch 10, Loss: 0.046555474400520325\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.19102303296525253, feed_forward_dim=1024, head_dim=32, lr=6.66186589554938e-05, num_heads=2, num_layers=2; total time=   1.2s\n",
      "Epoch 9, Loss: 0.006793374195694923\n",
      "Epoch 10, Loss: 0.006981407292187214\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.19102303296525253, feed_forward_dim=1024, head_dim=32, lr=6.66186589554938e-05, num_heads=2, num_layers=2; total time=   1.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 1.9514859914779663\n",
      "Epoch 2, Loss: 0.5201981663703918\n",
      "Epoch 1, Loss: 3.043739080429077\n",
      "Epoch 3, Loss: 0.08733972907066345\n",
      "Epoch 1, Loss: 0.8698686957359314\n",
      "Epoch 4, Loss: 0.24899116158485413\n",
      "Epoch 2, Loss: 1.0639203786849976\n",
      "Epoch 5, Loss: 0.47125786542892456\n",
      "Epoch 2, Loss: 0.17730599641799927\n",
      "Epoch 6, Loss: 0.5151314735412598\n",
      "Epoch 3, Loss: 0.1655530333518982\n",
      "Epoch 7, Loss: 0.42057812213897705\n",
      "Epoch 8, Loss: 0.2801196277141571\n",
      "Epoch 3, Loss: 0.18510577082633972\n",
      "Epoch 4, Loss: 0.1321418136358261\n",
      "Epoch 9, Loss: 0.14475442469120026\n",
      "Epoch 10, Loss: 0.061609115451574326\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.13145774756581108, feed_forward_dim=256, head_dim=8, lr=0.00040392496121433854, num_heads=2, num_layers=4; total time=   0.5s\n",
      "Epoch 5, Loss: 0.43853679299354553\n",
      "Epoch 4, Loss: 0.3433697521686554\n",
      "Epoch 6, Loss: 0.6331563591957092\n",
      "Epoch 5, Loss: 0.2984023690223694\n",
      "Epoch 7, Loss: 0.6214878559112549\n",
      "Epoch 6, Loss: 0.1646951586008072\n",
      "Epoch 8, Loss: 0.4886106252670288\n",
      "Epoch 7, Loss: 0.06543134897947311\n",
      "Epoch 9, Loss: 0.3156275749206543\n",
      "Epoch 8, Loss: 0.039947446435689926\n",
      "Epoch 10, Loss: 0.16350990533828735\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.13145774756581108, feed_forward_dim=256, head_dim=8, lr=0.00040392496121433854, num_heads=2, num_layers=4; total time=   0.8s\n",
      "Epoch 9, Loss: 0.06645064055919647\n",
      "Epoch 10, Loss: 0.10142738372087479\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.13145774756581108, feed_forward_dim=256, head_dim=8, lr=0.00040392496121433854, num_heads=2, num_layers=4; total time=   1.0s\n",
      "Epoch 1, Loss: 0.37267839908599854\n",
      "Epoch 2, Loss: 0.17426609992980957\n",
      "Epoch 3, Loss: 0.21908390522003174\n",
      "Epoch 1, Loss: 0.08448192477226257\n",
      "Epoch 4, Loss: 0.13474999368190765\n",
      "Epoch 5, Loss: 0.050162240862846375\n",
      "Epoch 6, Loss: 0.04583036154508591\n",
      "Epoch 2, Loss: 0.24516186118125916\n",
      "Epoch 7, Loss: 0.07437696307897568\n",
      "Epoch 8, Loss: 0.07310990989208221\n",
      "Epoch 3, Loss: 0.058475103229284286\n",
      "Epoch 9, Loss: 0.03639344871044159\n",
      "Epoch 10, Loss: 0.009926064871251583\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.13145774756581108, feed_forward_dim=256, head_dim=8, lr=0.00040392496121433854, num_heads=2, num_layers=4; total time=   0.6s\n",
      "Epoch 4, Loss: 0.03339710086584091\n",
      "Epoch 5, Loss: 0.10032550245523453\n",
      "Epoch 6, Loss: 0.07388637959957123\n",
      "Epoch 7, Loss: 0.017841631546616554\n",
      "Epoch 8, Loss: 0.006862007547169924\n",
      "Epoch 9, Loss: 0.03454143926501274\n",
      "Epoch 10, Loss: 0.051930371671915054\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.13145774756581108, feed_forward_dim=256, head_dim=8, lr=0.00040392496121433854, num_heads=2, num_layers=4; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.8162850737571716\n",
      "Epoch 2, Loss: 0.6394205689430237\n",
      "Epoch 1, Loss: 0.6967813968658447\n",
      "Epoch 3, Loss: 0.4766349196434021\n",
      "Epoch 4, Loss: 0.3543994128704071\n",
      "Epoch 2, Loss: 0.4946252405643463\n",
      "Epoch 1, Loss: 0.15312448143959045\n",
      "Epoch 5, Loss: 0.2478647232055664\n",
      "Epoch 3, Loss: 0.33707892894744873\n",
      "Epoch 6, Loss: 0.18056625127792358\n",
      "Epoch 1, Loss: 0.09846138954162598\n",
      "Epoch 7, Loss: 0.1331932544708252\n",
      "Epoch 4, Loss: 0.20693591237068176\n",
      "Epoch 8, Loss: 0.11616157740354538\n",
      "Epoch 2, Loss: 0.12119857966899872\n",
      "Epoch 9, Loss: 0.11121613532304764\n",
      "Epoch 5, Loss: 0.12287656217813492\n",
      "Epoch 10, Loss: 0.12019170820713043\n",
      "[CV] END activation=gelu, batch_size=16, dropout_rate=0.27941412325363846, feed_forward_dim=1024, head_dim=16, lr=7.760328091464899e-05, num_heads=8, num_layers=4; total time=   0.2s\n",
      "Epoch 2, Loss: 0.08941080421209335\n",
      "Epoch 6, Loss: 0.0688171237707138\n",
      "Epoch 3, Loss: 0.1066751554608345\n",
      "Epoch 7, Loss: 0.04313546419143677\n",
      "Epoch 8, Loss: 0.040646735578775406\n",
      "Epoch 3, Loss: 0.07930735498666763\n",
      "Epoch 4, Loss: 0.10280302911996841\n",
      "Epoch 9, Loss: 0.055388301610946655\n",
      "Epoch 10, Loss: 0.07596452534198761\n",
      "[CV] END activation=gelu, batch_size=16, dropout_rate=0.27941412325363846, feed_forward_dim=1024, head_dim=16, lr=7.760328091464899e-05, num_heads=8, num_layers=4; total time=   0.4s\n",
      "Epoch 5, Loss: 0.09838859736919403\n",
      "Epoch 4, Loss: 0.06544370949268341\n",
      "Epoch 6, Loss: 0.091607965528965\n",
      "Epoch 5, Loss: 0.05759996175765991\n",
      "Epoch 7, Loss: 0.08190571516752243\n",
      "Epoch 6, Loss: 0.050643209367990494\n",
      "Epoch 8, Loss: 0.07308677583932877\n",
      "Epoch 7, Loss: 0.043433066457509995\n",
      "Epoch 9, Loss: 0.06329180300235748\n",
      "Epoch 10, Loss: 0.05798029154539108\n",
      "Epoch 8, Loss: 0.037161361426115036\n",
      "[CV] END activation=gelu, batch_size=16, dropout_rate=0.27941412325363846, feed_forward_dim=1024, head_dim=16, lr=7.760328091464899e-05, num_heads=8, num_layers=4; total time=   0.7s\n",
      "Epoch 9, Loss: 0.03071218729019165\n",
      "Epoch 10, Loss: 0.026155903935432434\n",
      "[CV] END activation=gelu, batch_size=16, dropout_rate=0.27941412325363846, feed_forward_dim=1024, head_dim=16, lr=7.760328091464899e-05, num_heads=8, num_layers=4; total time=   0.9s\n",
      "Epoch 1, Loss: 2.1960573196411133\n",
      "Epoch 2, Loss: 1.823653221130371\n",
      "Epoch 3, Loss: 1.4856464862823486\n",
      "Epoch 4, Loss: 1.1712485551834106\n",
      "Epoch 5, Loss: 0.9053628444671631\n",
      "Epoch 6, Loss: 0.6720017194747925\n",
      "Epoch 7, Loss: 0.47168007493019104\n",
      "Epoch 8, Loss: 0.31108227372169495\n",
      "Epoch 9, Loss: 0.19165845215320587\n",
      "Epoch 10, Loss: 0.10255858302116394\n",
      "[CV] END activation=gelu, batch_size=16, dropout_rate=0.27941412325363846, feed_forward_dim=1024, head_dim=16, lr=7.760328091464899e-05, num_heads=8, num_layers=4; total time=   0.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.12400588393211365\n",
      "Epoch 2, Loss: 2.9683501720428467\n",
      "Epoch 1, Loss: 1.0284655094146729\n",
      "Epoch 3, Loss: 0.5672760605812073\n",
      "Epoch 1, Loss: 0.7551782131195068\n",
      "Epoch 2, Loss: 1.294701337814331\n",
      "Epoch 4, Loss: 0.07832665741443634\n",
      "Epoch 5, Loss: 0.5945315957069397\n",
      "Epoch 1, Loss: 0.10183611512184143\n",
      "Epoch 3, Loss: 0.67442786693573\n",
      "Epoch 6, Loss: 0.6452967524528503\n",
      "Epoch 1, Loss: 0.28054654598236084\n",
      "Epoch 2, Loss: 1.9239895343780518\n",
      "Epoch 7, Loss: 0.36215171217918396\n",
      "Epoch 4, Loss: 0.09638436138629913\n",
      "Epoch 8, Loss: 0.11296097189188004\n",
      "Epoch 2, Loss: 3.0048227310180664\n",
      "Epoch 9, Loss: 0.030572140589356422\n",
      "Epoch 3, Loss: 0.8011599183082581\n",
      "Epoch 5, Loss: 0.09647200256586075\n",
      "Epoch 10, Loss: 0.09410106390714645\n",
      "[CV] END activation=gelu, batch_size=32, dropout_rate=0.25798607113830774, feed_forward_dim=512, head_dim=32, lr=0.0013584144936851423, num_heads=4, num_layers=3; total time=   0.2s\n",
      "Epoch 2, Loss: 2.132446527481079\n",
      "Epoch 6, Loss: 0.26091882586479187\n",
      "Epoch 4, Loss: 0.10108524560928345\n",
      "Epoch 3, Loss: 0.2915209233760834\n",
      "Epoch 7, Loss: 0.28067106008529663\n",
      "Epoch 5, Loss: 0.1371094137430191\n",
      "Epoch 8, Loss: 0.17285099625587463\n",
      "Epoch 3, Loss: 0.523694634437561\n",
      "Epoch 4, Loss: 0.5122929215431213\n",
      "Epoch 9, Loss: 0.06792743504047394\n",
      "Epoch 6, Loss: 0.31949397921562195\n",
      "Epoch 10, Loss: 0.03209732100367546\n",
      "[CV] END activation=gelu, batch_size=32, dropout_rate=0.25798607113830774, feed_forward_dim=512, head_dim=32, lr=0.0013584144936851423, num_heads=4, num_layers=3; total time=   0.4s\n",
      "Epoch 4, Loss: 0.045686934143304825\n",
      "Epoch 5, Loss: 0.823216438293457\n",
      "Epoch 7, Loss: 0.3087465167045593\n",
      "Epoch 8, Loss: 0.17469090223312378\n",
      "Epoch 6, Loss: 0.4254969358444214\n",
      "Epoch 5, Loss: 0.3688187003135681\n",
      "Epoch 9, Loss: 0.05930446460843086\n",
      "Epoch 7, Loss: 0.09591535478830338\n",
      "Epoch 10, Loss: 0.02748507261276245\n",
      "Epoch 6, Loss: 0.469120055437088\n",
      "[CV] END activation=gelu, batch_size=32, dropout_rate=0.25798607113830774, feed_forward_dim=512, head_dim=32, lr=0.0013584144936851423, num_heads=4, num_layers=3; total time=   0.6s\n",
      "Epoch 8, Loss: 0.034367237240076065\n",
      "Epoch 7, Loss: 0.29778429865837097\n",
      "Epoch 9, Loss: 0.1261378526687622\n",
      "Epoch 8, Loss: 0.11098197847604752\n",
      "Epoch 10, Loss: 0.21600213646888733\n",
      "[CV] END activation=gelu, batch_size=32, dropout_rate=0.25798607113830774, feed_forward_dim=512, head_dim=32, lr=0.0013584144936851423, num_heads=4, num_layers=3; total time=   0.7s\n",
      "Epoch 9, Loss: 0.0330461822450161\n",
      "Epoch 10, Loss: 0.06535366922616959\n",
      "[CV] END activation=gelu, batch_size=32, dropout_rate=0.25798607113830774, feed_forward_dim=512, head_dim=32, lr=0.0013584144936851423, num_heads=4, num_layers=3; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.13022591173648834\n",
      "Epoch 2, Loss: 0.13279440999031067\n",
      "Epoch 1, Loss: 0.19109195470809937\n",
      "Epoch 3, Loss: 0.08667696267366409\n",
      "Epoch 1, Loss: 2.2539539337158203\n",
      "Epoch 4, Loss: 0.04400666058063507\n",
      "Epoch 2, Loss: 0.168313130736351\n",
      "Epoch 5, Loss: 0.049322858452796936\n",
      "Epoch 1, Loss: 0.24360032379627228\n",
      "Epoch 6, Loss: 0.05064646527171135\n",
      "Epoch 3, Loss: 0.12145299464464188\n",
      "Epoch 1, Loss: 0.10823829472064972\n",
      "Epoch 2, Loss: 0.9480904340744019\n",
      "Epoch 7, Loss: 0.024921422824263573\n",
      "Epoch 4, Loss: 0.059115029871463776\n",
      "Epoch 8, Loss: 0.0110324053093791\n",
      "Epoch 2, Loss: 0.08561410754919052\n",
      "Epoch 9, Loss: 0.013901236467063427\n",
      "Epoch 3, Loss: 0.24171803891658783\n",
      "Epoch 5, Loss: 0.048237625509500504\n",
      "Epoch 10, Loss: 0.02101794071495533\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.1490821535915651, feed_forward_dim=128, head_dim=32, lr=0.0002780542645592738, num_heads=4, num_layers=3; total time=   0.2s\n",
      "Epoch 2, Loss: 0.21053797006607056\n",
      "Epoch 6, Loss: 0.050279490649700165\n",
      "Epoch 4, Loss: 0.02739381231367588\n",
      "Epoch 3, Loss: 0.1631484180688858\n",
      "Epoch 7, Loss: 0.034963443875312805\n",
      "Epoch 5, Loss: 0.10976982116699219\n",
      "Epoch 8, Loss: 0.014401787891983986\n",
      "Epoch 3, Loss: 0.06299210339784622\n",
      "Epoch 4, Loss: 0.1160385012626648\n",
      "Epoch 9, Loss: 0.0172486063092947\n",
      "Epoch 6, Loss: 0.2780795991420746\n",
      "Epoch 10, Loss: 0.02622228115797043\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.1490821535915651, feed_forward_dim=128, head_dim=32, lr=0.0002780542645592738, num_heads=4, num_layers=3; total time=   0.4s\n",
      "Epoch 5, Loss: 0.050337061285972595\n",
      "Epoch 4, Loss: 0.08318545669317245\n",
      "Epoch 7, Loss: 0.3891407251358032\n",
      "Epoch 8, Loss: 0.4185579717159271\n",
      "Epoch 6, Loss: 0.038027361035346985\n",
      "Epoch 5, Loss: 0.10232016444206238\n",
      "Epoch 9, Loss: 0.368011474609375\n",
      "Epoch 7, Loss: 0.0606238953769207\n",
      "Epoch 10, Loss: 0.29158222675323486\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.1490821535915651, feed_forward_dim=128, head_dim=32, lr=0.0002780542645592738, num_heads=4, num_layers=3; total time=   0.6s\n",
      "Epoch 6, Loss: 0.0537104457616806\n",
      "Epoch 8, Loss: 0.06796423345804214\n",
      "Epoch 7, Loss: 0.017623258754611015\n",
      "Epoch 9, Loss: 0.048158321529626846\n",
      "Epoch 10, Loss: 0.022037174552679062\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.1490821535915651, feed_forward_dim=128, head_dim=32, lr=0.0002780542645592738, num_heads=4, num_layers=3; total time=   0.7s\n",
      "Epoch 8, Loss: 0.029535362496972084\n",
      "Epoch 9, Loss: 0.04730365425348282\n",
      "Epoch 10, Loss: 0.038354866206645966\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.1490821535915651, feed_forward_dim=128, head_dim=32, lr=0.0002780542645592738, num_heads=4, num_layers=3; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.061159320175647736\n",
      "Epoch 2, Loss: 0.4520706534385681\n",
      "Epoch 1, Loss: 0.7872601747512817\n",
      "Epoch 3, Loss: 0.014331010170280933\n",
      "Epoch 2, Loss: 0.2640150189399719\n",
      "Epoch 4, Loss: 0.2892735004425049\n",
      "Epoch 1, Loss: 0.029924556612968445\n",
      "Epoch 5, Loss: 0.19402973353862762\n",
      "Epoch 3, Loss: 0.4695459008216858\n",
      "Epoch 1, Loss: 0.03570631518959999\n",
      "Epoch 6, Loss: 0.03137112036347389\n",
      "Epoch 7, Loss: 0.02462954819202423\n",
      "Epoch 4, Loss: 0.233930766582489\n",
      "Epoch 8, Loss: 0.09149622172117233\n",
      "Epoch 2, Loss: 0.5916008949279785\n",
      "Epoch 9, Loss: 0.11347898095846176\n",
      "Epoch 5, Loss: 0.05857507139444351\n",
      "Epoch 10, Loss: 0.07560812681913376\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.2077068795764212, feed_forward_dim=1024, head_dim=16, lr=0.0007730544322582723, num_heads=4, num_layers=2; total time=   0.2s\n",
      "Epoch 2, Loss: 1.377084493637085\n",
      "Epoch 6, Loss: 0.07607942074537277\n",
      "Epoch 3, Loss: 0.07371577620506287\n",
      "Epoch 7, Loss: 0.14853137731552124\n",
      "Epoch 3, Loss: 0.12339167296886444\n",
      "Epoch 8, Loss: 0.16575323045253754\n",
      "Epoch 4, Loss: 0.3811849057674408\n",
      "Epoch 9, Loss: 0.11786351352930069\n",
      "Epoch 10, Loss: 0.0527457557618618\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.2077068795764212, feed_forward_dim=1024, head_dim=16, lr=0.0007730544322582723, num_heads=4, num_layers=2; total time=   0.4s\n",
      "Epoch 4, Loss: 0.23552682995796204\n",
      "Epoch 5, Loss: 0.17940214276313782\n",
      "Epoch 5, Loss: 0.5388310551643372\n",
      "Epoch 6, Loss: 0.01533555518835783\n",
      "Epoch 7, Loss: 0.04734396934509277\n",
      "Epoch 6, Loss: 0.38020360469818115\n",
      "Epoch 8, Loss: 0.12428116798400879\n",
      "Epoch 7, Loss: 0.135105699300766\n",
      "Epoch 9, Loss: 0.13378213346004486\n",
      "Epoch 8, Loss: 0.01582006737589836\n",
      "Epoch 10, Loss: 0.08341960608959198\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.2077068795764212, feed_forward_dim=1024, head_dim=16, lr=0.0007730544322582723, num_heads=4, num_layers=2; total time=   0.8s\n",
      "Epoch 9, Loss: 0.03985343873500824\n",
      "Epoch 10, Loss: 0.11725252121686935\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.2077068795764212, feed_forward_dim=1024, head_dim=16, lr=0.0007730544322582723, num_heads=4, num_layers=2; total time=   0.9s\n",
      "Epoch 1, Loss: 0.34468987584114075\n",
      "Epoch 2, Loss: 0.5195837616920471\n",
      "Epoch 3, Loss: 0.2763020694255829\n",
      "Epoch 4, Loss: 0.018564501777291298\n",
      "Epoch 5, Loss: 0.09589395672082901\n",
      "Epoch 6, Loss: 0.19271248579025269\n",
      "Epoch 7, Loss: 0.14759889245033264\n",
      "Epoch 8, Loss: 0.05275143310427666\n",
      "Epoch 9, Loss: 0.009470784105360508\n",
      "Epoch 10, Loss: 0.03591163083910942\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.2077068795764212, feed_forward_dim=1024, head_dim=16, lr=0.0007730544322582723, num_heads=4, num_layers=2; total time=   0.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.19666650891304016\n",
      "Epoch 1, Loss: 1.2702386379241943\n",
      "Epoch 2, Loss: 0.14331527054309845\n",
      "Epoch 1, Loss: 3.7153444290161133\n",
      "Epoch 3, Loss: 0.11015013605356216\n",
      "Epoch 2, Loss: 1.0586297512054443\n",
      "Epoch 4, Loss: 0.0943615734577179\n",
      "Epoch 1, Loss: 0.0143373878672719\n",
      "Epoch 3, Loss: 0.8542202115058899\n",
      "Epoch 1, Loss: 0.675952672958374\n",
      "Epoch 5, Loss: 0.08090784400701523\n",
      "Epoch 2, Loss: 3.3203139305114746\n",
      "Epoch 6, Loss: 0.08221551775932312\n",
      "Epoch 4, Loss: 0.6740700602531433\n",
      "Epoch 7, Loss: 0.08004515618085861\n",
      "Epoch 2, Loss: 0.010134302079677582\n",
      "Epoch 3, Loss: 2.955167770385742\n",
      "Epoch 5, Loss: 0.5170084834098816\n",
      "Epoch 8, Loss: 0.07946162670850754\n",
      "Epoch 2, Loss: 0.5162308812141418\n",
      "Epoch 9, Loss: 0.0737939402461052\n",
      "Epoch 6, Loss: 0.3826727867126465\n",
      "Epoch 4, Loss: 2.6069343090057373\n",
      "Epoch 10, Loss: 0.06888402998447418\n",
      "Epoch 3, Loss: 0.012102687731385231\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.24894001107901506, feed_forward_dim=1024, head_dim=8, lr=6.32760137409658e-05, num_heads=4, num_layers=1; total time=   0.5s\n",
      "Epoch 7, Loss: 0.26821404695510864\n",
      "Epoch 5, Loss: 2.276273488998413\n",
      "Epoch 3, Loss: 0.38554954528808594\n",
      "Epoch 8, Loss: 0.17878542840480804\n",
      "Epoch 4, Loss: 0.008928272873163223\n",
      "Epoch 6, Loss: 1.979162573814392\n",
      "Epoch 9, Loss: 0.11338112503290176\n",
      "Epoch 4, Loss: 0.28007927536964417\n",
      "Epoch 10, Loss: 0.06586703658103943\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.24894001107901506, feed_forward_dim=1024, head_dim=8, lr=6.32760137409658e-05, num_heads=4, num_layers=1; total time=   0.7s\n",
      "Epoch 5, Loss: 0.006519077345728874\n",
      "Epoch 7, Loss: 1.7018494606018066\n",
      "Epoch 8, Loss: 1.4445637464523315\n",
      "Epoch 6, Loss: 0.007273794151842594\n",
      "Epoch 5, Loss: 0.20288603007793427\n",
      "Epoch 9, Loss: 1.2129950523376465\n",
      "Epoch 7, Loss: 0.008823451586067677\n",
      "Epoch 10, Loss: 1.000610113143921\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.24894001107901506, feed_forward_dim=1024, head_dim=8, lr=6.32760137409658e-05, num_heads=4, num_layers=1; total time=   1.0s\n",
      "Epoch 6, Loss: 0.15194334089756012\n",
      "Epoch 8, Loss: 0.007052581291645765\n",
      "Epoch 7, Loss: 0.1204509288072586\n",
      "Epoch 9, Loss: 0.006025081966072321\n",
      "Epoch 10, Loss: 0.005585934966802597\n",
      "Epoch 8, Loss: 0.10427159070968628\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.24894001107901506, feed_forward_dim=1024, head_dim=8, lr=6.32760137409658e-05, num_heads=4, num_layers=1; total time=   1.1s\n",
      "Epoch 9, Loss: 0.10417032986879349\n",
      "Epoch 10, Loss: 0.1083160936832428\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.24894001107901506, feed_forward_dim=1024, head_dim=8, lr=6.32760137409658e-05, num_heads=4, num_layers=1; total time=   1.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.1930457353591919\n",
      "Epoch 2, Loss: 0.12951429188251495\n",
      "Epoch 1, Loss: 0.2514875531196594\n",
      "Epoch 3, Loss: 0.12741583585739136\n",
      "Epoch 1, Loss: 0.2810637354850769\n",
      "Epoch 4, Loss: 0.1120409443974495\n",
      "Epoch 2, Loss: 0.19643530249595642\n",
      "Epoch 5, Loss: 0.08231110125780106\n",
      "Epoch 1, Loss: 4.33938455581665\n",
      "Epoch 6, Loss: 0.06258849054574966\n",
      "Epoch 3, Loss: 0.15431833267211914\n",
      "Epoch 1, Loss: 2.1061315536499023\n",
      "Epoch 2, Loss: 0.1081920862197876\n",
      "Epoch 7, Loss: 0.04917879030108452\n",
      "Epoch 8, Loss: 0.04670974239706993\n",
      "Epoch 4, Loss: 0.11702097952365875\n",
      "Epoch 9, Loss: 0.03852267935872078\n",
      "Epoch 2, Loss: 3.5455307960510254\n",
      "Epoch 3, Loss: 0.052609775215387344\n",
      "Epoch 10, Loss: 0.03147213160991669\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.3614955785389645, feed_forward_dim=256, head_dim=16, lr=0.00013237274622277244, num_heads=2, num_layers=2; total time=   0.2s\n",
      "Epoch 5, Loss: 0.08604826778173447\n",
      "Epoch 2, Loss: 1.4429666996002197\n",
      "Epoch 4, Loss: 0.07017327845096588\n",
      "Epoch 6, Loss: 0.06397856026887894\n",
      "Epoch 3, Loss: 2.8271377086639404\n",
      "Epoch 7, Loss: 0.04627285525202751\n",
      "Epoch 5, Loss: 0.09668394923210144\n",
      "Epoch 3, Loss: 0.8960512280464172\n",
      "Epoch 8, Loss: 0.03275168314576149\n",
      "Epoch 4, Loss: 2.1952390670776367\n",
      "Epoch 6, Loss: 0.09949292242527008\n",
      "Epoch 9, Loss: 0.0231876689940691\n",
      "Epoch 7, Loss: 0.07826315611600876\n",
      "Epoch 10, Loss: 0.017608145251870155\n",
      "Epoch 4, Loss: 0.4881221354007721\n",
      "Epoch 5, Loss: 1.6623862981796265\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.3614955785389645, feed_forward_dim=256, head_dim=16, lr=0.00013237274622277244, num_heads=2, num_layers=2; total time=   0.4s\n",
      "Epoch 8, Loss: 0.04949989542365074\n",
      "Epoch 6, Loss: 1.2139689922332764\n",
      "Epoch 5, Loss: 0.21326123178005219\n",
      "Epoch 9, Loss: 0.026095446199178696\n",
      "Epoch 7, Loss: 0.8609398007392883\n",
      "Epoch 10, Loss: 0.014190609566867352\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.3614955785389645, feed_forward_dim=256, head_dim=16, lr=0.00013237274622277244, num_heads=2, num_layers=2; total time=   0.6s\n",
      "Epoch 6, Loss: 0.05922635644674301\n",
      "Epoch 8, Loss: 0.5883630514144897\n",
      "Epoch 7, Loss: 0.010598491877317429\n",
      "Epoch 9, Loss: 0.3900326192378998\n",
      "Epoch 10, Loss: 0.2632027566432953\n",
      "Epoch 8, Loss: 0.03591393306851387\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.3614955785389645, feed_forward_dim=256, head_dim=16, lr=0.00013237274622277244, num_heads=2, num_layers=2; total time=   0.8s\n",
      "Epoch 9, Loss: 0.10282482206821442\n",
      "Epoch 10, Loss: 0.1797880381345749\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.3614955785389645, feed_forward_dim=256, head_dim=16, lr=0.00013237274622277244, num_heads=2, num_layers=2; total time=   1.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.41367143392562866\n",
      "Epoch 2, Loss: 0.18198621273040771\n",
      "Epoch 1, Loss: 0.6447296738624573\n",
      "Epoch 3, Loss: 0.0675303116440773\n",
      "Epoch 1, Loss: 1.7859177589416504\n",
      "Epoch 4, Loss: 0.0624382421374321\n",
      "Epoch 2, Loss: 0.26346731185913086\n",
      "Epoch 5, Loss: 0.10538119822740555\n",
      "Epoch 1, Loss: 0.15127840638160706\n",
      "Epoch 6, Loss: 0.1303907036781311\n",
      "Epoch 1, Loss: 0.3067924380302429\n",
      "Epoch 3, Loss: 0.08891808241605759\n",
      "Epoch 7, Loss: 0.1311628222465515\n",
      "Epoch 2, Loss: 1.1454278230667114\n",
      "Epoch 8, Loss: 0.10517025738954544\n",
      "Epoch 4, Loss: 0.08973661065101624\n",
      "Epoch 2, Loss: 0.12092288583517075\n",
      "Epoch 9, Loss: 0.0726572647690773\n",
      "Epoch 10, Loss: 0.0419759638607502\n",
      "Epoch 3, Loss: 0.650058388710022\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.32238482331040824, feed_forward_dim=256, head_dim=16, lr=0.00017717388242560026, num_heads=2, num_layers=1; total time=   0.3s\n",
      "Epoch 5, Loss: 0.15783709287643433\n",
      "Epoch 2, Loss: 0.11787087470293045\n",
      "Epoch 3, Loss: 0.11256527900695801\n",
      "Epoch 6, Loss: 0.19732455909252167\n",
      "Epoch 4, Loss: 0.30525267124176025\n",
      "Epoch 7, Loss: 0.1812325268983841\n",
      "Epoch 3, Loss: 0.04673561081290245\n",
      "Epoch 5, Loss: 0.11778172105550766\n",
      "Epoch 4, Loss: 0.08101050555706024\n",
      "Epoch 8, Loss: 0.12945471704006195\n",
      "Epoch 9, Loss: 0.07468142360448837\n",
      "Epoch 6, Loss: 0.06493699550628662\n",
      "Epoch 5, Loss: 0.06123187392950058\n",
      "Epoch 10, Loss: 0.034116409718990326\n",
      "Epoch 4, Loss: 0.06293193250894547\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.32238482331040824, feed_forward_dim=256, head_dim=16, lr=0.00017717388242560026, num_heads=2, num_layers=1; total time=   0.5s\n",
      "Epoch 7, Loss: 0.10651237517595291\n",
      "Epoch 6, Loss: 0.05476250499486923\n",
      "Epoch 8, Loss: 0.1911107897758484\n",
      "Epoch 5, Loss: 0.10055374354124069\n",
      "Epoch 9, Loss: 0.2629663050174713\n",
      "Epoch 7, Loss: 0.047298651188611984\n",
      "Epoch 10, Loss: 0.29752638936042786\n",
      "Epoch 6, Loss: 0.11219403147697449\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.32238482331040824, feed_forward_dim=256, head_dim=16, lr=0.00017717388242560026, num_heads=2, num_layers=1; total time=   0.8s\n",
      "Epoch 8, Loss: 0.033438947051763535\n",
      "Epoch 7, Loss: 0.09760689735412598\n",
      "Epoch 9, Loss: 0.025222936645150185\n",
      "Epoch 10, Loss: 0.023210689425468445\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.32238482331040824, feed_forward_dim=256, head_dim=16, lr=0.00017717388242560026, num_heads=2, num_layers=1; total time=   0.9s\n",
      "Epoch 8, Loss: 0.06827033311128616\n",
      "Epoch 9, Loss: 0.04036719352006912\n",
      "Epoch 10, Loss: 0.024078650400042534\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.32238482331040824, feed_forward_dim=256, head_dim=16, lr=0.00017717388242560026, num_heads=2, num_layers=1; total time=   1.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.5535163879394531\n",
      "Epoch 2, Loss: 7.761477470397949\n",
      "Epoch 1, Loss: 0.17592762410640717\n",
      "Epoch 1, Loss: 0.22688111662864685\n",
      "Epoch 3, Loss: 2.5433545112609863\n",
      "Epoch 2, Loss: 8.129206657409668\n",
      "Epoch 4, Loss: 0.16654565930366516\n",
      "Epoch 1, Loss: 1.3060246706008911\n",
      "Epoch 3, Loss: 0.9637580513954163\n",
      "Epoch 5, Loss: 0.4636436700820923\n",
      "Epoch 2, Loss: 8.85469913482666\n",
      "Epoch 1, Loss: 0.6683678030967712\n",
      "Epoch 6, Loss: 0.7952061891555786\n",
      "Epoch 4, Loss: 0.5756082534790039\n",
      "Epoch 7, Loss: 0.5246894955635071\n",
      "Epoch 8, Loss: 0.21103167533874512\n",
      "Epoch 2, Loss: 8.834517478942871\n",
      "Epoch 3, Loss: 2.3722825050354004\n",
      "Epoch 5, Loss: 0.9894370436668396\n",
      "Epoch 9, Loss: 0.06831946223974228\n",
      "Epoch 10, Loss: 0.10111074149608612\n",
      "Epoch 2, Loss: 7.511740684509277\n",
      "Epoch 6, Loss: 0.4965958595275879\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.29951685292305474, feed_forward_dim=1024, head_dim=16, lr=0.0030690163751730033, num_heads=8, num_layers=4; total time=   0.3s\n",
      "Epoch 4, Loss: 0.04721122235059738\n",
      "Epoch 3, Loss: 3.165513277053833\n",
      "Epoch 7, Loss: 0.12770633399486542\n",
      "Epoch 5, Loss: 0.7917561531066895\n",
      "Epoch 8, Loss: 0.0664043128490448\n",
      "Epoch 3, Loss: 2.163069248199463\n",
      "Epoch 4, Loss: 0.3627551794052124\n",
      "Epoch 9, Loss: 0.16710443794727325\n",
      "Epoch 6, Loss: 0.8914910554885864\n",
      "Epoch 10, Loss: 0.2390410304069519\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.29951685292305474, feed_forward_dim=1024, head_dim=16, lr=0.0030690163751730033, num_heads=8, num_layers=4; total time=   0.4s\n",
      "Epoch 5, Loss: 0.20778658986091614\n",
      "Epoch 7, Loss: 0.44550150632858276\n",
      "Epoch 4, Loss: 0.07575017958879471\n",
      "Epoch 8, Loss: 0.11078198999166489\n",
      "Epoch 6, Loss: 0.7159464955329895\n",
      "Epoch 5, Loss: 0.5455235838890076\n",
      "Epoch 9, Loss: 0.059031661599874496\n",
      "Epoch 7, Loss: 0.7360069155693054\n",
      "Epoch 10, Loss: 0.16914260387420654\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.29951685292305474, feed_forward_dim=1024, head_dim=16, lr=0.0030690163751730033, num_heads=8, num_layers=4; total time=   0.6s\n",
      "Epoch 6, Loss: 0.7815727591514587\n",
      "Epoch 8, Loss: 0.4322912096977234\n",
      "Epoch 7, Loss: 0.4921545684337616\n",
      "Epoch 9, Loss: 0.1526917666196823\n",
      "Epoch 10, Loss: 0.05874820426106453\n",
      "Epoch 8, Loss: 0.18109309673309326\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.29951685292305474, feed_forward_dim=1024, head_dim=16, lr=0.0030690163751730033, num_heads=8, num_layers=4; total time=   0.8s\n",
      "Epoch 9, Loss: 0.05461975932121277\n",
      "Epoch 10, Loss: 0.10486496984958649\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.29951685292305474, feed_forward_dim=1024, head_dim=16, lr=0.0030690163751730033, num_heads=8, num_layers=4; total time=   1.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.4073256254196167\n",
      "Epoch 2, Loss: 11.56861400604248\n",
      "Epoch 1, Loss: 0.06529945880174637\n",
      "Epoch 3, Loss: 3.160357713699341\n",
      "Epoch 2, Loss: 12.393647193908691\n",
      "Epoch 1, Loss: 1.0454449653625488\n",
      "Epoch 4, Loss: 0.07681445777416229\n",
      "Epoch 5, Loss: 0.9558172821998596\n",
      "Epoch 3, Loss: 2.2083168029785156\n",
      "Epoch 1, Loss: 0.5752276182174683\n",
      "Epoch 2, Loss: 6.225448131561279\n",
      "Epoch 1, Loss: 0.6806747913360596\n",
      "Epoch 6, Loss: 0.8173654675483704\n",
      "Epoch 7, Loss: 0.3357192575931549\n",
      "Epoch 4, Loss: 0.2950000464916229\n",
      "Epoch 8, Loss: 0.09720619022846222\n",
      "Epoch 3, Loss: 1.3781710863113403\n",
      "Epoch 2, Loss: 10.101666450500488\n",
      "Epoch 9, Loss: 0.08404288440942764\n",
      "Epoch 5, Loss: 0.8625394105911255\n",
      "Epoch 2, Loss: 12.936256408691406\n",
      "Epoch 10, Loss: 0.1531708687543869\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.004999999999999999, num_heads=4, num_layers=2; total time=   0.3s\n",
      "Epoch 4, Loss: 0.07553105056285858\n",
      "Epoch 6, Loss: 0.41555067896842957\n",
      "Epoch 3, Loss: 2.1888134479522705\n",
      "Epoch 7, Loss: 0.10296520590782166\n",
      "Epoch 5, Loss: 0.6194935441017151\n",
      "Epoch 3, Loss: 4.216156482696533\n",
      "Epoch 8, Loss: 0.08731875568628311\n",
      "Epoch 4, Loss: 0.0755203515291214\n",
      "Epoch 6, Loss: 0.5658565163612366\n",
      "Epoch 9, Loss: 0.16634415090084076\n",
      "Epoch 10, Loss: 0.1784437596797943\n",
      "Epoch 4, Loss: 0.16834256052970886\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.004999999999999999, num_heads=4, num_layers=2; total time=   0.5s\n",
      "Epoch 7, Loss: 0.24400006234645844\n",
      "Epoch 5, Loss: 0.7368695139884949\n",
      "Epoch 8, Loss: 0.07253849506378174\n",
      "Epoch 5, Loss: 0.9114522337913513\n",
      "Epoch 6, Loss: 0.43952757120132446\n",
      "Epoch 9, Loss: 0.09334138035774231\n",
      "Epoch 7, Loss: 0.10810206085443497\n",
      "Epoch 10, Loss: 0.1635841727256775\n",
      "Epoch 6, Loss: 0.9495037198066711\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.004999999999999999, num_heads=4, num_layers=2; total time=   0.6s\n",
      "Epoch 8, Loss: 0.0586370974779129\n",
      "Epoch 7, Loss: 0.4003206789493561\n",
      "Epoch 9, Loss: 0.13138549029827118\n",
      "Epoch 8, Loss: 0.10235004127025604\n",
      "Epoch 10, Loss: 0.16300144791603088\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.004999999999999999, num_heads=4, num_layers=2; total time=   0.9s\n",
      "Epoch 9, Loss: 0.0618242584168911\n",
      "Epoch 10, Loss: 0.12550951540470123\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=16, lr=0.004999999999999999, num_heads=4, num_layers=2; total time=   1.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.4324096143245697\n",
      "Epoch 2, Loss: 14.15774917602539\n",
      "Epoch 1, Loss: 2.068065643310547\n",
      "Epoch 3, Loss: 3.107086658477783\n",
      "Epoch 4, Loss: 0.06297283619642258\n",
      "Epoch 2, Loss: 11.895424842834473\n",
      "Epoch 1, Loss: 0.11855047941207886\n",
      "Epoch 5, Loss: 0.9691033959388733\n",
      "Epoch 1, Loss: 0.03303688019514084\n",
      "Epoch 6, Loss: 0.9253341555595398\n",
      "Epoch 3, Loss: 2.409043073654175\n",
      "Epoch 1, Loss: 0.6633981466293335\n",
      "Epoch 7, Loss: 0.42716312408447266\n",
      "Epoch 2, Loss: 17.77559471130371\n",
      "Epoch 8, Loss: 0.1234050989151001\n",
      "Epoch 4, Loss: 0.0802234634757042\n",
      "Epoch 9, Loss: 0.08077336102724075\n",
      "Epoch 2, Loss: 11.336092948913574\n",
      "Epoch 5, Loss: 0.9090973734855652\n",
      "Epoch 10, Loss: 0.1589115709066391\n",
      "Epoch 3, Loss: 4.090775489807129\n",
      "[CV] END activation=gelu, batch_size=32, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=0.004999999999999999, num_heads=4, num_layers=2; total time=   0.3s\n",
      "Epoch 2, Loss: 10.69417667388916\n",
      "Epoch 6, Loss: 0.6291121244430542\n",
      "Epoch 3, Loss: 1.0528961420059204\n",
      "Epoch 7, Loss: 0.15943863987922668\n",
      "Epoch 4, Loss: 0.11121940612792969\n",
      "Epoch 8, Loss: 0.07980044931173325\n",
      "Epoch 3, Loss: 2.1065258979797363\n",
      "Epoch 4, Loss: 1.5498074293136597\n",
      "Epoch 5, Loss: 0.8825230598449707\n",
      "Epoch 9, Loss: 0.20235034823417664\n",
      "Epoch 10, Loss: 0.2586718797683716\n",
      "[CV] END activation=gelu, batch_size=32, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=0.004999999999999999, num_heads=4, num_layers=2; total time=   0.5s\n",
      "Epoch 6, Loss: 0.9190245866775513\n",
      "Epoch 5, Loss: 0.879945695400238\n",
      "Epoch 4, Loss: 0.14238420128822327\n",
      "Epoch 7, Loss: 0.37678810954093933\n",
      "Epoch 6, Loss: 0.20206734538078308\n",
      "Epoch 5, Loss: 0.8508720397949219\n",
      "Epoch 8, Loss: 0.07592590898275375\n",
      "Epoch 7, Loss: 0.0512470118701458\n",
      "Epoch 9, Loss: 0.14228683710098267\n",
      "Epoch 6, Loss: 0.4305117428302765\n",
      "Epoch 10, Loss: 0.268685907125473\n",
      "Epoch 8, Loss: 0.1359090507030487\n",
      "[CV] END activation=gelu, batch_size=32, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=0.004999999999999999, num_heads=4, num_layers=2; total time=   0.7s\n",
      "Epoch 7, Loss: 0.07895314693450928\n",
      "Epoch 9, Loss: 0.2086479365825653\n",
      "Epoch 8, Loss: 0.09686198830604553\n",
      "Epoch 10, Loss: 0.20071572065353394\n",
      "[CV] END activation=gelu, batch_size=32, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=0.004999999999999999, num_heads=4, num_layers=2; total time=   0.8s\n",
      "Epoch 9, Loss: 0.19216009974479675\n",
      "Epoch 10, Loss: 0.18839091062545776\n",
      "[CV] END activation=gelu, batch_size=32, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=0.004999999999999999, num_heads=4, num_layers=2; total time=   1.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.25942108035087585\n",
      "Epoch 2, Loss: 0.15183301270008087\n",
      "Epoch 3, Loss: 0.16861525177955627\n",
      "Epoch 1, Loss: 0.08706282824277878\n",
      "Epoch 4, Loss: 0.0838131383061409\n",
      "Epoch 5, Loss: 0.03451390564441681\n",
      "Epoch 2, Loss: 0.2731005847454071\n",
      "Epoch 1, Loss: 0.2369699478149414\n",
      "Epoch 6, Loss: 0.045037344098091125\n",
      "Epoch 1, Loss: 2.301445484161377\n",
      "Epoch 7, Loss: 0.06073557212948799\n",
      "Epoch 3, Loss: 0.06616397202014923\n",
      "Epoch 1, Loss: 0.7746071219444275\n",
      "Epoch 8, Loss: 0.05012279748916626\n",
      "Epoch 2, Loss: 0.047802429646253586\n",
      "Epoch 4, Loss: 0.060303185135126114\n",
      "Epoch 9, Loss: 0.02406913973391056\n",
      "Epoch 2, Loss: 0.8205358982086182\n",
      "Epoch 10, Loss: 0.019528571516275406\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.17112329555957523, feed_forward_dim=256, head_dim=16, lr=0.00038302356947301727, num_heads=4, num_layers=2; total time=   0.3s\n",
      "Epoch 3, Loss: 0.1698525846004486\n",
      "Epoch 5, Loss: 0.1252312958240509\n",
      "Epoch 2, Loss: 0.07492388039827347\n",
      "Epoch 6, Loss: 0.07967273890972137\n",
      "Epoch 3, Loss: 0.1350962072610855\n",
      "Epoch 4, Loss: 0.09329405426979065\n",
      "Epoch 7, Loss: 0.018112260848283768\n",
      "Epoch 5, Loss: 0.014325696974992752\n",
      "Epoch 8, Loss: 0.01968408189713955\n",
      "Epoch 3, Loss: 0.07504896074533463\n",
      "Epoch 4, Loss: 0.0727313905954361\n",
      "Epoch 9, Loss: 0.053227704018354416\n",
      "Epoch 6, Loss: 0.025591356679797173\n",
      "Epoch 10, Loss: 0.05742378905415535\n",
      "Epoch 5, Loss: 0.28853651881217957\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.17112329555957523, feed_forward_dim=256, head_dim=16, lr=0.00038302356947301727, num_heads=4, num_layers=2; total time=   0.5s\n",
      "Epoch 4, Loss: 0.2569500207901001\n",
      "Epoch 7, Loss: 0.06871727854013443\n",
      "Epoch 8, Loss: 0.07149362564086914\n",
      "Epoch 6, Loss: 0.4489116370677948\n",
      "Epoch 5, Loss: 0.268787145614624\n",
      "Epoch 9, Loss: 0.03702943027019501\n",
      "Epoch 7, Loss: 0.47360292077064514\n",
      "Epoch 10, Loss: 0.008948643691837788\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.17112329555957523, feed_forward_dim=256, head_dim=16, lr=0.00038302356947301727, num_heads=4, num_layers=2; total time=   0.6s\n",
      "Epoch 6, Loss: 0.16891707479953766\n",
      "Epoch 8, Loss: 0.3911997675895691\n",
      "Epoch 7, Loss: 0.06433338671922684\n",
      "Epoch 9, Loss: 0.26740771532058716\n",
      "Epoch 10, Loss: 0.15018673241138458\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.17112329555957523, feed_forward_dim=256, head_dim=16, lr=0.00038302356947301727, num_heads=4, num_layers=2; total time=   0.8s\n",
      "Epoch 8, Loss: 0.01273191999644041\n",
      "Epoch 9, Loss: 0.019117234274744987\n",
      "Epoch 10, Loss: 0.058251965790987015\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.17112329555957523, feed_forward_dim=256, head_dim=16, lr=0.00038302356947301727, num_heads=4, num_layers=2; total time=   1.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.2840249538421631\n",
      "Epoch 2, Loss: 0.10395894199609756\n",
      "Epoch 1, Loss: 0.12980160117149353\n",
      "Epoch 3, Loss: 0.13364043831825256\n",
      "Epoch 4, Loss: 0.16671226918697357\n",
      "Epoch 2, Loss: 0.08036573231220245\n",
      "Epoch 5, Loss: 0.1387668401002884\n",
      "Epoch 6, Loss: 0.0869845375418663\n",
      "Epoch 1, Loss: 0.3096518814563751\n",
      "Epoch 3, Loss: 0.09574591368436813\n",
      "Epoch 1, Loss: 1.8109925985336304\n",
      "Epoch 7, Loss: 0.05540178716182709\n",
      "Epoch 8, Loss: 0.05535520240664482\n",
      "Epoch 1, Loss: 0.7657338976860046\n",
      "Epoch 4, Loss: 0.055905312299728394\n",
      "Epoch 2, Loss: 0.04483041539788246\n",
      "Epoch 9, Loss: 0.073833167552948\n",
      "Epoch 10, Loss: 0.07616925984621048\n",
      "Epoch 5, Loss: 0.02987278439104557\n",
      "[CV] END activation=gelu, batch_size=32, dropout_rate=0.10725740225454802, feed_forward_dim=512, head_dim=32, lr=0.00020919568398432788, num_heads=2, num_layers=1; total time=   0.3s\n",
      "Epoch 2, Loss: 1.101197361946106\n",
      "Epoch 3, Loss: 0.026339391246438026\n",
      "Epoch 6, Loss: 0.034971170127391815\n",
      "Epoch 2, Loss: 0.27976006269454956\n",
      "Epoch 7, Loss: 0.03784031793475151\n",
      "Epoch 4, Loss: 0.10092424601316452\n",
      "Epoch 3, Loss: 0.5791186094284058\n",
      "Epoch 8, Loss: 0.021097343415021896\n",
      "Epoch 5, Loss: 0.12519751489162445\n",
      "Epoch 3, Loss: 0.06979917734861374\n",
      "Epoch 4, Loss: 0.2383168339729309\n",
      "Epoch 9, Loss: 0.008533235639333725\n",
      "Epoch 6, Loss: 0.09698982536792755\n",
      "Epoch 10, Loss: 0.010272943414747715\n",
      "[CV] END activation=gelu, batch_size=32, dropout_rate=0.10725740225454802, feed_forward_dim=512, head_dim=32, lr=0.00020919568398432788, num_heads=2, num_layers=1; total time=   0.5s\n",
      "Epoch 5, Loss: 0.07398313283920288\n",
      "Epoch 4, Loss: 0.07781563699245453\n",
      "Epoch 7, Loss: 0.04910764470696449\n",
      "Epoch 6, Loss: 0.042549069970846176\n",
      "Epoch 8, Loss: 0.01622653752565384\n",
      "Epoch 5, Loss: 0.1760098934173584\n",
      "Epoch 9, Loss: 0.0111288633197546\n",
      "Epoch 7, Loss: 0.0970560610294342\n",
      "Epoch 10, Loss: 0.027387358248233795\n",
      "Epoch 6, Loss: 0.2346622794866562\n",
      "[CV] END activation=gelu, batch_size=32, dropout_rate=0.10725740225454802, feed_forward_dim=512, head_dim=32, lr=0.00020919568398432788, num_heads=2, num_layers=1; total time=   0.6s\n",
      "Epoch 8, Loss: 0.1773826777935028\n",
      "Epoch 7, Loss: 0.21808023750782013\n",
      "Epoch 9, Loss: 0.24174652993679047\n",
      "Epoch 10, Loss: 0.2737160921096802\n",
      "Epoch 8, Loss: 0.16161470115184784\n",
      "[CV] END activation=gelu, batch_size=32, dropout_rate=0.10725740225454802, feed_forward_dim=512, head_dim=32, lr=0.00020919568398432788, num_heads=2, num_layers=1; total time=   0.8s\n",
      "Epoch 9, Loss: 0.09546061605215073\n",
      "Epoch 10, Loss: 0.044274888932704926\n",
      "[CV] END activation=gelu, batch_size=32, dropout_rate=0.10725740225454802, feed_forward_dim=512, head_dim=32, lr=0.00020919568398432788, num_heads=2, num_layers=1; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.48718053102493286\n",
      "Epoch 2, Loss: 0.19737310707569122\n",
      "Epoch 1, Loss: 0.3637380599975586\n",
      "Epoch 3, Loss: 0.1469683051109314\n",
      "Epoch 1, Loss: 0.2453170120716095\n",
      "Epoch 4, Loss: 0.19861891865730286\n",
      "Epoch 2, Loss: 0.12198331952095032\n",
      "Epoch 1, Loss: 3.4343349933624268\n",
      "Epoch 5, Loss: 0.20446830987930298\n",
      "Epoch 2, Loss: 0.030047576874494553\n",
      "Epoch 1, Loss: 1.3516745567321777\n",
      "Epoch 3, Loss: 0.1525653600692749\n",
      "Epoch 6, Loss: 0.14993979036808014\n",
      "Epoch 7, Loss: 0.08760601282119751\n",
      "Epoch 2, Loss: 2.383815050125122\n",
      "Epoch 4, Loss: 0.18174247443675995\n",
      "Epoch 3, Loss: 0.06124579906463623\n",
      "Epoch 8, Loss: 0.05115300416946411\n",
      "Epoch 9, Loss: 0.03784569725394249\n",
      "Epoch 5, Loss: 0.1327773481607437\n",
      "Epoch 2, Loss: 0.574722170829773\n",
      "Epoch 10, Loss: 0.04967585951089859\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.2582261112662213, feed_forward_dim=128, head_dim=32, lr=0.0002162407874306904, num_heads=2, num_layers=2; total time=   0.3s\n",
      "Epoch 4, Loss: 0.11411700397729874\n",
      "Epoch 3, Loss: 1.5094671249389648\n",
      "Epoch 6, Loss: 0.06999702751636505\n",
      "Epoch 7, Loss: 0.03969905152916908\n",
      "Epoch 5, Loss: 0.0940580666065216\n",
      "Epoch 4, Loss: 0.8466382622718811\n",
      "Epoch 8, Loss: 0.04459286108613014\n",
      "Epoch 3, Loss: 0.172230526804924\n",
      "Epoch 6, Loss: 0.04460863396525383\n",
      "Epoch 9, Loss: 0.05878452584147453\n",
      "Epoch 5, Loss: 0.3896699547767639\n",
      "Epoch 10, Loss: 0.0646490827202797\n",
      "Epoch 7, Loss: 0.01028699055314064\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.2582261112662213, feed_forward_dim=128, head_dim=32, lr=0.0002162407874306904, num_heads=2, num_layers=2; total time=   0.4s\n",
      "Epoch 4, Loss: 0.08555520325899124\n",
      "Epoch 8, Loss: 0.009127402678132057\n",
      "Epoch 6, Loss: 0.13907037675380707\n",
      "Epoch 5, Loss: 0.17673973739147186\n",
      "Epoch 9, Loss: 0.029893336817622185\n",
      "Epoch 7, Loss: 0.044233471155166626\n",
      "Epoch 10, Loss: 0.04651924595236778\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.2582261112662213, feed_forward_dim=128, head_dim=32, lr=0.0002162407874306904, num_heads=2, num_layers=2; total time=   0.6s\n",
      "Epoch 6, Loss: 0.2917476296424866\n",
      "Epoch 8, Loss: 0.06495163589715958\n",
      "Epoch 9, Loss: 0.14959588646888733\n",
      "Epoch 7, Loss: 0.343517005443573\n",
      "Epoch 10, Loss: 0.2539573609828949\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.2582261112662213, feed_forward_dim=128, head_dim=32, lr=0.0002162407874306904, num_heads=2, num_layers=2; total time=   0.7s\n",
      "Epoch 8, Loss: 0.32809147238731384\n",
      "Epoch 9, Loss: 0.2617853581905365\n",
      "Epoch 10, Loss: 0.17880991101264954\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.2582261112662213, feed_forward_dim=128, head_dim=32, lr=0.0002162407874306904, num_heads=2, num_layers=2; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.021983694285154343\n",
      "Epoch 1, Loss: 0.7884106040000916\n",
      "Epoch 2, Loss: 0.01758274808526039\n",
      "Epoch 1, Loss: 0.8979478478431702\n",
      "Epoch 3, Loss: 0.01412266306579113\n",
      "Epoch 2, Loss: 0.6393788456916809\n",
      "Epoch 1, Loss: 0.18536214530467987\n",
      "Epoch 4, Loss: 0.01148780807852745\n",
      "Epoch 1, Loss: 0.13852106034755707\n",
      "Epoch 5, Loss: 0.009729596786201\n",
      "Epoch 2, Loss: 0.733725905418396\n",
      "Epoch 3, Loss: 0.5066397190093994\n",
      "Epoch 6, Loss: 0.00766376219689846\n",
      "Epoch 2, Loss: 0.13007153570652008\n",
      "Epoch 7, Loss: 0.00606229342520237\n",
      "Epoch 4, Loss: 0.3894747495651245\n",
      "Epoch 3, Loss: 0.600977897644043\n",
      "Epoch 8, Loss: 0.0058525032363832\n",
      "Epoch 9, Loss: 0.0049115451984107494\n",
      "Epoch 2, Loss: 0.09301033616065979\n",
      "Epoch 5, Loss: 0.30009326338768005\n",
      "Epoch 10, Loss: 0.004976780153810978\n",
      "Epoch 3, Loss: 0.08328356593847275\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.23745166782645022, feed_forward_dim=1024, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   0.4s\n",
      "Epoch 4, Loss: 0.4818558096885681\n",
      "Epoch 6, Loss: 0.2164427936077118\n",
      "Epoch 5, Loss: 0.38592594861984253\n",
      "Epoch 3, Loss: 0.06251391023397446\n",
      "Epoch 7, Loss: 0.15230414271354675\n",
      "Epoch 4, Loss: 0.050573091953992844\n",
      "Epoch 8, Loss: 0.10718712955713272\n",
      "Epoch 6, Loss: 0.31183499097824097\n",
      "Epoch 5, Loss: 0.03003240004181862\n",
      "Epoch 9, Loss: 0.07770582288503647\n",
      "Epoch 4, Loss: 0.04486827179789543\n",
      "Epoch 7, Loss: 0.24855618178844452\n",
      "Epoch 10, Loss: 0.05637811869382858\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.23745166782645022, feed_forward_dim=1024, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   0.6s\n",
      "Epoch 6, Loss: 0.01808682456612587\n",
      "Epoch 8, Loss: 0.20808103680610657\n",
      "Epoch 5, Loss: 0.038510553538799286\n",
      "Epoch 9, Loss: 0.17983460426330566\n",
      "Epoch 7, Loss: 0.01569719798862934\n",
      "Epoch 10, Loss: 0.16542062163352966\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.23745166782645022, feed_forward_dim=1024, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   0.7s\n",
      "Epoch 6, Loss: 0.04086397588253021\n",
      "Epoch 8, Loss: 0.01969871111214161\n",
      "Epoch 9, Loss: 0.025216756388545036\n",
      "Epoch 7, Loss: 0.04383569583296776\n",
      "Epoch 10, Loss: 0.031912658363580704\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.23745166782645022, feed_forward_dim=1024, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   0.8s\n",
      "Epoch 8, Loss: 0.04572179168462753\n",
      "Epoch 9, Loss: 0.04612945392727852\n",
      "Epoch 10, Loss: 0.04320614039897919\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.23745166782645022, feed_forward_dim=1024, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   1.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.3716046214103699\n",
      "Epoch 2, Loss: 0.285719633102417\n",
      "Epoch 1, Loss: 0.4946296513080597\n",
      "Epoch 3, Loss: 0.2091187685728073\n",
      "Epoch 1, Loss: 1.3031665086746216\n",
      "Epoch 4, Loss: 0.14838024973869324\n",
      "Epoch 1, Loss: 1.6447381973266602\n",
      "Epoch 2, Loss: 0.3944803476333618\n",
      "Epoch 5, Loss: 0.09743287414312363\n",
      "Epoch 1, Loss: 0.011696507222950459\n",
      "Epoch 6, Loss: 0.0611833818256855\n",
      "Epoch 3, Loss: 0.31199002265930176\n",
      "Epoch 2, Loss: 1.1180180311203003\n",
      "Epoch 7, Loss: 0.032603900879621506\n",
      "Epoch 2, Loss: 1.4156160354614258\n",
      "Epoch 4, Loss: 0.2430180311203003\n",
      "Epoch 8, Loss: 0.017059018835425377\n",
      "Epoch 9, Loss: 0.008081172592937946\n",
      "Epoch 2, Loss: 0.011190006509423256\n",
      "Epoch 3, Loss: 0.9477073550224304\n",
      "Epoch 10, Loss: 0.008128616027534008\n",
      "Epoch 5, Loss: 0.18861021101474762\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=5e-05, num_heads=4, num_layers=2; total time=   0.3s\n",
      "Epoch 3, Loss: 1.2005339860916138\n",
      "Epoch 6, Loss: 0.15597663819789886\n",
      "Epoch 4, Loss: 0.789847731590271\n",
      "Epoch 3, Loss: 0.009808474220335484\n",
      "Epoch 7, Loss: 0.1254941076040268\n",
      "Epoch 4, Loss: 0.9996282458305359\n",
      "Epoch 5, Loss: 0.6562579274177551\n",
      "Epoch 8, Loss: 0.1139715388417244\n",
      "Epoch 9, Loss: 0.10725869238376617\n",
      "Epoch 6, Loss: 0.5366547107696533\n",
      "Epoch 4, Loss: 0.007885473780333996\n",
      "Epoch 5, Loss: 0.8178686499595642\n",
      "Epoch 10, Loss: 0.10937371104955673\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=5e-05, num_heads=4, num_layers=2; total time=   0.5s\n",
      "Epoch 7, Loss: 0.43987223505973816\n",
      "Epoch 6, Loss: 0.6560826301574707\n",
      "Epoch 5, Loss: 0.007412373088300228\n",
      "Epoch 8, Loss: 0.3606616258621216\n",
      "Epoch 7, Loss: 0.516080379486084\n",
      "Epoch 9, Loss: 0.2937690317630768\n",
      "Epoch 6, Loss: 0.006957172881811857\n",
      "Epoch 8, Loss: 0.39656758308410645\n",
      "Epoch 10, Loss: 0.2417852282524109\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=5e-05, num_heads=4, num_layers=2; total time=   0.8s\n",
      "Epoch 7, Loss: 0.006057704333215952\n",
      "Epoch 9, Loss: 0.2946638762950897\n",
      "Epoch 8, Loss: 0.0058015151880681515\n",
      "Epoch 10, Loss: 0.20782658457756042\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=5e-05, num_heads=4, num_layers=2; total time=   0.9s\n",
      "Epoch 9, Loss: 0.005802979227155447\n",
      "Epoch 10, Loss: 0.0063950116746127605\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.4, feed_forward_dim=1024, head_dim=16, lr=5e-05, num_heads=4, num_layers=2; total time=   1.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.6460472941398621\n",
      "Epoch 2, Loss: 5.359430313110352\n",
      "Epoch 1, Loss: 0.7348535060882568\n",
      "Epoch 3, Loss: 1.180782437324524\n",
      "Epoch 2, Loss: 6.868032932281494\n",
      "Epoch 4, Loss: 0.05338593199849129\n",
      "Epoch 1, Loss: 0.2331874668598175\n",
      "Epoch 1, Loss: 3.3077280521392822\n",
      "Epoch 5, Loss: 0.5996620059013367\n",
      "Epoch 3, Loss: 1.520033597946167\n",
      "Epoch 1, Loss: 0.14127305150032043\n",
      "Epoch 6, Loss: 0.6099114418029785\n",
      "Epoch 2, Loss: 14.9491605758667\n",
      "Epoch 2, Loss: 5.445384979248047\n",
      "Epoch 7, Loss: 0.3097003102302551\n",
      "Epoch 4, Loss: 0.058999259024858475\n",
      "Epoch 8, Loss: 0.0984693244099617\n",
      "Epoch 9, Loss: 0.06862447410821915\n",
      "Epoch 5, Loss: 0.46017104387283325\n",
      "Epoch 3, Loss: 3.5290188789367676\n",
      "Epoch 10, Loss: 0.13431185483932495\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.2606551950202966, feed_forward_dim=128, head_dim=16, lr=0.0034566733062286626, num_heads=2, num_layers=3; total time=   0.3s\n",
      "Epoch 3, Loss: 1.8330398797988892\n",
      "Epoch 2, Loss: 10.246091842651367\n",
      "Epoch 6, Loss: 0.6702961325645447\n",
      "Epoch 4, Loss: 0.08757712692022324\n",
      "Epoch 7, Loss: 0.4548397362232208\n",
      "Epoch 4, Loss: 0.18013416230678558\n",
      "Epoch 8, Loss: 0.18750619888305664\n",
      "Epoch 3, Loss: 1.7928656339645386\n",
      "Epoch 5, Loss: 0.6463268995285034\n",
      "Epoch 9, Loss: 0.06672978401184082\n",
      "Epoch 5, Loss: 0.17805248498916626\n",
      "Epoch 10, Loss: 0.10814689844846725\n",
      "Epoch 6, Loss: 1.030173897743225\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.2606551950202966, feed_forward_dim=128, head_dim=16, lr=0.0034566733062286626, num_heads=2, num_layers=3; total time=   0.4s\n",
      "Epoch 4, Loss: 0.16275779902935028\n",
      "Epoch 7, Loss: 0.6963938474655151\n",
      "Epoch 6, Loss: 0.4381921589374542\n",
      "Epoch 8, Loss: 0.25928494334220886\n",
      "Epoch 5, Loss: 0.9758519530296326\n",
      "Epoch 7, Loss: 0.36469072103500366\n",
      "Epoch 9, Loss: 0.061179518699645996\n",
      "Epoch 8, Loss: 0.17145060002803802\n",
      "Epoch 6, Loss: 0.7237057685852051\n",
      "Epoch 10, Loss: 0.13885632157325745\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.2606551950202966, feed_forward_dim=128, head_dim=16, lr=0.0034566733062286626, num_heads=2, num_layers=3; total time=   0.6s\n",
      "Epoch 9, Loss: 0.05939501151442528\n",
      "Epoch 7, Loss: 0.24805907905101776\n",
      "Epoch 10, Loss: 0.07766346633434296\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.2606551950202966, feed_forward_dim=128, head_dim=16, lr=0.0034566733062286626, num_heads=2, num_layers=3; total time=   0.7s\n",
      "Epoch 8, Loss: 0.05196680501103401\n",
      "Epoch 9, Loss: 0.11394301056861877\n",
      "Epoch 10, Loss: 0.21004872024059296\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.2606551950202966, feed_forward_dim=128, head_dim=16, lr=0.0034566733062286626, num_heads=2, num_layers=3; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.12421642243862152\n",
      "Epoch 2, Loss: 0.08910287171602249\n",
      "Epoch 1, Loss: 0.15333712100982666\n",
      "Epoch 3, Loss: 0.063604436814785\n",
      "Epoch 4, Loss: 0.05597700923681259\n",
      "Epoch 1, Loss: 0.11073561757802963\n",
      "Epoch 2, Loss: 0.12816885113716125\n",
      "Epoch 5, Loss: 0.05394270271062851\n",
      "Epoch 1, Loss: 0.22959615290164948\n",
      "Epoch 6, Loss: 0.056069400161504745\n",
      "Epoch 2, Loss: 0.09881635010242462\n",
      "Epoch 1, Loss: 0.2977686822414398\n",
      "Epoch 3, Loss: 0.11654266715049744\n",
      "Epoch 7, Loss: 0.05536237359046936\n",
      "Epoch 8, Loss: 0.05507786571979523\n",
      "Epoch 4, Loss: 0.10709645599126816\n",
      "Epoch 2, Loss: 0.1743878275156021\n",
      "Epoch 9, Loss: 0.050009213387966156\n",
      "Epoch 3, Loss: 0.0879286527633667\n",
      "Epoch 10, Loss: 0.04626769572496414\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=2, num_layers=3; total time=   0.3s\n",
      "Epoch 5, Loss: 0.09933754056692123\n",
      "Epoch 2, Loss: 0.2130695879459381\n",
      "Epoch 6, Loss: 0.09056401252746582\n",
      "Epoch 4, Loss: 0.07880517095327377\n",
      "Epoch 3, Loss: 0.13818122446537018\n",
      "Epoch 7, Loss: 0.0799514502286911\n",
      "Epoch 5, Loss: 0.07045638561248779\n",
      "Epoch 3, Loss: 0.14355967938899994\n",
      "Epoch 8, Loss: 0.07034656405448914\n",
      "Epoch 4, Loss: 0.11673128604888916\n",
      "Epoch 9, Loss: 0.061987150460481644\n",
      "Epoch 6, Loss: 0.06351859122514725\n",
      "Epoch 10, Loss: 0.05416388437151909\n",
      "Epoch 5, Loss: 0.10372521728277206\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=2, num_layers=3; total time=   0.4s\n",
      "Epoch 4, Loss: 0.09361451864242554\n",
      "Epoch 7, Loss: 0.056890204548835754\n",
      "Epoch 6, Loss: 0.10294390469789505\n",
      "Epoch 8, Loss: 0.05019146949052811\n",
      "Epoch 5, Loss: 0.062098030000925064\n",
      "Epoch 9, Loss: 0.04569613188505173\n",
      "Epoch 7, Loss: 0.10608229041099548\n",
      "Epoch 10, Loss: 0.03866686671972275\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=2, num_layers=3; total time=   0.6s\n",
      "Epoch 6, Loss: 0.04525338113307953\n",
      "Epoch 8, Loss: 0.10493548214435577\n",
      "Epoch 9, Loss: 0.10333934426307678\n",
      "Epoch 7, Loss: 0.04311950504779816\n",
      "Epoch 10, Loss: 0.09749853610992432\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=2, num_layers=3; total time=   0.8s\n",
      "Epoch 8, Loss: 0.04705440625548363\n",
      "Epoch 9, Loss: 0.056660935282707214\n",
      "Epoch 10, Loss: 0.06410731375217438\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=5e-05, num_heads=2, num_layers=3; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.24048934876918793\n",
      "Epoch 2, Loss: 5.620438575744629\n",
      "Epoch 3, Loss: 1.168129563331604\n",
      "Epoch 1, Loss: 0.761344313621521\n",
      "Epoch 4, Loss: 0.05531620606780052\n",
      "Epoch 5, Loss: 0.6490486860275269\n",
      "Epoch 2, Loss: 4.380259990692139\n",
      "Epoch 1, Loss: 0.08564748615026474\n",
      "Epoch 6, Loss: 0.6975299119949341\n",
      "Epoch 3, Loss: 1.3794821500778198\n",
      "Epoch 1, Loss: 0.04887421429157257\n",
      "Epoch 7, Loss: 0.3925849497318268\n",
      "Epoch 8, Loss: 0.14116285741329193\n",
      "Epoch 1, Loss: 0.10560568422079086\n",
      "Epoch 4, Loss: 0.10973100364208221\n",
      "Epoch 2, Loss: 5.081151008605957\n",
      "Epoch 9, Loss: 0.06039152666926384\n",
      "Epoch 10, Loss: 0.1078023836016655\n",
      "Epoch 5, Loss: 0.2608982026576996\n",
      "Epoch 2, Loss: 8.9054594039917\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.22841561465491758, feed_forward_dim=1024, head_dim=16, lr=0.0022483764567165494, num_heads=4, num_layers=2; total time=   0.3s\n",
      "Epoch 3, Loss: 0.04603488743305206\n",
      "Epoch 6, Loss: 0.53227698802948\n",
      "Epoch 2, Loss: 3.980727434158325\n",
      "Epoch 7, Loss: 0.4771636426448822\n",
      "Epoch 3, Loss: 0.7689257264137268\n",
      "Epoch 4, Loss: 2.29919695854187\n",
      "Epoch 8, Loss: 0.2707957625389099\n",
      "Epoch 3, Loss: 0.7779219746589661\n",
      "Epoch 5, Loss: 1.0285989046096802\n",
      "Epoch 4, Loss: 1.320643663406372\n",
      "Epoch 9, Loss: 0.10793468356132507\n",
      "Epoch 10, Loss: 0.056619103997945786\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.22841561465491758, feed_forward_dim=1024, head_dim=16, lr=0.0022483764567165494, num_heads=4, num_layers=2; total time=   0.5s\n",
      "Epoch 6, Loss: 0.13638845086097717\n",
      "Epoch 4, Loss: 0.06233339384198189\n",
      "Epoch 5, Loss: 1.4295419454574585\n",
      "Epoch 7, Loss: 0.0642894059419632\n",
      "Epoch 6, Loss: 0.5579068064689636\n",
      "Epoch 5, Loss: 0.5345986485481262\n",
      "Epoch 8, Loss: 0.242864191532135\n",
      "Epoch 7, Loss: 0.07114017009735107\n",
      "Epoch 9, Loss: 0.33336424827575684\n",
      "Epoch 6, Loss: 0.5529533624649048\n",
      "Epoch 10, Loss: 0.2884444296360016\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.22841561465491758, feed_forward_dim=1024, head_dim=16, lr=0.0022483764567165494, num_heads=4, num_layers=2; total time=   0.7s\n",
      "Epoch 8, Loss: 0.09610629826784134\n",
      "Epoch 7, Loss: 0.3027307689189911\n",
      "Epoch 9, Loss: 0.27349603176116943\n",
      "Epoch 8, Loss: 0.10043448209762573\n",
      "Epoch 10, Loss: 0.3336468040943146\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.22841561465491758, feed_forward_dim=1024, head_dim=16, lr=0.0022483764567165494, num_heads=4, num_layers=2; total time=   0.8s\n",
      "Epoch 9, Loss: 0.04625660181045532\n",
      "Epoch 10, Loss: 0.09848207980394363\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.22841561465491758, feed_forward_dim=1024, head_dim=16, lr=0.0022483764567165494, num_heads=4, num_layers=2; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.12416214495897293\n",
      "Epoch 1, Loss: 0.30467450618743896\n",
      "Epoch 2, Loss: 0.5583268404006958\n",
      "Epoch 3, Loss: 0.12258916348218918\n",
      "Epoch 1, Loss: 1.5531063079833984\n",
      "Epoch 2, Loss: 0.3448778986930847\n",
      "Epoch 4, Loss: 0.0834658220410347\n",
      "Epoch 5, Loss: 0.2357284277677536\n",
      "Epoch 1, Loss: 0.046406716108322144\n",
      "Epoch 3, Loss: 0.19475048780441284\n",
      "Epoch 6, Loss: 0.17155520617961884\n",
      "Epoch 2, Loss: 0.1314419060945511\n",
      "Epoch 1, Loss: 0.9477897882461548\n",
      "Epoch 7, Loss: 0.0458078533411026\n",
      "Epoch 4, Loss: 0.02847868576645851\n",
      "Epoch 8, Loss: 0.020887330174446106\n",
      "Epoch 2, Loss: 0.8610947728157043\n",
      "Epoch 3, Loss: 0.4857553243637085\n",
      "Epoch 9, Loss: 0.07482291013002396\n",
      "Epoch 5, Loss: 0.06138899177312851\n",
      "Epoch 10, Loss: 0.10814917832612991\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.22202647042001294, feed_forward_dim=1024, head_dim=16, lr=0.0005930751973428741, num_heads=8, num_layers=2; total time=   0.3s\n",
      "Epoch 2, Loss: 0.0693255290389061\n",
      "Epoch 6, Loss: 0.11078882217407227\n",
      "Epoch 4, Loss: 0.6120924949645996\n",
      "Epoch 3, Loss: 0.0677269846200943\n",
      "Epoch 7, Loss: 0.07630445808172226\n",
      "Epoch 5, Loss: 0.3997974991798401\n",
      "Epoch 8, Loss: 0.018490402027964592\n",
      "Epoch 3, Loss: 0.3739273250102997\n",
      "Epoch 4, Loss: 0.16266988217830658\n",
      "Epoch 9, Loss: 0.008941838517785072\n",
      "Epoch 6, Loss: 0.1578211784362793\n",
      "Epoch 10, Loss: 0.03734473139047623\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.22202647042001294, feed_forward_dim=1024, head_dim=16, lr=0.0005930751973428741, num_heads=8, num_layers=2; total time=   0.5s\n",
      "Epoch 5, Loss: 0.37535780668258667\n",
      "Epoch 4, Loss: 0.3871065080165863\n",
      "Epoch 7, Loss: 0.049787960946559906\n",
      "Epoch 8, Loss: 0.07417044788599014\n",
      "Epoch 6, Loss: 0.29085856676101685\n",
      "Epoch 5, Loss: 0.19175976514816284\n",
      "Epoch 9, Loss: 0.15528398752212524\n",
      "Epoch 7, Loss: 0.11286371201276779\n",
      "Epoch 10, Loss: 0.19933028519153595\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.22202647042001294, feed_forward_dim=1024, head_dim=16, lr=0.0005930751973428741, num_heads=8, num_layers=2; total time=   0.6s\n",
      "Epoch 6, Loss: 0.04326088726520538\n",
      "Epoch 8, Loss: 0.013480653055012226\n",
      "Epoch 7, Loss: 0.023687515407800674\n",
      "Epoch 9, Loss: 0.029871076345443726\n",
      "Epoch 10, Loss: 0.09645937383174896\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.22202647042001294, feed_forward_dim=1024, head_dim=16, lr=0.0005930751973428741, num_heads=8, num_layers=2; total time=   0.7s\n",
      "Epoch 8, Loss: 0.08020644634962082\n",
      "Epoch 9, Loss: 0.13210847973823547\n",
      "Epoch 10, Loss: 0.13512291014194489\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.22202647042001294, feed_forward_dim=1024, head_dim=16, lr=0.0005930751973428741, num_heads=8, num_layers=2; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 1.1855857372283936\n",
      "Epoch 2, Loss: 0.09852620214223862\n",
      "Epoch 1, Loss: 0.14544478058815002\n",
      "Epoch 3, Loss: 0.3576829433441162\n",
      "Epoch 4, Loss: 0.4942592680454254\n",
      "Epoch 1, Loss: 0.10263322293758392\n",
      "Epoch 2, Loss: 0.26562151312828064\n",
      "Epoch 5, Loss: 0.33119967579841614\n",
      "Epoch 1, Loss: 0.20052415132522583\n",
      "Epoch 6, Loss: 0.1354658603668213\n",
      "Epoch 1, Loss: 0.7489742040634155\n",
      "Epoch 3, Loss: 0.12500403821468353\n",
      "Epoch 2, Loss: 0.6178321242332458\n",
      "Epoch 7, Loss: 0.048657651990652084\n",
      "Epoch 8, Loss: 0.0653461143374443\n",
      "Epoch 2, Loss: 0.33682486414909363\n",
      "Epoch 4, Loss: 0.011628752574324608\n",
      "Epoch 9, Loss: 0.12489251792430878\n",
      "Epoch 3, Loss: 0.06716634333133698\n",
      "Epoch 2, Loss: 0.11555463075637817\n",
      "Epoch 10, Loss: 0.16631126403808594\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.28880243899487146, feed_forward_dim=1024, head_dim=16, lr=0.0005970471766984318, num_heads=4, num_layers=2; total time=   0.3s\n",
      "Epoch 5, Loss: 0.07604145258665085\n",
      "Epoch 3, Loss: 0.15418888628482819\n",
      "Epoch 4, Loss: 0.1314578801393509\n",
      "Epoch 6, Loss: 0.11001609265804291\n",
      "Epoch 3, Loss: 0.4142409861087799\n",
      "Epoch 5, Loss: 0.27110835909843445\n",
      "Epoch 7, Loss: 0.05866241827607155\n",
      "Epoch 4, Loss: 0.011120612733066082\n",
      "Epoch 8, Loss: 0.01138901337981224\n",
      "Epoch 6, Loss: 0.1807652711868286\n",
      "Epoch 9, Loss: 0.016045914962887764\n",
      "Epoch 4, Loss: 0.29026150703430176\n",
      "Epoch 5, Loss: 0.08903011679649353\n",
      "Epoch 7, Loss: 0.05161866918206215\n",
      "Epoch 10, Loss: 0.04513949528336525\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.28880243899487146, feed_forward_dim=1024, head_dim=16, lr=0.0005970471766984318, num_heads=4, num_layers=2; total time=   0.5s\n",
      "Epoch 8, Loss: 0.012791105546057224\n",
      "Epoch 6, Loss: 0.13824400305747986\n",
      "Epoch 5, Loss: 0.09184765815734863\n",
      "Epoch 9, Loss: 0.05842582508921623\n",
      "Epoch 7, Loss: 0.08383801579475403\n",
      "Epoch 6, Loss: 0.03240049630403519\n",
      "Epoch 10, Loss: 0.10414575785398483\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.28880243899487146, feed_forward_dim=1024, head_dim=16, lr=0.0005970471766984318, num_heads=4, num_layers=2; total time=   0.6s\n",
      "Epoch 8, Loss: 0.021532636135816574\n",
      "Epoch 7, Loss: 0.08993516117334366\n",
      "Epoch 9, Loss: 0.015151254832744598\n",
      "Epoch 8, Loss: 0.14314424991607666\n",
      "Epoch 10, Loss: 0.049958210438489914\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.28880243899487146, feed_forward_dim=1024, head_dim=16, lr=0.0005970471766984318, num_heads=4, num_layers=2; total time=   0.8s\n",
      "Epoch 9, Loss: 0.13332711160182953\n",
      "Epoch 10, Loss: 0.08151373267173767\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.28880243899487146, feed_forward_dim=1024, head_dim=16, lr=0.0005970471766984318, num_heads=4, num_layers=2; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.19222740828990936\n",
      "Epoch 1, Loss: 0.12352640181779861\n",
      "Epoch 2, Loss: 0.16188666224479675\n",
      "Epoch 3, Loss: 0.148978590965271\n",
      "Epoch 2, Loss: 0.11307988315820694\n",
      "Epoch 4, Loss: 0.13981109857559204\n",
      "Epoch 1, Loss: 0.2974560558795929\n",
      "Epoch 1, Loss: 0.09828154742717743\n",
      "Epoch 5, Loss: 0.13564975559711456\n",
      "Epoch 3, Loss: 0.10611196607351303\n",
      "Epoch 6, Loss: 0.1308513730764389\n",
      "Epoch 1, Loss: 0.165074422955513\n",
      "Epoch 7, Loss: 0.12945492565631866\n",
      "Epoch 4, Loss: 0.09359275549650192\n",
      "Epoch 2, Loss: 0.2367224395275116\n",
      "Epoch 8, Loss: 0.12210994213819504\n",
      "Epoch 9, Loss: 0.11576171219348907\n",
      "Epoch 5, Loss: 0.08514390140771866\n",
      "Epoch 2, Loss: 0.06434127688407898\n",
      "Epoch 10, Loss: 0.10872658342123032\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=4, num_layers=2; total time=   0.3s\n",
      "Epoch 3, Loss: 0.18538235127925873\n",
      "Epoch 6, Loss: 0.07743943482637405\n",
      "Epoch 2, Loss: 0.13805899024009705\n",
      "Epoch 7, Loss: 0.07059396803379059\n",
      "Epoch 3, Loss: 0.0454549714922905\n",
      "Epoch 4, Loss: 0.15055342018604279\n",
      "Epoch 8, Loss: 0.06324958056211472\n",
      "Epoch 3, Loss: 0.12243282049894333\n",
      "Epoch 5, Loss: 0.12524521350860596\n",
      "Epoch 9, Loss: 0.056099630892276764\n",
      "Epoch 4, Loss: 0.04114721342921257\n",
      "Epoch 10, Loss: 0.049475833773612976\n",
      "Epoch 6, Loss: 0.10845697671175003\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=4, num_layers=2; total time=   0.4s\n",
      "Epoch 5, Loss: 0.04246557876467705\n",
      "Epoch 4, Loss: 0.11532587558031082\n",
      "Epoch 7, Loss: 0.10236334800720215\n",
      "Epoch 8, Loss: 0.10037398338317871\n",
      "Epoch 6, Loss: 0.048070162534713745\n",
      "Epoch 5, Loss: 0.11108388006687164\n",
      "Epoch 9, Loss: 0.10071173310279846\n",
      "Epoch 7, Loss: 0.047999586910009384\n",
      "Epoch 10, Loss: 0.10061810165643692\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=4, num_layers=2; total time=   0.6s\n",
      "Epoch 6, Loss: 0.10648559033870697\n",
      "Epoch 8, Loss: 0.044630590826272964\n",
      "Epoch 9, Loss: 0.039937518537044525\n",
      "Epoch 7, Loss: 0.10095366090536118\n",
      "Epoch 10, Loss: 0.03483331575989723\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=4, num_layers=2; total time=   0.8s\n",
      "Epoch 8, Loss: 0.09302407503128052\n",
      "Epoch 9, Loss: 0.08692707121372223\n",
      "Epoch 10, Loss: 0.07825178653001785\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=5e-05, num_heads=4, num_layers=2; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 1.2137378454208374\n",
      "Epoch 2, Loss: 13.21165943145752\n",
      "Epoch 1, Loss: 2.5585825443267822\n",
      "Epoch 3, Loss: 3.1177165508270264\n",
      "Epoch 1, Loss: 2.209415912628174\n",
      "Epoch 4, Loss: 0.1246061697602272\n",
      "Epoch 2, Loss: 8.790726661682129\n",
      "Epoch 5, Loss: 0.5979883074760437\n",
      "Epoch 1, Loss: 0.02982374094426632\n",
      "Epoch 6, Loss: 0.9372169375419617\n",
      "Epoch 3, Loss: 2.859703540802002\n",
      "Epoch 2, Loss: 8.262163162231445\n",
      "Epoch 1, Loss: 0.67961186170578\n",
      "Epoch 7, Loss: 0.5881335735321045\n",
      "Epoch 8, Loss: 0.18703851103782654\n",
      "Epoch 2, Loss: 15.468570709228516\n",
      "Epoch 4, Loss: 0.18603532016277313\n",
      "Epoch 3, Loss: 1.8405232429504395\n",
      "Epoch 9, Loss: 0.079442597925663\n",
      "Epoch 10, Loss: 0.20725944638252258\n",
      "Epoch 5, Loss: 0.450376957654953\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.10761245511382163, feed_forward_dim=512, head_dim=32, lr=0.004999999999999999, num_heads=4, num_layers=1; total time=   0.3s\n",
      "Epoch 2, Loss: 8.051634788513184\n",
      "Epoch 4, Loss: 0.08357347548007965\n",
      "Epoch 3, Loss: 2.887845516204834\n",
      "Epoch 6, Loss: 0.6850162148475647\n",
      "Epoch 7, Loss: 0.3720865845680237\n",
      "Epoch 5, Loss: 0.7410337924957275\n",
      "Epoch 4, Loss: 0.11430568993091583\n",
      "Epoch 8, Loss: 0.10852578282356262\n",
      "Epoch 3, Loss: 1.7303274869918823\n",
      "Epoch 6, Loss: 0.44127851724624634\n",
      "Epoch 9, Loss: 0.08074852079153061\n",
      "Epoch 5, Loss: 0.8872473239898682\n",
      "Epoch 7, Loss: 0.1013219803571701\n",
      "Epoch 10, Loss: 0.16837762296199799\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.10761245511382163, feed_forward_dim=512, head_dim=32, lr=0.004999999999999999, num_heads=4, num_layers=1; total time=   0.4s\n",
      "Epoch 4, Loss: 0.068446584045887\n",
      "Epoch 8, Loss: 0.08744106441736221\n",
      "Epoch 6, Loss: 0.5795955657958984\n",
      "Epoch 5, Loss: 0.6945437788963318\n",
      "Epoch 9, Loss: 0.18974712491035461\n",
      "Epoch 7, Loss: 0.17224954068660736\n",
      "Epoch 10, Loss: 0.2119215577840805\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.10761245511382163, feed_forward_dim=512, head_dim=32, lr=0.004999999999999999, num_heads=4, num_layers=1; total time=   0.6s\n",
      "Epoch 6, Loss: 0.702930748462677\n",
      "Epoch 8, Loss: 0.05268580839037895\n",
      "Epoch 7, Loss: 0.37738895416259766\n",
      "Epoch 9, Loss: 0.12348654121160507\n",
      "Epoch 10, Loss: 0.17687159776687622\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.10761245511382163, feed_forward_dim=512, head_dim=32, lr=0.004999999999999999, num_heads=4, num_layers=1; total time=   0.8s\n",
      "Epoch 8, Loss: 0.1321602761745453\n",
      "Epoch 9, Loss: 0.056622061878442764\n",
      "Epoch 10, Loss: 0.09390336275100708\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.10761245511382163, feed_forward_dim=512, head_dim=32, lr=0.004999999999999999, num_heads=4, num_layers=1; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.5555734634399414\n",
      "Epoch 2, Loss: 0.42425358295440674\n",
      "Epoch 1, Loss: 1.5855265855789185\n",
      "Epoch 3, Loss: 0.31894999742507935\n",
      "Epoch 4, Loss: 0.23349478840827942\n",
      "Epoch 2, Loss: 1.3589602708816528\n",
      "Epoch 1, Loss: 0.3549081087112427\n",
      "Epoch 5, Loss: 0.1771528124809265\n",
      "Epoch 1, Loss: 1.45350980758667\n",
      "Epoch 1, Loss: 0.676944375038147\n",
      "Epoch 6, Loss: 0.12524352967739105\n",
      "Epoch 3, Loss: 1.1594992876052856\n",
      "Epoch 7, Loss: 0.09871494024991989\n",
      "Epoch 2, Loss: 0.2717963457107544\n",
      "Epoch 8, Loss: 0.08643732219934464\n",
      "Epoch 2, Loss: 0.5221824049949646\n",
      "Epoch 4, Loss: 0.9711709022521973\n",
      "Epoch 9, Loss: 0.08317544311285019\n",
      "Epoch 2, Loss: 1.2224282026290894\n",
      "Epoch 3, Loss: 0.20568111538887024\n",
      "Epoch 10, Loss: 0.08642749488353729\n",
      "[CV] END activation=gelu, batch_size=32, dropout_rate=0.14102675116407126, feed_forward_dim=1024, head_dim=16, lr=5.524865945440373e-05, num_heads=2, num_layers=2; total time=   0.3s\n",
      "Epoch 5, Loss: 0.8048729300498962\n",
      "Epoch 3, Loss: 0.4011884331703186\n",
      "Epoch 6, Loss: 0.6679391860961914\n",
      "Epoch 4, Loss: 0.1558264195919037\n",
      "Epoch 3, Loss: 1.0123847723007202\n",
      "Epoch 7, Loss: 0.5319035649299622\n",
      "Epoch 5, Loss: 0.12324430048465729\n",
      "Epoch 4, Loss: 0.29666033387184143\n",
      "Epoch 8, Loss: 0.4207476079463959\n",
      "Epoch 6, Loss: 0.10686757415533066\n",
      "Epoch 9, Loss: 0.3393048644065857\n",
      "Epoch 4, Loss: 0.8268100619316101\n",
      "Epoch 5, Loss: 0.21033161878585815\n",
      "Epoch 7, Loss: 0.10354902595281601\n",
      "Epoch 10, Loss: 0.2621561288833618\n",
      "[CV] END activation=gelu, batch_size=32, dropout_rate=0.14102675116407126, feed_forward_dim=1024, head_dim=16, lr=5.524865945440373e-05, num_heads=2, num_layers=2; total time=   0.6s\n",
      "Epoch 6, Loss: 0.14466246962547302\n",
      "Epoch 5, Loss: 0.6601139307022095\n",
      "Epoch 8, Loss: 0.10584630817174911\n",
      "Epoch 7, Loss: 0.09726395457983017\n",
      "Epoch 9, Loss: 0.10861499607563019\n",
      "Epoch 6, Loss: 0.5309174656867981\n",
      "Epoch 10, Loss: 0.11399809271097183\n",
      "[CV] END activation=gelu, batch_size=32, dropout_rate=0.14102675116407126, feed_forward_dim=1024, head_dim=16, lr=5.524865945440373e-05, num_heads=2, num_layers=2; total time=   0.7s\n",
      "Epoch 8, Loss: 0.06648162007331848\n",
      "Epoch 7, Loss: 0.4159344434738159\n",
      "Epoch 9, Loss: 0.05041542276740074\n",
      "Epoch 10, Loss: 0.04553505405783653\n",
      "Epoch 8, Loss: 0.324923574924469\n",
      "[CV] END activation=gelu, batch_size=32, dropout_rate=0.14102675116407126, feed_forward_dim=1024, head_dim=16, lr=5.524865945440373e-05, num_heads=2, num_layers=2; total time=   0.8s\n",
      "Epoch 9, Loss: 0.2560890018939972\n",
      "Epoch 10, Loss: 0.20478783547878265\n",
      "[CV] END activation=gelu, batch_size=32, dropout_rate=0.14102675116407126, feed_forward_dim=1024, head_dim=16, lr=5.524865945440373e-05, num_heads=2, num_layers=2; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.06797321140766144\n",
      "Epoch 2, Loss: 0.05410945788025856\n",
      "Epoch 1, Loss: 0.04548487812280655\n",
      "Epoch 3, Loss: 0.050888124853372574\n",
      "Epoch 4, Loss: 0.04038519039750099\n",
      "Epoch 1, Loss: 1.7964895963668823\n",
      "Epoch 5, Loss: 0.03160875290632248\n",
      "Epoch 1, Loss: 0.5561795234680176\n",
      "Epoch 2, Loss: 0.0341377817094326\n",
      "Epoch 6, Loss: 0.02241232618689537\n",
      "Epoch 7, Loss: 0.02188461646437645\n",
      "Epoch 1, Loss: 0.02435298077762127\n",
      "Epoch 3, Loss: 0.028144285082817078\n",
      "Epoch 8, Loss: 0.017519904300570488\n",
      "Epoch 2, Loss: 0.35669219493865967\n",
      "Epoch 9, Loss: 0.012682677246630192\n",
      "Epoch 2, Loss: 1.4968352317810059\n",
      "Epoch 4, Loss: 0.019445162266492844\n",
      "Epoch 10, Loss: 0.010339483618736267\n",
      "[CV] END activation=gelu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=8.034273919705689e-05, num_heads=4, num_layers=3; total time=   0.3s\n",
      "Epoch 5, Loss: 0.017244284972548485\n",
      "Epoch 3, Loss: 0.2101166844367981\n",
      "Epoch 2, Loss: 0.018881555646657944\n",
      "Epoch 3, Loss: 1.2206114530563354\n",
      "Epoch 6, Loss: 0.017007088288664818\n",
      "Epoch 4, Loss: 0.11173228174448013\n",
      "Epoch 7, Loss: 0.016457434743642807\n",
      "Epoch 4, Loss: 0.9795085787773132\n",
      "Epoch 5, Loss: 0.0664532482624054\n",
      "Epoch 3, Loss: 0.020138313993811607\n",
      "Epoch 8, Loss: 0.01524319313466549\n",
      "Epoch 9, Loss: 0.016989964991807938\n",
      "Epoch 6, Loss: 0.05740285664796829\n",
      "Epoch 5, Loss: 0.7626635432243347\n",
      "Epoch 10, Loss: 0.016561485826969147\n",
      "[CV] END activation=gelu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=8.034273919705689e-05, num_heads=4, num_layers=3; total time=   0.5s\n",
      "Epoch 4, Loss: 0.015042244456708431\n",
      "Epoch 7, Loss: 0.07042261958122253\n",
      "Epoch 6, Loss: 0.5775430798530579\n",
      "Epoch 8, Loss: 0.09487497806549072\n",
      "Epoch 5, Loss: 0.01139549445360899\n",
      "Epoch 7, Loss: 0.42669057846069336\n",
      "Epoch 9, Loss: 0.11736948788166046\n",
      "Epoch 6, Loss: 0.011590243317186832\n",
      "Epoch 10, Loss: 0.1296113282442093\n",
      "[CV] END activation=gelu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=8.034273919705689e-05, num_heads=4, num_layers=3; total time=   0.6s\n",
      "Epoch 8, Loss: 0.3046875298023224\n",
      "Epoch 7, Loss: 0.011232699267566204\n",
      "Epoch 9, Loss: 0.20112694799900055\n",
      "Epoch 10, Loss: 0.13032051920890808\n",
      "Epoch 8, Loss: 0.008989228866994381\n",
      "[CV] END activation=gelu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=8.034273919705689e-05, num_heads=4, num_layers=3; total time=   0.8s\n",
      "Epoch 9, Loss: 0.0070917620323598385\n",
      "Epoch 10, Loss: 0.00751427561044693\n",
      "[CV] END activation=gelu, batch_size=32, dropout_rate=0.1, feed_forward_dim=128, head_dim=32, lr=8.034273919705689e-05, num_heads=4, num_layers=3; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.8428280353546143\n",
      "Epoch 2, Loss: 15.499711990356445\n",
      "Epoch 3, Loss: 4.15145206451416\n",
      "Epoch 1, Loss: 0.3769967555999756\n",
      "Epoch 4, Loss: 0.1379421204328537\n",
      "Epoch 1, Loss: 0.12370907515287399\n",
      "Epoch 5, Loss: 0.7896358966827393\n",
      "Epoch 2, Loss: 8.215422630310059\n",
      "Epoch 1, Loss: 0.013438611291348934\n",
      "Epoch 6, Loss: 0.9040001034736633\n",
      "Epoch 3, Loss: 1.6736671924591064\n",
      "Epoch 7, Loss: 0.43826043605804443\n",
      "Epoch 1, Loss: 0.09688051789999008\n",
      "Epoch 2, Loss: 12.374032020568848\n",
      "Epoch 8, Loss: 0.12279883772134781\n",
      "Epoch 4, Loss: 0.0834718868136406\n",
      "Epoch 9, Loss: 0.09454615414142609\n",
      "Epoch 2, Loss: 12.41135311126709\n",
      "Epoch 10, Loss: 0.20422610640525818\n",
      "[CV] END activation=gelu, batch_size=32, dropout_rate=0.4, feed_forward_dim=256, head_dim=32, lr=0.004999999999999999, num_heads=4, num_layers=1; total time=   0.2s\n",
      "Epoch 3, Loss: 3.0821926593780518\n",
      "Epoch 5, Loss: 0.7624405026435852\n",
      "Epoch 2, Loss: 14.68187427520752\n",
      "Epoch 6, Loss: 0.6522451043128967\n",
      "Epoch 3, Loss: 2.6642327308654785\n",
      "Epoch 4, Loss: 0.11378529667854309\n",
      "Epoch 7, Loss: 0.2659139931201935\n",
      "Epoch 5, Loss: 1.1101298332214355\n",
      "Epoch 3, Loss: 3.0959243774414062\n",
      "Epoch 8, Loss: 0.07741487771272659\n",
      "Epoch 4, Loss: 0.1462792307138443\n",
      "Epoch 9, Loss: 0.09505125135183334\n",
      "Epoch 6, Loss: 0.6102243065834045\n",
      "Epoch 10, Loss: 0.1641995757818222\n",
      "Epoch 5, Loss: 0.8337245583534241\n",
      "Epoch 4, Loss: 0.10165077447891235\n",
      "[CV] END activation=gelu, batch_size=32, dropout_rate=0.4, feed_forward_dim=256, head_dim=32, lr=0.004999999999999999, num_heads=4, num_layers=1; total time=   0.4s\n",
      "Epoch 7, Loss: 0.16611623764038086\n",
      "Epoch 6, Loss: 0.5100332498550415\n",
      "Epoch 8, Loss: 0.06688547879457474\n",
      "Epoch 5, Loss: 1.0554800033569336\n",
      "Epoch 7, Loss: 0.17332936823368073\n",
      "Epoch 9, Loss: 0.13919499516487122\n",
      "Epoch 6, Loss: 0.7132418751716614\n",
      "Epoch 10, Loss: 0.18390506505966187\n",
      "[CV] END activation=gelu, batch_size=32, dropout_rate=0.4, feed_forward_dim=256, head_dim=32, lr=0.004999999999999999, num_heads=4, num_layers=1; total time=   0.6s\n",
      "Epoch 8, Loss: 0.05615788325667381\n",
      "Epoch 7, Loss: 0.1945459097623825\n",
      "Epoch 9, Loss: 0.08226893097162247\n",
      "Epoch 8, Loss: 0.06060754135251045\n",
      "Epoch 10, Loss: 0.12875932455062866\n",
      "[CV] END activation=gelu, batch_size=32, dropout_rate=0.4, feed_forward_dim=256, head_dim=32, lr=0.004999999999999999, num_heads=4, num_layers=1; total time=   0.7s\n",
      "Epoch 9, Loss: 0.1879757046699524\n",
      "Epoch 10, Loss: 0.250724196434021\n",
      "[CV] END activation=gelu, batch_size=32, dropout_rate=0.4, feed_forward_dim=256, head_dim=32, lr=0.004999999999999999, num_heads=4, num_layers=1; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.6052567958831787\n",
      "Epoch 2, Loss: 0.4933895170688629\n",
      "Epoch 1, Loss: 2.9538917541503906\n",
      "Epoch 3, Loss: 0.39103245735168457\n",
      "Epoch 4, Loss: 0.29871508479118347\n",
      "Epoch 2, Loss: 2.6647708415985107\n",
      "Epoch 1, Loss: 0.20662227272987366\n",
      "Epoch 5, Loss: 0.22732698917388916\n",
      "Epoch 3, Loss: 2.4091131687164307\n",
      "Epoch 6, Loss: 0.1564912050962448\n",
      "Epoch 1, Loss: 0.8941654562950134\n",
      "Epoch 7, Loss: 0.10980235785245895\n",
      "Epoch 2, Loss: 0.13604749739170074\n",
      "Epoch 4, Loss: 2.1528751850128174\n",
      "Epoch 8, Loss: 0.07274636626243591\n",
      "Epoch 1, Loss: 0.6473488807678223\n",
      "Epoch 9, Loss: 0.04841961711645126\n",
      "Epoch 5, Loss: 1.9260746240615845\n",
      "Epoch 3, Loss: 0.08057869225740433\n",
      "Epoch 10, Loss: 0.034243132919073105\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.3024121273880905, feed_forward_dim=128, head_dim=16, lr=5e-05, num_heads=4, num_layers=3; total time=   0.3s\n",
      "Epoch 2, Loss: 0.729607343673706\n",
      "Epoch 6, Loss: 1.6982685327529907\n",
      "Epoch 4, Loss: 0.04622296243906021\n",
      "Epoch 2, Loss: 0.5290313959121704\n",
      "Epoch 7, Loss: 1.494208574295044\n",
      "Epoch 3, Loss: 0.5936833620071411\n",
      "Epoch 5, Loss: 0.030046027153730392\n",
      "Epoch 8, Loss: 1.2921876907348633\n",
      "Epoch 3, Loss: 0.4275673031806946\n",
      "Epoch 9, Loss: 1.124054193496704\n",
      "Epoch 6, Loss: 0.027352454140782356\n",
      "Epoch 4, Loss: 0.47015392780303955\n",
      "Epoch 10, Loss: 0.9526838660240173\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.3024121273880905, feed_forward_dim=128, head_dim=16, lr=5e-05, num_heads=4, num_layers=3; total time=   0.5s\n",
      "Epoch 7, Loss: 0.03218039125204086\n",
      "Epoch 5, Loss: 0.3616015613079071\n",
      "Epoch 4, Loss: 0.33682486414909363\n",
      "Epoch 8, Loss: 0.04075029119849205\n",
      "Epoch 6, Loss: 0.28027990460395813\n",
      "Epoch 9, Loss: 0.0483064278960228\n",
      "Epoch 5, Loss: 0.25562888383865356\n",
      "Epoch 7, Loss: 0.21028025448322296\n",
      "Epoch 10, Loss: 0.0496976375579834\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.3024121273880905, feed_forward_dim=128, head_dim=16, lr=5e-05, num_heads=4, num_layers=3; total time=   0.6s\n",
      "Epoch 6, Loss: 0.19613289833068848\n",
      "Epoch 8, Loss: 0.15986523032188416\n",
      "Epoch 7, Loss: 0.14610299468040466\n",
      "Epoch 9, Loss: 0.12075542658567429\n",
      "Epoch 10, Loss: 0.0947098657488823\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.3024121273880905, feed_forward_dim=128, head_dim=16, lr=5e-05, num_heads=4, num_layers=3; total time=   0.8s\n",
      "Epoch 8, Loss: 0.10767554491758347\n",
      "Epoch 9, Loss: 0.08189721405506134\n",
      "Epoch 10, Loss: 0.06505867093801498\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.3024121273880905, feed_forward_dim=128, head_dim=16, lr=5e-05, num_heads=4, num_layers=3; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.017305361106991768\n",
      "Epoch 1, Loss: 0.10155569016933441\n",
      "Epoch 2, Loss: 0.34914276003837585\n",
      "Epoch 1, Loss: 0.07182589173316956\n",
      "Epoch 1, Loss: 0.3513852655887604\n",
      "Epoch 3, Loss: 0.02871195413172245\n",
      "Epoch 2, Loss: 0.18068772554397583\n",
      "Epoch 4, Loss: 0.09246784448623657\n",
      "Epoch 2, Loss: 0.3164423704147339\n",
      "Epoch 3, Loss: 0.08597705513238907\n",
      "Epoch 2, Loss: 0.09372001141309738\n",
      "Epoch 5, Loss: 0.17640364170074463\n",
      "Epoch 6, Loss: 0.10643087327480316\n",
      "Epoch 4, Loss: 0.00800374150276184\n",
      "Epoch 3, Loss: 0.06076964735984802\n",
      "Epoch 7, Loss: 0.025622189044952393\n",
      "Epoch 3, Loss: 0.22152411937713623\n",
      "Epoch 5, Loss: 0.05640765279531479\n",
      "Epoch 8, Loss: 0.011292223818600178\n",
      "Epoch 4, Loss: 0.04668794944882393\n",
      "Epoch 9, Loss: 0.04890786483883858\n",
      "Epoch 6, Loss: 0.07818876206874847\n",
      "Epoch 4, Loss: 0.16589738428592682\n",
      "Epoch 10, Loss: 0.0776168629527092\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.00039462917284481563, num_heads=2, num_layers=2; total time=   0.5s\n",
      "Epoch 5, Loss: 0.1336372196674347\n",
      "Epoch 7, Loss: 0.04014846682548523\n",
      "Epoch 8, Loss: 0.007270870730280876\n",
      "Epoch 6, Loss: 0.10633601248264313\n",
      "Epoch 5, Loss: 0.06537137180566788\n",
      "Epoch 9, Loss: 0.015513259917497635\n",
      "Epoch 7, Loss: 0.03513022139668465\n",
      "Epoch 6, Loss: 0.031371794641017914\n",
      "Epoch 10, Loss: 0.03833218663930893\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.00039462917284481563, num_heads=2, num_layers=2; total time=   0.6s\n",
      "Epoch 8, Loss: 0.010772621259093285\n",
      "Epoch 7, Loss: 0.06293538957834244\n",
      "Epoch 9, Loss: 0.03863447159528732\n",
      "Epoch 8, Loss: 0.09023547917604446\n",
      "Epoch 10, Loss: 0.06414711475372314\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.00039462917284481563, num_heads=2, num_layers=2; total time=   0.8s\n",
      "Epoch 9, Loss: 0.07064790278673172\n",
      "Epoch 10, Loss: 0.034257739782333374\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.00039462917284481563, num_heads=2, num_layers=2; total time=   0.9s\n",
      "Epoch 1, Loss: 0.18255089223384857\n",
      "Epoch 2, Loss: 0.18243408203125\n",
      "Epoch 3, Loss: 0.1286398023366928\n",
      "Epoch 4, Loss: 0.03847876191139221\n",
      "Epoch 5, Loss: 0.048676226288080215\n",
      "Epoch 6, Loss: 0.07115714251995087\n",
      "Epoch 7, Loss: 0.04387123882770538\n",
      "Epoch 8, Loss: 0.012302096001803875\n",
      "Epoch 9, Loss: 0.015187270939350128\n",
      "Epoch 10, Loss: 0.03600362688302994\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.00039462917284481563, num_heads=2, num_layers=2; total time=   0.7s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.21326704323291779\n",
      "Epoch 2, Loss: 0.17036478221416473\n",
      "Epoch 1, Loss: 0.18101167678833008\n",
      "Epoch 3, Loss: 0.14516054093837738\n",
      "Epoch 4, Loss: 0.13360920548439026\n",
      "Epoch 2, Loss: 0.150190532207489\n",
      "Epoch 1, Loss: 0.6473017930984497\n",
      "Epoch 1, Loss: 0.14925630390644073\n",
      "Epoch 5, Loss: 0.12983635067939758\n",
      "Epoch 3, Loss: 0.13336791098117828\n",
      "Epoch 6, Loss: 0.12751905620098114\n",
      "Epoch 1, Loss: 0.16473878920078278\n",
      "Epoch 2, Loss: 0.5304296016693115\n",
      "Epoch 7, Loss: 0.12330371141433716\n",
      "Epoch 4, Loss: 0.12420988827943802\n",
      "Epoch 2, Loss: 0.12470106035470963\n",
      "Epoch 8, Loss: 0.11791200190782547\n",
      "Epoch 5, Loss: 0.11881276965141296\n",
      "Epoch 9, Loss: 0.10958517342805862\n",
      "Epoch 3, Loss: 0.42212438583374023\n",
      "Epoch 10, Loss: 0.10153485834598541\n",
      "Epoch 2, Loss: 0.14943893253803253\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   0.3s\n",
      "Epoch 6, Loss: 0.11585172265768051\n",
      "Epoch 3, Loss: 0.11285489797592163\n",
      "Epoch 4, Loss: 0.3267105221748352\n",
      "Epoch 7, Loss: 0.10742047429084778\n",
      "Epoch 3, Loss: 0.13866238296031952\n",
      "Epoch 4, Loss: 0.10507263243198395\n",
      "Epoch 8, Loss: 0.09752926230430603\n",
      "Epoch 5, Loss: 0.24284540116786957\n",
      "Epoch 9, Loss: 0.09033892303705215\n",
      "Epoch 6, Loss: 0.17552794516086578\n",
      "Epoch 5, Loss: 0.10267747938632965\n",
      "Epoch 10, Loss: 0.0823449045419693\n",
      "Epoch 4, Loss: 0.12716606259346008\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   0.4s\n",
      "Epoch 7, Loss: 0.12358177453279495\n",
      "Epoch 6, Loss: 0.09703175723552704\n",
      "Epoch 8, Loss: 0.07759834825992584\n",
      "Epoch 5, Loss: 0.11309754103422165\n",
      "Epoch 7, Loss: 0.09135614335536957\n",
      "Epoch 9, Loss: 0.04953240603208542\n",
      "Epoch 6, Loss: 0.10309243202209473\n",
      "Epoch 10, Loss: 0.030011603608727455\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   0.6s\n",
      "Epoch 8, Loss: 0.08415836840867996\n",
      "Epoch 9, Loss: 0.0754503607749939\n",
      "Epoch 7, Loss: 0.09415367990732193\n",
      "Epoch 10, Loss: 0.06937041878700256\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   0.8s\n",
      "Epoch 8, Loss: 0.08424747735261917\n",
      "Epoch 9, Loss: 0.0762922391295433\n",
      "Epoch 10, Loss: 0.06810128688812256\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=5e-05, num_heads=2, num_layers=2; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.15451988577842712\n",
      "Epoch 2, Loss: 9.526860237121582\n",
      "Epoch 1, Loss: 0.06473439186811447\n",
      "Epoch 3, Loss: 0.7993950247764587\n",
      "Epoch 4, Loss: 1.497564435005188\n",
      "Epoch 1, Loss: 0.1666150838136673\n",
      "Epoch 2, Loss: 12.055468559265137\n",
      "Epoch 1, Loss: 0.19577588140964508\n",
      "Epoch 5, Loss: 0.7466101050376892\n",
      "Epoch 1, Loss: 0.25339001417160034\n",
      "Epoch 6, Loss: 0.16002413630485535\n",
      "Epoch 3, Loss: 0.5332499742507935\n",
      "Epoch 2, Loss: 14.812333106994629\n",
      "Epoch 7, Loss: 0.07050251960754395\n",
      "Epoch 2, Loss: 8.11455249786377\n",
      "Epoch 4, Loss: 4.677772521972656\n",
      "Epoch 8, Loss: 0.16388849914073944\n",
      "Epoch 9, Loss: 0.1979287713766098\n",
      "Epoch 2, Loss: 14.148856163024902\n",
      "Epoch 3, Loss: 2.640697717666626\n",
      "Epoch 5, Loss: 1.036644697189331\n",
      "Epoch 10, Loss: 0.15896418690681458\n",
      "[CV] END activation=gelu, batch_size=16, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.004999999999999999, num_heads=4, num_layers=2; total time=   0.3s\n",
      "Epoch 3, Loss: 1.4944010972976685\n",
      "Epoch 6, Loss: 0.08070466667413712\n",
      "Epoch 4, Loss: 0.2865312397480011\n",
      "Epoch 7, Loss: 0.1251535266637802\n",
      "Epoch 3, Loss: 3.0958549976348877\n",
      "Epoch 4, Loss: 0.09687194973230362\n",
      "Epoch 5, Loss: 1.0924263000488281\n",
      "Epoch 8, Loss: 0.2591809332370758\n",
      "Epoch 9, Loss: 0.2516433000564575\n",
      "Epoch 6, Loss: 0.5299742221832275\n",
      "Epoch 4, Loss: 0.04989102482795715\n",
      "Epoch 5, Loss: 0.6958224177360535\n",
      "Epoch 10, Loss: 0.16143175959587097\n",
      "[CV] END activation=gelu, batch_size=16, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.004999999999999999, num_heads=4, num_layers=2; total time=   0.4s\n",
      "Epoch 7, Loss: 0.0956593006849289\n",
      "Epoch 6, Loss: 0.5081720352172852\n",
      "Epoch 5, Loss: 0.7750908732414246\n",
      "Epoch 8, Loss: 0.12858249247074127\n",
      "Epoch 7, Loss: 0.19037944078445435\n",
      "Epoch 9, Loss: 0.26279690861701965\n",
      "Epoch 6, Loss: 0.802158772945404\n",
      "Epoch 10, Loss: 0.23076346516609192\n",
      "Epoch 8, Loss: 0.05645240843296051\n",
      "[CV] END activation=gelu, batch_size=16, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.004999999999999999, num_heads=4, num_layers=2; total time=   0.6s\n",
      "Epoch 7, Loss: 0.3640436828136444\n",
      "Epoch 9, Loss: 0.07780719548463821\n",
      "Epoch 10, Loss: 0.1345629245042801\n",
      "Epoch 8, Loss: 0.08358927071094513\n",
      "[CV] END activation=gelu, batch_size=16, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.004999999999999999, num_heads=4, num_layers=2; total time=   0.7s\n",
      "Epoch 9, Loss: 0.08273150771856308\n",
      "Epoch 10, Loss: 0.17787550389766693\n",
      "[CV] END activation=gelu, batch_size=16, dropout_rate=0.1, feed_forward_dim=1024, head_dim=32, lr=0.004999999999999999, num_heads=4, num_layers=2; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 2.0993056297302246\n",
      "Epoch 2, Loss: 1.8863767385482788\n",
      "Epoch 1, Loss: 0.07303032279014587\n",
      "Epoch 3, Loss: 1.6594111919403076\n",
      "Epoch 4, Loss: 1.4423118829727173\n",
      "Epoch 1, Loss: 0.8205986618995667\n",
      "Epoch 2, Loss: 0.06558747589588165\n",
      "Epoch 5, Loss: 1.2527862787246704\n",
      "Epoch 1, Loss: 0.21209728717803955\n",
      "Epoch 6, Loss: 1.0784015655517578\n",
      "Epoch 1, Loss: 0.02935921959578991\n",
      "Epoch 2, Loss: 0.6555547118186951\n",
      "Epoch 3, Loss: 0.05466049909591675\n",
      "Epoch 7, Loss: 0.911723792552948\n",
      "Epoch 8, Loss: 0.7651422023773193\n",
      "Epoch 2, Loss: 0.16537678241729736\n",
      "Epoch 4, Loss: 0.046589192003011703\n",
      "Epoch 9, Loss: 0.6130834221839905\n",
      "Epoch 3, Loss: 0.5148744583129883\n",
      "Epoch 10, Loss: 0.4934050440788269\n",
      "Epoch 2, Loss: 0.02060060016810894\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.12687498471417072, feed_forward_dim=512, head_dim=8, lr=5.047968079047605e-05, num_heads=2, num_layers=2; total time=   0.2s\n",
      "Epoch 5, Loss: 0.03788447752594948\n",
      "Epoch 3, Loss: 0.12927135825157166Epoch 4, Loss: 0.39319726824760437\n",
      "\n",
      "Epoch 6, Loss: 0.032115638256073\n",
      "Epoch 7, Loss: 0.027841471135616302\n",
      "Epoch 5, Loss: 0.28992995619773865\n",
      "Epoch 3, Loss: 0.020831521600484848\n",
      "Epoch 4, Loss: 0.10298167169094086\n",
      "Epoch 8, Loss: 0.023826315999031067\n",
      "Epoch 6, Loss: 0.20377181470394135\n",
      "Epoch 9, Loss: 0.020788373425602913\n",
      "Epoch 5, Loss: 0.08699379861354828\n",
      "Epoch 4, Loss: 0.02023587003350258\n",
      "Epoch 10, Loss: 0.019643262028694153\n",
      "Epoch 7, Loss: 0.1437758207321167\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.12687498471417072, feed_forward_dim=512, head_dim=8, lr=5.047968079047605e-05, num_heads=2, num_layers=2; total time=   0.4s\n",
      "Epoch 8, Loss: 0.10220631957054138\n",
      "Epoch 6, Loss: 0.07804127037525177\n",
      "Epoch 5, Loss: 0.01948484405875206\n",
      "Epoch 9, Loss: 0.07265199720859528\n",
      "Epoch 7, Loss: 0.07476861774921417\n",
      "Epoch 10, Loss: 0.058975499123334885\n",
      "Epoch 6, Loss: 0.016078073531389236\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.12687498471417072, feed_forward_dim=512, head_dim=8, lr=5.047968079047605e-05, num_heads=2, num_layers=2; total time=   0.6s\n",
      "Epoch 8, Loss: 0.07350970059633255\n",
      "Epoch 7, Loss: 0.014020736329257488\n",
      "Epoch 9, Loss: 0.07268591970205307\n",
      "Epoch 10, Loss: 0.07282477617263794\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.12687498471417072, feed_forward_dim=512, head_dim=8, lr=5.047968079047605e-05, num_heads=2, num_layers=2; total time=   0.7s\n",
      "Epoch 8, Loss: 0.012688683345913887\n",
      "Epoch 9, Loss: 0.012528536841273308\n",
      "Epoch 10, Loss: 0.012038961984217167\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.12687498471417072, feed_forward_dim=512, head_dim=8, lr=5.047968079047605e-05, num_heads=2, num_layers=2; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.5260797142982483\n",
      "Epoch 2, Loss: 9.61181640625\n",
      "Epoch 1, Loss: 0.21856684982776642\n",
      "Epoch 3, Loss: 2.2128348350524902\n",
      "Epoch 1, Loss: 0.15428559482097626\n",
      "Epoch 2, Loss: 10.341383934020996\n",
      "Epoch 4, Loss: 0.07165539264678955\n",
      "Epoch 1, Loss: 0.534455418586731\n",
      "Epoch 5, Loss: 0.7664244771003723\n",
      "Epoch 2, Loss: 9.529168128967285\n",
      "Epoch 3, Loss: 2.976358652114868\n",
      "Epoch 1, Loss: 0.6068878769874573\n",
      "Epoch 6, Loss: 0.6253493428230286\n",
      "Epoch 4, Loss: 0.07010804861783981\n",
      "Epoch 7, Loss: 0.2391369789838791\n",
      "Epoch 3, Loss: 0.26067861914634705\n",
      "Epoch 2, Loss: 13.361912727355957\n",
      "Epoch 8, Loss: 0.07708876579999924\n",
      "Epoch 5, Loss: 0.9512183666229248\n",
      "Epoch 9, Loss: 0.0937209203839302\n",
      "Epoch 2, Loss: 11.65424633026123\n",
      "Epoch 4, Loss: 2.3581066131591797\n",
      "Epoch 10, Loss: 0.14334718883037567\n",
      "Epoch 6, Loss: 0.6327198147773743\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.004999999999999999, num_heads=4, num_layers=2; total time=   0.3s\n",
      "Epoch 3, Loss: 2.7747719287872314\n",
      "Epoch 7, Loss: 0.20440100133419037\n",
      "Epoch 5, Loss: 0.8441272974014282\n",
      "Epoch 3, Loss: 2.57710599899292\n",
      "Epoch 8, Loss: 0.06891777366399765\n",
      "Epoch 4, Loss: 0.05112702026963234\n",
      "Epoch 6, Loss: 0.11485596746206284\n",
      "Epoch 9, Loss: 0.11868475377559662\n",
      "Epoch 10, Loss: 0.17398273944854736\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.004999999999999999, num_heads=4, num_layers=2; total time=   0.4s\n",
      "Epoch 7, Loss: 0.0863967090845108\n",
      "Epoch 4, Loss: 0.13293591141700745\n",
      "Epoch 5, Loss: 0.8454857468605042\n",
      "Epoch 8, Loss: 0.22004224359989166\n",
      "Epoch 6, Loss: 0.8099900484085083\n",
      "Epoch 5, Loss: 0.9983816742897034\n",
      "Epoch 9, Loss: 0.24737869203090668\n",
      "Epoch 7, Loss: 0.32571953535079956\n",
      "Epoch 10, Loss: 0.18227726221084595\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.004999999999999999, num_heads=4, num_layers=2; total time=   0.6s\n",
      "Epoch 6, Loss: 0.5316024422645569\n",
      "Epoch 8, Loss: 0.06706679612398148\n",
      "Epoch 7, Loss: 0.14576023817062378\n",
      "Epoch 9, Loss: 0.12606513500213623\n",
      "Epoch 8, Loss: 0.053752124309539795\n",
      "Epoch 10, Loss: 0.22709377110004425\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.004999999999999999, num_heads=4, num_layers=2; total time=   0.7s\n",
      "Epoch 9, Loss: 0.09953023493289948\n",
      "Epoch 10, Loss: 0.142489954829216\n",
      "[CV] END activation=relu, batch_size=16, dropout_rate=0.1, feed_forward_dim=256, head_dim=32, lr=0.004999999999999999, num_heads=4, num_layers=2; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.1384456902742386\n",
      "Epoch 2, Loss: 9.181225776672363\n",
      "Epoch 3, Loss: 0.2891436219215393\n",
      "Epoch 1, Loss: 0.19519361853599548\n",
      "Epoch 4, Loss: 1.4799227714538574\n",
      "Epoch 1, Loss: 0.6206704378128052\n",
      "Epoch 5, Loss: 1.1208312511444092\n",
      "Epoch 2, Loss: 9.233146667480469\n",
      "Epoch 1, Loss: 0.07769835740327835\n",
      "Epoch 6, Loss: 0.31673702597618103\n",
      "Epoch 2, Loss: 8.894636154174805\n",
      "Epoch 1, Loss: 0.04887200519442558\n",
      "Epoch 7, Loss: 0.06491067260503769\n",
      "Epoch 3, Loss: 2.282113790512085\n",
      "Epoch 8, Loss: 0.22436851263046265\n",
      "Epoch 9, Loss: 0.31557029485702515\n",
      "Epoch 2, Loss: 8.691829681396484\n",
      "Epoch 4, Loss: 0.06733709573745728\n",
      "Epoch 3, Loss: 2.5520081520080566\n",
      "Epoch 10, Loss: 0.25198113918304443\n",
      "[CV] END activation=gelu, batch_size=16, dropout_rate=0.14949196862940706, feed_forward_dim=512, head_dim=32, lr=0.0036594804967747356, num_heads=8, num_layers=3; total time=   0.4s\n",
      "Epoch 5, Loss: 0.639729380607605\n",
      "Epoch 2, Loss: 3.7578346729278564\n",
      "Epoch 4, Loss: 0.07323877513408661\n",
      "Epoch 3, Loss: 1.5433259010314941\n",
      "Epoch 6, Loss: 0.827694296836853\n",
      "Epoch 5, Loss: 0.6934905052185059\n",
      "Epoch 7, Loss: 0.5126261711120605\n",
      "Epoch 3, Loss: 1.978994607925415\n",
      "Epoch 4, Loss: 0.14220622181892395\n",
      "Epoch 8, Loss: 0.19588972628116608\n",
      "Epoch 6, Loss: 0.8106578588485718\n",
      "Epoch 9, Loss: 0.07068534940481186\n",
      "Epoch 7, Loss: 0.38046905398368835\n",
      "Epoch 10, Loss: 0.09764744341373444\n",
      "Epoch 4, Loss: 0.77727210521698\n",
      "[CV] END activation=gelu, batch_size=16, dropout_rate=0.14949196862940706, feed_forward_dim=512, head_dim=32, lr=0.0036594804967747356, num_heads=8, num_layers=3; total time=   0.6s\n",
      "Epoch 5, Loss: 0.858015239238739\n",
      "Epoch 8, Loss: 0.0979076698422432\n",
      "Epoch 6, Loss: 0.6644349694252014\n",
      "Epoch 9, Loss: 0.08758676052093506\n",
      "Epoch 5, Loss: 0.06674287468194962\n",
      "Epoch 10, Loss: 0.196113720536232\n",
      "Epoch 7, Loss: 0.26022863388061523\n",
      "[CV] END activation=gelu, batch_size=16, dropout_rate=0.14949196862940706, feed_forward_dim=512, head_dim=32, lr=0.0036594804967747356, num_heads=8, num_layers=3; total time=   0.8s\n",
      "Epoch 6, Loss: 0.08407122641801834\n",
      "Epoch 8, Loss: 0.06557933986186981\n",
      "Epoch 7, Loss: 0.22003285586833954\n",
      "Epoch 9, Loss: 0.07637184113264084\n",
      "Epoch 8, Loss: 0.22310054302215576\n",
      "Epoch 10, Loss: 0.15256427228450775\n",
      "[CV] END activation=gelu, batch_size=16, dropout_rate=0.14949196862940706, feed_forward_dim=512, head_dim=32, lr=0.0036594804967747356, num_heads=8, num_layers=3; total time=   1.0s\n",
      "Epoch 9, Loss: 0.141108900308609\n",
      "Epoch 10, Loss: 0.0702614039182663\n",
      "[CV] END activation=gelu, batch_size=16, dropout_rate=0.14949196862940706, feed_forward_dim=512, head_dim=32, lr=0.0036594804967747356, num_heads=8, num_layers=3; total time=   1.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.16877374053001404\n",
      "Epoch 2, Loss: 9.508317947387695\n",
      "Epoch 3, Loss: 1.4991462230682373\n",
      "Epoch 1, Loss: 0.12443337589502335\n",
      "Epoch 4, Loss: 0.2207450419664383\n",
      "Epoch 5, Loss: 0.7964496612548828\n",
      "Epoch 2, Loss: 9.069782257080078\n",
      "Epoch 1, Loss: 0.23602406680583954\n",
      "Epoch 6, Loss: 0.46212151646614075\n",
      "Epoch 7, Loss: 0.11318645626306534\n",
      "Epoch 1, Loss: 0.07642988860607147\n",
      "Epoch 3, Loss: 0.2960714101791382\n",
      "Epoch 8, Loss: 0.10163554549217224\n",
      "Epoch 1, Loss: 1.222161889076233\n",
      "Epoch 2, Loss: 9.80606746673584\n",
      "Epoch 9, Loss: 0.2215692698955536\n",
      "Epoch 4, Loss: 0.20645025372505188\n",
      "Epoch 10, Loss: 0.22178836166858673\n",
      "[CV] END activation=gelu, batch_size=16, dropout_rate=0.2626854936753834, feed_forward_dim=128, head_dim=32, lr=0.004999999999999999, num_heads=4, num_layers=3; total time=   0.2s\n",
      "Epoch 2, Loss: 9.03410530090332\n",
      "Epoch 5, Loss: 0.04892921447753906\n",
      "Epoch 3, Loss: 2.415463447570801\n",
      "Epoch 2, Loss: 7.645790100097656\n",
      "Epoch 6, Loss: 0.14379717409610748\n",
      "Epoch 4, Loss: 0.06219521909952164\n",
      "Epoch 7, Loss: 0.1113174706697464\n",
      "Epoch 3, Loss: 0.6781883239746094\n",
      "Epoch 5, Loss: 0.8698095083236694\n",
      "Epoch 8, Loss: 0.06380604207515717\n",
      "Epoch 3, Loss: 1.5866328477859497\n",
      "Epoch 9, Loss: 0.08601289242506027\n",
      "Epoch 4, Loss: 1.137175440788269\n",
      "Epoch 6, Loss: 0.8232635259628296\n",
      "Epoch 10, Loss: 0.11917267739772797\n",
      "[CV] END activation=gelu, batch_size=16, dropout_rate=0.2626854936753834, feed_forward_dim=128, head_dim=32, lr=0.004999999999999999, num_heads=4, num_layers=3; total time=   0.4s\n",
      "Epoch 7, Loss: 0.4091793894767761\n",
      "Epoch 4, Loss: 0.11031074076890945\n",
      "Epoch 5, Loss: 0.8110300898551941\n",
      "Epoch 8, Loss: 0.13815197348594666\n",
      "Epoch 6, Loss: 0.22171573340892792\n",
      "Epoch 5, Loss: 0.7847821712493896\n",
      "Epoch 9, Loss: 0.061371635645627975\n",
      "Epoch 7, Loss: 0.052635569125413895\n",
      "Epoch 10, Loss: 0.09782316535711288\n",
      "[CV] END activation=gelu, batch_size=16, dropout_rate=0.2626854936753834, feed_forward_dim=128, head_dim=32, lr=0.004999999999999999, num_heads=4, num_layers=3; total time=   0.6s\n",
      "Epoch 6, Loss: 0.6240167021751404\n",
      "Epoch 8, Loss: 0.12555626034736633\n",
      "Epoch 7, Loss: 0.25053563714027405\n",
      "Epoch 9, Loss: 0.18306878209114075\n",
      "Epoch 10, Loss: 0.15543048083782196\n",
      "Epoch 8, Loss: 0.06702879816293716\n",
      "[CV] END activation=gelu, batch_size=16, dropout_rate=0.2626854936753834, feed_forward_dim=128, head_dim=32, lr=0.004999999999999999, num_heads=4, num_layers=3; total time=   0.8s\n",
      "Epoch 9, Loss: 0.08047238737344742\n",
      "Epoch 10, Loss: 0.15651774406433105\n",
      "[CV] END activation=gelu, batch_size=16, dropout_rate=0.2626854936753834, feed_forward_dim=128, head_dim=32, lr=0.004999999999999999, num_heads=4, num_layers=3; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.07372478395700455\n",
      "Epoch 2, Loss: 2.4948244094848633\n",
      "Epoch 3, Loss: 0.029128003865480423\n",
      "Epoch 1, Loss: 0.31353437900543213\n",
      "Epoch 4, Loss: 0.4179864227771759\n",
      "Epoch 1, Loss: 0.5563092231750488\n",
      "Epoch 2, Loss: 8.2220458984375\n",
      "Epoch 1, Loss: 0.09854995459318161\n",
      "Epoch 5, Loss: 0.0802135020494461\n",
      "Epoch 1, Loss: 0.11345437914133072\n",
      "Epoch 6, Loss: 0.24128901958465576\n",
      "Epoch 3, Loss: 2.0363523960113525\n",
      "Epoch 2, Loss: 9.623711585998535\n",
      "Epoch 7, Loss: 0.12879595160484314\n",
      "Epoch 8, Loss: 0.07720200717449188\n",
      "Epoch 4, Loss: 0.11318567395210266\n",
      "Epoch 2, Loss: 12.393545150756836\n",
      "Epoch 3, Loss: 2.2971365451812744\n",
      "Epoch 9, Loss: 0.1418432593345642\n",
      "Epoch 5, Loss: 0.9069838523864746\n",
      "Epoch 10, Loss: 0.14637622237205505\n",
      "Epoch 2, Loss: 15.479277610778809\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.3656273009480119, feed_forward_dim=1024, head_dim=32, lr=0.004999999999999999, num_heads=2, num_layers=2; total time=   0.3s\n",
      "Epoch 4, Loss: 0.06046302989125252\n",
      "Epoch 6, Loss: 0.6145484447479248\n",
      "Epoch 3, Loss: 1.8871686458587646\n",
      "Epoch 7, Loss: 0.20750734210014343\n",
      "Epoch 5, Loss: 0.8849194645881653\n",
      "Epoch 3, Loss: 2.8869645595550537\n",
      "Epoch 4, Loss: 0.6722478866577148\n",
      "Epoch 8, Loss: 0.0685097873210907\n",
      "Epoch 6, Loss: 0.6397081017494202\n",
      "Epoch 9, Loss: 0.11280864477157593\n",
      "Epoch 5, Loss: 0.9070069193840027\n",
      "Epoch 10, Loss: 0.17574679851531982\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.3656273009480119, feed_forward_dim=1024, head_dim=32, lr=0.004999999999999999, num_heads=2, num_layers=2; total time=   0.5s\n",
      "Epoch 4, Loss: 0.1392509937286377\n",
      "Epoch 7, Loss: 0.2112063467502594\n",
      "Epoch 8, Loss: 0.06315884739160538\n",
      "Epoch 6, Loss: 0.34876370429992676\n",
      "Epoch 5, Loss: 0.7761734127998352\n",
      "Epoch 9, Loss: 0.11581900715827942\n",
      "Epoch 7, Loss: 0.07326056808233261\n",
      "Epoch 10, Loss: 0.17913004755973816\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.3656273009480119, feed_forward_dim=1024, head_dim=32, lr=0.004999999999999999, num_heads=2, num_layers=2; total time=   0.6s\n",
      "Epoch 6, Loss: 0.39439481496810913\n",
      "Epoch 8, Loss: 0.08422545343637466\n",
      "Epoch 7, Loss: 0.07180781662464142\n",
      "Epoch 9, Loss: 0.17450958490371704\n",
      "Epoch 10, Loss: 0.19246108829975128\n",
      "Epoch 8, Loss: 0.10291323065757751\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.3656273009480119, feed_forward_dim=1024, head_dim=32, lr=0.004999999999999999, num_heads=2, num_layers=2; total time=   0.8s\n",
      "Epoch 9, Loss: 0.20260602235794067\n",
      "Epoch 10, Loss: 0.18353483080863953\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.3656273009480119, feed_forward_dim=1024, head_dim=32, lr=0.004999999999999999, num_heads=2, num_layers=2; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.8727220296859741\n",
      "Epoch 2, Loss: 13.19873046875\n",
      "Epoch 1, Loss: 0.06745053827762604\n",
      "Epoch 3, Loss: 2.8491785526275635\n",
      "Epoch 1, Loss: 0.4395379424095154\n",
      "Epoch 4, Loss: 0.1023457944393158\n",
      "Epoch 2, Loss: 2.5767123699188232\n",
      "Epoch 5, Loss: 1.040981650352478\n",
      "Epoch 1, Loss: 1.0692036151885986\n",
      "Epoch 3, Loss: 6.20488977432251\n",
      "Epoch 6, Loss: 0.8039709329605103\n",
      "Epoch 2, Loss: 12.948993682861328\n",
      "Epoch 1, Loss: 0.24984396994113922\n",
      "Epoch 7, Loss: 0.25555649399757385\n",
      "Epoch 4, Loss: 1.7217341661453247\n",
      "Epoch 2, Loss: 10.483235359191895\n",
      "Epoch 8, Loss: 0.07397390902042389\n",
      "Epoch 3, Loss: 3.8111915588378906\n",
      "Epoch 5, Loss: 0.07835426926612854\n",
      "Epoch 9, Loss: 0.19719162583351135\n",
      "Epoch 2, Loss: 4.980991840362549\n",
      "Epoch 10, Loss: 0.304538756608963\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.004999999999999999, num_heads=2, num_layers=3; total time=   0.3s\n",
      "Epoch 6, Loss: 0.3157573938369751\n",
      "Epoch 3, Loss: 2.565185070037842\n",
      "Epoch 4, Loss: 0.26569822430610657\n",
      "Epoch 7, Loss: 0.4816385805606842\n",
      "Epoch 5, Loss: 0.4005410075187683\n",
      "Epoch 8, Loss: 0.318808913230896\n",
      "Epoch 3, Loss: 1.3509682416915894\n",
      "Epoch 4, Loss: 0.062502421438694\n",
      "Epoch 9, Loss: 0.12675531208515167\n",
      "Epoch 6, Loss: 0.6445470452308655\n",
      "Epoch 10, Loss: 0.07287347316741943\n",
      "Epoch 5, Loss: 0.8162153959274292\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.004999999999999999, num_heads=2, num_layers=3; total time=   0.4s\n",
      "Epoch 4, Loss: 0.18001772463321686\n",
      "Epoch 7, Loss: 0.3495883643627167\n",
      "Epoch 6, Loss: 0.8486616611480713\n",
      "Epoch 8, Loss: 0.0937800407409668\n",
      "Epoch 5, Loss: 0.07592247426509857\n",
      "Epoch 9, Loss: 0.08685149252414703\n",
      "Epoch 7, Loss: 0.3846866190433502\n",
      "Epoch 10, Loss: 0.18455715477466583\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.004999999999999999, num_heads=2, num_layers=3; total time=   0.6s\n",
      "Epoch 6, Loss: 0.18436972796916962\n",
      "Epoch 8, Loss: 0.09620390087366104\n",
      "Epoch 9, Loss: 0.06937971711158752\n",
      "Epoch 7, Loss: 0.12470788508653641\n",
      "Epoch 10, Loss: 0.16125866770744324\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.004999999999999999, num_heads=2, num_layers=3; total time=   0.7s\n",
      "Epoch 8, Loss: 0.05800876393914223\n",
      "Epoch 9, Loss: 0.06930288672447205\n",
      "Epoch 10, Loss: 0.11105335503816605\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=8, lr=0.004999999999999999, num_heads=2, num_layers=3; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.1866430640220642\n",
      "Epoch 1, Loss: 0.08060504496097565\n",
      "Epoch 2, Loss: 0.10487841069698334\n",
      "Epoch 1, Loss: 0.3872925639152527\n",
      "Epoch 3, Loss: 0.05954070761799812\n",
      "Epoch 1, Loss: 0.9924124479293823\n",
      "Epoch 4, Loss: 0.049995094537734985\n",
      "Epoch 2, Loss: 0.030498208478093147\n",
      "Epoch 1, Loss: 0.25209394097328186\n",
      "Epoch 5, Loss: 0.06099554896354675\n",
      "Epoch 2, Loss: 0.23364242911338806\n",
      "Epoch 6, Loss: 0.07184675335884094\n",
      "Epoch 3, Loss: 0.01885524019598961\n",
      "Epoch 7, Loss: 0.07062895596027374\n",
      "Epoch 2, Loss: 0.7824848294258118\n",
      "Epoch 8, Loss: 0.06355515122413635\n",
      "Epoch 3, Loss: 0.12783049046993256\n",
      "Epoch 4, Loss: 0.025938712060451508\n",
      "Epoch 9, Loss: 0.053372692316770554\n",
      "Epoch 2, Loss: 0.16004154086112976\n",
      "Epoch 10, Loss: 0.034127745777368546\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.12462823237882598, feed_forward_dim=512, head_dim=8, lr=7.30186045378304e-05, num_heads=2, num_layers=2; total time=   0.3s\n",
      "Epoch 5, Loss: 0.03226422518491745\n",
      "Epoch 3, Loss: 0.5977331399917603\n",
      "Epoch 4, Loss: 0.0545332245528698\n",
      "Epoch 6, Loss: 0.031041447073221207\n",
      "Epoch 5, Loss: 0.0178882647305727\n",
      "Epoch 3, Loss: 0.09410593658685684\n",
      "Epoch 7, Loss: 0.023254912346601486\n",
      "Epoch 4, Loss: 0.4348222315311432\n",
      "Epoch 8, Loss: 0.01322384923696518\n",
      "Epoch 6, Loss: 0.013819572515785694\n",
      "Epoch 5, Loss: 0.30387571454048157\n",
      "Epoch 4, Loss: 0.056244753301143646\n",
      "Epoch 9, Loss: 0.008425471372902393\n",
      "Epoch 7, Loss: 0.027444669976830482\n",
      "Epoch 10, Loss: 0.008809447288513184\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.12462823237882598, feed_forward_dim=512, head_dim=8, lr=7.30186045378304e-05, num_heads=2, num_layers=2; total time=   0.5s\n",
      "Epoch 6, Loss: 0.20229540765285492\n",
      "Epoch 8, Loss: 0.05103486403822899\n",
      "Epoch 5, Loss: 0.04147319123148918\n",
      "Epoch 9, Loss: 0.06876562535762787\n",
      "Epoch 7, Loss: 0.12307273596525192\n",
      "Epoch 10, Loss: 0.076685331761837\n",
      "Epoch 6, Loss: 0.04367063567042351\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.12462823237882598, feed_forward_dim=512, head_dim=8, lr=7.30186045378304e-05, num_heads=2, num_layers=2; total time=   0.6s\n",
      "Epoch 8, Loss: 0.07199165225028992\n",
      "Epoch 7, Loss: 0.05639951303601265\n",
      "Epoch 9, Loss: 0.04050237685441971\n",
      "Epoch 10, Loss: 0.026899229735136032\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.12462823237882598, feed_forward_dim=512, head_dim=8, lr=7.30186045378304e-05, num_heads=2, num_layers=2; total time=   0.8s\n",
      "Epoch 8, Loss: 0.06592343747615814\n",
      "Epoch 9, Loss: 0.07297300547361374\n",
      "Epoch 10, Loss: 0.06978120654821396\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.12462823237882598, feed_forward_dim=512, head_dim=8, lr=7.30186045378304e-05, num_heads=2, num_layers=2; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.3808126747608185\n",
      "Epoch 2, Loss: 0.08120100945234299\n",
      "Epoch 1, Loss: 2.2806336879730225\n",
      "Epoch 3, Loss: 0.1592695415019989\n",
      "Epoch 4, Loss: 0.20787639915943146\n",
      "Epoch 1, Loss: 0.6694155931472778\n",
      "Epoch 2, Loss: 1.332594633102417\n",
      "Epoch 5, Loss: 0.12487580627202988\n",
      "Epoch 1, Loss: 2.3913261890411377\n",
      "Epoch 6, Loss: 0.052254218608140945\n",
      "Epoch 3, Loss: 0.6288341879844666\n",
      "Epoch 7, Loss: 0.028201142325997353\n",
      "Epoch 1, Loss: 0.6367864608764648\n",
      "Epoch 2, Loss: 0.20805665850639343\n",
      "Epoch 8, Loss: 0.051879268139600754\n",
      "Epoch 4, Loss: 0.2186291664838791\n",
      "Epoch 9, Loss: 0.07733173668384552\n",
      "Epoch 2, Loss: 1.4209893941879272\n",
      "Epoch 10, Loss: 0.07516290992498398\n",
      "Epoch 3, Loss: 0.03320562094449997\n",
      "Epoch 5, Loss: 0.050951648503541946\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=0.00023036909595373315, num_heads=2, num_layers=2; total time=   0.3s\n",
      "Epoch 2, Loss: 0.15420448780059814\n",
      "Epoch 6, Loss: 0.08410600572824478\n",
      "Epoch 4, Loss: 0.07035283744335175\n",
      "Epoch 3, Loss: 0.7168223857879639\n",
      "Epoch 7, Loss: 0.214528426527977\n",
      "Epoch 5, Loss: 0.16433629393577576\n",
      "Epoch 8, Loss: 0.33187758922576904\n",
      "Epoch 3, Loss: 0.07384775578975677\n",
      "Epoch 4, Loss: 0.2793443202972412\n",
      "Epoch 9, Loss: 0.3837140202522278\n",
      "Epoch 6, Loss: 0.2000972479581833\n",
      "Epoch 10, Loss: 0.36849281191825867\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=0.00023036909595373315, num_heads=2, num_layers=2; total time=   0.5s\n",
      "Epoch 4, Loss: 0.20188435912132263\n",
      "Epoch 5, Loss: 0.08869045227766037\n",
      "Epoch 7, Loss: 0.1747003197669983\n",
      "Epoch 8, Loss: 0.1142020970582962\n",
      "Epoch 6, Loss: 0.0758674293756485\n",
      "Epoch 5, Loss: 0.2507152557373047\n",
      "Epoch 9, Loss: 0.05555526539683342\n",
      "Epoch 7, Loss: 0.16088232398033142\n",
      "Epoch 10, Loss: 0.01959173008799553\n",
      "Epoch 6, Loss: 0.19499471783638\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=0.00023036909595373315, num_heads=2, num_layers=2; total time=   0.7s\n",
      "Epoch 8, Loss: 0.2655862867832184\n",
      "Epoch 7, Loss: 0.10758845508098602\n",
      "Epoch 9, Loss: 0.3403658866882324\n",
      "Epoch 8, Loss: 0.043862685561180115\n",
      "Epoch 10, Loss: 0.3593294024467468\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=0.00023036909595373315, num_heads=2, num_layers=2; total time=   0.9s\n",
      "Epoch 9, Loss: 0.03099580481648445\n",
      "Epoch 10, Loss: 0.05263163521885872\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.1, feed_forward_dim=512, head_dim=32, lr=0.00023036909595373315, num_heads=2, num_layers=2; total time=   1.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.14246520400047302\n",
      "Epoch 2, Loss: 0.10046133399009705\n",
      "Epoch 1, Loss: 0.13930612802505493\n",
      "Epoch 3, Loss: 0.10540985316038132\n",
      "Epoch 4, Loss: 0.04083767533302307\n",
      "Epoch 1, Loss: 0.15644210577011108\n",
      "Epoch 2, Loss: 0.09415014088153839\n",
      "Epoch 5, Loss: 0.020725883543491364\n",
      "Epoch 1, Loss: 0.034875836223363876\n",
      "Epoch 6, Loss: 0.044211842119693756\n",
      "Epoch 3, Loss: 0.0991164818406105\n",
      "Epoch 2, Loss: 0.05399588495492935\n",
      "Epoch 1, Loss: 0.09993395209312439\n",
      "Epoch 7, Loss: 0.04280270263552666\n",
      "Epoch 8, Loss: 0.025661712512373924\n",
      "Epoch 4, Loss: 0.04995734989643097\n",
      "Epoch 2, Loss: 0.2900441586971283\n",
      "Epoch 3, Loss: 0.1069287583231926\n",
      "Epoch 9, Loss: 0.016642840579152107\n",
      "Epoch 5, Loss: 0.02786083146929741\n",
      "Epoch 10, Loss: 0.024558937177062035\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.30296337554197095, feed_forward_dim=1024, head_dim=32, lr=0.0003065711791489977, num_heads=4, num_layers=2; total time=   0.2s\n",
      "Epoch 2, Loss: 0.14193105697631836\n",
      "Epoch 4, Loss: 0.06601201742887497\n",
      "Epoch 6, Loss: 0.0399743877351284\n",
      "Epoch 3, Loss: 0.021493706852197647\n",
      "Epoch 7, Loss: 0.039488133043050766\n",
      "Epoch 5, Loss: 0.02142755314707756\n",
      "Epoch 3, Loss: 0.06394458562135696\n",
      "Epoch 8, Loss: 0.021555036306381226\n",
      "Epoch 4, Loss: 0.10047803819179535\n",
      "Epoch 6, Loss: 0.023169416934251785\n",
      "Epoch 9, Loss: 0.007532607298344374\n",
      "Epoch 7, Loss: 0.04039009287953377\n",
      "Epoch 10, Loss: 0.012196607887744904\n",
      "Epoch 5, Loss: 0.15910974144935608\n",
      "Epoch 4, Loss: 0.06616023182868958\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.30296337554197095, feed_forward_dim=1024, head_dim=32, lr=0.0003065711791489977, num_heads=4, num_layers=2; total time=   0.4s\n",
      "Epoch 8, Loss: 0.0396374948322773\n",
      "Epoch 6, Loss: 0.08602696657180786\n",
      "Epoch 5, Loss: 0.06885303556919098\n",
      "Epoch 9, Loss: 0.021070802584290504\n",
      "Epoch 7, Loss: 0.014566018246114254\n",
      "Epoch 10, Loss: 0.008134548552334309\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.30296337554197095, feed_forward_dim=1024, head_dim=32, lr=0.0003065711791489977, num_heads=4, num_layers=2; total time=   0.6s\n",
      "Epoch 6, Loss: 0.041480839252471924\n",
      "Epoch 8, Loss: 0.01966783218085766\n",
      "Epoch 7, Loss: 0.02148050256073475\n",
      "Epoch 9, Loss: 0.061235927045345306\n",
      "Epoch 10, Loss: 0.07584953308105469\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.30296337554197095, feed_forward_dim=1024, head_dim=32, lr=0.0003065711791489977, num_heads=4, num_layers=2; total time=   0.7s\n",
      "Epoch 8, Loss: 0.027467375621199608\n",
      "Epoch 9, Loss: 0.03433570638298988\n",
      "Epoch 10, Loss: 0.023615125566720963\n",
      "[CV] END activation=relu, batch_size=32, dropout_rate=0.30296337554197095, feed_forward_dim=1024, head_dim=32, lr=0.0003065711791489977, num_heads=4, num_layers=2; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.490200012922287\n",
      "Epoch 2, Loss: 6.3866286277771\n",
      "Epoch 1, Loss: 0.03964098542928696\n",
      "Epoch 3, Loss: 2.353114128112793\n",
      "Epoch 4, Loss: 0.18767119944095612\n",
      "Epoch 1, Loss: 2.381767988204956\n",
      "Epoch 2, Loss: 6.806220054626465\n",
      "Epoch 5, Loss: 0.31888338923454285\n",
      "Epoch 1, Loss: 4.063648223876953\n",
      "Epoch 6, Loss: 0.7458159327507019\n",
      "Epoch 3, Loss: 0.12625865638256073\n",
      "Epoch 1, Loss: 1.0764057636260986\n",
      "Epoch 2, Loss: 4.37808895111084\n",
      "Epoch 7, Loss: 0.6613776087760925\n",
      "Epoch 8, Loss: 0.3697644770145416\n",
      "Epoch 4, Loss: 2.1314711570739746\n",
      "Epoch 9, Loss: 0.14241492748260498Epoch 2, Loss: 2.990920305252075\n",
      "\n",
      "Epoch 3, Loss: 1.6512302160263062\n",
      "Epoch 10, Loss: 0.05894899740815163\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.002654924757454332, num_heads=2, num_layers=3; total time=   0.2s\n",
      "Epoch 5, Loss: 0.8618532419204712\n",
      "Epoch 2, Loss: 5.938879489898682\n",
      "Epoch 4, Loss: 0.18803733587265015\n",
      "Epoch 3, Loss: 1.4535102844238281\n",
      "Epoch 6, Loss: 0.08785726875066757\n",
      "Epoch 7, Loss: 0.09464192390441895\n",
      "Epoch 5, Loss: 0.1585851013660431\n",
      "Epoch 3, Loss: 2.018218755722046\n",
      "Epoch 4, Loss: 0.2254573255777359\n",
      "Epoch 8, Loss: 0.2756785452365875\n",
      "Epoch 6, Loss: 0.47561079263687134\n",
      "Epoch 9, Loss: 0.3266524076461792\n",
      "Epoch 5, Loss: 0.08754123747348785\n",
      "Epoch 4, Loss: 0.1584962010383606\n",
      "Epoch 7, Loss: 0.5295253396034241\n",
      "Epoch 10, Loss: 0.24737611413002014\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.002654924757454332, num_heads=2, num_layers=3; total time=   0.4s\n",
      "Epoch 8, Loss: 0.376211553812027\n",
      "Epoch 6, Loss: 0.32641714811325073\n",
      "Epoch 5, Loss: 0.32251226902008057\n",
      "Epoch 9, Loss: 0.19114570319652557\n",
      "Epoch 7, Loss: 0.4016305208206177\n",
      "Epoch 10, Loss: 0.08207964897155762\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.002654924757454332, num_heads=2, num_layers=3; total time=   0.6s\n",
      "Epoch 6, Loss: 0.7203890085220337\n",
      "Epoch 8, Loss: 0.2869907021522522\n",
      "Epoch 7, Loss: 0.6354172825813293\n",
      "Epoch 9, Loss: 0.1345849484205246\n",
      "Epoch 8, Loss: 0.3488169014453888\n",
      "Epoch 10, Loss: 0.0528598427772522\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.002654924757454332, num_heads=2, num_layers=3; total time=   0.8s\n",
      "Epoch 9, Loss: 0.1239086389541626\n",
      "Epoch 10, Loss: 0.05784272775053978\n",
      "[CV] END activation=relu, batch_size=64, dropout_rate=0.4, feed_forward_dim=128, head_dim=32, lr=0.002654924757454332, num_heads=2, num_layers=3; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 1.3007298707962036\n",
      "Epoch 1, Loss: 0.048081766813993454\n",
      "Epoch 2, Loss: 1.1170719861984253\n",
      "Epoch 3, Loss: 0.9232928156852722\n",
      "Epoch 1, Loss: 0.5803943276405334\n",
      "Epoch 2, Loss: 0.02716843970119953\n",
      "Epoch 4, Loss: 0.7656120657920837\n",
      "Epoch 5, Loss: 0.631260335445404\n",
      "Epoch 1, Loss: 0.20078901946544647\n",
      "Epoch 3, Loss: 0.02005428448319435\n",
      "Epoch 1, Loss: 2.5033652782440186\n",
      "Epoch 2, Loss: 0.4726245105266571\n",
      "Epoch 6, Loss: 0.5144284963607788\n",
      "Epoch 4, Loss: 0.022696729749441147\n",
      "Epoch 7, Loss: 0.39426612854003906\n",
      "Epoch 2, Loss: 0.15596075356006622\n",
      "Epoch 3, Loss: 0.37222960591316223\n",
      "Epoch 8, Loss: 0.312661737203598\n",
      "Epoch 5, Loss: 0.0234217531979084\n",
      "Epoch 9, Loss: 0.23964226245880127\n",
      "Epoch 6, Loss: 0.02130136825144291\n",
      "Epoch 10, Loss: 0.18435092270374298\n",
      "Epoch 2, Loss: 2.2094600200653076\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.16290232323382825, feed_forward_dim=1024, head_dim=32, lr=5e-05, num_heads=8, num_layers=2; total time=   0.3s\n",
      "Epoch 4, Loss: 0.2897929549217224\n",
      "Epoch 3, Loss: 0.1242084875702858\n",
      "Epoch 7, Loss: 0.015405148267745972\n",
      "Epoch 8, Loss: 0.011803810484707355\n",
      "Epoch 5, Loss: 0.2249787151813507\n",
      "Epoch 3, Loss: 1.9398547410964966\n",
      "Epoch 9, Loss: 0.008624270558357239\n",
      "Epoch 4, Loss: 0.10647113621234894\n",
      "Epoch 6, Loss: 0.17161720991134644\n",
      "Epoch 10, Loss: 0.008649088442325592\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.16290232323382825, feed_forward_dim=1024, head_dim=32, lr=5e-05, num_heads=8, num_layers=2; total time=   0.4s\n",
      "Epoch 7, Loss: 0.1303241103887558\n",
      "Epoch 5, Loss: 0.1024029329419136\n",
      "Epoch 4, Loss: 1.6898115873336792\n",
      "Epoch 8, Loss: 0.10412493348121643\n",
      "Epoch 6, Loss: 0.10067471861839294\n",
      "Epoch 5, Loss: 1.4503240585327148\n",
      "Epoch 9, Loss: 0.08403826504945755\n",
      "Epoch 7, Loss: 0.09819099307060242\n",
      "Epoch 10, Loss: 0.07572998851537704\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.16290232323382825, feed_forward_dim=1024, head_dim=32, lr=5e-05, num_heads=8, num_layers=2; total time=   0.6s\n",
      "Epoch 6, Loss: 1.2315173149108887\n",
      "Epoch 8, Loss: 0.09482817351818085\n",
      "Epoch 7, Loss: 1.0303361415863037\n",
      "Epoch 9, Loss: 0.09311161190271378\n",
      "Epoch 8, Loss: 0.8509401082992554\n",
      "Epoch 10, Loss: 0.08245007693767548\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.16290232323382825, feed_forward_dim=1024, head_dim=32, lr=5e-05, num_heads=8, num_layers=2; total time=   0.7s\n",
      "Epoch 9, Loss: 0.6895689368247986\n",
      "Epoch 10, Loss: 0.5480093955993652\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.16290232323382825, feed_forward_dim=1024, head_dim=32, lr=5e-05, num_heads=8, num_layers=2; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 1.5446953773498535\n",
      "Epoch 2, Loss: 8.021402359008789\n",
      "Epoch 3, Loss: 1.9683290719985962\n",
      "Epoch 1, Loss: 0.1343086063861847\n",
      "Epoch 4, Loss: 0.10247696191072464\n",
      "Epoch 5, Loss: 0.908863365650177\n",
      "Epoch 1, Loss: 0.3476227819919586\n",
      "Epoch 2, Loss: 18.14536476135254\n",
      "Epoch 6, Loss: 0.6073299646377563\n",
      "Epoch 1, Loss: 0.8192593455314636\n",
      "Epoch 7, Loss: 0.1540307253599167\n",
      "Epoch 3, Loss: 3.254554510116577\n",
      "Epoch 2, Loss: 15.367086410522461\n",
      "Epoch 8, Loss: 0.08819689601659775\n",
      "Epoch 1, Loss: 0.17868170142173767\n",
      "Epoch 9, Loss: 0.22079938650131226\n",
      "Epoch 4, Loss: 0.32960379123687744\n",
      "Epoch 10, Loss: 0.27946341037750244\n",
      "Epoch 2, Loss: 8.1048583984375\n",
      "Epoch 3, Loss: 3.451910972595215\n",
      "[CV] END activation=gelu, batch_size=16, dropout_rate=0.21066772215493126, feed_forward_dim=1024, head_dim=16, lr=0.004827379466460817, num_heads=4, num_layers=2; total time=   0.3s\n",
      "Epoch 5, Loss: 1.288003921508789\n",
      "Epoch 2, Loss: 10.180102348327637\n",
      "Epoch 4, Loss: 0.06099889799952507\n",
      "Epoch 6, Loss: 0.761349081993103\n",
      "Epoch 3, Loss: 1.8536128997802734\n",
      "Epoch 7, Loss: 0.21696969866752625\n",
      "Epoch 5, Loss: 0.8869204521179199\n",
      "Epoch 3, Loss: 0.36875832080841064\n",
      "Epoch 4, Loss: 0.10488561540842056\n",
      "Epoch 8, Loss: 0.07258401811122894\n",
      "Epoch 6, Loss: 0.9376974105834961\n",
      "Epoch 9, Loss: 0.18245522677898407\n",
      "Epoch 5, Loss: 0.7626105546951294\n",
      "Epoch 7, Loss: 0.46090641617774963\n",
      "Epoch 10, Loss: 0.24900923669338226\n",
      "Epoch 4, Loss: 2.254585027694702\n",
      "[CV] END activation=gelu, batch_size=16, dropout_rate=0.21066772215493126, feed_forward_dim=1024, head_dim=16, lr=0.004827379466460817, num_heads=4, num_layers=2; total time=   0.5s\n",
      "Epoch 8, Loss: 0.11818333715200424\n",
      "Epoch 6, Loss: 0.48812347650527954\n",
      "Epoch 5, Loss: 0.9955216646194458\n",
      "Epoch 9, Loss: 0.0848357304930687\n",
      "Epoch 7, Loss: 0.14152991771697998\n",
      "Epoch 10, Loss: 0.2187960147857666\n",
      "[CV] END activation=gelu, batch_size=16, dropout_rate=0.21066772215493126, feed_forward_dim=1024, head_dim=16, lr=0.004827379466460817, num_heads=4, num_layers=2; total time=   0.6s\n",
      "Epoch 6, Loss: 0.14320476353168488\n",
      "Epoch 8, Loss: 0.05520191043615341\n",
      "Epoch 7, Loss: 0.08991441875696182\n",
      "Epoch 9, Loss: 0.11024703085422516\n",
      "Epoch 8, Loss: 0.2664663791656494\n",
      "Epoch 10, Loss: 0.16111528873443604\n",
      "[CV] END activation=gelu, batch_size=16, dropout_rate=0.21066772215493126, feed_forward_dim=1024, head_dim=16, lr=0.004827379466460817, num_heads=4, num_layers=2; total time=   0.8s\n",
      "Epoch 9, Loss: 0.3074471652507782\n",
      "Epoch 10, Loss: 0.2166045606136322\n",
      "[CV] END activation=gelu, batch_size=16, dropout_rate=0.21066772215493126, feed_forward_dim=1024, head_dim=16, lr=0.004827379466460817, num_heads=4, num_layers=2; total time=   1.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.37441790103912354\n",
      "Epoch 2, Loss: 0.10487044602632523\n",
      "Epoch 3, Loss: 0.034744035452604294\n",
      "Epoch 1, Loss: 0.4768844544887543\n",
      "Epoch 4, Loss: 0.08211789280176163\n",
      "Epoch 5, Loss: 0.12450960278511047\n",
      "Epoch 1, Loss: 0.44916486740112305\n",
      "Epoch 2, Loss: 0.11151588708162308\n",
      "Epoch 6, Loss: 0.11883672326803207\n",
      "Epoch 1, Loss: 0.2394314855337143\n",
      "Epoch 7, Loss: 0.08442158252000809\n",
      "Epoch 3, Loss: 0.005636472720652819\n",
      "Epoch 2, Loss: 0.17192140221595764\n",
      "Epoch 8, Loss: 0.04114266484975815\n",
      "Epoch 1, Loss: 0.08521066606044769\n",
      "Epoch 4, Loss: 0.06366138905286789\n",
      "Epoch 9, Loss: 0.01752641797065735\n",
      "Epoch 10, Loss: 0.013912384398281574\n",
      "Epoch 3, Loss: 0.11176949739456177\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.13073099632924115, feed_forward_dim=1024, head_dim=32, lr=0.00020465284612152012, num_heads=2, num_layers=2; total time=   0.3s\n",
      "Epoch 2, Loss: 0.06355254352092743\n",
      "Epoch 5, Loss: 0.13681143522262573\n",
      "Epoch 2, Loss: 0.06949371099472046\n",
      "Epoch 6, Loss: 0.15034085512161255\n",
      "Epoch 4, Loss: 0.15850558876991272\n",
      "Epoch 3, Loss: 0.09518290311098099\n",
      "Epoch 7, Loss: 0.1113143190741539\n",
      "Epoch 5, Loss: 0.18046346306800842\n",
      "Epoch 8, Loss: 0.06261907517910004\n",
      "Epoch 3, Loss: 0.060863420367240906\n",
      "Epoch 4, Loss: 0.12434843182563782\n",
      "Epoch 6, Loss: 0.15096797049045563\n",
      "Epoch 9, Loss: 0.02230045199394226\n",
      "Epoch 10, Loss: 0.006588746793568134\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.13073099632924115, feed_forward_dim=1024, head_dim=32, lr=0.00020465284612152012, num_heads=2, num_layers=2; total time=   0.4s\n",
      "Epoch 7, Loss: 0.1011553630232811\n",
      "Epoch 4, Loss: 0.03651975840330124\n",
      "Epoch 5, Loss: 0.09551902860403061\n",
      "Epoch 8, Loss: 0.05491114780306816\n",
      "Epoch 6, Loss: 0.04829055443406105\n",
      "Epoch 5, Loss: 0.028634993359446526\n",
      "Epoch 9, Loss: 0.031815867871046066\n",
      "Epoch 10, Loss: 0.03445905074477196\n",
      "Epoch 7, Loss: 0.024175139144062996\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.13073099632924115, feed_forward_dim=1024, head_dim=32, lr=0.00020465284612152012, num_heads=2, num_layers=2; total time=   0.6s\n",
      "Epoch 6, Loss: 0.02962385304272175\n",
      "Epoch 8, Loss: 0.027543991804122925\n",
      "Epoch 7, Loss: 0.023176871240139008\n",
      "Epoch 9, Loss: 0.04390735179185867\n",
      "Epoch 8, Loss: 0.01342483889311552\n",
      "Epoch 10, Loss: 0.04898503050208092\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.13073099632924115, feed_forward_dim=1024, head_dim=32, lr=0.00020465284612152012, num_heads=2, num_layers=2; total time=   0.7s\n",
      "Epoch 9, Loss: 0.01095372810959816\n",
      "Epoch 10, Loss: 0.01387827005237341\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.13073099632924115, feed_forward_dim=1024, head_dim=32, lr=0.00020465284612152012, num_heads=2, num_layers=2; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.9172229170799255\n",
      "Epoch 2, Loss: 0.7016687989234924\n",
      "Epoch 1, Loss: 5.462525367736816\n",
      "Epoch 3, Loss: 0.5016547441482544\n",
      "Epoch 4, Loss: 0.3438046872615814\n",
      "Epoch 2, Loss: 4.869337558746338\n",
      "Epoch 1, Loss: 0.33582672476768494\n",
      "Epoch 5, Loss: 0.21728593111038208\n",
      "Epoch 3, Loss: 4.316937446594238\n",
      "Epoch 6, Loss: 0.12151850759983063\n",
      "Epoch 1, Loss: 1.644750952720642\n",
      "Epoch 7, Loss: 0.06195235997438431\n",
      "Epoch 4, Loss: 3.8089804649353027\n",
      "Epoch 2, Loss: 0.22273661196231842\n",
      "Epoch 8, Loss: 0.02788398787379265\n",
      "Epoch 1, Loss: 0.03466682881116867\n",
      "Epoch 5, Loss: 3.3310720920562744\n",
      "Epoch 9, Loss: 0.01598503254354\n",
      "Epoch 10, Loss: 0.022387171164155006\n",
      "Epoch 3, Loss: 0.15482337772846222\n",
      "[CV] END activation=gelu, batch_size=16, dropout_rate=0.22268014596789246, feed_forward_dim=1024, head_dim=32, lr=7.531835368499981e-05, num_heads=2, num_layers=2; total time=   0.3s\n",
      "Epoch 2, Loss: 1.3662558794021606\n",
      "Epoch 6, Loss: 2.8941731452941895\n",
      "Epoch 7, Loss: 2.4638378620147705\n",
      "Epoch 2, Loss: 0.02798747457563877\n",
      "Epoch 4, Loss: 0.11502102017402649\n",
      "Epoch 3, Loss: 1.1049572229385376\n",
      "Epoch 8, Loss: 2.089887857437134\n",
      "Epoch 5, Loss: 0.10735008865594864\n",
      "Epoch 9, Loss: 1.751137614250183\n",
      "Epoch 3, Loss: 0.026155423372983932\n",
      "Epoch 4, Loss: 0.8755207061767578\n",
      "Epoch 10, Loss: 1.4372756481170654\n",
      "Epoch 6, Loss: 0.11401969194412231\n",
      "[CV] END activation=gelu, batch_size=16, dropout_rate=0.22268014596789246, feed_forward_dim=1024, head_dim=32, lr=7.531835368499981e-05, num_heads=2, num_layers=2; total time=   0.4s\n",
      "Epoch 7, Loss: 0.12262558937072754\n",
      "Epoch 5, Loss: 0.6748120188713074\n",
      "Epoch 4, Loss: 0.019810672849416733\n",
      "Epoch 8, Loss: 0.12125763297080994\n",
      "Epoch 6, Loss: 0.5077450275421143\n",
      "Epoch 5, Loss: 0.015557234175503254\n",
      "Epoch 9, Loss: 0.1132572665810585\n",
      "Epoch 7, Loss: 0.36674827337265015\n",
      "Epoch 10, Loss: 0.10208028554916382\n",
      "[CV] END activation=gelu, batch_size=16, dropout_rate=0.22268014596789246, feed_forward_dim=1024, head_dim=32, lr=7.531835368499981e-05, num_heads=2, num_layers=2; total time=   0.6s\n",
      "Epoch 6, Loss: 0.013529208488762379\n",
      "Epoch 8, Loss: 0.2568795084953308\n",
      "Epoch 7, Loss: 0.012157399207353592\n",
      "Epoch 9, Loss: 0.1675795167684555\n",
      "Epoch 8, Loss: 0.010179760865867138\n",
      "Epoch 10, Loss: 0.10601172596216202\n",
      "[CV] END activation=gelu, batch_size=16, dropout_rate=0.22268014596789246, feed_forward_dim=1024, head_dim=32, lr=7.531835368499981e-05, num_heads=2, num_layers=2; total time=   0.7s\n",
      "Epoch 9, Loss: 0.007791567128151655\n",
      "Epoch 10, Loss: 0.007789590861648321\n",
      "[CV] END activation=gelu, batch_size=16, dropout_rate=0.22268014596789246, feed_forward_dim=1024, head_dim=32, lr=7.531835368499981e-05, num_heads=2, num_layers=2; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.4075700044631958\n",
      "Epoch 2, Loss: 0.024149468168616295\n",
      "Epoch 1, Loss: 0.10930142551660538\n",
      "Epoch 3, Loss: 0.20874102413654327\n",
      "Epoch 4, Loss: 0.1950458437204361\n",
      "Epoch 2, Loss: 0.26670148968696594\n",
      "Epoch 1, Loss: 0.5180922746658325\n",
      "Epoch 5, Loss: 0.07561443001031876\n",
      "Epoch 1, Loss: 0.5007995963096619\n",
      "Epoch 6, Loss: 0.01718093268573284\n",
      "Epoch 1, Loss: 0.7108887434005737\n",
      "Epoch 3, Loss: 0.0706668496131897\n",
      "Epoch 7, Loss: 0.040526796132326126\n",
      "Epoch 2, Loss: 0.08908689022064209\n",
      "Epoch 8, Loss: 0.08275096863508224\n",
      "Epoch 4, Loss: 0.0650823786854744\n",
      "Epoch 9, Loss: 0.09036285430192947\n",
      "Epoch 2, Loss: 0.14941634237766266\n",
      "Epoch 10, Loss: 0.063937708735466\n",
      "Epoch 5, Loss: 0.1192694827914238\n",
      "Epoch 3, Loss: 0.3036588132381439\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.11674973226928209, feed_forward_dim=256, head_dim=32, lr=0.0004469452372922998, num_heads=4, num_layers=2; total time=   0.3s\n",
      "Epoch 2, Loss: 0.10727992653846741\n",
      "Epoch 6, Loss: 0.07941969484090805\n",
      "Epoch 3, Loss: 0.32929128408432007\n",
      "Epoch 4, Loss: 0.21860907971858978\n",
      "Epoch 7, Loss: 0.024101272225379944\n",
      "Epoch 3, Loss: 0.33973073959350586\n",
      "Epoch 8, Loss: 0.019102217629551888\n",
      "Epoch 5, Loss: 0.06494402140378952\n",
      "Epoch 4, Loss: 0.18642576038837433\n",
      "Epoch 9, Loss: 0.048753831535577774\n",
      "Epoch 6, Loss: 0.02172842063009739\n",
      "Epoch 10, Loss: 0.055728353559970856\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.11674973226928209, feed_forward_dim=256, head_dim=32, lr=0.0004469452372922998, num_heads=4, num_layers=2; total time=   0.4s\n",
      "Epoch 4, Loss: 0.34588515758514404\n",
      "Epoch 5, Loss: 0.044239312410354614\n",
      "Epoch 7, Loss: 0.07038375735282898\n",
      "Epoch 6, Loss: 0.04737887158989906\n",
      "Epoch 8, Loss: 0.11417990177869797\n",
      "Epoch 5, Loss: 0.18445906043052673\n",
      "Epoch 9, Loss: 0.10154697299003601\n",
      "Epoch 7, Loss: 0.11668214201927185\n",
      "Epoch 10, Loss: 0.0509973019361496\n",
      "Epoch 6, Loss: 0.06154021993279457\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.11674973226928209, feed_forward_dim=256, head_dim=32, lr=0.0004469452372922998, num_heads=4, num_layers=2; total time=   0.6s\n",
      "Epoch 8, Loss: 0.12450211495161057\n",
      "Epoch 7, Loss: 0.049038782715797424\n",
      "Epoch 9, Loss: 0.07236029207706451\n",
      "Epoch 10, Loss: 0.022472256794571877\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.11674973226928209, feed_forward_dim=256, head_dim=32, lr=0.0004469452372922998, num_heads=4, num_layers=2; total time=   0.7s\n",
      "Epoch 8, Loss: 0.10039579123258591\n",
      "Epoch 9, Loss: 0.13713282346725464\n",
      "Epoch 10, Loss: 0.12546390295028687\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.11674973226928209, feed_forward_dim=256, head_dim=32, lr=0.0004469452372922998, num_heads=4, num_layers=2; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.5967342257499695\n",
      "Epoch 2, Loss: 3.5177688598632812\n",
      "Epoch 1, Loss: 0.1312565803527832\n",
      "Epoch 3, Loss: 1.2609084844589233\n",
      "Epoch 2, Loss: 3.3321268558502197\n",
      "Epoch 4, Loss: 0.120286725461483\n",
      "Epoch 1, Loss: 0.32097509503364563\n",
      "Epoch 5, Loss: 0.163584366440773\n",
      "Epoch 3, Loss: 0.041135773062705994\n",
      "Epoch 6, Loss: 0.4680464565753937\n",
      "Epoch 1, Loss: 0.10488969832658768\n",
      "Epoch 2, Loss: 3.0163073539733887\n",
      "Epoch 7, Loss: 0.5202950835227966\n",
      "Epoch 4, Loss: 0.9816250801086426\n",
      "Epoch 1, Loss: 0.058556415140628815\n",
      "Epoch 8, Loss: 0.3691112697124481\n",
      "Epoch 5, Loss: 0.9168412089347839\n",
      "Epoch 9, Loss: 0.18063348531723022\n",
      "Epoch 3, Loss: 0.906379222869873\n",
      "Epoch 2, Loss: 4.169236660003662\n",
      "Epoch 10, Loss: 0.07260172814130783\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.3679174374824926, feed_forward_dim=512, head_dim=16, lr=0.0018038577561864198, num_heads=2, num_layers=1; total time=   0.3s\n",
      "Epoch 6, Loss: 0.36110222339630127\n",
      "Epoch 4, Loss: 0.040850214660167694\n",
      "Epoch 2, Loss: 1.691651463508606\n",
      "Epoch 7, Loss: 0.05524713546037674\n",
      "Epoch 3, Loss: 0.447563499212265\n",
      "Epoch 5, Loss: 0.2826851010322571\n",
      "Epoch 8, Loss: 0.07437204569578171\n",
      "Epoch 9, Loss: 0.2193165272474289\n",
      "Epoch 3, Loss: 0.5679596662521362\n",
      "Epoch 4, Loss: 0.4348914325237274\n",
      "Epoch 6, Loss: 0.4884432256221771\n",
      "Epoch 10, Loss: 0.29119232296943665\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.3679174374824926, feed_forward_dim=512, head_dim=16, lr=0.0018038577561864198, num_heads=2, num_layers=1; total time=   0.5s\n",
      "Epoch 7, Loss: 0.3832942843437195\n",
      "Epoch 5, Loss: 0.886387825012207\n",
      "Epoch 4, Loss: 0.5684560537338257\n",
      "Epoch 8, Loss: 0.18472324311733246\n",
      "Epoch 6, Loss: 0.5266249775886536\n",
      "Epoch 9, Loss: 0.0587344616651535\n",
      "Epoch 5, Loss: 0.07107444107532501\n",
      "Epoch 10, Loss: 0.04245448485016823\n",
      "Epoch 7, Loss: 0.14653591811656952\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.3679174374824926, feed_forward_dim=512, head_dim=16, lr=0.0018038577561864198, num_heads=2, num_layers=1; total time=   0.6s\n",
      "Epoch 6, Loss: 0.047764889895915985\n",
      "Epoch 8, Loss: 0.028855009004473686\n",
      "Epoch 9, Loss: 0.119388647377491\n",
      "Epoch 7, Loss: 0.19169281423091888\n",
      "Epoch 10, Loss: 0.22452853620052338\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.3679174374824926, feed_forward_dim=512, head_dim=16, lr=0.0018038577561864198, num_heads=2, num_layers=1; total time=   0.7s\n",
      "Epoch 8, Loss: 0.2083834558725357\n",
      "Epoch 9, Loss: 0.12698157131671906\n",
      "Epoch 10, Loss: 0.051090653985738754\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.3679174374824926, feed_forward_dim=512, head_dim=16, lr=0.0018038577561864198, num_heads=2, num_layers=1; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.06943558156490326\n",
      "Epoch 2, Loss: 3.827475070953369\n",
      "Epoch 1, Loss: 0.28398454189300537\n",
      "Epoch 3, Loss: 0.7758785486221313\n",
      "Epoch 4, Loss: 0.06542608886957169\n",
      "Epoch 1, Loss: 0.12612412869930267\n",
      "Epoch 2, Loss: 3.3593029975891113\n",
      "Epoch 5, Loss: 0.6065191626548767\n",
      "Epoch 1, Loss: 0.05165315419435501\n",
      "Epoch 6, Loss: 0.6086891293525696\n",
      "Epoch 2, Loss: 4.281504154205322\n",
      "Epoch 7, Loss: 0.3245129883289337\n",
      "Epoch 3, Loss: 0.912795901298523\n",
      "Epoch 1, Loss: 0.7619926333427429\n",
      "Epoch 8, Loss: 0.10171130299568176\n",
      "Epoch 9, Loss: 0.041262589395046234\n",
      "Epoch 2, Loss: 3.791957378387451\n",
      "Epoch 4, Loss: 0.042335595935583115\n",
      "Epoch 3, Loss: 0.5968219637870789\n",
      "Epoch 10, Loss: 0.08515405654907227\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.15013272828097654, feed_forward_dim=1024, head_dim=32, lr=0.0016576712570194484, num_heads=2, num_layers=4; total time=   0.3s\n",
      "Epoch 5, Loss: 0.38160446286201477\n",
      "Epoch 4, Loss: 0.21763496100902557\n",
      "Epoch 2, Loss: 2.405503511428833\n",
      "Epoch 3, Loss: 0.06266913563013077\n",
      "Epoch 6, Loss: 0.5738745927810669\n",
      "Epoch 5, Loss: 0.7421488165855408\n",
      "Epoch 7, Loss: 0.43125954270362854\n",
      "Epoch 4, Loss: 1.4285004138946533\n",
      "Epoch 3, Loss: 0.9297885894775391\n",
      "Epoch 8, Loss: 0.2052609920501709\n",
      "Epoch 6, Loss: 0.5603851079940796\n",
      "Epoch 9, Loss: 0.06521503627300262\n",
      "Epoch 5, Loss: 1.0420809984207153\n",
      "Epoch 7, Loss: 0.21296724677085876\n",
      "Epoch 10, Loss: 0.046597015112638474\n",
      "Epoch 4, Loss: 0.07905180007219315\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.15013272828097654, feed_forward_dim=1024, head_dim=32, lr=0.0016576712570194484, num_heads=2, num_layers=4; total time=   0.5s\n",
      "Epoch 8, Loss: 0.04084396734833717\n",
      "Epoch 6, Loss: 0.30062398314476013\n",
      "Epoch 9, Loss: 0.0705220028758049\n",
      "Epoch 5, Loss: 0.13712042570114136\n",
      "Epoch 7, Loss: 0.024073200300335884\n",
      "Epoch 10, Loss: 0.16932523250579834\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.15013272828097654, feed_forward_dim=1024, head_dim=32, lr=0.0016576712570194484, num_heads=2, num_layers=4; total time=   0.7s\n",
      "Epoch 8, Loss: 0.07930685579776764\n",
      "Epoch 6, Loss: 0.3594343066215515\n",
      "Epoch 9, Loss: 0.20866236090660095\n",
      "Epoch 7, Loss: 0.3629865050315857\n",
      "Epoch 10, Loss: 0.2667730450630188\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.15013272828097654, feed_forward_dim=1024, head_dim=32, lr=0.0016576712570194484, num_heads=2, num_layers=4; total time=   0.8s\n",
      "Epoch 8, Loss: 0.22609490156173706\n",
      "Epoch 9, Loss: 0.09213603287935257\n",
      "Epoch 10, Loss: 0.04451550543308258\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.15013272828097654, feed_forward_dim=1024, head_dim=32, lr=0.0016576712570194484, num_heads=2, num_layers=4; total time=   1.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1, Loss: 0.4056505858898163\n",
      "Epoch 2, Loss: 2.7496657371520996\n",
      "Epoch 1, Loss: 0.22457559406757355\n",
      "Epoch 3, Loss: 0.8329455852508545\n",
      "Epoch 1, Loss: 0.29514116048812866\n",
      "Epoch 4, Loss: 0.029231784865260124\n",
      "Epoch 2, Loss: 3.5090157985687256\n",
      "Epoch 5, Loss: 0.27921345829963684\n",
      "Epoch 1, Loss: 0.9241710305213928\n",
      "Epoch 6, Loss: 0.49000275135040283\n",
      "Epoch 3, Loss: 0.8109402656555176\n",
      "Epoch 2, Loss: 3.5470263957977295\n",
      "Epoch 7, Loss: 0.38081538677215576\n",
      "Epoch 1, Loss: 0.060272324830293655\n",
      "Epoch 8, Loss: 0.17452962696552277\n",
      "Epoch 4, Loss: 0.09948372840881348\n",
      "Epoch 2, Loss: 2.4813857078552246\n",
      "Epoch 9, Loss: 0.05285438522696495\n",
      "Epoch 3, Loss: 0.33755555748939514\n",
      "Epoch 10, Loss: 0.03902464359998703\n",
      "Epoch 5, Loss: 0.6747838258743286\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.16975749998272016, feed_forward_dim=128, head_dim=32, lr=0.001569413084906323, num_heads=4, num_layers=1; total time=   0.3s\n",
      "Epoch 6, Loss: 0.6424104571342468\n",
      "Epoch 2, Loss: 3.786728858947754\n",
      "Epoch 4, Loss: 0.3645319938659668\n",
      "Epoch 3, Loss: 1.047868251800537\n",
      "Epoch 7, Loss: 0.2889428436756134\n",
      "Epoch 5, Loss: 0.799092173576355\n",
      "Epoch 8, Loss: 0.06558826565742493\n",
      "Epoch 4, Loss: 0.06431419402360916\n",
      "Epoch 3, Loss: 0.11812350153923035\n",
      "Epoch 6, Loss: 0.5660799145698547\n",
      "Epoch 9, Loss: 0.06527367979288101\n",
      "Epoch 5, Loss: 0.19329778850078583\n",
      "Epoch 10, Loss: 0.17019867897033691\n",
      "Epoch 7, Loss: 0.20560863614082336\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.16975749998272016, feed_forward_dim=128, head_dim=32, lr=0.001569413084906323, num_heads=4, num_layers=1; total time=   0.5s\n",
      "Epoch 4, Loss: 1.2096630334854126\n",
      "Epoch 8, Loss: 0.038631170988082886\n",
      "Epoch 6, Loss: 0.48854032158851624\n",
      "Epoch 5, Loss: 0.9597575664520264\n",
      "Epoch 9, Loss: 0.0780128538608551\n",
      "Epoch 7, Loss: 0.44046276807785034\n",
      "Epoch 10, Loss: 0.18514564633369446\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.16975749998272016, feed_forward_dim=128, head_dim=32, lr=0.001569413084906323, num_heads=4, num_layers=1; total time=   0.6s\n",
      "Epoch 6, Loss: 0.28139299154281616\n",
      "Epoch 8, Loss: 0.2249235361814499\n",
      "Epoch 9, Loss: 0.0624421089887619\n",
      "Epoch 7, Loss: 0.015551300719380379\n",
      "Epoch 10, Loss: 0.029859183356165886\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.16975749998272016, feed_forward_dim=128, head_dim=32, lr=0.001569413084906323, num_heads=4, num_layers=1; total time=   0.8s\n",
      "Epoch 8, Loss: 0.1030416190624237\n",
      "Epoch 9, Loss: 0.25434526801109314\n",
      "Epoch 10, Loss: 0.3037329316139221\n",
      "[CV] END activation=gelu, batch_size=64, dropout_rate=0.16975749998272016, feed_forward_dim=128, head_dim=32, lr=0.001569413084906323, num_heads=4, num_layers=1; total time=   0.9s\n",
      "Epoch 1, Loss: 0.9340174794197083\n",
      "Epoch 2, Loss: 0.1752973049879074\n",
      "Epoch 3, Loss: 0.2905331552028656\n",
      "Epoch 4, Loss: 0.4000549614429474\n",
      "Epoch 5, Loss: 0.2884542942047119\n",
      "Epoch 6, Loss: 0.12977884709835052\n",
      "Epoch 7, Loss: 0.04080069065093994\n",
      "Epoch 8, Loss: 0.04568261653184891\n",
      "Epoch 9, Loss: 0.09704529494047165\n",
      "Epoch 10, Loss: 0.1303221434354782\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "              estimator=TFTEstimator(), n_jobs=-1, random_state=42,\n",
       "              scoring=&#x27;neg_mean_absolute_error&#x27;,\n",
       "              search_spaces={&#x27;activation&#x27;: Categorical(categories=(&#x27;relu&#x27;, &#x27;gelu&#x27;), prior=None),\n",
       "                             &#x27;batch_size&#x27;: Categorical(categories=(16, 32, 64), prior=None),\n",
       "                             &#x27;dropout_rate&#x27;: Real(low=0.1, high=0.4, prio...transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;feed_forward_dim&#x27;: Categorical(categories=(128, 256, 512, 1024), prior=None),\n",
       "                             &#x27;head_dim&#x27;: Categorical(categories=(8, 16, 32), prior=None),\n",
       "                             &#x27;lr&#x27;: Real(low=5e-05, high=0.005, prior=&#x27;log-uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;num_heads&#x27;: Categorical(categories=(2, 4, 8), prior=None),\n",
       "                             &#x27;num_layers&#x27;: Categorical(categories=(1, 2, 3, 4), prior=None)},\n",
       "              verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;BayesSearchCV<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>BayesSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "              estimator=TFTEstimator(), n_jobs=-1, random_state=42,\n",
       "              scoring=&#x27;neg_mean_absolute_error&#x27;,\n",
       "              search_spaces={&#x27;activation&#x27;: Categorical(categories=(&#x27;relu&#x27;, &#x27;gelu&#x27;), prior=None),\n",
       "                             &#x27;batch_size&#x27;: Categorical(categories=(16, 32, 64), prior=None),\n",
       "                             &#x27;dropout_rate&#x27;: Real(low=0.1, high=0.4, prio...transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;feed_forward_dim&#x27;: Categorical(categories=(128, 256, 512, 1024), prior=None),\n",
       "                             &#x27;head_dim&#x27;: Categorical(categories=(8, 16, 32), prior=None),\n",
       "                             &#x27;lr&#x27;: Real(low=5e-05, high=0.005, prior=&#x27;log-uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;num_heads&#x27;: Categorical(categories=(2, 4, 8), prior=None),\n",
       "                             &#x27;num_layers&#x27;: Categorical(categories=(1, 2, 3, 4), prior=None)},\n",
       "              verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: TFTEstimator</label><div class=\"sk-toggleable__content fitted\"><pre>TFTEstimator()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">TFTEstimator</label><div class=\"sk-toggleable__content fitted\"><pre>TFTEstimator()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "              estimator=TFTEstimator(), n_jobs=-1, random_state=42,\n",
       "              scoring='neg_mean_absolute_error',\n",
       "              search_spaces={'activation': Categorical(categories=('relu', 'gelu'), prior=None),\n",
       "                             'batch_size': Categorical(categories=(16, 32, 64), prior=None),\n",
       "                             'dropout_rate': Real(low=0.1, high=0.4, prio...transform='normalize'),\n",
       "                             'feed_forward_dim': Categorical(categories=(128, 256, 512, 1024), prior=None),\n",
       "                             'head_dim': Categorical(categories=(8, 16, 32), prior=None),\n",
       "                             'lr': Real(low=5e-05, high=0.005, prior='log-uniform', transform='normalize'),\n",
       "                             'num_heads': Categorical(categories=(2, 4, 8), prior=None),\n",
       "                             'num_layers': Categorical(categories=(1, 2, 3, 4), prior=None)},\n",
       "              verbose=2)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wrap the model with BayesSearchCV\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=TFTEstimator(\n",
    "        look_back=look_back,\n",
    "        n_steps_ahead=n_steps_ahead\n",
    "    ),\n",
    "    search_spaces=search_space,\n",
    "    n_iter=50,\n",
    "    cv=TimeSeriesSplit(n_splits=5),\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the search\n",
    "bayes_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = bayes_search.best_estimator_\n",
    "best_params = bayes_search.best_params_\n",
    "best_score = -bayes_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/lookback7/tft_best_estimator.pkl']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(bayes_search.best_estimator_, \"../models/lookback7/tft_best_estimator.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqTemporalFusionTransformerWrapper(\n",
       "  (model): Seq2SeqTemporalFusionTransformer(\n",
       "    (input_projection): Linear(in_features=1, out_features=64, bias=True)\n",
       "    (positional_encoding): PositionalEncoding()\n",
       "    (activation_fn): ReLU()\n",
       "    (encoder_layers): ModuleList(\n",
       "      (0-1): 2 x ModuleDict(\n",
       "        (multi_head_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (decoder_layers): ModuleList(\n",
       "      (0-1): 2 x ModuleDict(\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (cross_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the trained estimator\n",
    "best_estimator = joblib.load(\"../models/lookback7/tft_best_estimator.pkl\")\n",
    "\n",
    "# Access the trained PyTorch model\n",
    "trained_model = best_estimator.model\n",
    "trained_model.eval()  # Set to evaluation mode for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.8725356459617615\n",
      "Mean Absolute Error (MAE): 0.8342059254646301\n",
      "Mean Absolute Percentage Error (MAPE): 5.713079452514648\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = trained_model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions\n",
    "y_pred_inverse = scaler.inverse_transform(y_pred)\n",
    "y_test_inverse = scaler.inverse_transform(y_test)\n",
    "\n",
    "# Evaluate the predictions\n",
    "mse = root_mean_squared_error(y_test_inverse, y_pred_inverse)\n",
    "mae = mean_absolute_error(y_test_inverse, y_pred_inverse)\n",
    "mape = mean_absolute_percentage_error(y_test_inverse, y_pred_inverse)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape}\")\n",
    "\n",
    "# save metrics as dataframe and save to csv\n",
    "metrics = pd.DataFrame({'MSE': [mse], 'MAE': [mae], 'MAPE': [mape]})\n",
    "metrics.to_csv('../results/metrics/lookback7/tft_seq2seq_metrics.csv', index=False)\n",
    "\n",
    "# Save the predictions as .npy file\n",
    "np.save('../results/predictions/test/lookback7/tft_seq2seq_predictions.npy', y_pred_inverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model weights and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test, label=\"True Values\")\n",
    "plt.plot(y_pred, label=\"Predicted Values\")\n",
    "plt.legend()\n",
    "plt.title(\"True vs Predicted Values\")\n",
    "plt.xlabel(\"Sample Index\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_days = 10\n",
    "\n",
    "# Get the most recent data\n",
    "recent_data = X_test[-1].reshape(1, -1, 1)  # Shape: (1, look_back, 1)\n",
    "recent_data = torch.tensor(recent_data, dtype=torch.float32)\n",
    "\n",
    "# Initialize a single list to store all predictions\n",
    "predictions = []  # This will store predictions for all 3 cases\n",
    "\n",
    "# Make predictions\n",
    "for _ in range(future_days):\n",
    "    with torch.no_grad():\n",
    "        # Predict the next `n_steps_ahead` days\n",
    "        prediction = trained_model(recent_data)  # Shape: (1, n_steps_ahead)\n",
    "    \n",
    "    # Append all predicted values to the predictions list\n",
    "    predictions.append(prediction.squeeze().tolist())  # Shape: (n_steps_ahead,)\n",
    "    \n",
    "    # Update recent_data for each case\n",
    "    # Case 1: Update with the first predicted value\n",
    "    recent_data_1 = torch.cat([recent_data[:, 1:, :], prediction[:, 0].unsqueeze(1).unsqueeze(-1)], dim=1)\n",
    "    \n",
    "    # Case 2: Update with the second predicted value\n",
    "    recent_data_2 = torch.cat([recent_data[:, 1:, :], prediction[:, 1].unsqueeze(1).unsqueeze(-1)], dim=1)\n",
    "    \n",
    "    # Case 3: Update with the third predicted value\n",
    "    recent_data_3 = torch.cat([recent_data[:, 1:, :], prediction[:, 2].unsqueeze(1).unsqueeze(-1)], dim=1)\n",
    "    \n",
    "    # For the next iteration, use the updated recent_data for each case\n",
    "    recent_data = recent_data_1  # Or recent_data_2 or recent_data_3, depending on which case you want to continue\n",
    "\n",
    "# Convert predictions list to a numpy array\n",
    "predictions = np.array(predictions)  # Shape: (future_days, n_steps_ahead)\n",
    "\n",
    "# Inverse transform the predictions\n",
    "predictions_inverse = scaler.inverse_transform(predictions)  # Shape: (future_days, n_steps_ahead)\n",
    "\n",
    "# Split the inverse-transformed predictions into 3 separate arrays\n",
    "predictions_1_inverse = predictions_inverse[:, 0]  # First predicted value\n",
    "predictions_2_inverse = predictions_inverse[:, 1]  # Second predicted value\n",
    "predictions_3_inverse = predictions_inverse[:, 2]  # Third predicted value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.18010201,  0.18009281,  0.1803091 ],\n",
       "       [ 0.05370392,  0.05369616,  0.05391108],\n",
       "       [-0.08186288, -0.08187078, -0.08165669],\n",
       "       [-0.2327201 , -0.23272764, -0.23251456],\n",
       "       [-0.39275662, -0.39276459, -0.39255377],\n",
       "       [-0.54455316, -0.54455984, -0.54434866],\n",
       "       [-0.69545071, -0.695459  , -0.6952489 ],\n",
       "       [-0.84663208, -0.84663955, -0.84643142],\n",
       "       [-0.95874177, -0.95875025, -0.95854298],\n",
       "       [-1.06244188, -1.0624505 , -1.06224582]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "module_name = \"arima_garch_forecast\"\n",
    "module_path = \"/Users/binnu/Library/CloudStorage/OneDrive-student.vgu.edu.vn/VGU/Current Program/Project/Bitcoin Prediction/src/utils/prediction.py\"\n",
    "\n",
    "# Load the module\n",
    "spec = importlib.util.spec_from_file_location(module_name, module_path)\n",
    "module = importlib.util.module_from_spec(spec)\n",
    "sys.modules[module_name] = module\n",
    "spec.loader.exec_module(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pca_df = pd.read_csv(\"../data/final/test_pca_df.csv\", parse_dates=[\"Date\"], index_col=\"Date\")\n",
    "val_pca_df = pd.read_csv(\"../data/final/val_pca_df.csv\", parse_dates=[\"Date\"], index_col=\"Date\")\n",
    "val_exog = val_pca_df.drop(columns=[\"btc_close\"])\n",
    "test_exog = test_pca_df.drop(columns=[\"btc_close\"])\n",
    "# concat val and test exog\n",
    "exog = pd.concat([val_exog, test_exog])\n",
    "\n",
    "arimax_garch_future = module.arima_garch_forecast(exog, '../models', future_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_date = test_residuals_df.index[-1]\n",
    "\n",
    "# Undo log-transform (ARIMA-GARCH predictions + TFT predictions)\n",
    "final_predictions = []\n",
    "\n",
    "for i in range(3):\n",
    "    final_predictions.append(np.exp(predictions_inverse[:, i] + arimax_garch_future) - 1)\n",
    "\n",
    "future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=len(final_predictions[0]))\n",
    "\n",
    "# Create the DataFrame of future predictions\n",
    "df_predictions =  pd.DataFrame(final_predictions).T  # Transpose to make each array a column\n",
    "\n",
    "# Rename the index to 'Day' for clarity\n",
    "df_predictions.index = future_dates\n",
    "\n",
    "df_predictions.columns = ['Forecast Price (Case 1)', 'Forecast Price (Case 2)', 'Forecast Price (Case 3)']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
